[
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_0",
    "chunk_content": "Image"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_1",
    "chunk_content": "of  13  June  2024\nlaying down harmonised rules on artificial intelligence and amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU) 2018/858, (EU) 2018/1139 and (EU) 2019/2144 and Directives 2014/90/EU, (EU) 2016/797 and (EU) 2020/1828 (Artificial Intelligence Act)"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_2",
    "chunk_content": "(Text  with  EEA relevance)\nTHE EUROPEAN PARLIAMENT AND THE COUNCIL OF THE EUROPEAN UNION,\nHaving regard to the Treaty on the  Functioning  of  the  European  Union, and  in particular  Articles  16  and  114  thereof,\nHaving regard to the proposal  from the  European Commission,\nAfter  transmission  of  the  draft  legislative  act  to  the  national  parliaments,\nHaving regard to the opinion of  the European  Economic and Social Committee ( 1 ),\nHaving regard to the opinion of  the European  Central  Bank ( 2 ),\nHaving regard to the opinion of  the Committee of  the Regions ( 3 ),\nActing  in  accordance  with  the  ordinary  legislative  procedure ( 4 ),"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_3",
    "chunk_content": "Whereas:\n(1) The purpose of this Regulation is to improve the functioning of the internal market by laying down a uniform legal framework  in  particular  for  the  development,  the  placing  on  the  market,  the  putting  into  service  and  the  use  of artificial intelligence systems (AI systems) in the Union, in accordance with Union values, to promote the uptake of human centric and trustworthy artificial intelligence (AI) while ensuring a high level of protection of health, safety, fundamental  rights  as  enshrined  in  the  Charter  of  Fundamental  Rights  of  the  European  Union  (the  'Charter'), including  democracy,  the  rule  of  law  and  environmental  protection,  to  protect  against  the  harmful  effects  of  AI systems  in  the  Union,  and  to  support  innovation.  This  Regulation  ensures  the  free  movement,  cross-border,  of AI-based  goods  and  services,  thus  preventing  Member  States  from  imposing  restrictions  on  the  development, marketing and use of AI systems, unless  explicitly  authorised  by this  Regulation.\n(2) This Regulation should be applied in accordance with the values of the Union enshrined as in the Charter, facilitating the  protection  of  natural  persons,  undertakings,  democracy,  the  rule  of  law  and  environmental  protection,  while boosting innovation and employment and making the Union a leader  in the uptake of  trustworthy AI.\n(3) AI systems can be easily deployed in a large variety of sectors of the economy and many parts of society, including across  borders,  and  can  easily  circulate  throughout  the  Union.  Certain  Member  States  have  already  explored  the adoption of national rules to ensure that AI is trustworthy and safe and is developed and used in accordance with fundamental rights obligations. Diverging national rules may lead to the fragmentation of  the internal market and may decrease  legal  certainty  for  operators  that  develop,  import  or  use  AI  systems.  A  consistent  and  high  level  of protection throughout the Union should therefore be ensured in order to achieve trustworthy AI, while divergences hampering  the  free  circulation,  innovation,  deployment  and  the  uptake  of  AI  systems  and  related  products  and services  within  the  internal  market  should  be  prevented  by  laying  down  uniform  obligations  for  operators  and\n12.7.2024\nguaranteeing the uniform protection of overriding reasons of public interest and of rights of persons throughout the internal market on the basis of Article 114 of the Treaty on the Functioning of the European Union (TFEU). To the extent that this Regulation contains specific rules on the protection of individuals with regard to the processing of personal data concerning restrictions of the use of AI systems for remote biometric identification for the purpose of law  enforcement,  of  the  use  of  AI  systems  for  risk  assessments  of  natural  persons  for  the  purpose  of  law enforcement  and  of  the  use  of  AI  systems  of  biometric  categorisation  for  the  purpose  of  law  enforcement,  it  is appropriate to base this Regulation, in so far as those specific rules are concerned, on Article 16 TFEU. In light of those specific  rules and the recourse to Article 16 TFEU, it is appropriate to consult the European Data Protection Board.\n(4) AI is a fast evolving family of technologies that contributes to a wide array of economic, environmental and societal benefits across the entire spectrum of industries and social activities. By improving prediction, optimising operations and resource allocation, and personalising digital solutions available for individuals and organisations, the use of AI can  provide  key  competitive  advantages  to  undertakings  and  support  socially  and  environmentally  beneficial outcomes,  for  example  in  healthcare,  agriculture,  food  safety,  education  and  training,  media,  sports,  culture, infrastructure  management,  energy,  transport  and  logistics,  public  services,  security,  justice,  resource  and  energy efficiency,  environmental monitoring,  the conservation and restoration of biodiversity and ecosystems and climate change mitigation  and  adaptation.\n(5) At the same time, depending on the circumstances regarding its specific application, use, and level of technological development, AI may generate risks and cause harm to public interests and fundamental rights that are protected by Union  law.  Such  harm  might  be  material  or  immaterial,  including  physical,  psychological,  societal  or  economic harm.\n(6) Given the major impact that AI can have on society and the need to build trust, it is vital for AI and its regulatory framework to be developed in accordance with Union values as enshrined in Article 2 of  the Treaty on European Union  (TEU),  the  fundamental  rights  and  freedoms  enshrined  in  the  Treaties  and,  pursuant  to  Article  6  TEU,  the Charter. As a prerequisite, AI should be a human-centric technology. It should serve as a tool for  people, with the ultimate aim  of  increasing  human well-being.\n(7) In  order  to  ensure  a  consistent  and  high  level  of  protection  of  public  interests  as  regards  health,  safety  and fundamental rights, common rules for high-risk AI systems should be established. Those rules should be consistent with  the  Charter,  non-discriminatory  and  in  line  with  the  Union's  international  trade  commitments.  They  should also  take  into  account  the  European  Declaration  on  Digital  Rights  and  Principles  for  the  Digital  Decade  and  the Ethics  guidelines  for  trustworthy  AI  of  the  High-Level  Expert  Group  on  Artificial  Intelligence  (AI  HLEG).\n(8) A Union legal framework laying down harmonised rules on AI is therefore needed to foster  the development, use and uptake of AI in the internal market that at the same time meets a high level of protection of public interests, such as  health  and  safety  and  the  protection  of  fundamental  rights,  including  democracy,  the  rule  of  law  and environmental protection as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market, the putting into service and the use of certain AI systems should be laid down, thus ensuring the  smooth  functioning  of  the  internal  market  and  allowing  those  systems  to  benefit  from  the  principle  of  free movement  of  goods  and  services.  Those  rules  should  be  clear  and  robust  in  protecting  fundamental  rights, supportive  of  new  innovative  solutions,  enabling  a  European  ecosystem  of  public  and  private  actors  creating  AI systems in line with Union values and unlocking the potential of the digital transformation across all regions of the Union. By laying down those rules as well as measures in support of innovation with a particular focus on small and medium enterprises (SMEs), including  startups,  this  Regulation  supports  the  objective  of  promoting  the  European human-centric approach to AI and being a global leader in the development of secure, trustworthy and ethical AI as stated by the European Council ( 5 ), and it ensures the protection of ethical principles, as specifically requested by the European Parliament ( 6 ).\n(9) Harmonised  rules  applicable  to  the  placing  on  the  market,  the  putting  into  service  and  the  use  of  high-risk  AI systems should be laid down consistently with Regulation (EC) No 765/2008 of the European Parliament and of the Council ( 7 ),  Decision  No  768/2008/EC  of  the  European  Parliament  and  of  the  Council ( 8 )  and  Regulation  (EU) 2019/1020 of the European Parliament and of the Council ( 9 )  (New  Legislative  Framework). The harmonised rules laid down in this Regulation should apply across sectors and, in line with the New Legislative Framework, should be without prejudice to existing Union law, in particular on data protection, consumer protection, fundamental rights, employment,  and  protection  of  workers,  and  product  safety,  to  which  this  Regulation  is  complementary.  As a consequence, all rights and remedies provided for by such Union law to consumers, and other persons on whom AI  systems  may  have  a  negative  impact,  including  as  regards  the  compensation  of  possible  damages  pursuant  to Council  Directive  85/374/EEC ( 10 ) remain  unaffected  and  fully  applicable.  Furthermore,  in  the  context  of employment and protection of workers, this Regulation should therefore not affect Union law on social policy and national  labour  law,  in  compliance  with  Union  law,  concerning  employment  and  working  conditions,  including health  and  safety  at  work  and  the  relationship  between  employers  and  workers.  This  Regulation  should  also  not affect the exercise of fundamental rights as recognised in the Member States and at Union level, including the right or freedom to strike or to take other action covered by the specific industrial relations systems in Member States as well as  the  right  to  negotiate,  to  conclude  and  enforce  collective  agreements  or  to  take  collective  action  in  accordance with  national  law.  This  Regulation  should  not  affect  the  provisions  aiming  to  improve  working  conditions  in platform  work  laid  down  in  a  Directive  of  the  European  Parliament  and  of  the  Council  on  improving  working conditions in platform work. Moreover, this Regulation aims to strengthen the effectiveness of such existing rights and  remedies  by  establishing  specific  requirements  and  obligations,  including  in  respect  of  the  transparency, technical  documentation  and  record-keeping  of  AI  systems.  Furthermore,  the  obligations  placed  on  various operators  involved in  the  AI  value  chain  under  this  Regulation  should  apply  without  prejudice  to  national  law,  in compliance with Union law, having the effect of  limiting the use of certain AI systems where such law falls outside the  scope  of  this  Regulation  or  pursues  legitimate  public  interest  objectives  other  than  those  pursued  by  this Regulation. For example, national labour law and law on the protection of minors, namely persons below the age of 18, taking into account the UNCRC General Comment No 25 (2021) on children's rights in relation to the digital environment,  insofar  as  they  are  not  specific  to  AI  systems  and  pursue  other  legitimate  public  interest  objectives, should not  be  affected  by  this  Regulation.\n(10) The  fundamental  right  to  the  protection  of  personal  data  is  safeguarded  in  particular  by  Regulations  (EU) 2016/679 ( 11 ) and (EU) 2018/1725 ( 12 ) of the European Parliament and of the Council and Directive (EU) 2016/680 of  the  European  Parliament  and  of  the  Council ( 13 ).  Directive  2002/58/EC  of  the  European  Parliament  and  of  the Council ( 14 )  additionally  protects  private  life  and  the  confidentiality  of  communications,  including  by  way  of providing  conditions  for  any  storing  of  personal  and  non-personal  data  in,  and  access  from,  terminal  equipment. Those Union legal acts provide the basis for sustainable and responsible data processing, including where data sets include a mix of personal and non-personal data. This Regulation does not seek to affect the application of existing Union law governing the processing of personal data, including the tasks and powers of the independent supervisory authorities  competent  to  monitor  compliance  with  those  instruments.  It  also  does  not  affect  the  obligations  of providers  and  deployers  of  AI  systems  in  their  role  as  data  controllers  or  processors  stemming  from  Union  or national  law on  the  protection  of  personal  data  in  so  far  as  the  design,  the  development  or  the  use  of  AI  systems involves the processing of personal data. It is also appropriate to clarify that data subjects continue to enjoy all the\n( 7 ) Regulation  (EC)  No  765/2008  of  the  European  Parliament  and  of  the  Council  of  9  July  2008  setting  out  the  requirements  for accreditation  and  repealing  Regulation  (EEC)  No  339/93  (OJ  L  218,  13.8.2008,  p.  30).\n( 8 ) Decision  No  768/2008/EC  of  the  European  Parliament  and  of  the  Council  of  9  July  2008  on  a  common  framework  for  the marketing  of  products,  and  repealing  Council  Decision  93/465/EEC  (OJ  L  218,  13.8.2008,  p.  82).\n( 9 ) Regulation (EU) 2019/1020 of the European Parliament and of the Council of 20 June 2019 on market surveillance and compliance of products and amending Directive 2004/42/EC and Regulations (EC) No 765/2008 and (EU) No 305/2011 (OJ L 169, 25.6.2019, p.  1).\n( 10 ) Council Directive 85/374/EEC of 25 July 1985 on the approximation of the laws, regulations and administrative provisions of the Member States concerning liability  for  defective  products  (OJ  L  210,  7.8.1985,  p.  29).\n( 11 ) Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation)  (OJ  L  119,  4.5.2016,  p.  1).\n( 12 ) Regulation  (EU)  2018/1725  of  the  European  Parliament  and  of  the  Council  of  23  October  2018  on  the  protection  of  natural persons  with  regard  to  the  processing  of  personal  data  by  the  Union  institutions,  bodies,  offices  and  agencies  and  on  the  free movement of such data, and repealing Regulation (EC) No 45/2001 and Decision No 1247/2002/EC (OJ L 295, 21.11.2018, p. 39).\n( 13 ) Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard  to  the  processing  of  personal  data  by competent  authorities  for  the  purposes  of  the  prevention,  investigation,  detection or prosecution  of  criminal  offences  or  the  execution  of  criminal  penalties,  and  on  the  free  movement  of  such  data,  and  repealing Council Framework Decision 2008/977/JHA (OJ L 119, 4.5.2016, p. 89).\n( 14 ) Directive 2002/58/EC of the European Parliament and of the Council of 12 July 2002 concerning the processing of personal data and  the  protection  of  privacy  in  the  electronic  communications  sector  (Directive  on  privacy  and  electronic  communications)  (OJ L  201,  31.7.2002,  p.  37).\nrights and guarantees awarded to them by such Union law, including the rights related to solely automated individual decision-making, including profiling. Harmonised rules for  the placing on the market, the putting into service and the use of AI systems established under this Regulation should facilitate the effective implementation and enable the exercise of  the data  subjects'  rights  and  other  remedies  guaranteed under Union law on the protection of personal data  and  of other  fundamental  rights.\n(11) This  Regulation  should  be  without  prejudice  to  the  provisions  regarding  the  liability  of  providers  of  intermediary services  as  set  out  in  Regulation  (EU)  2022/2065  of  the  European  Parliament  and  of  the  Council ( 15 ).\n(12) The notion of 'AI system' in this Regulation should be clearly defined and should be closely aligned with the work of international  organisations  working  on  AI  to  ensure  legal  certainty,  facilitate  international  convergence  and  wide acceptance,  while  providing  the  flexibility  to  accommodate  the  rapid  technological  developments  in  this  field. Moreover,  the  definition  should  be  based  on  key  characteristics  of  AI  systems  that  distinguish  it  from  simpler traditional software systems or programming approaches and should not cover systems that are based on the rules defined  solely  by  natural  persons  to  automatically  execute  operations.  A  key  characteristic  of  AI  systems  is  their capability to infer. This capability to infer refers to the process of obtaining the outputs, such as predictions, content, recommendations,  or  decisions,  which  can  influence  physical  and  virtual  environments,  and  to  a  capability  of  AI systems  to  derive  models  or  algorithms,  or  both,  from  inputs  or  data.  The  techniques  that  enable  inference  while building an AI system include machine learning approaches that learn from data how to achieve certain objectives, and logic- and knowledge-based approaches that infer from encoded knowledge or symbolic representation of  the task  to  be  solved.  The  capacity  of  an  AI  system  to  infer  transcends  basic  data  processing  by  enabling  learning, reasoning or modelling. The term 'machine-based' refers to the fact that AI systems run on machines. The reference to explicit or implicit objectives underscores that AI systems can operate according to explicit defined objectives or to implicit objectives. The objectives of the AI system may be different from the intended purpose of the AI system in a specific context. For the purposes of this Regulation, environments should be understood to be the contexts in which the AI systems operate, whereas outputs generated by the AI system reflect different functions performed by AI systems and include predictions, content, recommendations or decisions. AI systems are designed to operate with varying  levels  of  autonomy,  meaning  that  they  have  some  degree  of  independence  of  actions  from  human involvement and of capabilities to operate without human intervention. The adaptiveness that an AI system could exhibit after deployment, refers to self-learning capabilities, allowing the system to change while in use. AI systems can be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serves the functionality of  the product without being integrated therein (non-embedded).\n(13) The notion of 'deployer' referred to in this Regulation should be interpreted as any natural or legal person, including a public authority, agency or other body, using an AI system under its authority, except where the AI system is used in the course of a personal non-professional activity. Depending on the type of AI system, the use of the system may affect  persons  other  than  the  deployer.\n(14) The notion of 'biometric data' used in this Regulation should be interpreted in light of the notion of biometric data as defined in Article 4, point (14) of Regulation (EU) 2016/679, Article 3, point (18) of Regulation (EU) 2018/1725 and Article 3, point (13) of Directive (EU) 2016/680. Biometric data can allow for the authentication, identification or  categorisation  of  natural  persons  and  for  the  recognition  of  emotions  of  natural  persons.\n(15) The notion of 'biometric identification' referred to in this Regulation should be defined as the automated recognition of  physical,  physiological  and  behavioural  human  features  such  as  the  face,  eye  movement,  body  shape,  voice, prosody, gait, posture, heart rate, blood pressure, odour, keystrokes characteristics, for the purpose of establishing an individual's  identity  by  comparing  biometric  data  of  that  individual  to  stored  biometric  data  of  individuals  in a  reference  database,  irrespective  of  whether  the  individual  has  given  its  consent  or  not.  This  excludes  AI  systems intended to be used for biometric verification, which includes authentication, whose sole purpose is to confirm that a specific natural person is the person he or she claims to be and to confirm the identity of a natural person for the sole  purpose  of  having  access  to  a  service,  unlocking  a  device  or  having  security  access  to  premises.\n(16) The notion of 'biometric categorisation' referred to in this Regulation should be defined as assigning natural persons to specific categories on the basis of their biometric data. Such specific categories can relate to aspects such as sex, age,  hair  colour,  eye colour, tattoos, behavioural or  personality traits, language, religion, membership of a national minority,  sexual  or  political  orientation.  This  does  not  include  biometric  categorisation  systems  that  are  a  purely ancillary  feature  intrinsically  linked  to  another  commercial  service,  meaning  that  the  feature  cannot,  for  objective technical  reasons,  be  used  without  the  principal  service,  and  the  integration  of  that  feature  or  functionality  is  not a means to circumvent the applicability of the rules of this Regulation. For example, filters categorising facial or body features used on online marketplaces could constitute such an ancillary feature as they can be used only in relation to the  principal  service  which  consists  in  selling  a  product  by  allowing  the  consumer  to  preview  the  display  of  the product on him or herself and help the consumer to make a purchase decision. Filters used on online social network services  which  categorise  facial  or  body  features  to  allow  users  to  add  or  modify  pictures  or  videos  could  also  be considered to be ancillary feature  as such filter  cannot  be  used  without  the  principal  service of  the  social  network services  consisting  in  the  sharing  of  content  online.\n(17) The notion of 'remote biometric identification system' referred to in this Regulation should be defined functionally, as  an  AI  system  intended  for  the  identification  of  natural  persons  without  their  active  involvement,  typically  at a  distance,  through  the  comparison  of  a  person's  biometric  data  with  the  biometric  data  contained  in  a  reference database,  irrespectively  of  the  particular  technology,  processes  or  types  of  biometric  data  used.  Such  remote biometric identification systems are typically used to perceive multiple persons or their behaviour simultaneously in order  to  facilitate significantly  the  identification  of  natural  persons  without their  active involvement.  This excludes AI systems intended to be used for biometric verification, which includes authentication, the sole purpose of which is  to  confirm  that  a  specific  natural  person  is  the  person  he  or  she  claims  to  be  and  to  confirm  the  identity  of a  natural person for  the sole purpose of having access to a service, unlocking a device or having security access to premises. That exclusion is justified by the fact that such systems are likely to have a minor impact on fundamental rights  of  natural  persons  compared  to  the  remote  biometric  identification  systems  which  may  be  used  for  the processing  of  the  biometric  data  of  a  large  number  of  persons  without  their  active  involvement.  In  the  case  of 'real-time'  systems,  the  capturing  of  the  biometric  data,  the  comparison  and  the  identification  occur  all instantaneously, near-instantaneously or in any event without a significant delay. In this regard, there should be no scope for circumventing the rules of this Regulation on the 'real-time' use of the AI systems concerned by providing for minor delays. 'Real-time' systems involve the use of 'live' or 'near-live' material, such as video footage, generated by a camera or other device with similar functionality. In the case of 'post' systems, in contrast, the biometric data has already been captured and the comparison and identification occur only after a significant delay. This involves material, such as pictures or  video footage generated by closed circuit television cameras or  private devices, which has  been  generated  before  the  use  of  the  system  in  respect  of  the  natural  persons  concerned.\n(18) The notion of 'emotion recognition system' referred to in this Regulation should be defined as an AI system for the purpose of identifying or  inferring emotions or  intentions of  natural persons on  the basis of  their  biometric data. The  notion  refers  to  emotions  or  intentions  such  as  happiness,  sadness,  anger,  surprise,  disgust,  embarrassment, excitement,  shame,  contempt,  satisfaction  and  amusement.  It  does  not  include  physical  states,  such  as  pain  or fatigue, including, for example, systems used in detecting the state of fatigue of professional pilots or drivers for the purpose  of  preventing  accidents.  This  does  also  not  include  the  mere  detection  of  readily  apparent  expressions, gestures or  movements, unless they are used for  identifying or  inferring emotions. Those expressions can be basic facial  expressions,  such  as  a  frown  or  a  smile,  or  gestures  such  as  the  movement  of  hands,  arms  or  head,  or characteristics  of  a  person's  voice,  such  as  a  raised  voice  or  whispering.\n(19) For the purposes of this Regulation the notion of 'publicly accessible space' should be understood as referring to any physical  space  that  is  accessible  to  an  undetermined  number  of  natural  persons,  and  irrespective  of  whether  the space in question is privately or publicly owned, irrespective of the activity for which the space may be used, such as for  commerce,  for  example,  shops,  restaurants,  cafés;  for  services,  for  example,  banks,  professional  activities, hospitality;  for  sport,  for  example,  swimming  pools,  gyms,  stadiums;  for  transport,  for  example,  bus,  metro  and railway stations, airports, means of transport; for entertainment, for example, cinemas, theatres, museums, concert and conference halls; or for leisure or otherwise, for example, public roads and squares, parks, forests, playgrounds. A  space  should  also  be  classified  as  being  publicly  accessible  if,  regardless  of  potential  capacity  or  security restrictions, access is subject to certain predetermined conditions which can be fulfilled by an undetermined number of persons, such as the purchase of a ticket or title of transport, prior registration or having a certain age. In contrast, a space should not be considered to be publicly accessible if access is limited to specific and defined natural persons through either Union or national law directly related to public safety or security or through the clear manifestation\nof will by the person having the relevant authority over the space. The factual possibility of access alone, such as an unlocked door  or  an  open  gate  in  a  fence,  does  not  imply  that  the  space  is  publicly  accessible  in  the  presence  of indications or circumstances suggesting the contrary, such as. signs prohibiting or restricting access. Company and factory premises, as well as offices and workplaces that are intended to be accessed only by relevant employees and service providers, are spaces that are not publicly accessible. Publicly accessible spaces should not include prisons or border control. Some other spaces may comprise both publicly accessible and non-publicly accessible spaces, such as the hallway of a private residential building necessary to access a doctor's office or an airport. Online spaces are not covered,  as  they  are  not  physical  spaces.  Whether  a  given  space  is  accessible  to  the  public  should  however  be determined on a case-by-case  basis,  having regard to the  specificities  of  the  individual  situation  at  hand.\n(20) In order to obtain the greatest benefits from AI systems while protecting fundamental rights, health and safety and to enable  democratic  control,  AI  literacy  should  equip  providers,  deployers  and  affected  persons  with  the  necessary notions  to  make  informed  decisions  regarding  AI  systems.  Those  notions  may  vary  with  regard  to  the  relevant context  and  can  include  understanding  the  correct  application  of  technical  elements  during  the  AI  system's development phase, the measures to be applied during its use, the suitable ways in which to interpret the AI system's output, and,  in  the  case  of  affected  persons,  the  knowledge  necessary  to  understand  how decisions  taken with  the assistance  of  AI  will  have  an  impact  on  them.  In  the  context of  the  application  this  Regulation,  AI  literacy  should provide all relevant actors in the AI value chain with the insights required to ensure the appropriate compliance and its  correct  enforcement.  Furthermore,  the  wide  implementation  of  AI  literacy  measures  and  the  introduction  of appropriate  follow-up  actions  could  contribute  to  improving  working  conditions  and  ultimately  sustain  the consolidation, and innovation path of trustworthy AI in the Union. The European Artificial Intelligence Board (the 'Board')  should  support  the  Commission,  to promote  AI  literacy  tools,  public  awareness  and  understanding  of  the benefits, risks, safeguards, rights and obligations in relation to the use of AI systems. In cooperation with the relevant stakeholders, the Commission and the Member States should facilitate the drawing up of voluntary codes of conduct to  advance  AI  literacy  among  persons  dealing  with  the  development,  operation  and  use  of  AI.\n(21) In  order  to ensure  a  level  playing  field  and  an  effective  protection  of  rights  and  freedoms  of  individuals  across  the Union,  the  rules  established  by  this  Regulation  should  apply  to  providers  of  AI  systems  in  a  non-discriminatory manner, irrespective of whether they are established within the Union or in a third country, and to deployers of AI systems  established  within  the  Union.\n(22) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are not placed on the market, put into service, or  used in the Union. This is the case, for example, where an operator established  in  the  Union  contracts  certain  services  to  an  operator  established  in  a  third  country  in  relation  to  an activity to be performed by an AI system that would qualify as high-risk. In those circumstances, the AI system used in  a  third  country  by  the  operator  could  process  data  lawfully  collected  in  and  transferred  from  the  Union,  and provide  to  the  contracting  operator  in  the  Union  the  output  of  that  AI  system  resulting  from  that  processing, without  that  AI  system  being  placed  on  the  market,  put  into  service  or  used  in  the  Union.  To  prevent  the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and deployers of AI systems that are established in a third country, to the extent the output produced by those systems is intended to be used in the Union. Nonetheless, to take into account existing arrangements and special needs for  future cooperation with foreign partners with whom information and evidence  is  exchanged,  this  Regulation  should  not  apply  to  public  authorities  of  a  third  country  and  international organisations  when  acting  in  the  framework  of  cooperation  or  international  agreements  concluded  at  Union  or national level for law enforcement and judicial cooperation with the Union or the Member States, provided that the relevant third country or  international organisation provides adequate safeguards with respect to the protection of fundamental rights and freedoms of individuals. Where relevant, this may cover activities of entities entrusted by the third  countries  to  carry  out  specific  tasks  in  support  of  such  law  enforcement  and  judicial  cooperation.  Such framework  for  cooperation  or  agreements  have  been  established  bilaterally  between  Member  States  and  third countries or between the European Union, Europol and other Union agencies and third countries and international organisations. The authorities competent for supervision of the law enforcement and judicial authorities under this Regulation should assess whether  those frameworks  for cooperation or  international agreements include adequate safeguards  with  respect  to  the  protection  of  fundamental  rights  and  freedoms  of  individuals.  Recipient  national"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_4",
    "chunk_content": "Whereas:\nauthorities  and  Union  institutions,  bodies,  offices  and  agencies  making  use  of  such  outputs  in  the  Union  remain accountable to ensure their use complies with Union law. When those international agreements are revised or new ones are concluded in the future, the contracting parties should make utmost efforts to align those agreements with the  requirements  of  this  Regulation.\n(23) This Regulation should also apply to Union institutions, bodies, offices and agencies when acting as a provider or deployer  of  an  AI  system.\n(24) If, and insofar as, AI systems are placed on the market, put into service, or used with or without modification of such systems  for  military,  defence  or  national  security  purposes,  those  should  be  excluded  from  the  scope  of  this Regulation regardless of which type of entity is carrying out those activities, such as whether it is a public or private entity.  As  regards  military  and  defence  purposes,  such  exclusion  is  justified  both  by  Article  4(2)  TEU  and  by  the specificities of the Member States' and the common Union defence policy covered by Chapter 2 of Title V TEU that are subject to public international law, which is therefore the more appropriate legal framework for the regulation of AI  systems  in  the  context  of  the  use  of  lethal  force  and  other  AI  systems  in  the  context  of  military  and  defence activities.  As  regards  national  security  purposes,  the  exclusion  is  justified  both  by  the  fact  that  national  security remains the sole responsibility of Member States in accordance with Article 4(2) TEU and by the specific nature and operational needs of national security activities and specific national rules applicable to those activities. Nonetheless, if  an  AI  system developed, placed on the market, put into service or  used for  military, defence or  national security purposes is used outside those temporarily or permanently for other purposes, for example, civilian or humanitarian purposes, law enforcement or public security purposes, such a system would fall within the scope of this Regulation. In  that  case,  the  entity  using  the  AI  system  for  other  than  military,  defence  or  national  security  purposes  should ensure  the  compliance  of  the  AI  system  with  this  Regulation,  unless  the  system  is  already  compliant  with  this Regulation. AI systems placed on the market or put into service for an excluded purpose, namely military, defence or national security, and one or more non-excluded purposes, such as civilian purposes or law enforcement, fall within the scope of this Regulation and providers of those systems should ensure compliance with this Regulation. In those cases,  the  fact  that  an  AI  system  may  fall  within  the  scope  of  this  Regulation  should  not  affect  the  possibility  of entities  carrying  out  national  security,  defence  and  military  activities,  regardless  of  the  type  of  entity  carrying  out those activities, to use AI systems for national security, military and defence purposes, the use of which is excluded from  the  scope  of  this  Regulation.  An  AI  system  placed  on  the  market  for  civilian  or  law  enforcement  purposes which is used with or without modification for military, defence or national security purposes should not fall within the  scope  of  this  Regulation,  regardless  of  the  type  of  entity  carrying  out  those  activities.\n(25) This Regulation should support innovation, should respect freedom of science, and should not undermine research and  development  activity.  It  is  therefore  necessary  to  exclude  from  its  scope  AI  systems  and  models  specifically developed and put into service for the sole purpose of scientific research and development. Moreover, it is necessary to ensure that this Regulation does not otherwise affect scientific research and development activity on AI systems or models prior  to being  placed  on  the  market or  put  into service.  As  regards  product-oriented  research, testing and development activity regarding AI systems or models, the provisions of this Regulation should also not apply prior to those systems and models being put into service or placed on the market. That exclusion is without prejudice to the obligation to comply with this Regulation where an AI system falling into the scope of this Regulation is placed on  the  market  or  put  into  service  as  a  result  of  such  research  and  development  activity  and  to  the  application  of provisions on AI regulatory sandboxes and testing in real world conditions. Furthermore, without prejudice to the exclusion  of  AI  systems  specifically  developed  and  put  into  service  for  the  sole  purpose  of  scientific  research  and development, any other AI system that may be used for the conduct of any research and development activity should remain subject to the provisions of this Regulation. In any event, any research and development activity should be carried  out  in  accordance  with  recognised  ethical  and  professional  standards  for  scientific  research  and  should  be conducted in accordance with applicable Union law.\n(26) In  order  to introduce a proportionate and effective set of binding rules for AI systems, a clearly defined  risk-based approach should be followed. That approach should tailor  the type and content of such rules to the intensity and scope of the risks that AI systems can generate. It is therefore necessary to prohibit certain unacceptable AI practices, to  lay  down  requirements  for  high-risk  AI  systems  and  obligations  for  the  relevant  operators,  and  to  lay  down transparency obligations for  certain  AI  systems.\n(27) While the risk-based approach is the basis for a proportionate and effective set of binding rules, it is important to recall  the  2019  Ethics  guidelines  for  trustworthy  AI  developed  by  the  independent  AI  HLEG  appointed  by  the Commission.  In  those  guidelines,  the  AI  HLEG  developed  seven  non-binding  ethical  principles  for  AI  which  are intended to help ensure that AI is trustworthy and ethically sound. The seven principles include human agency and oversight; technical robustness and safety; privacy and data governance; transparency; diversity, non-discrimination and  fairness;  societal  and  environmental  well-being  and  accountability.  Without  prejudice  to  the  legally  binding requirements  of  this  Regulation  and  any  other  applicable  Union  law,  those  guidelines  contribute  to  the  design  of coherent,  trustworthy  and  human-centric  AI,  in  line  with  the  Charter  and  with  the  values  on  which  the  Union  is founded.  According  to  the  guidelines  of  the  AI  HLEG,  human  agency  and  oversight  means  that  AI  systems  are developed  and  used  as  a  tool  that  serves  people,  respects  human  dignity  and  personal  autonomy,  and  that  is functioning in a way that can be appropriately controlled and overseen by humans. Technical robustness and safety means that AI systems are developed and used in a way that allows robustness in the case of problems and resilience against attempts to alter  the use or  performance of  the AI system so as to allow unlawful use by third parties, and minimise  unintended  harm.  Privacy  and  data  governance  means  that  AI  systems  are  developed  and  used  in accordance  with  privacy  and  data  protection  rules,  while  processing  data  that  meets  high  standards  in  terms  of quality and integrity. Transparency means that AI systems are developed and used in a way that allows appropriate traceability and explainability, while making humans aware that they communicate or interact with an AI system, as well as duly informing deployers of the capabilities and limitations of that AI system and affected persons about their rights.  Diversity,  non-discrimination  and  fairness  means  that  AI  systems  are  developed  and  used  in  a  way  that includes  diverse  actors  and  promotes  equal  access,  gender  equality  and  cultural  diversity,  while  avoiding discriminatory  impacts  and  unfair  biases  that  are  prohibited  by  Union  or  national  law.  Social  and  environmental well-being means that AI systems are developed and used in a sustainable and environmentally friendly manner as well  as  in  a  way  to  benefit  all  human  beings,  while  monitoring  and  assessing  the  long-term  impacts  on  the individual,  society  and  democracy.  The  application  of  those  principles  should  be  translated,  when  possible,  in  the design and use of AI models. They should in any case serve as a basis for the drafting of codes of conduct under this Regulation.  All  stakeholders,  including  industry,  academia,  civil  society  and  standardisation  organisations,  are encouraged  to  take  into  account,  as  appropriate,  the  ethical  principles  for  the  development  of  voluntary  best practices  and  standards.\n(28) Aside  from  the  many  beneficial  uses  of  AI,  it  can  also  be  misused  and  provide  novel  and  powerful  tools  for manipulative,  exploitative  and  social  control  practices.  Such  practices  are  particularly  harmful  and  abusive  and should  be  prohibited  because  they  contradict  Union  values  of  respect  for  human  dignity,  freedom,  equality, democracy  and  the  rule  of  law  and  fundamental  rights  enshrined  in  the  Charter,  including  the  right  to non-discrimination,  to data  protection  and  to  privacy  and  the  rights  of  the  child.\n(29) AI-enabled  manipulative  techniques  can  be  used  to  persuade  persons  to  engage  in  unwanted  behaviours,  or  to deceive them by nudging them into decisions in a way that subverts and impairs their autonomy, decision-making and  free  choices.  The  placing  on  the  market,  the  putting  into  service  or  the  use  of  certain  AI  systems  with  the objective to or  the effect of materially distorting human behaviour, whereby significant harms, in particular having sufficiently important adverse impacts on physical, psychological health or financial interests are likely to occur, are particularly dangerous and should therefore be prohibited. Such AI systems deploy subliminal components such as audio,  image, video  stimuli  that  persons  cannot  perceive,  as  those  stimuli  are  beyond  human  perception,  or  other manipulative or deceptive techniques that subvert or  impair  person's autonomy, decision-making or free choice in ways  that  people  are  not  consciously  aware  of  those  techniques  or,  where  they  are  aware  of  them,  can  still  be deceived or are not able to control or resist them. This could be facilitated, for example, by machine-brain interfaces or virtual reality as they allow for a higher degree of control of what stimuli are presented to persons, insofar as they may materially distort their behaviour in a significantly harmful manner. In addition, AI systems may also otherwise exploit the vulnerabilities of a person or a specific group of persons due to their age, disability within the meaning of Directive  (EU)  2019/882  of  the  European  Parliament  and  of  the  Council ( 16 ),  or  a  specific  social  or  economic situation  that  is  likely  to  make  those  persons  more  vulnerable  to  exploitation  such  as  persons  living  in  extreme poverty, ethnic or religious minorities. Such AI systems can be placed on the market, put into service or used with the  objective  to  or  the  effect  of  materially  distorting  the  behaviour  of  a  person  and  in  a  manner  that  causes  or  is reasonably likely to cause significant harm to that or another person or groups of persons, including harms that may be  accumulated  over  time  and  should  therefore  be  prohibited.  It  may  not  be  possible  to  assume  that  there  is  an\nintention to distort behaviour  where the distortion results from factors external to the AI system which are outside the control of the provider or the deployer, namely factors that may not be reasonably foreseeable and therefore not possible for the provider or the deployer of the AI system to mitigate. In any case, it is not necessary for the provider or  the  deployer  to  have  the  intention  to  cause  significant  harm,  provided  that  such  harm  results  from  the manipulative or exploitative AI-enabled practices. The prohibitions for such AI practices are complementary to the provisions contained in Directive 2005/29/EC of the European Parliament and of the Council ( 17 ), in particular unfair commercial practices leading to economic or financial harms to consumers are prohibited under all circumstances, irrespective of whether they are put in place through AI systems or otherwise. The prohibitions of manipulative and exploitative practices in this Regulation should not affect lawful practices in the context of medical treatment such as psychological  treatment  of  a  mental  disease  or  physical  rehabilitation,  when  those  practices  are  carried  out  in accordance with the applicable law and medical standards, for example explicit consent of  the individuals or  their legal  representatives.  In  addition,  common  and  legitimate  commercial  practices,  for  example  in  the  field  of advertising,  that  comply  with  the  applicable  law  should  not,  in  themselves,  be  regarded  as  constituting  harmful manipulative AI-enabled  practices.\n(30) Biometric categorisation  systems  that  are  based  on  natural  persons'  biometric  data,  such  as  an  individual  person's face  or  fingerprint,  to  deduce  or  infer  an  individuals'  political  opinions,  trade  union  membership,  religious  or philosophical beliefs, race, sex life or sexual orientation should be prohibited. That prohibition should not cover the lawful  labelling,  filtering  or  categorisation  of  biometric  data  sets  acquired  in  line  with  Union  or  national  law according  to  biometric  data,  such  as  the  sorting  of  images  according  to  hair  colour  or  eye  colour,  which  can  for example be used in the area of  law enforcement.\n(31) AI  systems  providing  social  scoring  of  natural  persons  by  public  or  private  actors  may  lead  to  discriminatory outcomes and the exclusion of certain groups. They may violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify natural persons or groups thereof on the basis of multiple data points related to their social behaviour in multiple contexts or known, inferred or predicted personal or personality characteristics over certain periods of time. The social score obtained from such AI systems may lead to  the  detrimental or  unfavourable treatment of natural persons or  whole groups thereof in social contexts, which are unrelated to the context in which the data was originally generated or collected or to a detrimental treatment that is  disproportionate  or  unjustified  to  the  gravity  of  their  social  behaviour.  AI  systems  entailing  such  unacceptable scoring  practices  and  leading  to  such  detrimental  or  unfavourable  outcomes  should  therefore  be  prohibited.  That prohibition should not affect lawful evaluation practices of natural persons that are carried out for a specific purpose in  accordance  with  Union  and  national  law.\n(32) The use of AI systems for 'real-time' remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement is particularly intrusive to the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. Such possible biased results and discriminatory effects are particularly relevant with regard to age,  ethnicity,  race,  sex  or  disabilities.  In  addition,  the  immediacy  of  the  impact  and  the  limited  opportunities  for further checks or corrections in relation to the use of such systems operating in real-time carry heightened risks for the  rights  and  freedoms  of  the  persons  concerned  in  the  context  of,  or  impacted  by,  law  enforcement  activities.\n(33) The use of those systems for the purpose of  law enforcement should therefore be prohibited, except in exhaustively listed and narrowly defined situations, where the use is strictly necessary to achieve a substantial public interest, the importance of which outweighs the risks. Those situations involve the search for certain victims of crime including missing persons; certain threats to the life or to the physical safety of natural persons or of a terrorist attack; and the localisation or identification of perpetrators or suspects of the criminal offences listed in an annex to this Regulation, where those criminal offences are punishable in the Member State concerned by a custodial sentence or a detention\norder  for  a  maximum  period  of  at  least  four  years  and  as  they  are  defined  in  the  law  of  that  Member  State.  Such a  threshold  for  the  custodial  sentence  or  detention  order  in  accordance  with  national  law  contributes  to  ensuring that the offence should be serious enough to potentially justify the use of 'real-time' remote biometric identification systems. Moreover, the list of criminal offences provided in an annex to this Regulation is based on the 32 criminal offences  listed  in  the  Council  Framework  Decision  2002/584/JHA ( 18 ),  taking  into  account  that  some  of  those offences are, in practice, likely to be more relevant than others, in that the recourse to 'real-time' remote biometric identification could, foreseeably, be necessary and proportionate to highly varying degrees for  the practical pursuit of  the  localisation  or  identification  of  a  perpetrator  or  suspect  of  the  different  criminal  offences  listed  and  having regard  to  the  likely  differences  in  the  seriousness,  probability  and  scale  of  the  harm  or  possible  negative consequences. An imminent threat to life or  the physical safety of natural persons could also result from a serious disruption of critical infrastructure, as defined in Article 2, point (4) of Directive (EU) 2022/2557 of the European Parliament and of the Council ( 19 ), where the disruption or destruction of such critical infrastructure would result in an imminent threat to life or the physical safety of a person, including through serious harm to the provision of basic supplies  to  the  population  or  to  the  exercise  of  the  core  function  of  the  State.  In  addition,  this  Regulation  should preserve  the  ability  for  law  enforcement,  border  control,  immigration  or  asylum  authorities  to  carry  out  identity checks in the presence of the person concerned in accordance with the conditions set out in Union and national law for such checks. In particular, law enforcement, border control, immigration or asylum authorities should be able to use  information  systems,  in  accordance  with  Union  or  national  law,  to  identify  persons  who,  during  an  identity check,  either  refuse  to  be  identified  or  are  unable  to  state  or  prove  their  identity,  without  being  required  by  this Regulation to obtain prior authorisation. This could be, for example, a person involved in a crime, being unwilling, or  unable  due  to  an  accident  or  a  medical  condition,  to  disclose  their  identity  to  law  enforcement  authorities.\n(34) In  order  to  ensure  that  those  systems  are  used  in  a  responsible  and  proportionate  manner,  it  is  also  important  to establish that, in each of those exhaustively listed and narrowly defined situations, certain elements should be taken into account, in particular as regards the nature of  the situation giving rise to the request and the consequences of the use for the rights and freedoms of all persons concerned and the safeguards and conditions provided for with the use.  In  addition,  the  use  of  'real-time'  remote  biometric  identification  systems  in  publicly  accessible  spaces  for  the purpose of  law  enforcement should be  deployed  only to confirm  the  specifically  targeted individual's  identity  and should be limited to what is strictly necessary concerning the period of time, as well as the geographic and personal scope, having regard in particular to the evidence or indications regarding the threats, the victims or perpetrator. The use of the real-time remote biometric identification system in publicly accessible spaces should be authorised only if the relevant law enforcement authority has completed a fundamental rights impact assessment and, unless provided otherwise  in  this  Regulation,  has  registered  the  system  in  the  database  as  set  out  in  this  Regulation.  The  reference database  of  persons  should  be  appropriate  for  each  use  case  in  each  of  the  situations  mentioned  above.\n(35) Each use of a 'real-time' remote biometric identification system in publicly accessible spaces for the purpose of  law enforcement should be subject to an express and specific authorisation by a judicial authority or by an independent administrative  authority of  a  Member  State  whose  decision  is  binding.  Such  authorisation  should,  in  principle,  be obtained prior  to the use  of  the  AI  system with  a view  to identifying  a  person  or  persons.  Exceptions to  that  rule should be allowed in duly justified situations on grounds of urgency, namely in situations where the need to use the systems  concerned  is  such  as  to  make  it  effectively  and  objectively  impossible  to  obtain  an  authorisation  before commencing the use of the AI system. In such situations of urgency, the use of the AI system should be restricted to the absolute minimum necessary and should be subject to appropriate safeguards and conditions, as determined in national law and specified in the context of each individual urgent use case by the law enforcement authority itself. In addition, the law enforcement authority should in such situations request such authorisation while providing the reasons for not having been able to request it earlier, without undue delay and at the latest within 24 hours. If such an authorisation is rejected, the use of real-time biometric identification systems linked to that authorisation should cease with immediate effect and all the data related to such use should be discarded and deleted. Such data includes\ninput data directly acquired by an AI system in the course of the use of such system as well as the results and outputs of the use linked to that authorisation. It should not include input that is legally acquired in accordance with another Union or national law. In any case, no decision producing an adverse legal effect on a person should be taken based solely on  the  output  of  the  remote  biometric  identification  system.\n(36) In order to carry out their tasks in accordance with the requirements set out in this Regulation as well as in national rules, the relevant market surveillance authority and the national data protection authority should be notified of each use of the real-time biometric identification system. Market surveillance authorities and the national data protection authorities  that  have  been  notified  should  submit  to  the  Commission  an  annual  report  on  the  use  of  real-time biometric  identification  systems.\n(37) Furthermore, it is appropriate to provide, within the exhaustive framework set by this Regulation that such use in the territory of a Member State in accordance with this Regulation should only be possible where and in as far as the Member State concerned has decided to expressly provide for the possibility to authorise such use in its detailed rules of national law. Consequently, Member States remain free under this Regulation not to provide for such a possibility at all or to only provide for such a possibility in respect of some of the objectives capable of justifying authorised use identified  in  this  Regulation.  Such  national  rules  should  be  notified  to  the  Commission  within  30  days  of  their adoption.\n(38) The use of AI systems for real-time remote biometric identification of natural persons in publicly accessible spaces for  the  purpose  of  law  enforcement  necessarily  involves  the  processing  of  biometric  data.  The  rules  of  this Regulation that prohibit, subject to certain exceptions, such use, which are based on Article 16 TFEU, should apply as lex  specialis in  respect of  the  rules  on  the  processing  of  biometric  data  contained  in  Article  10  of  Directive  (EU) 2016/680,  thus  regulating  such  use  and  the  processing  of  biometric  data  involved  in  an  exhaustive  manner. Therefore, such use and processing should be possible only in as far as it is compatible with the framework set by this Regulation, without there being scope, outside that framework, for the competent authorities, where they act for purpose of law enforcement, to use such systems and process such data in connection thereto on the grounds listed in Article 10 of Directive (EU) 2016/680. In that context, this Regulation is not intended to provide the legal basis for the processing of personal data under Article 8 of Directive (EU) 2016/680. However, the use of real-time remote biometric identification systems in publicly accessible spaces for purposes other than law enforcement, including by competent authorities, should not be covered by the specific framework regarding such use for the purpose of  law enforcement  set  by  this  Regulation.  Such  use  for  purposes  other  than  law  enforcement  should  therefore  not  be subject to the requirement of an authorisation under this Regulation and the applicable detailed rules of national law that  may  give  effect  to  that  authorisation.\n(39) Any  processing  of  biometric  data  and  other  personal  data  involved  in  the  use  of  AI  systems  for  biometric identification,  other  than  in  connection  to the  use  of  real-time  remote  biometric  identification  systems  in publicly accessible  spaces  for  the  purpose  of  law  enforcement  as  regulated  by  this  Regulation,  should  continue  to  comply with  all  requirements  resulting  from  Article  10  of  Directive  (EU)  2016/680.  For  purposes  other  than  law enforcement, Article 9(1) of Regulation (EU) 2016/679 and Article 10(1) of Regulation (EU) 2018/1725 prohibit the processing of biometric data subject to limited exceptions as provided in those Articles. In the application of Article 9(1)  of  Regulation  (EU)  2016/679,  the  use  of  remote  biometric  identification  for  purposes  other  than  law enforcement has already been subject  to prohibition  decisions  by national  data  protection  authorities.\n(40) In accordance with Article 6a of Protocol No 21 on the position of the United Kingdom and Ireland in respect of the area of freedom, security and justice, as annexed to the TEU and to the TFEU, Ireland is not bound by the rules laid down  in  Article  5(1),  first  subparagraph,  point  (g),  to  the  extent  it  applies  to  the  use  of  biometric  categorisation systems for activities in the field of police cooperation and judicial cooperation in criminal matters, Article 5(1), first subparagraph, point (d), to the extent it applies to the use of AI systems covered by that provision, Article 5(1), first subparagraph, point (h), Article 5(2) to (6) and Article 26(10) of this Regulation adopted on the basis of Article 16 TFEU  which  relate  to  the  processing  of  personal  data  by  the  Member  States  when  carrying  out  activities  falling within the scope of Chapter 4 or Chapter 5 of Title V of Part Three of the TFEU, where Ireland is not bound by the rules  governing  the  forms  of  judicial  cooperation  in  criminal  matters  or  police  cooperation  which  require compliance with the provisions laid down on the basis  of  Article  16  TFEU.\n(41) In accordance with Articles 2 and 2a of Protocol No 22 on the position of Denmark, annexed to the TEU and to the TFEU, Denmark is not bound by rules laid down in Article 5(1), first subparagraph, point (g), to the extent it applies to the use of biometric categorisation systems for activities in the field of police cooperation and judicial cooperation in  criminal  matters,  Article  5(1),  first  subparagraph,  point  (d),  to  the  extent  it  applies  to  the  use  of  AI  systems covered by that provision, Article 5(1), first subparagraph, point (h), (2) to (6) and Article 26(10) of this Regulation\nadopted on the basis of Article 16 TFEU, or subject to their application, which relate to the processing of personal data  by  the  Member  States  when  carrying  out  activities  falling  within  the  scope  of  Chapter  4  or  Chapter  5  of Title  V of  Part  Three  of  the  TFEU."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_5",
    "chunk_content": "Whereas:\n(42) In  line  with  the  presumption  of  innocence,  natural  persons  in  the  Union  should  always  be  judged  on  their  actual behaviour.  Natural  persons  should  never  be  judged  on  AI-predicted  behaviour  based  solely  on  their  profiling, personality traits or characteristics, such as nationality, place of birth, place of residence, number of children, level of debt  or  type  of  car,  without  a  reasonable  suspicion  of  that  person  being  involved  in  a  criminal  activity  based  on objective verifiable facts and without human assessment thereof. Therefore, risk assessments carried out with regard to  natural  persons  in  order  to  assess  the  likelihood  of  their  offending  or  to  predict  the  occurrence  of  an  actual  or potential criminal offence based solely on profiling them or on assessing their  personality traits and characteristics should be prohibited. In any case, that prohibition does not refer to or touch upon risk analytics that are not based on the profiling of individuals or on the personality traits and characteristics of individuals, such as AI systems using risk  analytics  to  assess  the  likelihood  of  financial  fraud  by  undertakings  on  the  basis  of  suspicious  transactions  or risk analytic tools to predict the likelihood of the localisation of narcotics or illicit goods by customs authorities, for example on the basis  of  known trafficking  routes.\n(43) The placing on the market, the putting into service for that specific purpose, or the use of AI systems that create or expand  facial  recognition  databases  through  the  untargeted  scraping  of  facial  images  from  the  internet  or  CCTV footage,  should  be  prohibited  because  that  practice  adds  to  the  feeling  of  mass  surveillance  and  can  lead  to  gross violations  of  fundamental  rights,  including  the  right  to  privacy.\n(44) There are serious concerns about the scientific basis of AI systems aiming to identify or infer emotions, particularly as  expression  of  emotions  vary  considerably  across  cultures  and  situations,  and  even  within  a  single  individual. Among  the  key  shortcomings  of  such  systems  are  the  limited  reliability,  the  lack  of  specificity  and  the  limited generalisability. Therefore, AI systems identifying or inferring emotions or intentions of natural persons on the basis of their biometric data may lead to discriminatory outcomes and can be intrusive to the rights and freedoms of the concerned persons.  Considering  the  imbalance  of  power  in  the  context  of  work  or  education,  combined  with  the intrusive  nature  of  these  systems,  such  systems  could  lead  to  detrimental  or  unfavourable  treatment  of  certain natural persons or whole groups thereof. Therefore, the placing on the market, the putting into service, or the use of AI systems intended to be used to detect the emotional state of individuals in situations related to the workplace and education  should  be  prohibited.  That  prohibition  should  not  cover  AI  systems  placed  on  the  market  strictly  for medical or  safety  reasons,  such  as  systems  intended  for  therapeutical  use.\n(45) Practices  that  are  prohibited  by  Union  law,  including  data  protection  law,  non-discrimination  law,  consumer protection  law,  and  competition  law,  should  not  be  affected  by  this  Regulation.\n(46) High-risk  AI  systems  should  only  be  placed  on  the  Union  market,  put  into  service  or  used  if  they  comply  with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as  recognised  and  protected  by  Union  law.  On  the  basis  of  the  New  Legislative  Framework,  as  clarified  in  the Commission notice 'The 'Blue Guide' on the implementation of EU product rules 2022' ( 20 ),  the general rule is that more  than  one  legal  act  of  Union  harmonisation  legislation,  such  as  Regulations  (EU)  2017/745 ( 21 )  and  (EU) 2017/746 ( 22 )  of  the  European Parliament and of the Council or Directive 2006/42/EC of the European Parliament and of the Council ( 23 ), may be applicable to one product, since the making available or putting into service can take\nplace  only  when  the  product  complies  with  all  applicable  Union  harmonisation  legislation.  To  ensure  consistency and avoid unnecessary administrative burdens or costs, providers of a product that contains one or more high-risk AI  systems,  to  which  the  requirements  of  this  Regulation  and  of  the  Union  harmonisation  legislation  listed  in  an annex  to  this  Regulation  apply,  should  have  flexibility  with  regard  to  operational  decisions  on  how  to  ensure compliance  of  a  product  that  contains  one  or  more  AI  systems  with  all  applicable  requirements  of  the  Union harmonisation legislation in an optimal manner. AI systems identified  as high-risk  should be limited to those that have  a  significant  harmful  impact  on  the  health,  safety  and  fundamental  rights  of  persons  in  the  Union  and  such limitation  should  minimise  any potential  restriction  to  international  trade.\n(47) AI  systems  could  have  an  adverse  impact  on  the  health  and  safety  of  persons,  in  particular  when  such  systems operate  as  safety  components  of  products.  Consistent  with  the  objectives  of  Union  harmonisation  legislation  to facilitate the free movement of products in the internal market and to ensure that only safe and otherwise compliant products find their  way into the market, it is important that the safety risks that may be generated by a product as a  whole  due  to  its  digital  components,  including  AI  systems,  are  duly  prevented  and  mitigated.  For  instance, increasingly autonomous robots, whether in the context of manufacturing or personal assistance and care should be able to safely operate and performs their functions in complex environments. Similarly, in the health sector  where the  stakes  for  life  and  health  are  particularly  high,  increasingly  sophisticated  diagnostics  systems  and  systems supporting human decisions should be reliable and accurate.\n(48) The extent of the adverse impact caused by the AI system on the fundamental rights protected by the Charter is of particular  relevance  when  classifying  an  AI  system  as  high  risk.  Those  rights  include  the  right  to  human  dignity, respect for  private and family life, protection of personal data, freedom of expression and information, freedom of assembly and of association, the right to non-discrimination, the right to education, consumer protection, workers' rights,  the  rights  of  persons  with  disabilities,  gender  equality,  intellectual  property  rights,  the  right  to  an  effective remedy  and  to  a  fair  trial,  the  right  of  defence  and  the  presumption  of  innocence,  and  the  right  to  good administration. In addition to those rights, it is important to highlight the fact that children have specific rights as enshrined  in  Article  24  of  the  Charter  and  in  the  United  Nations  Convention  on  the  Rights  of  the  Child,  further developed  in  the  UNCRC  General  Comment  No  25  as  regards  the  digital  environment,  both  of  which  require consideration  of  the  children's  vulnerabilities  and  provision  of  such  protection  and  care  as  necessary  for  their well-being.  The  fundamental  right  to  a  high  level  of  environmental  protection  enshrined  in  the  Charter  and implemented in Union policies should also be considered when assessing the severity of the harm that an AI system can  cause,  including  in  relation  to  the  health  and  safety of  persons.\n(49) As  regards  high-risk  AI  systems  that  are  safety  components  of  products  or  systems,  or  which  are  themselves products or systems falling within the scope of Regulation (EC) No 300/2008 of the European Parliament and of the Council ( 24 ), Regulation  (EU)  No  167/2013  of  the  European  Parliament  and  of  the  Council ( 25 ), Regulation (EU)  No  168/2013  of  the  European  Parliament  and  of  the  Council ( 26 ),  Directive  2014/90/EU  of  the  European Parliament  and  of  the  Council ( 27 ),  Directive  (EU)  2016/797  of  the  European  Parliament  and  of  the  Council ( 28 ), Regulation  (EU)  2018/858  of  the  European  Parliament  and  of  the  Council ( 29 ),  Regulation  (EU)  2018/1139  of  the\n( 26 ) Regulation  (EU)  No  168/2013  of  the  European  Parliament  and  of  the  Council  of  15  January  2013  on  the  approval  and  market surveillance  of  two-  or  three-wheel  vehicles  and  quadricycles  (OJ  L  60,  2.3.2013,  p.  52).\n( 28 ) Directive (EU) 2016/797 of the European Parliament and of the Council of 11 May 2016 on the interoperability of the rail system within  the  European  Union (OJ  L  138,  26.5.2016,  p.  44).\n( 29 ) Regulation (EU) 2018/858 of the European Parliament and of the Council of 30 May 2018 on the approval and market surveillance of motor vehicles and their trailers, and of systems, components and separate technical units intended for such vehicles, amending Regulations  (EC)  No  715/2007  and  (EC)  No  595/2009  and  repealing  Directive  2007/46/EC  (OJ  L  151,  14.6.2018,  p.  1).\nEuropean Parliament and of the Council ( 30 ), and Regulation (EU) 2019/2144 of the European Parliament and of the Council ( 31 ),  it  is  appropriate to amend those acts to ensure that the Commission takes into account, on the basis of the technical and regulatory specificities of each sector, and without interfering with existing governance, conformity assessment  and  enforcement  mechanisms  and  authorities  established  therein,  the  mandatory  requirements  for high-risk AI systems laid down in this Regulation when adopting any relevant delegated or implementing acts on the basis  of  those  acts.\n(50) As regards AI systems that are safety components of products, or which are themselves products, falling within the scope of certain Union harmonisation legislation listed in an annex to this Regulation, it is appropriate  to classify them as high-risk under  this Regulation if  the product concerned undergoes the conformity assessment procedure with  a  third-party  conformity  assessment  body  pursuant  to  that  relevant  Union  harmonisation  legislation.  In particular, such products are machinery, toys, lifts, equipment and protective systems intended for use in potentially explosive  atmospheres,  radio  equipment,  pressure  equipment,  recreational  craft  equipment,  cableway  installations, appliances  burning  gaseous  fuels,  medical  devices, in  vitro diagnostic  medical  devices,  automotive  and  aviation.\n(51) The  classification  of  an  AI  system  as  high-risk  pursuant  to  this  Regulation  should  not  necessarily  mean  that  the product whose safety component is the AI system, or the AI system itself as a product, is considered to be high-risk under the criteria established in the relevant Union harmonisation legislation that applies to the product. This is, in particular, the case for Regulations (EU) 2017/745 and (EU) 2017/746, where a third-party conformity assessment is provided  for  medium-risk  and  high-risk  products.\n(52) As  regards  stand-alone  AI  systems,  namely  high-risk  AI  systems  other  than  those  that  are  safety  components  of products, or that are themselves products, it is appropriate to classify them as high-risk if, in light of their intended purpose,  they  pose  a  high  risk of  harm  to  the  health  and  safety or  the  fundamental  rights  of  persons,  taking  into account both the severity of the possible harm and its probability of occurrence and they are used in a number of specifically  pre-defined areas  specified  in  this  Regulation.  The  identification  of  those  systems is  based  on  the  same methodology  and  criteria  envisaged  also  for  any  future  amendments  of  the  list  of  high-risk  AI  systems  that  the Commission should be empowered to adopt, via delegated acts, to take into account the rapid pace of technological development, as well as  the  potential  changes  in  the  use  of  AI  systems.\n(53) It  is  also  important  to  clarify  that  there  may  be  specific  cases  in  which  AI  systems  referred  to  in  pre-defined  areas specified in this Regulation do not lead to a significant risk of harm to the legal interests protected under those areas because they do not materially influence the decision-making or do not harm those interests substantially. For  the purposes of this Regulation, an AI system that does not materially influence the outcome of decision-making should be  understood  to  be  an  AI  system  that  does  not  have  an  impact  on  the  substance,  and  thereby  the  outcome,  of decision-making,  whether  human  or  automated.  An  AI  system  that  does  not  materially  influence  the  outcome  of decision-making  could  include  situations  in  which  one  or  more  of  the  following  conditions  are  fulfilled.  The  first such condition should be that the AI system is intended to perform a narrow procedural task, such as an AI system that  transforms  unstructured  data  into  structured  data,  an  AI  system  that  classifies  incoming  documents  into categories or an AI system that is used to detect duplicates among a large number of applications. Those tasks are of such narrow and limited nature that they pose only limited risks which are not increased through the use of an AI system in a context that is listed as a high-risk use in an annex to this Regulation. The second condition should be\nthat the task performed by the AI system is intended to improve the result of a previously completed human activity that may be relevant for the purposes of the high-risk uses listed in an annex to this Regulation. Considering those characteristics, the AI system provides only an additional layer to a human activity with consequently lowered risk. That condition would, for example, apply to AI systems that are intended to improve the language used in previously drafted  documents,  for  example  in  relation  to  professional  tone,  academic  style  of  language  or  by  aligning  text  to a  certain brand messaging. The third condition should be that the AI system is intended to detect decision-making patterns  or  deviations  from  prior  decision-making  patterns.  The  risk  would  be  lowered  because  the  use  of  the  AI system  follows  a  previously  completed  human  assessment  which  it  is  not  meant  to  replace  or  influence,  without proper human review. Such AI systems include for instance those that, given a certain grading pattern of a teacher, can be used to check ex post whether the teacher may have deviated from the grading pattern so as to flag potential inconsistencies or anomalies. The fourth condition should be that the AI system is intended to perform a task that is only preparatory to an assessment relevant for the purposes of the AI systems listed in an annex to this Regulation, thus  making  the  possible  impact  of  the  output  of  the  system  very  low  in  terms  of  representing  a  risk  for  the assessment  to  follow.  That  condition  covers,  inter  alia,  smart  solutions  for  file  handling,  which  include  various functions from indexing, searching, text and speech processing or linking data to other data sources, or AI systems used for translation of initial documents. In any case, AI systems used in high-risk use-cases listed in an annex to this Regulation should be considered to pose significant risks of harm to the health, safety or fundamental rights if the AI system  implies  profiling  within  the  meaning  of  Article  4,  point  (4)  of  Regulation  (EU)  2016/679  or  Article  3, point  (4)  of  Directive  (EU)  2016/680  or  Article  3,  point  (5)  of  Regulation  (EU)  2018/1725.  To  ensure  traceability and transparency, a provider who considers that an AI system is not high-risk on the basis of the conditions referred to  above should draw up documentation of the assessment before that system is placed on the market or put into service  and  should  provide  that  documentation  to  national  competent  authorities  upon  request.  Such  a  provider should  be  obliged  to  register  the  AI  system  in  the  EU  database  established  under  this  Regulation.  With  a  view  to providing further guidance for the practical implementation of the conditions under which the AI systems listed in an annex to this Regulation are, on an exceptional basis, non-high-risk, the Commission should, after consulting the Board, provide guidelines specifying that practical implementation, completed by a comprehensive list of practical examples of use cases  of  AI  systems  that  are  high-risk  and  use  cases  that  are  not.\n(54) As  biometric  data  constitutes  a  special  category  of  personal  data,  it  is  appropriate  to  classify  as  high-risk  several critical-use  cases  of  biometric  systems,  insofar  as  their  use  is  permitted  under  relevant  Union  and  national  law. Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased  results  and  entail  discriminatory  effects.  The  risk  of  such  biased  results  and  discriminatory  effects  is particularly  relevant  with  regard  to  age,  ethnicity,  race,  sex  or  disabilities.  Remote  biometric  identification  systems should  therefore  be  classified  as  high-risk  in  view  of  the  risks  that  they  pose.  Such  a  classification  excludes  AI systems  intended  to  be  used  for  biometric  verification,  including  authentication,  the  sole  purpose  of  which  is  to confirm that a specific natural person is who that person claims to be and to confirm the identity of a natural person for the sole purpose of having access to a service, unlocking a device or having secure access to premises. In addition, AI  systems  intended  to  be  used  for  biometric  categorisation  according  to  sensitive  attributes  or  characteristics protected under Article 9(1) of Regulation (EU) 2016/679 on the basis of biometric data, in so far as these are not prohibited  under  this  Regulation,  and  emotion  recognition  systems  that  are  not  prohibited  under  this  Regulation, should be classified as high-risk. Biometric systems which are intended to be used solely for the purpose of enabling cybersecurity  and  personal  data  protection  measures  should  not  be  considered  to  be  high-risk  AI  systems.\n(55) As regards the management and operation of critical infrastructure, it is appropriate to classify as high-risk the AI systems intended to be used as safety components in the management and operation of critical digital infrastructure as listed in point (8) of the Annex to Directive (EU) 2022/2557, road traffic and the supply of water, gas, heating and electricity, since their failure or malfunctioning may put at risk the life and health of persons at large scale and lead to appreciable  disruptions  in  the  ordinary  conduct  of  social  and  economic  activities.  Safety  components  of  critical infrastructure,  including  critical  digital  infrastructure,  are  systems  used  to  directly  protect  the  physical  integrity  of critical infrastructure or the health and safety of persons and property but which are not necessary in order for the\nsystem to function. The  failure  or  malfunctioning  of  such  components  might  directly  lead  to risks  to  the  physical integrity  of  critical  infrastructure  and  thus  to  risks  to  health  and  safety  of  persons  and  property.  Components intended to be used solely for cybersecurity purposes should not qualify as safety components. Examples of safety components  of  such  critical  infrastructure  may  include  systems  for  monitoring  water  pressure  or  fire  alarm controlling  systems  in  cloud  computing  centres.\n(56) The deployment of AI systems in education is important to promote high-quality digital education and training and to allow all learners and teachers to acquire and share the necessary digital skills and competences, including media literacy, and critical thinking, to take an active part in the economy, society, and in democratic processes. However, AI systems used in education or vocational training, in particular for determining access or admission, for assigning persons  to  educational  and  vocational  training  institutions  or  programmes  at  all  levels,  for  evaluating  learning outcomes of persons, for assessing the appropriate level of education for an individual and materially influencing the level of education and training that individuals will receive or will be able to access or for monitoring and detecting prohibited behaviour of students during tests should be classified as high-risk AI systems, since they may determine the  educational  and  professional  course  of  a  person's  life  and  therefore  may  affect  that  person's  ability  to  secure a  livelihood.  When  improperly designed and used, such systems may be particularly intrusive and may violate the right to education and training as well as the right not to be discriminated against and perpetuate historical patterns of  discrimination,  for  example  against  women,  certain  age  groups,  persons  with  disabilities,  or  persons  of  certain racial  or  ethnic  origins  or  sexual  orientation.\n(57) AI  systems  used  in  employment,  workers  management  and  access  to  self-employment,  in  particular  for  the recruitment  and  selection  of  persons,  for  making  decisions  affecting  terms  of  the  work-related  relationship, promotion and termination of work-related contractual relationships, for allocating tasks on the basis of individual behaviour, personal traits or characteristics and for monitoring or evaluation of persons in work-related contractual relationships,  should also  be  classified  as  high-risk,  since  those  systems  may  have  an  appreciable  impact on  future career  prospects,  livelihoods  of  those  persons  and  workers'  rights.  Relevant  work-related  contractual  relationships should, in a meaningful manner, involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Throughout the recruitment process and in the evaluation, promotion, or retention of persons in work-related contractual relationships, such systems may perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of such persons may also undermine their  fundamental rights to data protection and privacy.\n(58) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential  private  and  public  services  and  benefits  necessary  for  people  to fully  participate  in  society or  to  improve one's  standard  of  living.  In  particular,  natural  persons  applying  for  or  receiving  essential  public  assistance  benefits and  services  from  public  authorities  namely  healthcare  services,  social  security  benefits,  social  services  providing protection  in  cases  such  as  maternity,  illness,  industrial  accidents,  dependency or  old  age  and  loss  of  employment and social and housing assistance, are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should  be  granted,  denied,  reduced,  revoked  or  reclaimed  by  authorities,  including  whether  beneficiaries  are legitimately entitled to such benefits or services, those systems may have a significant impact on persons' livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or  an  effective  remedy  and  should  therefore  be  classified  as  high-risk.  Nonetheless,  this  Regulation  should  not hamper  the  development  and  use  of  innovative  approaches  in  the  public  administration,  which  would  stand  to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal  and  natural  persons.  In  addition,  AI  systems  used  to  evaluate  the  credit  score  or  creditworthiness  of  natural persons should be classified as high-risk AI systems, since they determine those persons' access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for those purposes may  lead  to  discrimination  between  persons  or  groups  and  may  perpetuate  historical  patterns  of  discrimination, such as that based on racial or ethnic origins, gender, disabilities, age or sexual orientation, or may create new forms of discriminatory impacts. However, AI systems provided for by Union law for the purpose of detecting fraud in the offering of financial services and for prudential purposes to calculate credit institutions' and insurance undertakings' capital requirements should not be considered to be high-risk under this Regulation. Moreover, AI systems intended\nto be used for risk assessment and pricing in relation to natural persons for health and life insurance can also have a  significant  impact  on  persons'  livelihood  and  if  not  duly  designed,  developed  and  used,  can  infringe  their fundamental rights and can lead to serious consequences for  people's life and health, including financial exclusion and  discrimination.  Finally,  AI  systems  used  to  evaluate  and  classify  emergency  calls  by  natural  persons  or  to dispatch or establish priority in the dispatching of emergency first response services, including by police, firefighters and medical aid, as well as of emergency healthcare patient triage systems, should also be classified as high-risk since they  make decisions  in very critical  situations  for  the  life  and  health  of  persons  and  their  property."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_6",
    "chunk_content": "Whereas:\n(59) Given their role and responsibility, actions by law enforcement authorities involving certain uses of AI systems are characterised  by  a  significant  degree  of  power  imbalance  and  may  lead  to  surveillance,  arrest  or  deprivation  of a  natural  person's  liberty  as  well  as  other  adverse  impacts  on  fundamental  rights  guaranteed  in  the  Charter.  In particular, if the AI system is not trained with high-quality data, does not meet adequate requirements in terms of its performance, its accuracy or  robustness, or  is not properly designed and tested before being put on the market or otherwise  put  into  service,  it  may  single  out  people  in  a  discriminatory  or  otherwise  incorrect  or  unjust  manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to  a  fair  trial  as  well  as  the  right  of  defence  and  the  presumption  of  innocence,  could  be  hampered,  in  particular, where such AI systems are not sufficiently transparent, explainable and documented. It is therefore appropriate to classify as high-risk, insofar as their use is permitted under relevant Union and national law, a number of AI systems intended  to  be  used  in  the  law  enforcement  context  where  accuracy,  reliability  and  transparency  is  particularly important to avoid adverse impacts, retain public trust and ensure accountability and effective redress. In view of the nature  of  the  activities  and  the  risks  relating  thereto,  those  high-risk  AI  systems  should  include  in  particular  AI systems intended to be used by or on behalf of law enforcement authorities or by Union institutions, bodies, offices, or agencies in support of law enforcement authorities for assessing the risk of a natural person to become a victim of criminal offences, as polygraphs and similar tools, for the evaluation of the reliability of evidence in in the course of investigation or prosecution of criminal offences, and, insofar as not prohibited under this Regulation, for assessing the risk of a natural person offending or reoffending not solely on the basis of the profiling of natural persons or the assessment of personality traits and characteristics or  the past criminal behaviour of natural persons or groups, for profiling  in  the  course  of  detection,  investigation  or  prosecution  of  criminal  offences.  AI  systems  specifically intended to be used for administrative proceedings by tax and customs authorities as well as by financial intelligence units carrying out administrative tasks analysing information pursuant to Union anti-money laundering law should not  be  classified  as  high-risk  AI  systems  used  by  law  enforcement  authorities  for  the  purpose  of  prevention, detection,  investigation  and  prosecution  of  criminal  offences.  The  use  of  AI  tools  by  law  enforcement  and  other relevant authorities should not become a factor of inequality, or exclusion. The impact of the use of AI tools on the defence rights of suspects should not be ignored, in particular the difficulty in obtaining meaningful information on the  functioning  of  those  systems  and  the  resulting  difficulty  in  challenging  their  results  in  court,  in  particular  by natural  persons  under  investigation.\n(60) AI systems used in migration, asylum and border control management affect persons who are often in particularly vulnerable position and who are dependent on the outcome of the actions of the competent public authorities. The accuracy,  non-discriminatory  nature  and  transparency  of  the  AI  systems  used  in  those  contexts  are  therefore particularly  important  to  guarantee  respect  for  the  fundamental  rights  of  the  affected  persons,  in  particular  their rights  to  free  movement,  non-discrimination,  protection  of  private  life  and  personal  data,  international  protection and good administration. It is therefore appropriate to classify as high-risk,  insofar  as their  use is  permitted under relevant Union and national law, AI systems intended to be used by or on behalf of competent public authorities or by  Union institutions,  bodies,  offices  or  agencies  charged  with  tasks  in  the  fields  of  migration,  asylum  and  border control management as polygraphs and similar  tools, for assessing certain risks posed by natural persons entering the  territory  of  a  Member  State  or  applying  for  visa  or  asylum,  for  assisting  competent  public  authorities  for  the examination, including related assessment of the reliability of evidence, of applications for asylum, visa and residence permits  and  associated  complaints  with  regard  to  the  objective  to  establish  the  eligibility  of  the  natural  persons applying  for  a  status,  for  the  purpose  of  detecting,  recognising  or  identifying  natural  persons  in  the  context  of migration,  asylum  and  border  control  management,  with  the  exception  of  verification  of  travel  documents.  AI systems in the area of migration, asylum and border control management covered by this Regulation should comply with the relevant procedural requirements set by the Regulation (EC) No 810/2009 of the European Parliament and\nof the Council ( 32 ),  the Directive 2013/32/EU of the European Parliament and of the Council ( 33 ),  and other relevant Union law. The use of AI systems in migration, asylum and border control management should, in no circumstances, be  used  by  Member  States  or  Union  institutions,  bodies,  offices  or  agencies  as  a  means  to  circumvent  their international  obligations  under  the  UN  Convention  relating  to  the  Status  of  Refugees  done  at  Geneva  on  28  July 1951  as  amended  by  the  Protocol  of  31  January  1967.  Nor  should  they  be  used  to  in  any  way  infringe  on  the principle of non-refoulement, or  to deny safe and effective legal avenues into the territory of  the Union, including the  right  to  international  protection.\n(61) Certain  AI  systems  intended  for  the  administration  of  justice  and  democratic  processes  should  be  classified  as high-risk, considering their potentially significant impact on democracy, the rule of  law, individual freedoms as well as the right to an effective remedy and to a fair trial. In particular, to address the risks of potential biases, errors and opacity, it is appropriate to qualify as high-risk AI systems intended to be used by a judicial authority or on its behalf to assist judicial authorities in researching and interpreting facts and the law and in applying the law to a concrete set of facts. AI systems intended to be used by alternative dispute resolution bodies for  those purposes should also be considered to be high-risk when the outcomes of the alternative dispute resolution proceedings produce legal effects for  the parties. The use of AI tools can support the decision-making power of judges or judicial independence, but should  not  replace  it:  the  final  decision-making  must  remain  a  human-driven  activity.  The  classification  of  AI systems as high-risk should not, however, extend to AI systems intended for purely ancillary administrative activities that  do  not  affect  the  actual  administration  of  justice  in  individual  cases,  such  as  anonymisation  or pseudonymisation of judicial decisions, documents or data, communication between personnel, administrative tasks.\n(62) Without  prejudice  to  the  rules  provided  for  in  Regulation  (EU)  2024/900  of  the  European  Parliament  and  of  the Council ( 34 ),  and  in  order  to  address  the  risks  of  undue  external  interference  with  the  right  to  vote  enshrined  in Article 39 of the Charter, and of adverse effects on democracy and the rule of law, AI systems intended to be used to influence  the  outcome  of an  election  or  referendum  or  the  voting  behaviour  of  natural  persons  in  the  exercise  of their  vote  in  elections  or  referenda  should  be  classified  as  high-risk  AI  systems  with  the  exception  of  AI  systems whose  output  natural  persons  are  not  directly  exposed  to,  such  as  tools  used  to  organise,  optimise  and  structure political  campaigns  from  an  administrative  and  logistical  point  of  view.\n(63) The fact that an AI system is classified as a high-risk AI system under  this Regulation should not be interpreted as indicating that the use of the system is lawful under other acts of Union law or under national law compatible with Union law, such as on the protection of personal data, on the use of polygraphs and similar tools or other systems to detect the emotional state of natural persons. Any such use should continue to occur solely in accordance with the applicable  requirements  resulting  from  the  Charter  and  from  the  applicable  acts  of  secondary  Union  law  and national law. This Regulation should not be understood as providing for the legal ground for processing of personal data, including special categories of personal data, where relevant, unless it is specifically otherwise provided for in this  Regulation.\n(64) To mitigate the risks from high-risk AI systems placed on the market or put into service and to ensure a high level of trustworthiness,  certain  mandatory  requirements  should  apply  to  high-risk  AI  systems,  taking  into  account  the intended  purpose  and  the  context  of  use  of  the  AI  system  and  according  to  the  risk-management  system  to  be established by the provider. The measures adopted by the providers to comply with the mandatory requirements of this  Regulation  should  take  into  account  the  generally  acknowledged  state  of  the  art  on  AI,  be  proportionate  and effective  to  meet  the  objectives  of  this  Regulation.  Based  on  the  New  Legislative  Framework,  as  clarified  in Commission  notice  'The  'Blue  Guide'  on  the  implementation  of  EU  product  rules  2022',  the  general  rule  is  that more  than  one  legal  act  of  Union  harmonisation  legislation  may  be  applicable  to  one  product,  since  the  making available  or  putting  into  service  can  take  place  only  when  the  product  complies  with  all  applicable  Union harmonisation  legislation.  The  hazards  of  AI  systems  covered  by  the  requirements  of  this  Regulation  concern different aspects than the existing Union harmonisation legislation and therefore the requirements of this Regulation would complement the existing body of  the Union  harmonisation  legislation.  For  example,  machinery or  medical devices  products  incorporating  an  AI  system  might  present  risks  not  addressed  by  the  essential  health  and  safety\nrequirements  set  out  in  the  relevant  Union  harmonised  legislation,  as  that  sectoral  law  does  not  deal  with  risks specific to AI systems. This calls for a simultaneous and complementary application of the various legislative acts. To ensure consistency and to avoid an unnecessary administrative burden and unnecessary costs, providers of a product that  contains  one  or  more  high-risk  AI  system,  to  which  the  requirements  of  this  Regulation  and  of  the  Union harmonisation legislation based on the New Legislative Framework and listed in an annex to this Regulation apply, should have flexibility with regard to operational decisions on how to ensure compliance of a product that contains one  or  more  AI  systems  with  all  the  applicable  requirements  of  that  Union  harmonised  legislation  in  an  optimal manner.  That  flexibility  could  mean,  for  example  a  decision  by  the  provider  to  integrate  a  part  of  the  necessary testing and reporting processes, information and documentation required under this Regulation into already existing documentation  and  procedures  required  under  existing  Union  harmonisation  legislation  based  on  the  New Legislative  Framework  and  listed  in  an  annex  to  this  Regulation.  This  should  not,  in  any  way,  undermine  the obligation  of  the  provider  to  comply  with  all  the  applicable  requirements.\n(65) The risk-management system should consist of a continuous, iterative process that is planned and run throughout the entire lifecycle of a high-risk AI system. That process should be aimed at identifying and mitigating the relevant risks  of  AI  systems  on  health,  safety  and  fundamental  rights.  The  risk-management  system  should  be  regularly reviewed  and  updated  to  ensure  its  continuing  effectiveness,  as  well  as  justification  and  documentation  of  any significant  decisions  and  actions  taken  subject  to  this  Regulation.  This  process  should  ensure  that  the  provider identifies  risks  or  adverse  impacts  and  implements  mitigation  measures  for  the  known  and  reasonably  foreseeable risks  of  AI  systems  to  the  health,  safety  and  fundamental  rights  in  light  of  their  intended  purpose  and  reasonably foreseeable  misuse,  including  the  possible  risks  arising  from  the  interaction  between  the  AI  system  and  the environment  within  which  it  operates.  The  risk-management  system  should  adopt  the  most  appropriate risk-management  measures  in  light  of  the  state  of  the  art  in  AI.  When  identifying  the  most  appropriate risk-management  measures,  the  provider  should  document  and  explain  the  choices  made  and,  when  relevant, involve experts and external stakeholders. In identifying the reasonably foreseeable misuse of high-risk AI systems, the  provider  should  cover  uses  of  AI  systems  which,  while  not  directly  covered  by  the  intended  purpose  and provided  for  in  the  instruction  for  use  may  nevertheless  be  reasonably  expected  to  result  from  readily  predictable human  behaviour  in  the  context  of  the  specific  characteristics  and  use  of  a  particular  AI  system.  Any  known  or foreseeable circumstances related to the use of  the high-risk AI system in accordance with its intended purpose or under conditions of reasonably foreseeable misuse, which may lead to risks to the health and safety or fundamental rights  should  be  included  in  the  instructions  for  use  that  are  provided  by  the  provider.  This  is  to  ensure  that  the deployer  is  aware  and  takes  them  into  account  when  using  the  high-risk  AI  system.  Identifying and  implementing risk mitigation measures for foreseeable misuse under this Regulation should not require specific additional training for the high-risk AI system by the provider to address foreseeable misuse. The providers however are encouraged to consider such additional training measures to mitigate reasonable foreseeable misuses as necessary and appropriate.\n(66) Requirements should apply to high-risk AI systems as regards  risk management, the quality and relevance of data sets used, technical documentation and record-keeping, transparency and the provision of information to deployers, human  oversight,  and  robustness,  accuracy  and  cybersecurity.  Those  requirements  are  necessary  to  effectively mitigate the risks for health, safety and fundamental rights. As no other less trade restrictive measures are reasonably available  those  requirements  are  not  unjustified  restrictions  to  trade.\n(67) High-quality  data  and  access  to  high-quality  data  plays  a  vital  role  in  providing  structure  and  in  ensuring  the performance of many AI systems, especially when techniques involving the training of models are used, with a view to  ensure  that  the  high-risk  AI  system  performs  as  intended  and  safely  and  it  does  not  become  a  source  of discrimination  prohibited  by  Union  law.  High-quality  data  sets  for  training,  validation  and  testing  require  the implementation  of  appropriate  data  governance  and  management  practices.  Data  sets  for  training,  validation  and testing,  including  the  labels,  should  be  relevant,  sufficiently  representative,  and  to  the  best  extent  possible  free  of errors and complete in view of the intended purpose of the system. In order to facilitate compliance with Union data protection  law,  such  as  Regulation  (EU)  2016/679,  data  governance  and  management  practices  should  include,  in the case of personal data, transparency about the original purpose of the data collection. The data sets should also have the appropriate statistical properties, including as regards the persons or groups of persons in relation to whom the high-risk AI system is intended to be used, with specific attention to the mitigation of possible biases in the data sets, that are likely to affect the health and safety of persons, have a negative impact on fundamental rights or lead to discrimination  prohibited  under  Union  law,  especially  where  data  outputs  influence  inputs  for  future  operations\n(feedback loops). Biases can for example be inherent in underlying data sets, especially when historical data is being used, or generated when the systems are implemented in real world settings. Results provided by AI systems could be influenced by such inherent biases that are inclined to gradually increase and thereby perpetuate and amplify existing discrimination,  in particular  for  persons  belonging  to  certain  vulnerable  groups,  including  racial  or  ethnic  groups. The requirement for the data sets to be to the best extent possible complete and free of errors should not affect the use of privacy-preserving techniques in the context of the development and testing of AI systems. In particular, data sets  should  take  into  account,  to  the  extent  required  by  their  intended  purpose,  the  features,  characteristics  or elements that are particular  to the specific geographical, contextual, behavioural or functional setting which the AI system is intended to be used. The requirements related to data governance can be complied with by having recourse to  third  parties  that offer  certified  compliance services  including verification of data governance, data set integrity, and data training, validation and testing practices, as far as compliance with the data requirements of this Regulation are  ensured."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_7",
    "chunk_content": "Whereas:\n(68) For  the  development and assessment of high-risk AI systems, certain actors, such as providers, notified bodies and other relevant entities, such as European Digital Innovation Hubs, testing experimentation facilities and researchers, should be able to access and use high-quality data sets within the fields of activities of those actors which are related to this Regulation. European common data spaces established by the Commission and the facilitation of data sharing between businesses and with government in the public interest will be instrumental to provide trustful, accountable and  non-discriminatory  access  to  high-quality  data  for  the  training,  validation  and  testing  of  AI  systems.  For example, in health, the  European health data  space will  facilitate  non-discriminatory  access  to health  data  and  the training  of  AI  algorithms  on  those  data  sets,  in  a  privacy-preserving,  secure,  timely,  transparent  and  trustworthy manner, and with an appropriate institutional governance. Relevant competent authorities, including sectoral ones, providing  or  supporting  the  access  to  data  may  also  support  the  provision  of  high-quality  data  for  the  training, validation  and  testing  of  AI  systems.\n(69) The right to privacy and to protection of personal data must be guaranteed throughout the entire lifecycle of the AI system. In this regard, the principles of data minimisation and data protection by design and by default, as set out in Union data protection law, are applicable when personal data are processed. Measures taken by providers to ensure compliance  with  those  principles  may  include  not  only  anonymisation  and  encryption,  but  also  the  use  of technology  that  permits  algorithms  to  be  brought  to  the  data  and  allows  training  of  AI  systems  without  the transmission  between  parties  or  copying  of  the  raw  or  structured  data  themselves,  without  prejudice  to  the requirements on data governance provided for  in this  Regulation.\n(70) In  order  to  protect  the  right  of  others  from  the  discrimination  that  might  result  from  the  bias  in  AI  systems,  the providers should, exceptionally, to the extent that it is strictly necessary for  the purpose of ensuring bias detection and correction in relation to the high-risk AI systems, subject to appropriate safeguards for  the fundamental rights and  freedoms  of  natural  persons  and  following  the  application  of  all  applicable  conditions  laid  down  under  this Regulation in addition to the conditions laid down in Regulations (EU) 2016/679 and (EU) 2018/1725 and Directive (EU) 2016/680, be able to process also special categories of personal data, as a matter of substantial public interest within the meaning of Article 9(2), point (g) of Regulation (EU) 2016/679 and Article 10(2), point (g) of Regulation (EU)  2018/1725.\n(71) Having  comprehensible  information  on  how  high-risk  AI  systems  have  been  developed  and  how  they  perform throughout their lifetime is essential to enable traceability of those systems, verify compliance with the requirements under this Regulation, as well as monitoring of their operations and post market monitoring. This requires keeping records  and  the  availability  of  technical  documentation,  containing  information  which  is  necessary  to  assess  the compliance of the AI system with the relevant requirements and facilitate post market monitoring. Such information should  include  the  general  characteristics,  capabilities  and  limitations  of  the  system,  algorithms,  data,  training, testing and validation processes used as well as documentation on the relevant risk-management system and drawn in  a  clear  and  comprehensive  form.  The  technical  documentation  should  be  kept  up  to  date,  appropriately throughout  the  lifetime  of  the  AI  system.  Furthermore,  high-risk  AI  systems  should  technically  allow  for  the automatic  recording  of events,  by  means  of  logs,  over  the  duration  of  the  lifetime  of  the  system.\n(72) To  address  concerns  related  to  opacity  and  complexity  of  certain  AI  systems  and  help  deployers  to  fulfil  their obligations under  this Regulation, transparency should be required for high-risk AI systems before they are placed on the market or  put  it  into service.  High-risk  AI  systems  should  be  designed  in  a  manner  to  enable  deployers  to understand  how  the  AI  system  works,  evaluate  its  functionality,  and  comprehend  its  strengths  and  limitations. High-risk  AI  systems  should  be  accompanied  by  appropriate information  in  the  form  of  instructions  of  use.  Such information should include the characteristics, capabilities and limitations of performance of  the AI system. Those would  cover  information  on  possible  known  and  foreseeable  circumstances  related  to  the  use  of  the  high-risk  AI system, including deployer action that may influence system behaviour and performance, under which the AI system can  lead  to  risks  to  health,  safety,  and  fundamental  rights,  on  the  changes  that  have  been  pre-determined  and assessed for conformity by the provider and on the relevant human oversight measures, including the measures to facilitate  the  interpretation  of  the  outputs  of  the  AI  system  by  the  deployers.  Transparency,  including  the accompanying instructions for use, should assist deployers in the use of the system and support informed decision making by them. Deployers should, inter alia, be in a better position to make the correct choice of the system that they intend to use in light of the obligations applicable to them, be educated about the intended and precluded uses, and use the AI system correctly and as appropriate. In order to enhance legibility and accessibility of the information included in the instructions of use, where appropriate, illustrative examples, for instance on the limitations and on the  intended  and  precluded  uses  of  the  AI  system,  should  be  included.  Providers  should  ensure  that  all documentation,  including  the  instructions  for  use,  contains  meaningful,  comprehensive,  accessible  and understandable  information,  taking  into  account  the  needs  and  foreseeable  knowledge  of  the  target  deployers. Instructions for  use should be made available in a language which can be easily understood by target deployers, as determined by the Member State concerned.\n(73) High-risk  AI  systems  should  be  designed  and  developed  in  such  a  way  that  natural  persons  can  oversee  their functioning, ensure that they are used as intended and that their impacts are addressed over the system's lifecycle. To that end, appropriate human oversight measures should be identified by the provider of the system before its placing on  the  market  or  putting  into  service.  In  particular,  where  appropriate,  such  measures  should  guarantee  that  the system is subject to in-built operational constraints that cannot be overridden by the system itself and is responsive to the human operator, and that the natural persons to whom human oversight has been assigned have the necessary competence, training and authority to carry out that role. It is also essential, as appropriate, to ensure that high-risk AI systems include mechanisms to guide and inform a natural person to whom human oversight has been assigned to make informed decisions if, when and how to intervene in order to avoid negative consequences or risks, or stop the system if it does not perform as intended. Considering the significant consequences for persons in the case of an incorrect  match  by  certain  biometric  identification  systems,  it  is  appropriate  to  provide  for  an  enhanced  human oversight requirement for those systems so that no action or decision may be taken by the deployer on the basis of the  identification  resulting  from  the  system  unless  this  has  been  separately  verified  and  confirmed  by  at  least  two natural persons. Those persons could be from one or  more entities and include the person operating or  using the system. This requirement should not pose unnecessary burden or delays and it could be sufficient that the separate verifications  by  the  different  persons  are  automatically  recorded  in  the  logs  generated  by  the  system.  Given  the specificities  of  the  areas  of  law  enforcement,  migration,  border  control  and  asylum,  this  requirement  should  not apply where Union or  national law considers the application  of  that  requirement  to be  disproportionate.\n(74) High-risk  AI  systems  should  perform  consistently  throughout  their  lifecycle  and  meet  an  appropriate  level  of accuracy,  robustness  and  cybersecurity,  in  light  of  their  intended  purpose  and  in  accordance  with  the  generally acknowledged state of the art. The Commission and relevant organisations and stakeholders are encouraged to take due  consideration  of  the  mitigation  of  risks  and  the  negative  impacts  of  the  AI  system.  The  expected  level  of performance  metrics  should  be  declared  in  the  accompanying  instructions  of  use.  Providers  are  urged  to communicate that information to deployers in a clear and easily understandable way, free of misunderstandings or misleading statements. Union law on legal metrology, including Directives 2014/31/EU ( 35 )  and  2014/32/EU ( 36 )  of the  European  Parliament  and  of  the  Council,  aims  to  ensure  the  accuracy  of  measurements  and  to  help  the transparency and fairness of commercial transactions. In that context, in cooperation with relevant stakeholders and organisation, such as metrology and benchmarking authorities, the Commission should encourage, as appropriate, the  development  of  benchmarks  and  measurement  methodologies  for  AI  systems.  In  doing  so,  the  Commission should  take  note  and  collaborate  with  international  partners  working  on  metrology  and  relevant  measurement indicators  relating  to  AI.\n(75) Technical robustness is a key requirement for high-risk AI systems. They should be resilient in relation to harmful or otherwise undesirable behaviour  that may result from limitations within the systems or  the environment in which the systems  operate  (e.g.  errors,  faults,  inconsistencies,  unexpected  situations).  Therefore,  technical  and organisational  measures  should  be  taken  to  ensure  robustness  of  high-risk  AI  systems,  for  example  by  designing and developing appropriate technical solutions to prevent or minimise harmful or otherwise undesirable behaviour. Those technical solution may include for instance mechanisms enabling the system to safely interrupt its operation (fail-safe  plans)  in  the  presence  of  certain  anomalies  or  when  operation  takes  place  outside  certain  predetermined boundaries.  Failure  to  protect  against  these  risks  could  lead  to  safety  impacts  or  negatively  affect  the  fundamental rights,  for  example  due  to  erroneous  decisions  or  wrong  or  biased  outputs  generated  by  the  AI  system.\n(76) Cybersecurity  plays  a  crucial  role  in  ensuring  that  AI  systems  are  resilient  against  attempts  to  alter  their  use, behaviour, performance or compromise their security properties by malicious third parties exploiting the system's vulnerabilities.  Cyberattacks  against  AI  systems  can  leverage  AI  specific  assets,  such  as  training  data  sets  (e.g.  data poisoning) or  trained models (e.g. adversarial attacks or  membership inference), or exploit vulnerabilities in the AI system's digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, suitable measures, such as security controls, should therefore be taken by the providers of high-risk AI systems, also taking  into  account  as  appropriate  the  underlying  ICT  infrastructure.\n(77) Without  prejudice  to  the  requirements  related  to  robustness  and  accuracy  set  out  in  this  Regulation,  high-risk  AI systems  which fall  within  the  scope  of  a  regulation  of  the  European  Parliament  and  of  the  Council  on  horizontal cybersecurity requirements for products with digital elements, in accordance with that regulation may demonstrate compliance  with  the  cybersecurity  requirements  of  this  Regulation  by  fulfilling  the  essential  cybersecurity requirements set out in that regulation. When high-risk AI systems fulfil the essential requirements of a regulation of the  European  Parliament  and  of  the  Council  on  horizontal  cybersecurity  requirements  for  products  with  digital elements, they should be deemed compliant with the cybersecurity requirements set out in this Regulation in so far as  the  achievement  of  those  requirements  is  demonstrated  in  the  EU  declaration  of  conformity  or  parts  thereof issued  under  that  regulation.  To  that  end,  the  assessment  of  the  cybersecurity  risks,  associated  to  a  product  with digital elements classified as high-risk AI system according to this Regulation, carried out under a regulation of the European  Parliament  and  of  the  Council  on  horizontal  cybersecurity  requirements  for  products  with  digital elements,  should  consider  risks  to  the  cyber  resilience  of  an  AI  system  as  regards  attempts  by  unauthorised  third parties  to  alter  its  use,  behaviour  or  performance,  including  AI  specific  vulnerabilities  such  as  data  poisoning  or adversarial  attacks,  as  well  as,  as  relevant,  risks  to  fundamental  rights  as  required  by  this  Regulation.\n(78) The  conformity  assessment  procedure  provided  by  this  Regulation  should  apply  in  relation  to  the  essential cybersecurity  requirements  of a  product  with  digital  elements  covered  by a  regulation  of  the  European  Parliament and  of  the  Council  on  horizontal  cybersecurity  requirements  for  products  with  digital  elements  and  classified  as a high-risk AI system under this Regulation. However, this rule should not result in reducing the necessary level of assurance for critical products with digital elements covered by a regulation of the European Parliament and of the Council  on  horizontal  cybersecurity  requirements  for  products  with  digital  elements.  Therefore,  by  way  of derogation from this rule, high-risk AI systems that fall within the scope of this Regulation and are also qualified as important and critical products with digital elements pursuant to a regulation of the European Parliament and of the Council on horizontal cybersecurity requirements for  products with digital elements and to which the conformity assessment  procedure  based  on  internal  control  set  out  in  an  annex  to  this  Regulation  applies,  are  subject  to  the conformity  assessment  provisions  of  a  regulation  of  the  European  Parliament  and  of  the  Council  on  horizontal cybersecurity requirements for products with digital elements insofar as the essential cybersecurity requirements of that  regulation  are  concerned.  In  this  case,  for  all  the  other  aspects  covered  by  this  Regulation  the  respective provisions on conformity assessment based on internal control set out in an annex to this Regulation should apply. Building on the knowledge and expertise of ENISA on the cybersecurity policy and tasks assigned to ENISA under the Regulation (EU) 2019/881 of the European Parliament and of the Council ( 37 ), the Commission should cooperate with ENISA on issues related to  cybersecurity of  AI  systems.\n(79) It is appropriate that a specific natural or legal person, defined as the provider, takes responsibility for the placing on the market or the putting into service of a high-risk AI system, regardless of whether that natural or legal person is the  person  who  designed  or  developed  the  system.\n(80) As  signatories  to  the  United  Nations  Convention  on  the  Rights  of  Persons  with  Disabilities,  the  Union  and  the Member States are legally obliged to protect persons with disabilities from discrimination and promote their equality, to  ensure  that  persons  with  disabilities  have  access,  on  an  equal  basis  with  others,  to  information  and communications technologies and systems, and to ensure respect for privacy for persons with disabilities. Given the growing importance and use of AI systems, the application of universal design principles to all new technologies and services should ensure full and equal access for everyone potentially affected by or using AI technologies, including persons  with  disabilities,  in  a  way  that  takes  full  account  of  their  inherent  dignity  and  diversity.  It  is  therefore essential that providers ensure full compliance with accessibility requirements, including Directive (EU) 2016/2102 of  the  European  Parliament  and  of  the  Council ( 38 ) and  Directive  (EU)  2019/882.  Providers  should  ensure compliance with these requirements by design. Therefore, the necessary measures should be integrated as much as possible  into  the  design  of  the  high-risk  AI  system.\n(81) The  provider  should  establish  a  sound  quality  management  system,  ensure  the  accomplishment  of  the  required conformity  assessment  procedure,  draw  up  the  relevant  documentation  and  establish  a  robust  post-market monitoring system. Providers of high-risk AI systems that are subject to obligations regarding quality management systems  under  relevant  sectoral  Union  law  should  have  the  possibility  to  include  the  elements  of  the  quality management system provided for in this Regulation as part of the existing quality management system provided for in  that  other  sectoral  Union  law.  The  complementarity  between  this  Regulation  and  existing  sectoral  Union  law should also be taken into account in future standardisation activities or guidance adopted by the Commission. Public authorities which put into service high-risk AI systems for their own use may adopt and implement the rules for the quality  management  system  as  part  of  the  quality  management  system  adopted  at  a  national  or  regional  level,  as appropriate, taking into account the specificities of  the sector and the competences and organisation of  the public authority concerned.\n(82) To enable enforcement of this Regulation and create a level playing field for operators, and, taking into account the different  forms  of  making  available  of  digital  products,  it  is  important  to  ensure  that,  under  all  circumstances, a person established in the Union can provide authorities with all the necessary information on the compliance of an AI  system.  Therefore,  prior  to  making  their  AI  systems  available  in  the  Union,  providers  established  in  third countries should, by written mandate, appoint an authorised representative established in the Union. This authorised representative plays a pivotal role in ensuring the compliance of  the high-risk AI systems placed on the market or put into service in the Union by those providers who are not established in the Union and in serving as their contact person established  in  the  Union.\n(83) In  light  of  the  nature  and  complexity  of  the  value  chain  for  AI  systems  and  in  line  with  the  New  Legislative Framework, it is essential to ensure legal certainty and facilitate the compliance with this Regulation. Therefore, it is necessary  to  clarify  the  role  and  the  specific  obligations  of  relevant  operators  along  that  value  chain,  such  as importers  and  distributors  who  may  contribute  to  the  development  of  AI  systems.  In  certain  situations  those operators  could  act  in  more  than  one  role  at  the  same  time  and  should  therefore  fulfil  cumulatively  all  relevant obligations associated with those roles. For example, an operator could act as a distributor and an importer at the same time.\n(84) To ensure legal certainty, it  is  necessary  to clarify  that,  under  certain  specific  conditions,  any distributor,  importer, deployer or other third-party should be considered to be a provider of a high-risk AI system and therefore assume all the  relevant obligations.  This  would be the  case if  that  party  puts  its  name  or  trademark on a  high-risk  AI  system already placed on the market or put into service, without prejudice to contractual arrangements stipulating that the obligations  are  allocated  otherwise.  This  would  also  be  the  case  if  that  party  makes  a  substantial  modification  to a high-risk AI system that has already been placed on the market or has already been put into service in a way that it remains a high-risk  AI  system  in  accordance  with  this  Regulation,  or  if  it  modifies  the  intended  purpose  of  an  AI system,  including  a  general-purpose  AI  system,  which  has  not  been  classified  as  high-risk  and  has  already  been placed on the market or put into service, in a way that the AI system becomes a high-risk AI system in accordance with  this  Regulation.  Those  provisions  should  apply  without  prejudice  to  more  specific  provisions  established  in certain  Union  harmonisation  legislation  based  on  the  New  Legislative  Framework,  together  with  which  this\nRegulation should apply. For example, Article 16(2) of Regulation (EU) 2017/745, establishing that certain changes should  not  be  considered  to  be  modifications  of  a  device  that  could  affect  its  compliance  with  the  applicable requirements, should continue to apply to high-risk AI systems that are medical devices within the meaning of that Regulation.\n(85) General-purpose AI systems may be used as high-risk AI systems by themselves or be components of other high-risk AI systems. Therefore, due to their particular nature and in order to ensure a fair sharing of responsibilities along the AI  value  chain,  the  providers  of  such  systems  should,  irrespective  of  whether  they  may  be  used  as  high-risk  AI systems as such by other providers or as components of high-risk AI systems and unless provided otherwise under this Regulation, closely cooperate with the providers of the relevant high-risk AI systems to enable their compliance with  the  relevant  obligations  under  this  Regulation  and  with  the  competent  authorities  established  under  this Regulation.\n(86) Where, under  the  conditions  laid  down  in  this  Regulation,  the  provider  that  initially  placed  the  AI  system  on  the market or put it into service should no longer be considered to be the provider for the purposes of this Regulation, and  when  that  provider  has  not  expressly  excluded  the  change  of  the  AI  system  into  a  high-risk  AI  system,  the former provider should nonetheless closely cooperate and make available the necessary information and provide the reasonably expected technical access and other assistance that are required for  the fulfilment of  the obligations set out  in  this  Regulation,  in  particular  regarding  the  compliance  with  the  conformity  assessment  of  high-risk  AI systems.\n(87) In  addition,  where  a  high-risk  AI  system  that  is  a  safety  component  of  a  product  which  falls  within  the  scope  of Union harmonisation legislation based on the New Legislative Framework is not placed on the market or  put into service  independently  from  the  product,  the  product  manufacturer  defined  in  that  legislation  should  comply  with the  obligations  of  the  provider  established  in  this  Regulation  and  should,  in  particular,  ensure  that  the  AI  system embedded in the final  product  complies  with  the  requirements  of  this  Regulation.\n(88) Along  the  AI  value  chain  multiple  parties  often  supply  AI  systems,  tools  and  services  but  also  components  or processes  that  are  incorporated  by  the  provider  into  the  AI  system  with  various  objectives,  including  the  model training,  model  retraining,  model  testing  and  evaluation,  integration  into  software,  or  other  aspects  of  model development. Those parties have an important role to play in the value chain towards the provider of the high-risk AI system into which their AI systems, tools, services, components or processes are integrated, and should provide by written agreement this provider with the necessary information, capabilities, technical access and other assistance based  on  the  generally  acknowledged  state  of  the  art,  in  order  to  enable  the  provider  to  fully  comply  with  the obligations set out in this Regulation, without compromising their own intellectual property rights or trade secrets.\n(89) Third  parties  making  accessible  to  the  public  tools,  services,  processes,  or  AI  components  other  than general-purpose  AI  models,  should  not  be  mandated  to  comply  with  requirements  targeting  the  responsibilities along  the  AI  value  chain,  in  particular  towards  the  provider  that  has  used  or  integrated  them,  when  those  tools, services, processes, or AI components are made accessible under a free and open-source licence. Developers of free and  open-source  tools,  services,  processes,  or  AI  components  other  than  general-purpose  AI  models  should  be encouraged to implement widely adopted documentation practices, such as model cards and data sheets, as a way to accelerate  information sharing along the AI value chain, allowing the promotion of  trustworthy AI systems in the Union.\n(90) The Commission could develop and recommend voluntary model contractual terms between providers of high-risk AI  systems  and  third  parties  that  supply  tools,  services,  components  or  processes  that  are  used  or  integrated  in high-risk  AI  systems,  to  facilitate  the  cooperation  along  the  value  chain.  When  developing  voluntary  model contractual  terms,  the  Commission  should  also  take  into  account  possible  contractual  requirements  applicable  in specific  sectors  or  business  cases.\n(91) Given  the  nature  of  AI  systems  and  the  risks  to  safety  and  fundamental  rights  possibly  associated  with  their  use, including as regards the need to ensure proper monitoring of the performance of an AI system in a real-life setting, it is appropriate to set specific responsibilities for deployers. Deployers should in particular take appropriate technical and organisational measures to ensure they use high-risk AI systems in accordance with the instructions of use and certain other obligations should be provided for with regard to monitoring of the functioning of the AI systems and with  regard  to  record-keeping,  as  appropriate.  Furthermore,  deployers  should  ensure  that  the  persons  assigned  to implement  the  instructions  for  use  and  human  oversight  as  set  out  in  this  Regulation  have  the  necessary\ncompetence, in particular an adequate level of AI literacy, training and authority to properly fulfil those tasks. Those obligations  should  be  without  prejudice  to  other  deployer  obligations  in  relation  to  high-risk  AI  systems  under Union or  national  law.\n(92) This  Regulation  is  without  prejudice  to  obligations  for  employers  to  inform  or  to  inform  and  consult  workers  or their  representatives  under  Union  or  national  law  and  practice,  including  Directive  2002/14/EC  of  the  European Parliament and of the Council ( 39 ),  on decisions to put into service or use AI systems. It remains necessary to ensure information  of  workers  and  their  representatives  on  the  planned  deployment  of  high-risk  AI  systems  at  the workplace  where  the  conditions  for  those  information  or  information  and  consultation  obligations  in  other  legal instruments  are  not  fulfilled.  Moreover,  such  information  right  is  ancillary  and  necessary  to  the  objective  of protecting  fundamental  rights  that  underlies  this  Regulation.  Therefore,  an  information  requirement  to  that  effect should be laid  down  in  this  Regulation,  without  affecting  any existing  rights  of  workers.\n(93) Whilst risks related  to AI  systems can  result  from  the  way  such  systems are  designed,  risks  can  as  well  stem  from how  such  AI  systems  are  used.  Deployers  of  high-risk  AI  system  therefore  play  a  critical  role  in  ensuring  that fundamental rights are protected,  complementing  the obligations  of  the  provider  when  developing  the  AI  system. Deployers  are  best  placed  to  understand  how  the  high-risk  AI  system  will  be  used  concretely  and  can  therefore identify potential significant risks that were not foreseen in the development phase, due to a more precise knowledge of the context of use, the persons or groups of persons likely to be affected, including vulnerable groups. Deployers of high-risk AI systems listed in an annex to this Regulation also play a critical role in informing natural persons and should, when they make decisions or assist in making decisions related to natural persons, where applicable, inform the natural persons that they are subject to the use of the high-risk AI system. This information should include the intended  purpose  and  the  type  of  decisions  it  makes.  The  deployer  should  also  inform  the  natural  persons  about their  right  to  an  explanation  provided  under  this  Regulation.  With  regard  to  high-risk  AI  systems  used  for  law enforcement  purposes,  that  obligation  should  be  implemented  in  accordance  with  Article  13  of  Directive  (EU) 2016/680.\n(94) Any processing of biometric data involved in the use of AI systems for biometric identification for  the purpose of law  enforcement  needs  to  comply  with  Article  10  of  Directive  (EU)  2016/680,  that  allows  such  processing  only where strictly necessary, subject to appropriate safeguards for the rights and freedoms of the data subject, and where authorised by Union or Member State law. Such use, when authorised, also needs to respect the principles laid down in  Article  4  (1)  of  Directive  (EU)  2016/680  including  lawfulness,  fairness  and  transparency,  purpose  limitation, accuracy and storage limitation.\n(95) Without prejudice to applicable Union law, in particular  Regulation (EU) 2016/679 and Directive (EU) 2016/680, considering the intrusive nature of post-remote biometric identification systems, the use of post-remote biometric identification systems should be subject to safeguards. Post-remote biometric identification systems should always be used in a way that is proportionate, legitimate and strictly necessary, and thus targeted, in terms of the individuals to be identified,  the  location,  temporal scope and based on a closed data set of  legally acquired video footage. In any case, post-remote biometric identification systems should not be used in the framework of  law enforcement to lead to  indiscriminate  surveillance.  The  conditions  for  post-remote  biometric  identification  should  in  any  case  not provide a basis to circumvent the conditions of the prohibition and strict exceptions for real time remote biometric identification.\n(96) In order to efficiently ensure that fundamental rights are protected, deployers of high-risk AI systems that are bodies governed by public law, or  private entities  providing public services  and deployers of  certain high-risk  AI  systems listed  in  an  annex  to  this  Regulation,  such  as  banking  or  insurance  entities,  should  carry out  a  fundamental  rights impact assessment prior to putting it into use. Services important for individuals that are of public nature may also be provided by private entities. Private entities providing such public services are linked to tasks in the public interest such  as  in  the  areas  of  education,  healthcare,  social  services,  housing,  administration  of  justice.  The  aim  of  the fundamental rights impact assessment is for the deployer to identify the specific risks to the rights of individuals or groups of individuals likely to be affected, identify measures to be taken in the case of a materialisation of those risks. The  impact  assessment  should  be  performed  prior  to  deploying  the  high-risk  AI  system,  and  should  be  updated"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_8",
    "chunk_content": "Whereas:\nwhen the deployer considers that any of  the relevant factors have changed. The impact assessment should identify the deployer's relevant processes in which the high-risk AI system will be used in line with its intended purpose, and should include a description of the period of time and frequency in which the system is intended to be used as well as of specific categories of natural persons and groups who are likely to be affected in the specific context of use. The assessment  should  also  include  the  identification  of  specific  risks  of  harm  likely  to  have  an  impact  on  the fundamental  rights  of  those  persons  or  groups.  While  performing  this  assessment,  the  deployer  should  take  into account  information  relevant  to  a  proper  assessment  of  the  impact,  including  but  not  limited  to  the  information given by the provider of the high-risk AI system in the instructions for use. In light of the risks identified, deployers should  determine  measures  to  be  taken  in  the  case  of  a  materialisation  of  those  risks,  including  for  example governance arrangements in that specific context of use, such as arrangements for human oversight according to the instructions of use or, complaint handling and redress procedures, as they could be instrumental in mitigating risks to fundamental rights in concrete use-cases. After performing that impact assessment, the deployer should notify the relevant market surveillance authority. Where appropriate, to collect relevant information necessary to perform the impact  assessment,  deployers  of  high-risk  AI  system,  in  particular  when  AI  systems  are  used  in  the  public  sector, could involve relevant stakeholders, including the representatives of groups of persons likely to be affected by the AI system,  independent experts,  and  civil  society organisations in  conducting  such  impact  assessments  and  designing measures to be taken in the case of materialisation of the risks. The European Artificial Intelligence Office (AI Office) should develop a template for a questionnaire in order to facilitate compliance and reduce the administrative burden for  deployers.\n(97) The notion of general-purpose AI models should be clearly defined and set apart from the notion of AI systems to enable legal certainty. The definition should be based on the key functional characteristics of a general-purpose AI model, in particular  the generality and the capability to competently perform a wide range of distinct tasks. These models  are  typically  trained  on  large  amounts  of  data,  through  various  methods,  such  as  self-supervised, unsupervised or reinforcement learning. General-purpose AI models may be placed on the market in various ways, including  through  libraries,  application  programming  interfaces  (APIs),  as  direct  download,  or  as  physical  copy. These  models  may  be  further  modified  or  fine-tuned  into  new  models.  Although  AI  models  are  essential components of AI systems, they do not constitute AI systems on their own. AI models require the addition of further components, such as for example a user interface, to become AI systems. AI models are typically integrated into and form  part  of  AI  systems.  This  Regulation  provides  specific  rules  for  general-purpose  AI  models  and  for general-purpose AI models that pose systemic risks, which should apply also when these models are integrated or form  part  of  an  AI  system.  It  should  be  understood  that  the  obligations  for  the  providers  of  general-purpose  AI models  should  apply  once  the  general-purpose  AI  models  are  placed  on  the  market.  When  the  provider  of a general-purpose AI model integrates an own model into its own AI system that is made available on the market or put into service, that model should be considered to be placed on the market and, therefore, the obligations in this Regulation for models should continue to apply in addition to those for AI systems. The obligations laid down for models should in any case not apply when an own model is used for purely internal processes that are not essential for  providing a product or a service to third parties and the rights of natural persons are not affected. Considering their  potential  significantly  negative  effects,  the  general-purpose  AI  models  with  systemic  risk  should  always  be subject to the relevant obligations under this Regulation. The definition should not cover AI models used before their placing  on  the  market  for  the  sole  purpose  of  research,  development  and  prototyping  activities.  This  is  without prejudice to the obligation to comply with this Regulation when, following such activities, a model is placed on the market.\n(98) Whereas the generality of a model could, inter alia, also be determined by a number of parameters, models with at least  a  billion  of  parameters  and  trained  with  a  large  amount  of  data  using  self-supervision  at  scale  should  be considered  to  display  significant  generality  and  to  competently  perform  a  wide  range  of  distinctive  tasks.\n(99) Large generative AI models are a typical example for a general-purpose AI model, given that they allow for flexible generation  of  content,  such  as  in  the  form  of  text,  audio,  images  or  video,  that  can  readily  accommodate  a  wide range  of  distinctive  tasks.\n(100) When a general-purpose AI model is integrated into or forms part of an AI system, this system should be considered to  be  general-purpose  AI  system  when,  due  to  this  integration,  this  system  has  the  capability  to  serve  a  variety  of purposes. A general-purpose AI system can be used directly,  or  it  may  be  integrated  into other  AI  systems.\n(101) Providers  of  general-purpose  AI  models  have  a  particular  role  and  responsibility  along  the  AI  value  chain,  as  the models  they  provide  may  form  the  basis  for  a  range  of  downstream  systems,  often  provided  by  downstream providers that necessitate a good understanding of the models and their capabilities, both to enable the integration of such  models  into  their  products,  and  to  fulfil  their  obligations  under  this  or  other  regulations.  Therefore, proportionate  transparency  measures  should  be  laid  down,  including  the  drawing  up  and  keeping  up  to  date  of documentation, and the provision of information on the general-purpose AI model for its usage by the downstream providers.  Technical  documentation  should  be  prepared  and  kept  up  to  date  by  the  general-purpose  AI  model provider  for  the  purpose  of  making  it  available,  upon  request,  to  the  AI  Office  and  the  national  competent authorities. The minimal set of elements to be included in such documentation should be set out in specific annexes to  this  Regulation.  The  Commission  should  be empowered to amend those annexes by means of delegated acts in light  of  evolving  technological  developments.\n(102) Software and data, including models, released under a free and open-source licence that allows them to be openly shared  and  where  users  can  freely  access,  use,  modify  and  redistribute  them  or  modified  versions  thereof,  can contribute to research and innovation in the market and can provide significant growth opportunities for the Union economy. General-purpose AI models released under free and open-source licences should be considered to ensure high levels of  transparency and openness if  their  parameters, including the weights, the information on the model architecture, and the information on model usage are made publicly available. The licence should be considered to be free and open-source also when it allows users to run, copy, distribute, study, change and improve software and data, including models under the condition that the original provider of the model is credited, the identical or comparable terms  of  distribution  are  respected.\n(103) Free  and  open-source  AI  components  covers  the  software  and  data,  including  models  and  general-purpose  AI models, tools, services or processes of an AI system. Free and open-source AI components can be provided through different  channels,  including  their  development  on  open  repositories.  For  the  purposes  of  this  Regulation,  AI components that are provided against a price or otherwise monetised, including through the provision of technical support  or  other  services,  including  through  a  software  platform,  related  to  the  AI  component,  or  the  use  of personal data for reasons other  than exclusively for  improving the security, compatibility or interoperability of  the software,  with  the  exception  of  transactions  between  microenterprises,  should  not  benefit  from  the  exceptions provided  to  free  and  open-source  AI  components.  The  fact  of  making  AI  components  available  through  open repositories  should  not,  in  itself,  constitute  a  monetisation.\n(104) The  providers  of  general-purpose  AI  models  that  are  released  under  a  free  and  open-source  licence,  and  whose parameters, including the weights, the information on the model architecture, and the information on model usage, are  made  publicly  available  should  be  subject  to  exceptions  as  regards  the  transparency-related  requirements imposed on general-purpose AI models, unless they can be considered to present a systemic risk, in which case the circumstance that the model is transparent and accompanied by an open-source license should not be considered to be a sufficient reason to exclude compliance with the obligations under  this Regulation. In any case, given that the release  of  general-purpose  AI  models  under  free  and  open-source  licence  does  not  necessarily  reveal  substantial information on the data set used for the training or fine-tuning of the model and on how compliance of copyright law  was  thereby  ensured,  the  exception  provided  for  general-purpose  AI  models  from  compliance  with  the transparency-related requirements should not concern the obligation to produce a summary about the content used for  model training and the obligation to put in place a policy to comply with Union copyright law, in particular to identify  and  comply  with  the  reservation  of  rights  pursuant  to  Article  4(3)  of  Directive  (EU)  2019/790  of  the European Parliament and of  the Council ( 40 ).\n(105) General-purpose AI models, in particular large generative AI models, capable of generating text, images, and other content, present unique innovation opportunities but also challenges to artists, authors, and other creators and the way their creative content is created, distributed, used and consumed. The development and training of such models require access to vast amounts of text, images, videos and other data. Text and data mining techniques may be used extensively in this context for  the retrieval and analysis of such content, which may be protected by copyright and related  rights.  Any  use  of  copyright  protected  content  requires  the  authorisation  of  the  rightsholder  concerned unless  relevant  copyright  exceptions  and  limitations  apply.  Directive  (EU)  2019/790  introduced  exceptions  and limitations allowing reproductions and extractions of works or other subject matter, for the purpose of text and data\nmining,  under  certain  conditions.  Under  these  rules,  rightsholders  may  choose  to  reserve  their  rights  over  their works  or  other  subject  matter  to  prevent  text  and  data  mining,  unless  this  is  done  for  the  purposes  of  scientific research.  Where  the  rights  to  opt  out  has  been  expressly  reserved  in  an  appropriate  manner,  providers  of general-purpose  AI  models  need  to  obtain  an  authorisation  from  rightsholders  if  they  want  to  carry  out  text  and data  mining  over  such  works.\n(106) Providers  that  place  general-purpose  AI  models  on  the  Union  market  should  ensure  compliance  with  the  relevant obligations in this Regulation. To that end, providers of general-purpose AI models should put in place a policy to comply with Union law on copyright and related rights, in particular to identify and comply with the reservation of rights  expressed  by  rightsholders  pursuant  to  Article  4(3)  of  Directive  (EU)  2019/790.  Any  provider  placing a general-purpose AI model on the Union market should comply with this obligation, regardless of the jurisdiction in which the copyright-relevant acts underpinning the training of those general-purpose AI models take place. This is necessary to ensure a level playing field among providers of general-purpose AI models where no provider should be  able  to  gain  a  competitive  advantage  in  the  Union  market  by  applying  lower  copyright  standards  than  those provided  in  the  Union.\n(107) In  order  to  increase  transparency  on  the  data  that  is  used  in  the  pre-training  and  training  of  general-purpose  AI models, including text and data protected by copyright law, it is adequate that providers of such models draw up and make  publicly  available  a  sufficiently  detailed  summary  of  the  content  used  for  training  the  general-purpose  AI model. While taking into due account the need to protect trade secrets and confidential business information, this summary  should  be  generally  comprehensive  in  its  scope  instead  of  technically  detailed  to  facilitate  parties  with legitimate interests, including copyright holders, to exercise and enforce their rights under Union law, for example by listing the main data collections or sets that went into training the model, such as large private or public databases or data archives, and by providing a narrative explanation about other data sources used. It is appropriate for  the AI Office to provide a template for the summary, which should be simple, effective, and allow the provider to provide the  required  summary  in  narrative  form.\n(108) With  regard  to  the  obligations  imposed  on  providers  of  general-purpose  AI  models  to  put  in  place  a  policy  to comply with Union copyright law and make publicly available a summary of the content used for the training, the AI Office  should  monitor  whether  the  provider  has  fulfilled  those  obligations  without  verifying  or  proceeding  to a  work-by-work assessment of  the training data in terms of copyright compliance. This Regulation does not affect the  enforcement of  copyright  rules  as  provided  for  under  Union  law.\n(109) Compliance with the obligations applicable to the providers of general-purpose AI models should be commensurate and proportionate to the type of model provider, excluding the need for compliance for persons who develop or use models for non-professional or scientific research purposes, who should nevertheless be encouraged to voluntarily comply  with  these  requirements.  Without  prejudice  to  Union  copyright  law,  compliance  with  those  obligations should  take  due  account  of  the  size  of  the  provider  and  allow  simplified  ways  of  compliance  for  SMEs,  including start-ups,  that  should  not  represent  an  excessive  cost  and  not  discourage  the  use  of  such  models.  In  the  case  of a  modification  or  fine-tuning  of  a  model,  the  obligations  for  providers  of  general-purpose  AI  models  should  be limited  to  that  modification  or  fine-tuning,  for  example  by  complementing  the  already  existing  technical documentation with information on the modifications, including new training data sources, as a means to comply with the  value  chain  obligations  provided  in  this  Regulation.\n(110) General-purpose AI models could pose systemic risks which include, but are not limited to, any actual or reasonably foreseeable negative effects in relation to major accidents, disruptions of critical sectors and serious consequences to public health and safety; any actual or  reasonably foreseeable negative effects on democratic processes, public and economic security; the dissemination of illegal, false, or discriminatory content. Systemic risks should be understood to  increase  with  model  capabilities  and  model  reach,  can  arise  along  the  entire  lifecycle  of  the  model,  and  are influenced  by conditions of misuse, model reliability, model  fairness and  model security,  the level of autonomy of\nthe  model,  its  access  to  tools,  novel  or  combined  modalities,  release  and  distribution  strategies,  the  potential  to remove  guardrails  and  other  factors.  In  particular,  international  approaches  have  so  far  identified  the  need  to  pay attention  to  risks  from  potential  intentional  misuse  or  unintended  issues  of  control  relating  to  alignment  with human intent; chemical, biological, radiological, and nuclear risks, such as the ways in which barriers to entry can be lowered,  including  for  weapons  development,  design  acquisition,  or  use;  offensive  cyber  capabilities,  such  as  the ways in vulnerability  discovery,  exploitation,  or  operational  use  can  be  enabled;  the  effects  of  interaction  and  tool use,  including  for  example  the  capacity  to  control  physical  systems  and  interfere  with  critical  infrastructure;  risks from models of making copies of themselves or 'self-replicating' or training other models; the ways in which models can give rise to harmful bias and discrimination with risks to individuals, communities or societies; the facilitation of disinformation or harming privacy with threats to democratic values and human rights; risk that a particular event could  lead  to  a  chain  reaction  with  considerable  negative  effects  that  could  affect  up  to  an  entire  city,  an  entire domain activity or  an  entire  community.\n(111) It  is  appropriate to establish a methodology for  the classification of general-purpose AI models as general-purpose AI  model  with  systemic  risks.  Since  systemic  risks  result  from  particularly  high  capabilities,  a  general-purpose  AI model  should  be  considered  to  present  systemic  risks  if  it  has  high-impact  capabilities,  evaluated  on  the  basis  of appropriate  technical  tools  and  methodologies,  or  significant  impact  on  the  internal  market  due  to  its  reach. High-impact  capabilities  in  general-purpose  AI  models  means  capabilities  that  match  or  exceed  the  capabilities recorded in the most advanced general-purpose AI models. The full range of capabilities in a model could be better understood after its placing on the market or when deployers interact with the model. According to the state of the art at the time of entry into force of this Regulation, the cumulative amount of computation used for the training of the general-purpose AI model measured in floating point operations is one of the relevant approximations for model capabilities.  The  cumulative  amount  of  computation  used  for  training  includes  the  computation  used  across  the activities  and  methods  that  are  intended  to  enhance  the  capabilities  of  the  model  prior  to  deployment,  such  as pre-training,  synthetic  data  generation  and  fine-tuning.  Therefore,  an  initial  threshold  of  floating  point  operations should  be  set,  which,  if  met  by  a  general-purpose  AI  model,  leads  to  a  presumption  that  the  model  is a general-purpose AI model with systemic risks. This threshold should be adjusted over time to reflect technological and  industrial  changes,  such  as  algorithmic  improvements  or  increased  hardware  efficiency,  and  should  be supplemented  with  benchmarks  and  indicators  for  model  capability.  To  inform  this,  the  AI  Office  should  engage with the scientific community, industry, civil society and other experts. Thresholds, as well as tools and benchmarks for  the  assessment  of  high-impact  capabilities,  should  be  strong  predictors  of  generality,  its  capabilities  and associated systemic risk of general-purpose AI models, and could take into account the way the model will be placed on the market or the number of users it may affect. To complement this system, there should be a possibility for the Commission  to  take  individual  decisions  designating  a  general-purpose  AI  model  as  a  general-purpose  AI  model with systemic risk if it is found that such model has capabilities or an impact equivalent to those captured by the set threshold. That decision should be taken on the basis of an overall assessment of the criteria for the designation of a general-purpose AI model with systemic risk set out in an annex to this Regulation, such as quality or size of the training  data  set,  number  of  business  and  end  users,  its  input  and  output  modalities,  its  level  of  autonomy  and scalability, or  the tools it has access to. Upon a reasoned request of a provider whose model has been designated as a  general-purpose  AI  model  with  systemic  risk,  the  Commission  should  take  the  request  into  account  and  may decide  to  reassess  whether  the  general-purpose  AI  model  can  still  be  considered  to  present  systemic  risks.\n(112) It  is  also  necessary  to  clarify  a  procedure  for  the  classification  of  a  general-purpose  AI  model  with  systemic  risks. A general-purpose AI model that meets the applicable threshold for high-impact capabilities should be presumed to be a general-purpose AI models with systemic risk. The provider should notify the AI Office at the latest two weeks after  the  requirements  are  met  or  it  becomes  known  that  a  general-purpose  AI  model  will  meet  the  requirements that  lead  to  the  presumption.  This  is  especially  relevant  in  relation  to  the  threshold  of  floating  point  operations because training of general-purpose AI models takes considerable planning which includes the upfront allocation of compute resources and, therefore,  providers  of  general-purpose  AI  models  are  able  to  know  if  their  model  would meet the threshold before the training is completed. In the context of that notification, the provider should be able to demonstrate that, because of its specific characteristics, a general-purpose AI model exceptionally does not present systemic  risks,  and  that  it  thus  should  not  be  classified  as  a  general-purpose  AI  model  with  systemic  risks.  That information is valuable for the AI Office to anticipate the placing on the market of general-purpose AI models with systemic  risks  and  the  providers  can  start  to  engage  with  the  AI  Office  early  on.  That  information  is  especially\nimportant with regard to general-purpose AI models that are planned to be released as open-source, given that, after the open-source model release, necessary measures to ensure compliance with the obligations under this Regulation may be more difficult to implement.\n(113) If  the Commission becomes aware of the fact that a general-purpose AI model meets the requirements to classify as a  general-purpose  AI  model  with  systemic  risk,  which  previously  had  either  not  been  known  or  of  which  the relevant  provider  has  failed  to  notify  the  Commission,  the  Commission  should  be  empowered  to  designate  it  so. A system of qualified alerts should ensure that the AI Office is made aware by the scientific panel of general-purpose AI  models  that  should  possibly  be  classified  as  general-purpose  AI  models  with  systemic  risk,  in  addition  to  the monitoring activities  of  the  AI  Office.\n(114) The  providers  of  general-purpose  AI  models  presenting  systemic  risks  should  be  subject,  in  addition  to  the obligations provided for providers of general-purpose AI models, to obligations aimed at identifying and mitigating those  risks  and  ensuring  an  adequate  level  of  cybersecurity  protection,  regardless  of  whether  it  is  provided  as a standalone model or embedded in an AI system or a product. To achieve those objectives, this Regulation should require providers to perform the necessary model evaluations, in particular prior  to its first placing on the market, including  conducting  and  documenting  adversarial  testing  of  models,  also,  as  appropriate,  through  internal  or independent  external  testing.  In  addition,  providers  of  general-purpose  AI  models  with  systemic  risks  should continuously assess and mitigate systemic risks, including for example by putting in place risk-management policies, such  as  accountability  and  governance  processes,  implementing  post-market  monitoring,  taking  appropriate measures along the entire  model's  lifecycle  and  cooperating  with  relevant  actors  along  the  AI  value  chain.\n(115) Providers  of  general-purpose  AI  models  with  systemic  risks  should  assess  and  mitigate  possible  systemic  risks.  If, despite efforts to identify and prevent risks related to a general-purpose AI model that may present systemic risks, the  development  or  use  of  the  model  causes  a  serious  incident,  the  general-purpose  AI  model  provider  should without undue delay keep track of the incident and report any relevant information and possible corrective measures to  the  Commission and national competent authorities. Furthermore, providers should ensure an adequate level of cybersecurity protection for the model and its physical infrastructure, if appropriate, along the entire model lifecycle. Cybersecurity  protection  related  to  systemic  risks  associated  with  malicious  use  or  attacks  should  duly  consider accidental model leakage, unauthorised releases, circumvention of safety measures, and defence against cyberattacks, unauthorised  access  or  model  theft.  That  protection  could  be  facilitated  by  securing  model  weights,  algorithms, servers, and data sets, such as through operational security measures for information security, specific cybersecurity policies,  adequate  technical  and  established  solutions,  and  cyber  and  physical  access  controls,  appropriate  to  the relevant  circumstances  and  the  risks  involved.\n(116) The AI Office should encourage and facilitate the drawing up, review and adaptation of codes of practice, taking into account  international  approaches.  All  providers  of  general-purpose  AI  models  could  be  invited  to  participate.  To ensure that the codes of practice reflect the state of the art and duly take into account a diverse set of perspectives, the AI Office should collaborate with relevant national competent authorities, and could, where appropriate, consult with  civil  society  organisations  and  other  relevant  stakeholders  and  experts,  including  the  Scientific  Panel,  for  the drawing up of such codes. Codes of practice should cover obligations  for  providers of  general-purpose AI  models and of general-purpose AI models presenting systemic risks. In addition, as regards systemic risks, codes of practice should help to establish a risk taxonomy of the type and nature of the systemic risks at Union level, including their sources.  Codes  of  practice  should  also  be  focused  on  specific  risk  assessment  and  mitigation  measures.\n(117) The codes of practice  should  represent  a  central  tool  for  the  proper  compliance  with  the  obligations  provided  for under  this  Regulation  for  providers  of  general-purpose  AI  models.  Providers  should  be  able  to  rely  on  codes  of practice  to  demonstrate  compliance  with  the  obligations.  By  means  of  implementing  acts,  the  Commission  may decide  to  approve  a  code  of  practice  and  give  it  a  general  validity  within  the  Union,  or,  alternatively,  to  provide common rules for the implementation of the relevant obligations, if, by the time this Regulation becomes applicable, a  code  of  practice  cannot  be  finalised  or  is  not  deemed  adequate by the  AI  Office.  Once  a  harmonised  standard  is\npublished and assessed as suitable  to cover  the  relevant obligations  by the  AI  Office,  compliance  with  a  European harmonised  standard  should  grant  providers  the  presumption  of  conformity.  Providers  of  general-purpose  AI models should furthermore be able to demonstrate compliance using alternative adequate means, if codes of practice or  harmonised standards  are  not  available,  or  they choose  not  to  rely on  those."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_9",
    "chunk_content": "Whereas:\n(118) This Regulation regulates AI systems and AI models by imposing certain requirements and obligations for relevant market actors that are placing them on the market, putting into service or use in the Union, thereby complementing obligations for providers of intermediary services that embed such systems or models into their services regulated by Regulation  (EU)  2022/2065.  To  the  extent  that  such  systems  or  models  are  embedded  into  designated  very  large online platforms or  very large online search engines, they are subject to the risk-management framework provided for  in  Regulation  (EU)  2022/2065.  Consequently,  the  corresponding  obligations  of  this  Regulation  should  be presumed to be fulfilled, unless significant systemic risks not covered by Regulation (EU) 2022/2065 emerge and are identified  in  such  models.  Within  this  framework,  providers  of  very  large  online  platforms  and  very  large  online search engines are obliged to assess potential systemic risks stemming from the design, functioning and use of their services, including how the design of algorithmic systems used in the service may contribute to such risks, as well as systemic  risks  stemming  from  potential  misuses.  Those  providers  are  also  obliged  to  take  appropriate  mitigating measures in observance of fundamental rights.\n(119) Considering  the  quick  pace  of  innovation  and  the  technological  evolution  of  digital  services  in  scope  of  different instruments  of  Union  law  in  particular  having  in  mind  the  usage  and  the  perception  of  their  recipients,  the  AI systems subject to this Regulation may be provided as intermediary services or parts thereof within the meaning of Regulation (EU) 2022/2065, which should be interpreted in a technology-neutral manner. For example, AI systems may be used to provide online search engines, in particular, to the extent that an AI system such as an online chatbot performs searches of, in principle, all websites, then incorporates the results into its existing knowledge and uses the updated knowledge to generate a single output that  combines different sources  of  information.\n(120) Furthermore, obligations placed on providers and deployers of certain AI systems in this Regulation to enable the detection and disclosure that the outputs of those systems are artificially generated or manipulated are particularly relevant to facilitate the effective implementation of Regulation (EU) 2022/2065. This applies in particular as regards the  obligations  of  providers  of  very  large  online  platforms  or  very  large  online  search  engines  to  identify  and mitigate  systemic  risks  that  may  arise  from  the  dissemination  of  content  that  has  been  artificially  generated  or manipulated, in particular risk of the actual or foreseeable negative effects on democratic processes, civic discourse and electoral  processes,  including  through  disinformation.\n(121) Standardisation  should  play  a  key  role  to  provide  technical  solutions  to  providers  to  ensure  compliance  with  this Regulation,  in  line  with  the  state  of  the  art,  to  promote  innovation  as  well  as  competitiveness  and  growth  in  the single  market.  Compliance  with  harmonised  standards  as  defined  in  Article  2,  point  (1)(c),  of  Regulation  (EU) No 1025/2012 of the European Parliament and of the Council ( 41 ),  which are normally expected to reflect the state of  the  art,  should  be  a  means  for  providers  to  demonstrate  conformity  with  the  requirements  of  this  Regulation. A  balanced  representation  of  interests  involving  all  relevant  stakeholders  in  the  development  of  standards,  in particular  SMEs,  consumer organisations and environmental and social stakeholders in accordance with Articles 5 and  6  of  Regulation  (EU)  No  1025/2012  should  therefore  be  encouraged.  In  order  to  facilitate  compliance,  the standardisation  requests  should  be  issued  by  the  Commission  without  undue  delay.  When  preparing  the standardisation  request,  the  Commission  should  consult  the  advisory  forum  and  the  Board  in  order  to  collect relevant expertise. However, in the absence of relevant references to harmonised standards, the Commission should be able to establish, via implementing acts, and after consultation of the advisory forum, common specifications for certain requirements under this Regulation. The common specification should be an exceptional fall back solution to facilitate  the  provider's  obligation  to  comply  with  the  requirements  of  this  Regulation,  when  the  standardisation request  has  not  been  accepted  by  any  of  the  European  standardisation  organisations,  or  when  the  relevant harmonised standards insufficiently address fundamental rights concerns, or when the harmonised standards do not comply with the request, or  when there are delays in the adoption of an appropriate harmonised standard. Where such a delay in the adoption of a harmonised standard is due to the technical complexity of that standard, this should\nbe  considered  by  the  Commission  before  contemplating  the  establishment  of  common  specifications.  When developing  common  specifications,  the  Commission  is  encouraged  to  cooperate  with  international  partners  and international  standardisation  bodies.\n(122) It is appropriate that, without prejudice to the use of harmonised standards and common specifications, providers of a  high-risk  AI  system  that  has  been  trained  and  tested  on  data  reflecting  the  specific  geographical,  behavioural, contextual or functional setting within which the AI system is intended to be used, should be presumed to comply with  the  relevant  measure  provided  for  under  the  requirement  on  data  governance  set  out  in  this  Regulation. Without prejudice to the requirements related to robustness and accuracy set out in this Regulation, in accordance with  Article  54(3)  of  Regulation  (EU)  2019/881,  high-risk  AI  systems  that  have  been  certified  or  for  which a  statement  of  conformity  has  been  issued  under  a  cybersecurity  scheme  pursuant  to  that  Regulation  and  the references of which have been published in the Official Journal of the European Union should be presumed to comply with  the  cybersecurity  requirement  of  this  Regulation  in  so  far  as  the  cybersecurity  certificate  or  statement  of conformity or parts thereof cover the cybersecurity requirement of this Regulation. This remains without prejudice to  the  voluntary  nature  of  that  cybersecurity  scheme.\n(123) In  order  to  ensure  a  high  level  of  trustworthiness  of  high-risk  AI  systems,  those  systems  should  be  subject  to a  conformity  assessment  prior  to  their  placing  on  the  market  or  putting  into  service.\n(124) It is appropriate that, in order to minimise the burden on operators and avoid any possible duplication, for high-risk AI  systems  related  to  products  which  are  covered  by  existing  Union  harmonisation  legislation  based  on  the  New Legislative  Framework,  the  compliance  of  those  AI  systems  with  the  requirements  of  this  Regulation  should  be assessed as part of the conformity assessment already provided for in that law. The applicability of the requirements of  this  Regulation  should  thus  not  affect  the  specific  logic,  methodology  or  general  structure  of  conformity assessment under  the relevant  Union  harmonisation  legislation.\n(125) Given the complexity of high-risk AI systems and the risks that are associated with them, it is important to develop an  adequate  conformity  assessment  procedure  for  high-risk  AI  systems  involving  notified  bodies,  so-called  third party conformity assessment. However, given the current experience of professional pre-market certifiers in the field of  product safety  and  the  different  nature  of  risks  involved,  it  is  appropriate to  limit,  at  least  in  an  initial  phase  of application  of  this  Regulation,  the  scope  of  application  of  third-party  conformity  assessment  for  high-risk  AI systems  other  than  those  related  to  products.  Therefore,  the  conformity  assessment  of  such  systems  should  be carried  out  as  a  general  rule  by  the  provider  under  its  own  responsibility,  with  the  only  exception  of  AI  systems intended  to  be  used  for  biometrics.\n(126) In order to carry out third-party conformity assessments when so required, notified bodies should be notified under this  Regulation  by  the  national  competent  authorities,  provided  that  they  comply  with  a  set  of  requirements,  in particular  on  independence, competence,  absence of conflicts  of  interests  and  suitable  cybersecurity  requirements. Notification  of  those  bodies  should  be  sent  by  national  competent  authorities  to  the  Commission  and  the  other Member States by means of the electronic notification tool developed and managed by the Commission pursuant to Article  R23  of  Annex  I  to  Decision  No  768/2008/EC.\n(127) In line with Union commitments under the World Trade Organization Agreement on Technical Barriers to Trade, it is adequate to facilitate the  mutual  recognition  of  conformity  assessment  results  produced  by competent conformity assessment  bodies,  independent  of  the  territory  in  which  they  are  established,  provided  that  those  conformity assessment bodies established under the law of a third country meet the applicable requirements of this Regulation and the Union has concluded an agreement to that extent. In this context, the Commission should actively explore possible  international  instruments  for  that  purpose  and  in particular  pursue  the  conclusion  of  mutual  recognition agreements with third  countries.\n(128) In  line  with  the  commonly  established  notion  of  substantial  modification  for  products  regulated  by  Union harmonisation  legislation,  it  is  appropriate  that  whenever  a  change  occurs  which  may  affect  the  compliance  of a  high-risk  AI  system with  this  Regulation  (e.g.  change of operating  system  or  software  architecture),  or  when  the intended purpose of the system changes, that AI system should be considered to be a new AI system which should undergo  a  new  conformity  assessment.  However,  changes  occurring  to  the  algorithm  and  the  performance  of  AI systems  which  continue  to  'learn'  after  being  placed  on  the  market  or  put  into  service,  namely  automatically adapting  how  functions  are  carried  out,  should  not  constitute  a  substantial  modification,  provided  that  those changes have been pre-determined by the provider and  assessed at the  moment of  the  conformity  assessment.\n(129) High-risk AI systems should bear the CE marking to indicate their conformity with this Regulation so that they can move freely  within  the  internal  market.  For  high-risk  AI  systems  embedded  in  a  product,  a  physical  CE  marking should  be  affixed,  and  may  be  complemented  by  a  digital  CE  marking.  For  high-risk  AI  systems  only  provided digitally,  a  digital  CE  marking  should be used. Member States should not create unjustified obstacles to the placing on the market or  the putting into service of high-risk AI systems that comply with the requirements laid down in this  Regulation  and  bear  the  CE  marking.\n(130) Under  certain  conditions,  rapid  availability  of  innovative  technologies  may  be  crucial  for  health  and  safety  of persons, the protection of the environment and climate change and for society as a whole. It is thus appropriate that under  exceptional  reasons  of  public  security  or  protection  of  life  and  health  of  natural  persons,  environmental protection  and  the  protection  of  key  industrial  and  infrastructural  assets,  market  surveillance  authorities  could authorise  the  placing  on  the  market  or  the  putting  into  service  of  AI  systems  which  have  not  undergone a conformity assessment. In duly justified situations, as provided for in this Regulation, law enforcement authorities or  civil  protection  authorities  may  put  a  specific  high-risk  AI  system  into  service  without  the  authorisation  of  the market surveillance authority, provided that such authorisation is requested during or after  the use without undue delay.\n(131) In  order  to  facilitate  the  work of  the  Commission  and  the  Member  States in  the  AI  field  as  well  as  to  increase  the transparency towards the public, providers of high-risk AI systems other than those related to products falling within the scope of relevant existing Union harmonisation legislation, as well as providers who consider that an AI system listed in the high-risk use cases in an annex to this Regulation is not high-risk on the basis of a derogation, should be required  to  register  themselves  and  information  about  their  AI  system  in  an  EU  database,  to  be  established  and managed  by  the  Commission.  Before  using  an  AI  system  listed  in  the  high-risk  use  cases  in  an  annex  to  this Regulation,  deployers  of  high-risk  AI  systems  that  are  public  authorities,  agencies  or  bodies,  should  register themselves in such database and select the system that they envisage to use. Other deployers should be entitled to do so voluntarily. This section of the EU database should be publicly accessible, free of charge, the information should be easily navigable, understandable and machine-readable. The EU database should also be user-friendly, for example by  providing  search  functionalities,  including  through  keywords,  allowing  the  general  public  to  find  relevant information  to  be  submitted  upon  the  registration  of  high-risk  AI  systems  and  on  the  use  case  of  high-risk  AI systems,  set  out  in  an  annex  to  this  Regulation,  to  which  the  high-risk  AI  systems  correspond.  Any  substantial modification  of  high-risk  AI  systems should  also  be  registered  in  the  EU  database.  For  high-risk  AI  systems  in  the area of  law enforcement, migration, asylum and border control management, the registration obligations should be fulfilled in a secure non-public section of the EU database. Access to the secure non-public section should be strictly limited to the Commission as well as to market surveillance authorities with regard to their national section of that database. High-risk AI systems in the area of critical infrastructure should only be registered  at national level. The Commission should be the controller of the EU database, in accordance with Regulation (EU) 2018/1725. In order to  ensure  the  full  functionality  of  the  EU  database,  when  deployed,  the  procedure  for  setting  the  database  should include  the  development  of  functional  specifications  by  the  Commission  and  an  independent  audit  report.  The Commission should take into account cybersecurity risks when carrying out its tasks  as data controller on the EU database. In order to maximise the availability and use of the EU database by the public, the EU database, including the  information  made  available  through  it,  should  comply  with  requirements  under  the  Directive  (EU)  2019/882.\n(132) Certain  AI  systems  intended  to  interact  with  natural  persons  or  to  generate  content  may  pose  specific  risks  of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of  these  systems  should  therefore  be  subject  to  specific  transparency  obligations  without  prejudice  to  the requirements  and  obligations  for  high-risk  AI  systems  and  subject  to  targeted  exceptions  to  take  into  account  the special need of law enforcement. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the point of view of a natural person who is reasonably well-informed, observant and circumspect taking into account the circumstances and the context of use. When implementing that obligation, the characteristics of natural persons belonging to vulnerable groups due to their age or disability should be taken into account to the extent the AI system is intended to interact with those groups as well. Moreover, natural persons should be notified when they are exposed to AI systems that, by processing their biometric data, can identify or infer the emotions or intentions of those persons or assign them to specific categories. Such specific categories can relate to  aspects  such  as  sex,  age,  hair  colour,  eye  colour,  tattoos,  personal  traits,  ethnic  origin,  personal  preferences  and interests.  Such information and notifications should be provided in accessible formats for persons with disabilities.\n(133) A variety of AI systems can generate large quantities of synthetic content that becomes increasingly hard for humans to  distinguish  from  human-generated  and  authentic  content.  The  wide  availability  and  increasing  capabilities  of those systems have a significant impact on the integrity and trust in the information ecosystem, raising new risks of misinformation and manipulation at scale, fraud, impersonation and consumer deception. In light of those impacts, the  fast  technological  pace  and  the  need  for  new  methods  and  techniques  to  trace  origin  of  information,  it  is appropriate  to  require  providers  of  those  systems  to  embed  technical  solutions  that  enable  marking  in  a  machine readable format and detection that the output has been generated or manipulated by an AI system and not a human. Such  techniques  and  methods  should  be  sufficiently  reliable,  interoperable,  effective  and  robust  as  far  as  this  is technically  feasible,  taking  into  account  available  techniques  or  a  combination  of  such  techniques,  such  as watermarks,  metadata  identifications,  cryptographic  methods  for  proving  provenance  and  authenticity of  content, logging  methods,  fingerprints  or  other  techniques,  as  may  be  appropriate.  When  implementing  this  obligation, providers should also take into account the specificities and the limitations of the different types of content and the relevant technological and market developments in the field, as reflected in the generally acknowledged state of the art. Such techniques and methods can be implemented at the level of the AI system or at the level of the AI model, including  general-purpose  AI  models  generating  content,  thereby  facilitating  fulfilment  of  this  obligation  by  the downstream  provider  of  the  AI  system.  To  remain  proportionate,  it  is  appropriate  to  envisage  that  this  marking obligation should not cover AI systems performing primarily an assistive function for standard editing or AI systems not  substantially  altering  the  input  data  provided  by  the  deployer  or  the  semantics  thereof.\n(134) Further  to the technical solutions employed by the providers of  the AI system, deployers who use an AI system to generate or  manipulate image, audio or  video content that appreciably resembles  existing persons, objects,  places, entities  or  events  and  would falsely  appear  to a  person  to be  authentic  or  truthful  (deep  fakes),  should  also  clearly and distinguishably disclose that the content has been artificially created or manipulated by labelling the AI output accordingly  and  disclosing  its  artificial  origin.  Compliance  with  this  transparency  obligation  should  not  be interpreted as indicating that the use of the AI system or its output impedes the right to freedom of expression and the right to freedom of the arts and sciences guaranteed in the Charter, in particular where the content is part of an evidently creative, satirical, artistic, fictional or analogous work or programme, subject to appropriate safeguards for the  rights  and  freedoms  of  third  parties.  In  those  cases,  the  transparency  obligation  for  deep  fakes  set  out  in  this Regulation  is  limited  to  disclosure  of  the  existence  of  such  generated  or  manipulated  content  in  an  appropriate manner that does not hamper the display or enjoyment of the work, including its normal exploitation and use, while maintaining  the  utility  and  quality  of  the  work.  In  addition,  it  is  also  appropriate  to  envisage  a  similar  disclosure obligation in relation to AI-generated or manipulated text to the extent it is published with the purpose of informing the public on matters of public interest unless the AI-generated content has undergone a process of human review or editorial  control  and  a  natural  or  legal  person  holds  editorial  responsibility  for  the  publication  of  the  content.\n(135) Without prejudice to the mandatory nature and full applicability of  the transparency obligations, the Commission may  also  encourage  and  facilitate  the  drawing  up  of  codes  of  practice  at  Union  level  to  facilitate  the  effective implementation  of  the  obligations  regarding  the  detection  and  labelling  of  artificially  generated  or  manipulated content,  including  to  support  practical  arrangements  for  making,  as  appropriate,  the  detection  mechanisms accessible and facilitating cooperation with other actors along the value chain, disseminating content or checking its authenticity  and  provenance  to  enable  the  public  to  effectively  distinguish  AI-generated  content.\n(136) The obligations placed on providers and deployers of certain AI systems in this Regulation to enable the detection and disclosure that the outputs of those systems are artificially generated or manipulated are particularly relevant to facilitate  the  effective  implementation  of  Regulation  (EU)  2022/2065.  This  applies  in  particular  as  regards  the obligations of providers of very large online platforms or  very large online search engines to identify and mitigate systemic risks that may arise from the dissemination of content that has been artificially generated or manipulated, in  particular  the  risk  of  the  actual  or  foreseeable  negative  effects  on  democratic  processes,  civic  discourse  and electoral  processes,  including  through  disinformation.  The  requirement  to  label  content  generated  by  AI  systems under  this  Regulation  is  without  prejudice  to  the  obligation  in  Article  16(6)  of  Regulation  (EU)  2022/2065  for providers  of  hosting  services  to  process  notices  on  illegal  content  received  pursuant  to  Article  16(1)  of  that Regulation and should not influence the assessment and the decision on the illegality of  the specific content. That assessment should be performed solely with reference to the  rules  governing  the  legality of  the  content.\n(137) Compliance  with  the  transparency  obligations  for  the  AI  systems  covered  by  this  Regulation  should  not  be interpreted as indicating that the use of  the AI system or  its output is lawful under  this Regulation or other Union and Member State law and should be without prejudice to other transparency obligations for deployers of AI systems laid  down  in  Union  or  national  law.\n(138) AI is a rapidly developing family of  technologies that requires regulatory oversight and a safe and controlled space for  experimentation,  while  ensuring  responsible  innovation  and  integration  of  appropriate  safeguards  and  risk mitigation  measures.  To  ensure  a  legal  framework  that  promotes  innovation,  is  future-proof  and  resilient  to disruption,  Member  States  should  ensure  that  their  national  competent  authorities  establish  at  least  one  AI regulatory sandbox at national level to facilitate the development and testing of innovative AI systems under strict regulatory  oversight  before  these  systems  are  placed  on  the  market  or  otherwise  put  into  service.  Member  States could also fulfil this obligation through participating in already existing regulatory sandboxes or establishing jointly a sandbox with one or more Member States' competent authorities, insofar as this participation provides equivalent level  of  national  coverage  for  the  participating  Member  States.  AI  regulatory  sandboxes  could  be  established  in physical, digital or hybrid form and may accommodate physical as well as digital products. Establishing authorities should  also  ensure  that  the  AI  regulatory  sandboxes  have  the  adequate  resources  for  their  functioning,  including financial  and  human  resources.\n(139) The  objectives  of  the  AI  regulatory  sandboxes  should  be  to  foster  AI  innovation  by  establishing  a  controlled experimentation  and  testing  environment  in  the  development  and  pre-marketing  phase  with  a  view  to  ensuring compliance of the innovative AI systems with this Regulation and other relevant Union and national law. Moreover, the  AI  regulatory  sandboxes  should  aim  to  enhance  legal  certainty  for  innovators  and  the  competent  authorities' oversight and understanding of the opportunities, emerging risks and the impacts of AI use, to facilitate regulatory learning  for  authorities  and  undertakings,  including  with  a  view  to  future  adaptions  of  the  legal  framework,  to support  cooperation  and  the  sharing  of  best  practices  with  the  authorities  involved  in  the  AI  regulatory  sandbox, and  to  accelerate  access  to  markets,  including  by  removing  barriers  for  SMEs,  including  start-ups.  AI  regulatory sandboxes  should  be  widely  available  throughout  the  Union,  and  particular  attention  should  be  given  to  their accessibility for SMEs, including start-ups. The participation in the AI regulatory sandbox should focus on issues that raise  legal  uncertainty  for  providers  and  prospective  providers  to  innovate,  experiment  with  AI  in  the  Union  and contribute  to  evidence-based  regulatory  learning.  The  supervision  of  the  AI  systems  in  the  AI  regulatory  sandbox should  therefore  cover  their  development,  training,  testing  and  validation  before  the  systems  are  placed  on  the market or put into service, as well as the notion and occurrence of substantial modification that may require a new conformity  assessment  procedure.  Any  significant  risks  identified  during  the  development  and  testing  of  such  AI systems  should  result  in  adequate  mitigation  and,  failing  that,  in  the  suspension  of  the  development  and  testing process. Where appropriate, national competent authorities establishing AI regulatory sandboxes should cooperate with other relevant authorities, including those supervising the protection of fundamental rights, and could allow for the involvement of other actors within the AI ecosystem such as national or European standardisation organisations, notified  bodies,  testing  and  experimentation  facilities,  research  and  experimentation  labs,  European  Digital Innovation Hubs and relevant stakeholder and civil society organisations. To ensure uniform implementation across the  Union  and  economies  of  scale,  it  is  appropriate  to  establish  common  rules  for  the  AI  regulatory  sandboxes' implementation and a framework for cooperation between the relevant authorities involved in the supervision of the sandboxes.  AI  regulatory  sandboxes  established  under  this  Regulation  should  be  without  prejudice  to  other  law allowing for the establishment of other sandboxes aiming to ensure compliance with law other than this Regulation. Where appropriate, relevant competent authorities in charge of  those  other  regulatory  sandboxes should  consider the  benefits  of  using  those  sandboxes  also  for  the  purpose  of  ensuring  compliance  of  AI  systems  with  this Regulation. Upon agreement between the national competent authorities and the participants in the AI regulatory sandbox, testing in real world conditions may also be operated and supervised in the framework of the AI regulatory sandbox.\n(140) This  Regulation  should  provide  the  legal  basis  for  the  providers  and  prospective  providers  in  the  AI  regulatory sandbox to use personal data collected for other  purposes for  developing certain  AI systems in  the public  interest within the AI regulatory sandbox, only under specified conditions, in accordance with Article 6(4) and Article 9(2), point  (g),  of  Regulation  (EU)  2016/679,  and  Articles  5,  6  and  10  of  Regulation  (EU)  2018/1725,  and  without prejudice  to  Article  4(2)  and  Article  10  of  Directive  (EU)  2016/680.  All  other  obligations  of  data  controllers  and rights of data subjects under Regulations (EU) 2016/679 and (EU) 2018/1725 and Directive (EU) 2016/680 remain applicable. In particular, this Regulation should not provide a legal basis in the meaning of Article 22(2), point (b) of Regulation  (EU)  2016/679  and  Article  24(2),  point  (b)  of  Regulation  (EU)  2018/1725.  Providers  and  prospective\nproviders  in  the  AI  regulatory  sandbox  should  ensure  appropriate  safeguards  and  cooperate  with  the  competent authorities, including by following their guidance and acting expeditiously and in good faith to adequately mitigate any  identified  significant  risks  to  safety,  health,  and  fundamental  rights  that  may  arise  during  the  development, testing  and  experimentation  in  that  sandbox."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_10",
    "chunk_content": "Whereas:\n(141) In order to accelerate the process of development and the placing on the market of the high-risk AI systems listed in an annex to this Regulation, it is important that providers or prospective providers of such systems may also benefit from a specific regime for  testing those systems in real world conditions, without participating in an AI regulatory sandbox.  However,  in  such  cases,  taking  into  account  the  possible  consequences  of  such  testing  on  individuals,  it should be ensured that appropriate and sufficient  guarantees and conditions are introduced by this Regulation for providers  or  prospective  providers.  Such  guarantees  should  include,  inter  alia,  requesting  informed  consent  of natural persons to participate in testing in real world conditions, with the exception of  law enforcement where the seeking of  informed consent would prevent the AI system from being tested. Consent of subjects to participate in such  testing  under  this  Regulation  is  distinct  from,  and  without  prejudice  to,  consent  of  data  subjects  for  the processing of  their  personal data under  the relevant data protection law. It is also important to minimise the risks and  enable  oversight  by  competent  authorities  and  therefore  require  prospective  providers  to  have  a  real-world testing plan submitted to competent market surveillance authority, register the testing in dedicated sections in the EU database  subject  to  some  limited  exceptions,  set  limitations  on  the  period  for  which  the  testing  can  be  done  and require  additional  safeguards  for  persons  belonging  to  certain  vulnerable  groups,  as  well  as  a  written  agreement defining  the  roles  and  responsibilities  of  prospective providers and deployers and effective  oversight by competent personnel  involved  in  the  real  world  testing.  Furthermore,  it  is  appropriate  to  envisage  additional  safeguards  to ensure  that  the  predictions,  recommendations  or  decisions  of  the  AI  system  can  be  effectively  reversed  and disregarded  and  that  personal  data  is  protected  and  is  deleted  when  the  subjects  have  withdrawn  their  consent  to participate in the testing without prejudice to their rights as data subjects under  the Union data protection law. As regards transfer of data, it is also appropriate to envisage that data collected and processed for the purpose of testing in  real-world conditions should be transferred to third countries only where appropriate and applicable safeguards under Union law are implemented, in particular in accordance with bases for transfer of personal data under Union law  on  data  protection,  while  for  non-personal  data  appropriate  safeguards  are  put  in  place  in  accordance  with Union law, such as Regulations (EU) 2022/868 ( 42 )  and (EU) 2023/2854 ( 43 )  of  the  European Parliament and of  the Council.\n(142) To  ensure  that  AI  leads  to  socially  and  environmentally  beneficial  outcomes,  Member  States  are  encouraged  to support  and  promote  research  and  development  of  AI  solutions  in  support  of  socially  and  environmentally beneficial  outcomes,  such  as  AI-based  solutions  to  increase  accessibility  for  persons  with  disabilities,  tackle socio-economic inequalities, or meet environmental targets, by allocating sufficient resources, including public and Union  funding,  and,  where  appropriate  and  provided  that  the  eligibility  and  selection  criteria  are  fulfilled, considering in particular  projects which pursue such objectives. Such projects should be based on the principle of interdisciplinary  cooperation  between  AI  developers,  experts  on  inequality  and  non-discrimination,  accessibility, consumer, environmental, and digital rights,  as  well  as  academics.\n(143) In order  to promote and protect innovation, it is important that the interests of SMEs, including start-ups, that are providers or deployers of AI systems are taken into particular account. To that end, Member States should develop initiatives,  which  are  targeted  at  those  operators,  including  on  awareness  raising  and  information  communication. Member States should provide SMEs, including start-ups, that have a registered office or a branch in the Union, with priority access to the AI regulatory sandboxes provided that they fulfil the eligibility conditions and selection criteria and  without  precluding  other  providers  and  prospective  providers  to  access  the  sandboxes  provided  the  same conditions and criteria are fulfilled. Member States should utilise existing channels and where appropriate, establish new  dedicated  channels  for  communication  with  SMEs,  including  start-ups,  deployers,  other  innovators  and,  as appropriate,  local  public  authorities,  to  support  SMEs  throughout  their  development  path  by  providing  guidance and responding to queries about the implementation of this Regulation. Where appropriate, these channels should work  together  to  create  synergies  and  ensure  homogeneity  in  their  guidance  to  SMEs,  including  start-ups,  and deployers. Additionally, Member States should facilitate the participation of SMEs and other relevant stakeholders in the  standardisation  development  processes.  Moreover,  the  specific  interests  and  needs  of  providers  that  are  SMEs,\nincluding  start-ups,  should  be  taken  into  account  when  notified  bodies  set  conformity  assessment  fees.  The Commission should regularly  assess  the  certification  and  compliance  costs  for  SMEs,  including  start-ups,  through transparent consultations and should work with Member States to lower such costs. For example, translation costs related  to  mandatory  documentation  and  communication  with  authorities  may  constitute  a  significant  cost  for providers and other operators, in particular those of a smaller scale. Member States should possibly ensure that one of  the  languages  determined  and  accepted by  them  for  relevant  providers'  documentation  and  for  communication with operators is one which is broadly understood by the largest possible number of cross-border deployers. In order to address the specific needs of SMEs, including start-ups, the Commission should provide standardised templates for the areas covered by this Regulation, upon request of the Board. Additionally, the Commission should complement Member States' efforts by providing a single information platform with easy-to-use information with regards to this Regulation for all providers and deployers, by organising appropriate communication campaigns to raise awareness about  the  obligations  arising  from  this  Regulation,  and  by  evaluating  and  promoting  the  convergence  of  best practices in public procurement procedures in relation to AI systems. Medium-sized enterprises which until recently qualified as small enterprises within the meaning of the Annex to Commission Recommendation 2003/361/EC ( 44 ) should have access to those support measures, as those new medium-sized enterprises may sometimes lack the legal resources  and  training  necessary  to  ensure  proper  understanding  of,  and  compliance  with,  this  Regulation.\n(144) In  order  to  promote  and  protect  innovation,  the  AI-on-demand  platform,  all  relevant  Union  funding  programmes and projects, such as Digital Europe Programme, Horizon Europe, implemented by the Commission and the Member States  at  Union  or  national  level  should,  as  appropriate,  contribute  to  the  achievement  of  the  objectives  of  this Regulation.\n(145) In  order  to minimise the risks  to implementation resulting from lack of knowledge and expertise in the market as well as  to facilitate  compliance  of  providers,  in particular  SMEs,  including  start-ups,  and  notified  bodies  with  their obligations  under  this  Regulation,  the  AI-on-demand  platform,  the  European  Digital  Innovation  Hubs  and  the testing  and  experimentation  facilities  established  by  the  Commission  and  the  Member  States  at  Union  or  national level  should  contribute  to  the  implementation  of  this  Regulation.  Within  their  respective  mission  and  fields  of competence,  the  AI-on-demand  platform,  the  European  Digital  Innovation  Hubs  and  the  testing  and experimentation  Facilities  are  able  to  provide  in  particular  technical  and  scientific  support  to  providers  and notified  bodies.\n(146) Moreover, in light of the very small size of some operators and in order to ensure proportionality regarding costs of innovation,  it  is  appropriate  to  allow  microenterprises  to  fulfil  one  of  the  most  costly  obligations,  namely  to establish a quality management system, in a simplified manner  which would reduce the administrative burden and the  costs  for  those  enterprises  without  affecting  the  level  of  protection  and  the  need  for  compliance  with  the requirements  for  high-risk  AI  systems.  The  Commission  should  develop  guidelines  to  specify  the  elements  of  the quality  management  system  to  be  fulfilled  in  this  simplified  manner  by  microenterprises.\n(147) It  is  appropriate  that  the  Commission  facilitates,  to  the  extent  possible,  access  to  testing  and  experimentation facilities  to  bodies,  groups  or  laboratories  established  or  accredited  pursuant  to  any  relevant  Union  harmonisation legislation  and  which  fulfil  tasks  in  the  context  of  conformity  assessment  of  products  or  devices  covered  by  that Union  harmonisation  legislation.  This  is,  in  particular,  the  case  as  regards  expert  panels,  expert  laboratories  and reference  laboratories  in  the  field  of  medical  devices  pursuant  to  Regulations  (EU)  2017/745  and  (EU)  2017/746.\n(148) This  Regulation  should  establish  a  governance  framework  that  both  allows  to  coordinate  and  support  the application of this Regulation at national level, as well as build capabilities at Union level and integrate stakeholders in the field of AI. The effective implementation and enforcement of this Regulation require a governance framework that allows to coordinate and build up central expertise at Union level. The AI Office was established by Commission Decision ( 45 ) and has as its mission to develop Union expertise and capabilities in the field of AI and to contribute to the  implementation of Union law on AI. Member States should facilitate the tasks  of  the AI Office with a view to support the development of Union expertise and capabilities at Union level and to strengthen the functioning of the digital single market. Furthermore, a Board composed of representatives of the Member States, a scientific panel to integrate the scientific community and an advisory forum to contribute stakeholder input to the implementation of this  Regulation,  at  Union  and  national  level,  should  be  established.  The  development  of  Union  expertise  and\ncapabilities should also include making use of existing resources and expertise, in particular through synergies with structures built up in the context of the Union level enforcement of other law and synergies with related initiatives at Union  level,  such  as  the  EuroHPC  Joint  Undertaking  and  the  AI  testing  and  experimentation  facilities  under  the Digital  Europe  Programme.\n(149) In  order  to  facilitate  a  smooth,  effective  and  harmonised  implementation  of  this  Regulation  a  Board  should  be established. The Board should reflect the various interests of the AI eco-system and be composed of representatives of  the Member States. The Board should be responsible for a number of advisory tasks, including issuing opinions, recommendations, advice or contributing to guidance on matters related to the implementation of this Regulation, including  on  enforcement  matters,  technical  specifications  or  existing  standards  regarding  the  requirements established  in  this  Regulation  and  providing  advice  to  the  Commission  and  the  Member  States  and  their  national competent authorities on specific questions related to AI. In order  to give some flexibility to Member States in the designation  of  their  representatives  in  the  Board,  such  representatives  may  be  any  persons  belonging  to  public entities  who  should  have  the  relevant  competences  and  powers  to  facilitate  coordination  at  national  level  and contribute to the achievement of the Board's tasks. The Board should establish two standing sub-groups to provide a platform for cooperation and exchange among market surveillance authorities and notifying authorities on issues related,  respectively,  to  market  surveillance  and  notified  bodies.  The  standing  subgroup  for  market  surveillance should act as the administrative cooperation group (ADCO) for this Regulation within the meaning of Article 30 of Regulation (EU) 2019/1020. In accordance with Article 33 of that Regulation, the Commission should support the activities  of  the  standing  subgroup  for  market  surveillance  by  undertaking  market  evaluations  or  studies,  in particular  with  a  view  to  identifying  aspects  of  this  Regulation  requiring  specific  and  urgent  coordination  among market surveillance authorities. The Board may establish other standing or temporary sub-groups as appropriate for the  purpose  of  examining  specific  issues.  The  Board  should  also  cooperate,  as  appropriate,  with  relevant  Union bodies, experts groups and networks active in the context of relevant Union law, including in particular those active under  relevant  Union  law on  data,  digital  products  and  services.\n(150) With a view to ensuring the involvement of stakeholders in the implementation and application of this Regulation, an advisory forum should be established to advise and provide technical expertise to the Board and the Commission. To ensure a varied and balanced stakeholder representation between commercial and non-commercial interest and, within  the  category  of  commercial  interests,  with  regards  to  SMEs  and  other  undertakings,  the  advisory  forum should comprise inter alia industry, start-ups, SMEs, academia, civil society, including the social partners, as well as the  Fundamental  Rights  Agency,  ENISA,  the  European  Committee  for  Standardization  (CEN),  the  European Committee  for  Electrotechnical  Standardization  (CENELEC)  and  the  European  Telecommunications  Standards Institute  (ETSI).\n(151) To support the implementation and enforcement of this Regulation, in particular the monitoring activities of the AI Office  as  regards  general-purpose  AI  models,  a  scientific  panel  of  independent  experts  should  be  established.  The independent  experts  constituting  the  scientific  panel  should  be  selected  on  the  basis  of  up-to-date  scientific  or technical  expertise  in  the  field  of  AI  and  should  perform  their  tasks  with  impartiality,  objectivity  and  ensure  the confidentiality of information and data obtained in carrying out their tasks and activities. To allow the reinforcement of  national  capacities  necessary  for  the  effective  enforcement  of  this  Regulation,  Member  States  should  be  able  to request  support  from  the  pool  of  experts  constituting  the  scientific  panel  for  their  enforcement  activities.\n(152) In order  to support adequate enforcement as regards AI systems and reinforce the capacities of the Member States, Union AI testing  support  structures  should  be  established  and  made  available  to  the  Member  States.\n(153) Member States hold a key role in the application and enforcement of this Regulation. In that respect, each Member State  should  designate  at  least  one  notifying  authority  and  at  least  one  market  surveillance  authority  as  national competent  authorities  for  the  purpose  of  supervising  the  application  and  implementation  of  this  Regulation. Member  States  may  decide  to  appoint  any  kind  of  public  entity  to  perform  the  tasks  of  the  national  competent authorities  within  the  meaning  of  this  Regulation,  in  accordance  with  their  specific  national  organisational characteristics and needs. In order to increase organisation efficiency on the side of Member States and to set a single point of contact vis-à-vis the public and other counterparts at Member State and Union levels, each Member State should designate a  market  surveillance  authority  to  act  as  a  single  point  of  contact.\n(154) The national competent authorities should exercise their powers independently, impartially and without bias, so as to  safeguard  the  principles  of  objectivity  of  their  activities  and  tasks  and  to  ensure  the  application  and implementation of this Regulation. The members of these authorities should refrain from any action incompatible with their  duties  and  should  be  subject  to  confidentiality  rules  under  this  Regulation.\n(155) In order to ensure that providers of high-risk AI systems can take into account the experience on the use of high-risk AI systems for improving their systems and the design and development process or can take any possible corrective action  in  a  timely  manner,  all  providers  should  have  a  post-market  monitoring  system  in  place.  Where  relevant, post-market monitoring should include an analysis of the interaction with other AI systems including other devices and  software.  Post-market  monitoring  should  not  cover  sensitive  operational  data  of  deployers  which  are  law enforcement authorities. This system is also key to ensure that the possible risks emerging from AI systems which continue to 'learn' after being placed on the market or put into service can be more efficiently and timely addressed. In this context, providers should also be required to have a system in place to report to the relevant authorities any serious incidents resulting from the use of their AI systems, meaning incident or malfunctioning leading to death or serious  damage  to  health,  serious  and  irreversible  disruption  of  the  management  and  operation  of  critical infrastructure,  infringements  of  obligations  under  Union  law  intended  to  protect  fundamental  rights  or  serious damage to property or  the  environment.\n(156) In  order  to  ensure  an  appropriate  and  effective  enforcement  of  the  requirements  and  obligations  set  out  by  this Regulation, which is Union harmonisation legislation, the system of market surveillance and compliance of products established  by  Regulation  (EU)  2019/1020  should  apply  in  its  entirety.  Market  surveillance  authorities  designated pursuant to this Regulation should have all enforcement powers laid down in this Regulation and in Regulation (EU) 2019/1020 and should exercise their powers and carry out their duties independently, impartially and without bias. Although the majority of AI systems are not subject to specific requirements and obligations under this Regulation, market  surveillance  authorities  may  take  measures  in  relation  to  all  AI  systems  when  they  present  a  risk  in accordance with this Regulation. Due to the specific nature of Union institutions, agencies and bodies falling within the scope of this Regulation, it is appropriate to designate the European Data Protection Supervisor as a competent market surveillance authority for  them. This should be without prejudice to the designation of national competent authorities by the Member States. Market surveillance activities should not affect the ability of the supervised entities to  carry  out  their  tasks  independently,  when  such  independence  is  required  by  Union  law.\n(157) This Regulation is without prejudice to the competences, tasks, powers and independence of relevant national public authorities or bodies which supervise the application of Union law protecting fundamental rights, including equality bodies  and  data  protection  authorities.  Where  necessary  for  their  mandate,  those  national  public  authorities  or bodies should also have access to any documentation created under this Regulation. A specific safeguard procedure should be set for ensuring adequate and timely enforcement against AI systems presenting a risk to health, safety and fundamental rights. The procedure for such AI systems presenting a risk should be applied to high-risk AI systems presenting a risk, prohibited systems which have been placed on the market, put into service or used in violation of the prohibited practices laid down in this Regulation and AI systems which have been made available in violation of the  transparency  requirements  laid  down in  this  Regulation  and  present  a  risk.\n(158) Union financial  services  law includes  internal  governance  and  risk-management  rules  and  requirements  which are applicable to regulated financial institutions in the course of provision of those services, including when they make use of AI systems. In order to ensure coherent application and enforcement of the obligations under this Regulation and  relevant  rules  and  requirements  of  the  Union  financial  services  legal  acts,  the  competent  authorities  for  the supervision  and  enforcement of  those  legal  acts,  in  particular  competent  authorities  as  defined  in  Regulation  (EU) No 575/2013 of the European Parliament and of the Council ( 46 )  and Directives 2008/48/EC ( 47 ),  2009/138/EC ( 48 ),\n2013/36/EU ( 49 ),  2014/17/EU ( 50 )  and  (EU)  2016/97 ( 51 )  of  the  European  Parliament and  of  the  Council,  should  be designated,  within  their  respective  competences,  as  competent  authorities  for  the  purpose  of  supervising  the implementation  of  this  Regulation,  including  for  market  surveillance  activities,  as  regards  AI  systems  provided  or used by regulated and supervised financial institutions unless Member States decide to designate another authority to fulfil these market surveillance tasks. Those competent authorities should have all powers under this Regulation and Regulation  (EU)  2019/1020  to  enforce  the  requirements  and  obligations  of  this  Regulation,  including  powers  to carry our ex post market surveillance activities that can be integrated, as appropriate, into their existing supervisory mechanisms and procedures under the relevant Union financial services law. It is appropriate to envisage that, when acting  as  market  surveillance  authorities  under  this  Regulation,  the  national  authorities  responsible  for  the supervision  of  credit  institutions  regulated  under  Directive  2013/36/EU,  which  are  participating  in  the  Single Supervisory Mechanism established by Council Regulation (EU) No 1024/2013 ( 52 ), should report, without delay, to the European Central Bank any information identified in the course of their market surveillance activities that may be of potential interest for the European Central Bank's prudential supervisory tasks as specified in that Regulation. To further enhance the consistency between this Regulation and the rules applicable to credit institutions regulated under  Directive  2013/36/EU,  it  is  also  appropriate  to  integrate  some  of  the  providers'  procedural  obligations  in relation  to  risk  management,  post  marketing  monitoring  and  documentation  into  the  existing  obligations  and procedures under Directive 2013/36/EU. In order to avoid overlaps, limited derogations should also be envisaged in relation  to  the  quality  management  system  of  providers  and  the  monitoring  obligation  placed  on  deployers  of high-risk  AI  systems  to  the  extent  that  these  apply  to  credit  institutions  regulated  by  Directive  2013/36/EU.  The same  regime  should  apply  to  insurance  and  re-insurance  undertakings  and  insurance  holding  companies  under Directive 2009/138/EC and the insurance intermediaries under Directive (EU) 2016/97 and other types of financial institutions subject to requirements regarding internal governance, arrangements or processes established pursuant to  the  relevant  Union  financial  services  law  to  ensure  consistency  and  equal  treatment  in  the  financial  sector.\n(159) Each market surveillance authority for high-risk  AI systems in the  area of  biometrics, as  listed in  an  annex  to  this Regulation  insofar  as  those  systems  are  used  for  the  purposes  of  law  enforcement,  migration,  asylum  and  border control management, or  the administration of justice and democratic processes, should have effective investigative and corrective powers, including at least the power to obtain access to all personal data that are being processed and to all  information necessary for  the performance of its tasks. The market surveillance authorities should be able to exercise their powers by acting with complete independence. Any limitations of their access to sensitive operational data  under  this  Regulation  should  be  without  prejudice  to  the  powers  conferred  to  them  by  Directive (EU) 2016/680. No exclusion on disclosing data to national data protection authorities under this Regulation should affect  the  current  or  future  powers  of  those  authorities  beyond  the  scope  of  this  Regulation.\n(160) The market surveillance authorities and the Commission should be able to propose joint activities, including joint investigations, to be conducted by market surveillance authorities or market surveillance authorities jointly with the Commission,  that  have  the  aim  of  promoting  compliance,  identifying  non-compliance,  raising  awareness  and providing guidance in relation to this Regulation with respect to specific categories of high-risk AI systems that are found to present a serious risk across two or more Member States. Joint activities to promote compliance should be carried out in accordance with Article 9 of Regulation (EU) 2019/1020. The AI Office should provide coordination support for  joint  investigations.\n(161) It is necessary to clarify the responsibilities and competences at Union and national level as regards AI systems that are  built  on  general-purpose  AI  models.  To  avoid  overlapping  competences,  where  an  AI  system  is  based  on a  general-purpose AI model and the model and system are provided by the same provider, the supervision should\n( 49 ) Directive 2013/36/EU of the European Parliament and of the Council of 26 June 2013 on access to the activity of credit institutions and  the  prudential  supervision  of  credit  institutions  and  investment  firms,  amending  Directive  2002/87/EC  and  repealing Directives  2006/48/EC  and  2006/49/EC (OJ  L  176,  27.6.2013,  p.  338).\n( 50 ) Directive  2014/17/EU  of  the  European  Parliament  and  of  the  Council  of  4  February  2014  on  credit  agreements  for  consumers relating  to  residential  immovable  property  and  amending  Directives  2008/48/EC  and  2013/36/EU  and  Regulation  (EU) No 1093/2010 (OJ L 60, 28.2.2014, p. 34).\n( 51 ) Directive  (EU)  2016/97  of  the  European  Parliament  and  of  the  Council  of  20  January  2016  on  insurance  distribution  (OJ  L  26, 2.2.2016,  p.  19).\n( 52 ) Council Regulation  (EU)  No  1024/2013 of  15  October  2013  conferring  specific  tasks  on  the  European  Central  Bank  concerning policies  relating  to  the  prudential  supervision  of  credit  institutions  (OJ  L  287,  29.10.2013,  p.  63).\ntake  place  at  Union  level  through  the  AI  Office,  which  should  have  the  powers  of  a  market  surveillance  authority within the meaning of Regulation (EU) 2019/1020 for this purpose. In all other cases, national market surveillance authorities remain responsible for the supervision of AI systems. However, for general-purpose AI systems that can be used directly by deployers for at least one purpose that is classified as high-risk, market surveillance authorities should cooperate with the AI Office to carry out evaluations of compliance and inform the Board and other market surveillance  authorities  accordingly.  Furthermore,  market  surveillance  authorities  should  be  able  to  request assistance  from  the  AI  Office  where  the  market  surveillance  authority  is  unable  to  conclude  an  investigation  on a high-risk AI system because of its inability to access certain information related to the general-purpose AI model on which the high-risk AI system is built. In such cases, the procedure regarding mutual assistance in cross-border cases  in  Chapter  VI  of  Regulation  (EU)  2019/1020  should  apply mutatis  mutandis .\n(162) To  make  best  use  of  the  centralised  Union  expertise  and  synergies  at  Union  level,  the  powers  of  supervision  and enforcement  of  the  obligations  on  providers  of  general-purpose  AI  models  should  be  a  competence  of  the Commission. The AI Office should be able to carry out all necessary actions to monitor the effective implementation of  this  Regulation  as  regards  general-purpose  AI  models.  It  should  be  able  to investigate  possible  infringements of the  rules  on  providers  of  general-purpose  AI  models  both  on  its  own  initiative,  following  the  results  of  its monitoring activities, or upon request from market surveillance authorities in line with the conditions set out in this Regulation. To support effective monitoring of the AI Office, it should provide for  the possibility that downstream providers lodge complaints about possible infringements of the rules on providers of general-purpose AI models and systems.\n(163) With a view to complementing the governance systems for general-purpose AI models, the scientific panel should support the monitoring activities of the AI Office and may, in certain cases, provide qualified alerts to the AI Office which trigger  follow-ups,  such  as  investigations.  This  should  be  the  case  where  the  scientific  panel  has  reason  to suspect  that  a  general-purpose  AI  model  poses  a  concrete  and  identifiable  risk  at  Union  level.  Furthermore,  this should be the case where the scientific panel has reason to suspect that a general-purpose AI model meets the criteria that would lead to a classification as general-purpose AI model with systemic risk. To equip the scientific panel with the information necessary for  the performance of those tasks, there should be a mechanism whereby the scientific panel  can  request  the  Commission  to require  documentation  or  information  from  a  provider.\n(164) The  AI  Office  should  be  able  to  take  the  necessary  actions  to  monitor  the  effective  implementation  of  and compliance with the obligations  for  providers  of  general-purpose  AI  models  laid  down  in  this  Regulation.  The  AI Office  should  be  able  to  investigate  possible  infringements  in  accordance  with  the  powers  provided  for  in  this Regulation,  including  by  requesting  documentation  and  information,  by  conducting  evaluations,  as  well  as  by requesting measures from providers of general-purpose AI models. When conducting evaluations, in order to make use  of  independent  expertise,  the  AI  Office  should  be  able  to  involve  independent  experts  to  carry  out  the evaluations on its behalf. Compliance with the obligations should be enforceable, inter alia, through requests to take appropriate measures, including risk mitigation measures in the case of identified systemic risks as well as restricting the making available on the market, withdrawing or recalling the model. As a safeguard, where needed beyond the procedural  rights  provided  for  in  this  Regulation,  providers  of  general-purpose  AI  models  should  have  the procedural  rights  provided  for  in  Article  18  of  Regulation  (EU)  2019/1020,  which  should  apply mutatis  mutandis , without prejudice  to more  specific  procedural  rights  provided  for  by  this  Regulation.\n(165) The  development  of  AI  systems  other  than  high-risk  AI  systems  in  accordance  with  the  requirements  of  this Regulation may lead to a larger uptake of ethical and trustworthy AI in the Union. Providers of AI systems that are not high-risk should be encouraged to create codes of conduct, including related governance mechanisms, intended to foster the voluntary application of some or all of the mandatory requirements applicable to high-risk AI systems, adapted  in  light  of  the  intended  purpose  of  the  systems  and  the  lower  risk  involved  and  taking  into  account  the available technical solutions and industry best practices such as model and data cards. Providers and, as appropriate, deployers of all AI systems, high-risk or not, and AI models should also be encouraged to apply on a voluntary basis additional  requirements  related,  for  example,  to  the  elements  of  the  Union's  Ethics  Guidelines  for  Trustworthy  AI,"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_11",
    "chunk_content": "Whereas:\nenvironmental  sustainability,  AI  literacy  measures,  inclusive  and  diverse  design  and  development  of  AI  systems, including attention to vulnerable persons and accessibility to persons with disability, stakeholders' participation with the involvement, as appropriate, of relevant stakeholders such as business and civil society organisations, academia, research  organisations,  trade  unions  and  consumer  protection  organisations  in  the  design  and  development  of  AI systems,  and  diversity of  the  development  teams,  including  gender  balance.  To  ensure  that  the  voluntary codes  of conduct  are  effective,  they  should  be  based  on  clear  objectives  and  key  performance  indicators  to  measure  the achievement  of  those  objectives.  They  should  also  be  developed  in  an  inclusive  way,  as  appropriate,  with  the involvement  of  relevant  stakeholders  such  as  business  and  civil  society  organisations,  academia,  research organisations,  trade  unions  and  consumer  protection  organisation.  The  Commission  may  develop  initiatives, including of a sectoral nature, to facilitate the lowering of technical barriers hindering cross-border exchange of data for AI development, including on data access infrastructure, semantic and technical interoperability of different types of  data.\n(166) It is important that AI systems related to products that are not high-risk in accordance with this Regulation and thus are not required to comply with the requirements set out for high-risk AI systems are nevertheless safe when placed on  the  market  or  put  into  service.  To  contribute  to  this  objective,  Regulation  (EU)  2023/988  of  the  European Parliament  and  of  the  Council ( 53 )  would  apply  as  a  safety  net.\n(167) In  order  to  ensure  trustful  and  constructive  cooperation  of  competent  authorities  on  Union  and  national  level,  all parties  involved  in  the  application  of  this  Regulation  should  respect  the  confidentiality  of  information  and  data obtained in carrying out their tasks, in accordance with Union or national law. They should carry out their tasks and activities in such a manner as to protect, in particular, intellectual property rights, confidential business information and trade secrets, the effective implementation of this Regulation, public and national security interests, the integrity of  criminal  and  administrative  proceedings,  and  the  integrity of  classified  information.\n(168) Compliance  with  this  Regulation  should  be  enforceable  by  means  of  the  imposition  of  penalties  and  other enforcement  measures.  Member  States  should  take  all  necessary  measures  to  ensure  that  the  provisions  of  this Regulation  are  implemented,  including  by  laying  down  effective,  proportionate  and  dissuasive  penalties  for  their infringement,  and  to  respect  the ne  bis  in  idem principle.  In  order  to  strengthen  and  harmonise  administrative penalties for infringement of this Regulation, the upper limits for setting the administrative fines for certain specific infringements  should  be  laid  down.  When  assessing  the  amount  of  the  fines,  Member  States  should,  in  each individual case, take into account all relevant circumstances of the specific situation, with due regard in particular to the  nature,  gravity  and  duration  of  the  infringement  and  of  its  consequences  and  to  the  size  of  the  provider,  in particular if the provider is an SME, including a start-up. The European Data Protection Supervisor should have the power  to impose  fines  on  Union  institutions,  agencies  and  bodies  falling  within  the  scope  of  this  Regulation.\n(169) Compliance with the obligations on providers of general-purpose AI models imposed under this Regulation should be  enforceable,  inter  alia,  by  means  of  fines.  To  that  end,  appropriate  levels  of  fines  should  also  be  laid  down  for infringement of  those  obligations,  including  the  failure  to  comply  with  measures  requested  by the  Commission  in accordance  with  this  Regulation,  subject  to  appropriate  limitation  periods  in  accordance  with  the  principle  of proportionality. All decisions taken by the Commission under this Regulation are subject to review by the Court of Justice  of  the  European  Union  in  accordance  with  the  TFEU,  including  the  unlimited  jurisdiction  of  the  Court  of Justice  with  regard  to  penalties  pursuant  to  Article  261  TFEU.\n(170) Union and national law already provide effective remedies to natural and legal persons whose rights and freedoms are adversely affected by the use of AI systems. Without prejudice to those remedies, any natural or legal person that has  grounds  to  consider  that  there  has  been  an  infringement  of  this  Regulation  should  be  entitled  to  lodge a  complaint to the  relevant  market  surveillance  authority.\n(171) Affected persons should have the right to obtain an explanation where a deployer's decision is based mainly upon the  output  from  certain  high-risk  AI  systems  that  fall  within  the  scope  of  this  Regulation  and  where  that  decision produces legal effects or similarly significantly affects those persons in a way that they consider  to have an adverse\nimpact on their health, safety or  fundamental rights. That explanation should be clear and meaningful and should provide  a  basis  on  which  the  affected  persons  are  able  to  exercise  their  rights.  The  right  to  obtain  an  explanation should not apply to the use of AI systems for  which exceptions or  restrictions follow from Union or  national law and should apply only to the  extent this  right  is  not  already  provided  for  under  Union  law.\n(172) Persons acting as whistleblowers on the infringements of this Regulation should be protected under the Union law. Directive (EU) 2019/1937 of the European Parliament and of the Council ( 54 ) should therefore apply to the reporting of  infringements  of  this  Regulation  and  the  protection  of  persons  reporting  such  infringements.\n(173) In  order  to  ensure  that  the  regulatory  framework  can  be  adapted  where  necessary,  the  power  to  adopt  acts  in accordance with Article 290 TFEU should be delegated to the Commission to amend the conditions under which an AI system is not to be considered to be high-risk, the list of high-risk AI systems, the provisions regarding technical documentation, the content of the EU declaration of conformity the provisions regarding the conformity assessment procedures,  the  provisions  establishing  the  high-risk  AI  systems  to  which  the  conformity  assessment  procedure based  on  assessment  of  the  quality  management  system  and  assessment  of  the  technical  documentation  should apply,  the  threshold,  benchmarks and indicators, including by supplementing those benchmarks and indicators, in the  rules  for  the  classification  of  general-purpose  AI  models  with  systemic  risk,  the  criteria  for  the  designation  of general-purpose  AI  models  with  systemic  risk,  the  technical  documentation  for  providers  of  general-purpose  AI models and the transparency information for providers of general-purpose AI models. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including at expert level, and that  those  consultations  be  conducted  in  accordance  with  the  principles  laid  down  in  the  Interinstitutional Agreement  of  13  April  2016  on  Better  Law-Making ( 55 ). In  particular,  to  ensure  equal  participation  in  the preparation of delegated acts, the  European Parliament  and the  Council receive  all  documents at the  same time  as Member  States'  experts,  and  their  experts  systematically  have  access  to  meetings  of  Commission  expert  groups dealing  with  the  preparation  of  delegated  acts.\n(174) Given the rapid technological developments and the technical expertise required to effectively apply this Regulation, the Commission should evaluate and review this Regulation by 2 August 2029 and every four years thereafter and report to the European Parliament and the Council. In addition, taking into account the implications for the scope of this  Regulation,  the  Commission  should  carry  out  an  assessment  of  the  need  to  amend  the  list  of  high-risk  AI systems and the list of prohibited practices once a year. Moreover, by 2 August 2028 and every four years thereafter, the Commission should evaluate and report to the European Parliament and to the Council on the need to amend the  list  of  high-risk  areas  headings  in  the  annex  to  this  Regulation,  the  AI  systems  within  the  scope  of  the transparency  obligations,  the  effectiveness  of  the  supervision  and  governance  system  and  the  progress  on  the development  of  standardisation  deliverables  on  energy  efficient  development  of  general-purpose  AI  models, including the need for further measures or actions. Finally, by 2 August 2028 and every three years thereafter, the Commission should evaluate the impact and effectiveness of voluntary codes of conduct to foster the application of the  requirements  provided for  high-risk  AI  systems  in  the  case  of  AI  systems  other  than  high-risk  AI  systems  and possibly other  additional  requirements  for  such  AI  systems.\n(175) In  order  to ensure  uniform conditions for  the implementation of  this Regulation, implementing powers should be conferred on the Commission. Those powers should be exercised in accordance with Regulation (EU) No 182/2011 of  the  European  Parliament  and  of  the  Council ( 56 ).\n(176) Since the objective of this Regulation, namely to improve the functioning of the internal market and to promote the uptake of human centric and trustworthy AI, while ensuring a high level of protection of health, safety, fundamental rights enshrined in the Charter, including democracy, the rule of  law and environmental protection against harmful effects of AI systems in the Union and supporting innovation, cannot be sufficiently achieved by the Member States and can rather, by reason of the scale or effects of the action, be better achieved at Union level, the Union may adopt\nmeasures  in  accordance  with  the  principle  of  subsidiarity  as  set  out  in  Article  5  TEU.  In  accordance  with  the principle of proportionality as set out in that Article, this Regulation does not go beyond what is necessary in order to  achieve  that  objective.\n(177) In order to ensure legal certainty, ensure an appropriate adaptation period for operators and avoid disruption to the market, including by ensuring continuity of the use of AI systems, it is appropriate that this Regulation applies to the high-risk AI systems that have been placed on the market or put into service before the general date of application thereof, only if, from that date, those systems are subject to significant changes in their design or intended purpose. It is appropriate to clarify that, in this respect, the concept of significant change should be understood as equivalent in  substance  to  the  notion  of  substantial  modification,  which  is  used  with  regard  only  to  high-risk  AI  systems pursuant to this Regulation. On an exceptional basis and in light of public accountability, operators of AI systems which are components of the large-scale IT systems established by the legal acts listed in an annex to this Regulation and operators of high-risk AI systems that are intended to be used by public authorities should, respectively, take the necessary  steps  to  comply  with  the  requirements  of  this  Regulation  by  end  of  2030  and  by  2  August  2030.\n(178) Providers  of  high-risk  AI  systems  are  encouraged  to  start  to  comply,  on  a  voluntary  basis,  with  the  relevant obligations  of  this  Regulation  already  during  the  transitional  period.\n(179) This Regulation should apply from 2 August 2026. However, taking into account the unacceptable risk associated with the use of AI in certain ways, the prohibitions as well as the general provisions of this Regulation should already apply  from  2  February  2025.  While  the  full  effect  of  those  prohibitions  follows  with  the  establishment  of  the governance and enforcement of this Regulation, anticipating the application of the prohibitions is important to take account  of  unacceptable  risks  and  to  have  an  effect  on  other  procedures,  such  as  in  civil  law.  Moreover,  the infrastructure  related  to  the  governance  and  the  conformity  assessment  system  should  be  operational  before 2 August 2026, therefore the provisions on notified bodies and governance structure should apply from 2 August 2025. Given the rapid pace of technological advancements and adoption of general-purpose AI models, obligations for providers of general-purpose AI models should apply from 2 August 2025. Codes of practice should be ready by 2  May  2025  in  view  of  enabling  providers  to  demonstrate  compliance  on  time.  The  AI  Office  should  ensure  that classification rules and procedures are up to date in light of technological developments. In addition, Member States should lay down and notify to the Commission the rules on penalties, including administrative fines, and ensure that they are properly and effectively implemented by the date of application of this Regulation. Therefore the provisions on penalties  should  apply  from  2  August  2025.\n(180) The  European  Data  Protection  Supervisor  and  the  European  Data  Protection  Board  were  consulted  in  accordance with Article  42(1)  and  (2)  of  Regulation  (EU)  2018/1725  and  delivered  their  joint  opinion  on  18  June  2021,\nHAVE ADOPTED THIS REGULATION:"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_12",
    "chunk_content": "Subject matter'\n[<Paragraph children=[<RawText children=('The  purpose  of  this  Regulation  is  to  improve  the  functioning  of  '\n 'the  internal  market  and  promote  the  uptake  of human-centric  and  '\n 'trustworthy  artificial  intelligence  (AI),  while  ensuring  a  high  '\n 'level  of  protection  of  health,  safety, fundamental rights enshrined in '\n 'the Charter, including democracy, the rule of  law and environmental '\n 'protection, against the  harmful  effects  of  AI  systems  in  the  Union  '\n 'and  supporting  innovation.')>]>]\n[<Paragraph children=[<RawText children='This  Regulation  lays  down:'>]>]\n(a) harmonised rules for  the  placing  on  the  market,  the  putting  into  service,  and  the  use  of  AI  systems  in  the  Union;\n(b) prohibitions  of  certain  AI  practices;\n(c) specific  requirements  for  high-risk  AI  systems  and  obligations  for  operators  of  such  systems;\n(d) harmonised transparency rules for certain  AI  systems;\n(e) harmonised rules for  the  placing  on  the  market  of  general-purpose  AI  models;\n(f) rules  on  market  monitoring,  market  surveillance,  governance  and  enforcement;\n(g) measures  to support  innovation,  with  a  particular  focus  on  SMEs,  including  start-ups."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_13",
    "chunk_content": "Scope\n[<Paragraph children=[<RawText children='This  Regulation  applies  to:'>]>]\n(a) providers placing on the market or putting into service AI systems or placing on the market general-purpose AI models in the Union, irrespective of whether those providers are established or located within the Union or in a third country;\n(b) deployers of  AI  systems  that  have  their  place  of  establishment  or  are  located  within  the  Union;\n(c) providers and deployers of AI systems that have their place of establishment or are located in a third country, where the output  produced by the  AI  system is  used  in  the  Union;\n(d) importers  and  distributors  of  AI  systems;\n(e) product  manufacturers  placing  on  the  market  or  putting  into  service  an  AI  system  together  with  their  product  and under  their  own  name  or  trademark;\n(f) authorised  representatives  of  providers,  which are  not  established  in  the  Union;\n(g) affected  persons  that  are  located  in  the  Union.\n[<Paragraph children=[<RawText children=('For AI systems classified as high-risk AI systems in accordance with Article '\n '6(1) related to products covered by the Union harmonisation legislation '\n 'listed in Section B of Annex I, only Article 6(1), Articles 102 to 109 and '\n 'Article 112 apply. Article 57 applies only in so far as the requirements for '\n 'high-risk AI systems under this Regulation have been integrated in that  '\n 'Union  harmonisation  legislation.')>]>]\n[<Paragraph children=[<RawText children=('This  Regulation  does  not  apply  to  areas  outside  the  scope  of  '\n 'Union  law,  and  shall  not,  in  any  event,  affect  the competences of '\n 'the Member States concerning national security, regardless of the type of '\n 'entity entrusted by the Member States  with  carrying  out  tasks  in  '\n 'relation  to  those  competences.')>]>]\nThis Regulation does not apply to AI systems where and in so far they are placed on the market, put into service, or used with or without modification exclusively for military, defence or national security purposes, regardless of the type of entity carrying  out  those  activities.\nThis Regulation does not apply to AI systems which are not placed on the market or put into service in the Union, where the  output  is  used  in  the  Union  exclusively  for  military,  defence  or  national  security  purposes,  regardless  of  the  type  of entity  carrying  out  those  activities.\n[<Paragraph children=[<RawText children=('This  Regulation  applies  neither  to  public  authorities  in  a  third  '\n 'country  nor  to  international  organisations  falling within the scope of '\n 'this Regulation pursuant to paragraph 1, where those authorities or '\n 'organisations use AI systems in the framework of  international  '\n 'cooperation  or  agreements  for  law  enforcement  and  judicial  '\n 'cooperation  with  the  Union  or with  one  or  more  Member  States,  '\n 'provided  that  such  a  third  country  or  international  organisation  '\n 'provides  adequate safeguards  with  respect  to  the  protection  of  '\n 'fundamental  rights  and  freedoms  of  individuals.')>]>]\n[<Paragraph children=[<RawText children=('This Regulation shall not affect the application of the provisions on the '\n 'liability of providers of intermediary services as  set  out  in  Chapter  '\n 'II  of  Regulation  (EU)  2022/2065.')>]>]\n[<Paragraph children=[<RawText children=('This Regulation does not apply to AI systems or AI models, including their '\n 'output, specifically developed and put into service  for  the  sole  '\n 'purpose  of  scientific  research  and  development.')>]>]\n[<Paragraph children=[<RawText children=('Union law on the protection of personal data, privacy and the '\n 'confidentiality of communications applies to personal data processed in '\n 'connection with the rights and obligations laid down in this Regulation. '\n 'This Regulation shall not affect Regulation  (EU)  2016/679 or (EU) '\n '2018/1725, or Directive 2002/58/EC or (EU) 2016/680, without prejudice to '\n 'Article 10(5)  and  Article  59  of  this  Regulation.')>]>]\n[<Paragraph children=[<RawText children=('This  Regulation  does  not  apply  to  any  research,  testing  or  '\n 'development  activity  regarding  AI  systems  or  AI  models prior  to  '\n 'their  being  placed  on  the  market  or  put  into  service.  Such  '\n 'activities  shall  be  conducted  in  accordance  with applicable  Union  '\n 'law.  Testing  in  real  world  conditions  shall  not  be  covered  by  '\n 'that  exclusion.')>]>]\n[<Paragraph children=[<RawText children=('This Regulation is without prejudice to the rules laid down by other Union '\n 'legal acts related to consumer protection and product safety.')>]>]\n[<Paragraph children=[<RawText children=('This Regulation does not apply to obligations of deployers who are natural '\n 'persons using AI systems in the course of a  purely  personal  '\n 'non-professional  activity.')>]>]\n[<Paragraph children=[<RawText children=('This Regulation does not preclude the Union or Member States from '\n 'maintaining or introducing laws, regulations or administrative provisions '\n 'which are more favourable to workers in terms of protecting their rights in '\n 'respect of the use of AI  systems  by  employers,  or  from  encouraging  '\n 'or  allowing  the  application  of  collective  agreements  which  are  more '\n 'favourable  to workers.')>]>]\n[<Paragraph children=[<RawText children=('This Regulation does not apply to AI systems released under free and '\n 'open-source licences, unless they are placed on the  market  or  put  into  '\n 'service  as  high-risk  AI  systems  or  as  an  AI  system  that  falls  '\n 'under  Article  5  or  50.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_14",
    "chunk_content": "Definitions\nFor  the  purposes  of  this  Regulation,  the  following  definitions  apply:\n(1) 'AI system' means a machine-based system that is designed to operate with varying levels of autonomy and that may exhibit  adaptiveness  after  deployment,  and  that,  for  explicit  or  implicit  objectives,  infers,  from  the  input  it  receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual  environments;\n(2) 'risk'  means  the  combination  of  the  probability of  an  occurrence  of  harm  and  the  severity of  that  harm;\n(3) 'provider'  means  a  natural  or  legal  person,  public  authority,  agency  or  other  body  that  develops  an  AI  system  or a  general-purpose AI model or  that has an AI system or a general-purpose AI model developed and places it on the market or puts the AI system into service under its own name or trademark, whether for payment or free of charge;\n(4) 'deployer'  means  a  natural  or  legal  person,  public  authority,  agency  or  other  body  using  an  AI  system  under  its authority  except  where  the  AI  system  is  used  in  the  course  of  a  personal  non-professional  activity;\n(5) 'authorised representative' means a natural or legal person located or established in the Union who has received and accepted a written mandate from a provider of an AI system or a general-purpose AI model to, respectively, perform and carry out on its  behalf  the  obligations  and  procedures  established  by  this  Regulation;\n(6) 'importer' means a natural or legal person located or established in the Union that places on the market an AI system that  bears  the  name  or  trademark of  a  natural  or  legal  person  established  in  a  third  country;\n(7) 'distributor' means a natural or legal person in the supply chain, other  than the provider or the importer, that makes an  AI  system  available  on  the  Union  market;\n(8) 'operator'  means  a  provider,  product  manufacturer,  deployer,  authorised  representative,  importer  or  distributor;\n(9) 'placing on the market' means the first making available of an AI system or a general-purpose AI model on the Union market;\n(10) 'making available on the market' means the supply of an AI system or a general-purpose AI model for distribution or use  on  the  Union  market  in  the  course  of  a  commercial  activity,  whether  in  return  for  payment  or  free  of  charge;\n(11) 'putting into service' means the supply of an AI system for first use directly to the deployer or for own use in the Union for  its  intended  purpose;\n(12) 'intended purpose' means the use for  which an AI system is intended by the provider, including the specific context and conditions of use, as specified in the information supplied by the provider in the instructions for use, promotional or  sales  materials  and  statements,  as  well  as  in  the  technical  documentation;\n(13) 'reasonably  foreseeable  misuse'  means  the  use  of  an  AI  system  in  a  way  that  is  not  in  accordance  with  its  intended purpose,  but  which  may  result  from  reasonably  foreseeable  human  behaviour  or  interaction  with  other  systems, including  other  AI  systems;\n(14) 'safety component' means a component of a product or of an AI system which fulfils a safety function for that product or  AI  system,  or  the  failure  or  malfunctioning  of  which  endangers  the  health  and  safety of  persons  or  property;\n(15) 'instructions for  use' means the information provided by the provider  to inform the deployer of, in particular, an AI system's  intended  purpose  and  proper  use;\n(16) 'recall  of  an  AI  system'  means  any  measure  aiming  to  achieve  the  return  to  the  provider  or  taking  out  of  service  or disabling  the  use  of  an  AI  system  made  available  to  deployers;\n(17) 'withdrawal  of  an  AI  system'  means  any  measure  aiming  to  prevent  an  AI  system  in  the  supply  chain  being  made available  on  the  market;\n(18) 'performance of an AI  system'  means  the  ability of  an  AI  system  to  achieve  its  intended  purpose;\n(19) 'notifying authority' means the national authority responsible for setting up and carrying out the necessary procedures for  the  assessment,  designation  and  notification  of  conformity  assessment  bodies  and  for  their  monitoring;\n(20) 'conformity assessment' means the process of demonstrating whether the requirements set out in Chapter III, Section 2 relating  to  a  high-risk  AI  system  have  been  fulfilled;\n(21) 'conformity  assessment  body'  means  a  body  that  performs  third-party  conformity  assessment  activities,  including testing,  certification  and  inspection;\n(22) 'notified  body'  means  a  conformity  assessment  body  notified  in  accordance  with  this  Regulation  and  other  relevant Union harmonisation legislation;\n(23) 'substantial modification' means a change to an AI system after its placing on the market or putting into service which is not foreseen or planned in the initial conformity assessment carried out by the provider and as a result of which the compliance  of  the  AI  system  with  the  requirements  set  out  in  Chapter  III,  Section  2  is  affected  or  results  in a  modification  to  the  intended  purpose  for  which  the  AI  system  has  been  assessed;\n(24) 'CE marking' means a marking by which a provider indicates that an AI system is in conformity with the requirements set  out  in  Chapter  III,  Section  2  and  other  applicable  Union  harmonisation  legislation  providing  for  its  affixing;\n(25) 'post-market  monitoring  system'  means  all  activities  carried  out  by  providers  of  AI  systems  to  collect  and  review experience  gained  from  the  use  of  AI  systems  they  place  on  the  market  or  put  into  service  for  the  purpose  of identifying any  need  to  immediately  apply  any  necessary corrective  or  preventive  actions;\n(26) 'market  surveillance  authority'  means  the  national  authority  carrying  out  the  activities  and  taking  the  measures pursuant to Regulation  (EU)  2019/1020;\n(27) 'harmonised  standard'  means  a  harmonised  standard  as  defined  in  Article  2(1),  point  (c),  of  Regulation  (EU) No 1025/2012;\n(28) 'common  specification'  means  a  set  of  technical  specifications  as  defined  in  Article  2,  point  (4)  of  Regulation  (EU) No 1025/2012, providing means to comply with certain requirements established under  this Regulation;\n(29) 'training  data'  means  data  used  for  training  an  AI  system  through  fitting  its  learnable  parameters;\n(30) 'validation data' means data used for providing an evaluation of the trained AI system and for tuning its non-learnable parameters  and  its  learning  process  in  order,  inter  alia,  to  prevent  underfitting  or  overfitting;\n(31) 'validation  data  set'  means  a  separate  data  set  or  part  of  the  training  data  set,  either  as  a  fixed  or  variable  split;\n(32) 'testing  data'  means  data  used  for  providing  an  independent  evaluation  of  the  AI  system  in  order  to  confirm  the expected  performance of  that  system  before  its  placing  on  the  market or  putting  into  service;\n(33) 'input data' means data provided to or directly acquired by an AI system on the basis of which the system produces an output;\n(34) 'biometric data' means personal data resulting from specific technical processing relating to the physical, physiological or  behavioural  characteristics  of  a  natural  person,  such  as  facial  images  or  dactyloscopic  data;\n(35) 'biometric  identification'  means  the  automated  recognition  of  physical,  physiological,  behavioural,  or  psychological human features for  the purpose of establishing the identity of a natural person by comparing biometric data of  that individual  to  biometric  data  of  individuals  stored  in  a  database;\n(36) 'biometric  verification'  means  the  automated,  one-to-one  verification,  including  authentication,  of  the  identity  of natural  persons  by comparing  their  biometric  data  to  previously  provided biometric  data;\n(37) 'special categories of personal data' means the categories of personal data referred to in Article 9(1) of Regulation (EU) 2016/679, Article  10 of  Directive  (EU)  2016/680  and  Article  10(1)  of  Regulation  (EU)  2018/1725;\n(38) 'sensitive  operational  data'  means  operational  data  related  to  activities  of  prevention,  detection,  investigation  or prosecution of  criminal  offences,  the  disclosure  of  which  could  jeopardise  the  integrity of  criminal  proceedings;\n(39) 'emotion recognition system' means an AI system for the purpose of identifying or inferring emotions or intentions of natural  persons  on  the  basis  of  their  biometric  data;\n(40) 'biometric  categorisation  system'  means  an  AI  system  for  the  purpose  of  assigning  natural  persons  to  specific categories  on  the  basis  of  their  biometric  data,  unless  it  is  ancillary  to  another  commercial  service  and  strictly necessary  for  objective  technical  reasons;\n(41) 'remote biometric identification system' means an AI system for  the purpose of identifying natural persons, without their  active  involvement,  typically  at  a  distance  through  the  comparison  of  a  person's  biometric  data  with  the biometric  data  contained  in  a  reference  database;\n(42) 'real-time  remote  biometric  identification  system'  means  a  remote  biometric  identification  system,  whereby  the capturing  of  biometric  data,  the  comparison  and  the  identification  all  occur  without  a  significant  delay,  comprising not only  instant  identification,  but  also  limited  short  delays  in  order  to  avoid  circumvention;\n(43) 'post-remote  biometric  identification  system'  means  a  remote  biometric  identification  system  other  than  a  real-time remote biometric  identification  system;\n(44) 'publicly accessible space' means any publicly or privately owned physical place accessible to an undetermined number of  natural  persons,  regardless  of  whether  certain  conditions  for  access  may  apply,  and  regardless  of  the  potential capacity  restrictions;\n(45) 'law enforcement  authority'  means:\n(a) any public authority competent for the prevention, investigation, detection or prosecution of criminal offences or the  execution  of  criminal  penalties,  including  the  safeguarding  against  and  the  prevention  of  threats  to  public security;  or\n(b) any  other  body or  entity  entrusted  by  Member  State  law  to  exercise  public  authority  and  public  powers  for  the purposes  of  the  prevention,  investigation,  detection  or  prosecution  of  criminal  offences  or  the  execution  of criminal  penalties,  including  the  safeguarding against  and  the  prevention  of  threats  to  public  security;\n(46) 'law enforcement'  means activities  carried  out  by law  enforcement  authorities  or  on  their  behalf  for  the  prevention, investigation,  detection  or  prosecution  of  criminal  offences  or  the  execution  of  criminal  penalties,  including safeguarding against and  preventing  threats  to  public  security;\n(47) 'AI Office' means the Commission's function of contributing to the implementation, monitoring and supervision of AI systems  and  general-purpose  AI  models,  and  AI  governance,  provided  for  in  Commission  Decision  of  24  January 2024; references  in  this  Regulation  to  the  AI  Office  shall  be  construed  as  references  to  the  Commission;\n(48) 'national competent authority' means a notifying authority or a market surveillance authority; as regards AI systems put  into  service  or  used  by  Union  institutions,  agencies,  offices  and  bodies,  references  to  national  competent authorities or market surveillance authorities in this Regulation shall be construed as references to the European Data Protection  Supervisor;\n(49) 'serious incident' means an incident or  malfunctioning of an AI system that directly or  indirectly leads to any of  the following:\n(a) the  death  of  a  person,  or  serious  harm  to  a  person's  health;\n(b) a  serious  and  irreversible  disruption  of  the  management  or  operation  of  critical  infrastructure;\n(c) the  infringement of obligations  under  Union  law intended to protect fundamental  rights;\n(d) serious  harm  to  property or  the  environment;\n(50) 'personal  data'  means  personal  data  as  defined  in  Article  4,  point  (1),  of  Regulation  (EU)  2016/679;\n(51) 'non-personal  data'  means  data  other  than  personal  data  as  defined  in  Article  4,  point  (1),  of  Regulation  (EU) 2016/679;\n(52) 'profiling'  means  profiling  as  defined  in  Article  4,  point  (4),  of  Regulation  (EU)  2016/679;\n(53) 'real-world testing plan' means a document that describes the objectives, methodology, geographical, population and temporal scope, monitoring, organisation and conduct of  testing  in  real-world conditions;\n(54) 'sandbox plan' means a document agreed between the participating provider and the competent authority describing the objectives, conditions, timeframe, methodology and requirements for the activities carried out within the sandbox;\n(55) 'AI  regulatory  sandbox'  means  a  controlled  framework  set  up  by  a  competent  authority  which  offers  providers  or prospective providers of AI systems the possibility to develop, train, validate and test, where appropriate in real-world conditions,  an  innovative  AI  system,  pursuant  to  a  sandbox  plan  for  a  limited  time  under  regulatory  supervision;\n(56) 'AI  literacy'  means  skills,  knowledge  and  understanding  that  allow  providers,  deployers  and  affected  persons,  taking into account their respective rights and obligations in the context of this Regulation, to make an informed deployment of  AI  systems,  as  well  as  to  gain  awareness  about  the  opportunities  and  risks  of  AI  and  possible  harm  it  can  cause;\n(57) 'testing in real-world conditions' means the temporary testing of an AI system for its intended purpose in real-world conditions outside a laboratory or otherwise simulated environment, with a view to gathering reliable and robust data and to assessing and verifying the conformity of  the AI system with the requirements of  this Regulation and it does not qualify as placing the AI system on the market or  putting it into service within the meaning of  this Regulation, provided  that  all  the  conditions  laid  down  in  Article  57  or  60  are  fulfilled;\n(58) 'subject',  for  the  purpose  of  real-world  testing,  means  a  natural  person  who  participates  in  testing  in  real-world conditions;\n(59) 'informed  consent'  means  a  subject's  freely  given,  specific,  unambiguous  and  voluntary  expression  of  his  or  her willingness to participate in a particular  testing in real-world conditions, after having been informed of all aspects of the  testing  that  are  relevant  to  the  subject's  decision  to  participate;\n(60) 'deep fake' means AI-generated or manipulated image, audio or video content that resembles existing persons, objects, places,  entities  or  events  and  would  falsely  appear  to  a  person  to  be  authentic  or  truthful;\n(61) 'widespread  infringement'  means  any  act  or  omission  contrary  to  Union  law  protecting  the  interest  of  individuals, which:\n(a) has harmed or is likely to harm the collective interests of individuals residing in at least two Member States other than the  Member State in which:\n(i) the  act  or  omission  originated  or  took  place;\n(ii) the  provider  concerned,  or,  where  applicable,  its  authorised  representative  is  located  or  established;  or\n(iii) the  deployer  is  established,  when  the  infringement  is  committed  by  the  deployer;\n(b) has  caused,  causes  or  is  likely  to  cause  harm  to  the  collective  interests  of  individuals  and  has  common  features, including  the  same  unlawful  practice  or  the  same  interest  being  infringed,  and  is  occurring  concurrently, committed by the same operator, in at  least  three  Member  States;\n(62) 'critical  infrastructure'  means  critical  infrastructure  as  defined  in  Article  2,  point  (4),  of  Directive  (EU)  2022/2557;\n(63) 'general-purpose AI model' means an AI model, including where such an AI model is trained with a large amount of data  using  self-supervision  at  scale,  that  displays  significant  generality  and  is  capable  of  competently  performing a wide range of distinct tasks regardless of the way the model is placed on the market and that can be integrated into a  variety  of  downstream  systems  or  applications,  except  AI  models  that  are  used  for  research,  development  or prototyping activities  before  they  are  placed  on  the  market;\n(64) 'high-impact  capabilities'  means  capabilities  that  match  or  exceed  the  capabilities  recorded  in  the  most  advanced general-purpose AI  models;\n(65) 'systemic  risk'  means  a  risk  that  is  specific  to  the  high-impact  capabilities  of  general-purpose  AI  models,  having a significant impact on the Union market due to their reach, or due to actual or reasonably foreseeable negative effects on public health, safety, public security, fundamental rights, or the society as a whole, that can be propagated at scale across  the  value  chain;\n(66) 'general-purpose  AI  system'  means  an  AI  system  which  is  based  on  a  general-purpose  AI  model  and  which  has  the capability  to  serve  a  variety  of  purposes,  both  for  direct  use  as  well  as  for  integration  in  other  AI  systems;\n(67) 'floating-point operation' means any mathematical operation or assignment involving floating-point numbers, which are  a  subset  of  the  real  numbers  typically  represented  on  computers  by  an  integer  of  fixed  precision  scaled  by  an integer  exponent  of  a  fixed  base;\n(68) 'downstream provider' means a provider of an AI system, including a general-purpose AI system, which integrates an AI  model,  regardless  of  whether  the  AI  model  is  provided  by  themselves  and  vertically  integrated  or  provided  by another entity  based  on  contractual  relations."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_15",
    "chunk_content": "AI literacy\nProviders and deployers of AI systems shall take measures to ensure, to their best extent, a sufficient level of AI literacy of their  staff  and  other  persons  dealing  with  the  operation  and  use  of  AI  systems  on  their  behalf,  taking  into  account  their technical knowledge, experience, education and training and the context the AI systems are to be used in, and considering the  persons  or  groups  of  persons  on  whom  the  AI  systems  are  to  be  used.\nCHAPTER II"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_16",
    "chunk_content": "PROHIBITED AI PRACTICES\nArticle  5"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_17",
    "chunk_content": "Prohibited AI practices\n[<Paragraph children=[<RawText children='The following  AI  practices  shall  be  prohibited:'>]>]\n(a) the placing on the market, the putting into service or the use of an AI system that deploys subliminal techniques beyond a  person's  consciousness  or  purposefully  manipulative  or  deceptive  techniques,  with  the  objective,  or  the  effect  of materially distorting the behaviour of a person or a group of persons by appreciably impairing their ability to make an informed decision, thereby causing them to take a decision that they would not have otherwise taken in a manner that causes  or  is  reasonably  likely  to  cause  that  person,  another  person  or  group  of  persons  significant  harm;\n(b) the placing on the market, the putting into service or the use of an AI system that exploits any of the vulnerabilities of a natural person or a specific group of persons due to their age, disability or a specific social or economic situation, with the objective, or the effect, of materially distorting the behaviour of that person or a person belonging to that group in a  manner  that  causes  or  is  reasonably  likely  to  cause  that  person  or  another  person  significant  harm;\n(c) the placing on the market, the putting into service or the use of AI systems for the evaluation or classification of natural persons  or  groups  of  persons  over  a  certain  period  of  time  based  on  their  social  behaviour  or  known,  inferred  or predicted personal  or  personality characteristics,  with  the  social  score  leading  to  either  or  both  of  the  following:\n(i) detrimental  or  unfavourable  treatment of  certain  natural  persons  or  groups  of  persons  in  social  contexts  that  are unrelated  to  the  contexts  in  which  the  data  was  originally  generated  or  collected;\n(ii) detrimental  or  unfavourable  treatment  of  certain  natural  persons  or  groups  of  persons  that  is  unjustified  or disproportionate to their  social  behaviour  or  its  gravity;\n(d) the placing on the market, the putting into service for this specific purpose, or the use of an AI system for making risk assessments of natural persons in order to assess or predict the risk of a natural person committing a criminal offence, based  solely  on  the  profiling  of  a  natural  person  or  on  assessing  their  personality  traits  and  characteristics;  this prohibition  shall  not  apply  to  AI  systems  used  to  support  the  human  assessment  of  the  involvement  of  a  person  in a  criminal  activity,  which  is  already  based  on  objective  and  verifiable  facts  directly  linked  to  a  criminal  activity;\n(e) the  placing  on  the  market,  the  putting  into  service  for  this  specific  purpose,  or  the  use  of  AI  systems  that  create  or expand facial recognition databases through the untargeted scraping of facial images from the internet or CCTV footage;\n(f) the placing on the market, the putting into service for this specific purpose, or the use of AI systems to infer emotions of  a  natural  person  in  the  areas  of  workplace  and  education  institutions,  except  where  the  use  of  the  AI  system  is intended  to  be  put  in  place  or  into  the  market  for  medical  or  safety  reasons;\n(g) the  placing  on  the  market,  the  putting  into  service  for  this  specific  purpose,  or  the  use  of  biometric  categorisation systems that categorise individually natural persons based on their biometric data to deduce or infer their race, political opinions, trade union membership, religious or philosophical beliefs, sex life or sexual orientation; this prohibition does not cover any labelling or filtering of  lawfully acquired biometric datasets, such as images, based on biometric data or categorizing  of  biometric  data  in  the  area  of  law  enforcement;\n(h) the  use  of  'real-time'  remote  biometric  identification  systems  in  publicly  accessible  spaces  for  the  purposes  of  law enforcement, unless  and  in  so  far  as  such  use  is  strictly  necessary  for  one  of  the  following  objectives:\n(i) the targeted search for specific victims of abduction, trafficking in human beings or sexual exploitation of human beings,  as  well  as  the  search  for  missing  persons;\n(ii) the  prevention  of  a  specific,  substantial  and  imminent  threat  to  the  life  or  physical  safety  of  natural  persons  or a  genuine  and  present  or  genuine  and  foreseeable  threat  of  a  terrorist  attack;\n(iii) the localisation or identification of a person suspected of having committed a criminal offence, for the purpose of conducting  a  criminal  investigation  or  prosecution  or  executing  a  criminal  penalty  for  offences  referred  to  in Annex  II  and  punishable  in  the  Member  State  concerned  by  a  custodial  sentence  or  a  detention  order  for a  maximum period of at least four  years.\nPoint  (h)  of  the  first  subparagraph  is  without  prejudice  to  Article  9  of  Regulation  (EU)  2016/679  for  the  processing  of biometric  data  for  purposes  other  than  law  enforcement.\n[<Paragraph children=[<RawText children=(\"The  use  of  'real-time'  remote  biometric  identification  systems  in  \"\n 'publicly  accessible  spaces  for  the  purposes  of  law enforcement  for  '\n 'any of  the  objectives  referred  to  in  paragraph  1,  first  '\n 'subparagraph,  point  (h),  shall  be  deployed  for  the purposes  set  '\n 'out  in  that  point  only  to  confirm  the  identity  of  the  '\n 'specifically  targeted  individual,  and  it  shall  take  into account the  '\n 'following  elements:')>]>]\n(a) the nature of the situation giving rise to the possible use, in particular the seriousness, probability and scale of the harm that  would  be  caused  if  the  system were  not  used;\n(b) the  consequences  of  the  use  of  the  system  for  the  rights  and  freedoms  of  all  persons  concerned,  in  particular  the seriousness,  probability  and  scale  of  those  consequences.\nIn addition, the use of 'real-time' remote biometric identification systems in publicly accessible spaces for  the purposes of law  enforcement  for  any  of  the  objectives  referred  to  in  paragraph  1,  first  subparagraph,  point  (h),  of  this  Article  shall comply with necessary and proportionate safeguards and conditions in relation to the use in accordance with the national law authorising the use thereof, in particular as regards the temporal, geographic and personal limitations. The use of the 'real-time'  remote  biometric  identification  system  in  publicly  accessible  spaces  shall  be  authorised  only  if  the  law enforcement  authority  has  completed  a  fundamental  rights  impact  assessment  as  provided  for  in  Article  27  and  has registered the system in the EU database according to Article 49. However, in duly justified cases of urgency, the use of such systems  may  be  commenced  without  the  registration  in  the  EU  database,  provided  that  such  registration  is  completed without undue delay.\n[<Paragraph children=[<RawText children=('For  the  purposes  of  paragraph  1,  first  subparagraph,  point  (h)  '\n 'and  paragraph  2,  each  use  for  the  purposes  of  law enforcement of a '\n \"'real-time' remote biometric identification system in publicly accessible \"\n 'spaces shall be subject to a prior authorisation granted by a judicial '\n 'authority or an independent administrative authority whose decision is '\n 'binding of  the Member State in which the use is to take place, issued upon '\n 'a reasoned request and in accordance with the detailed rules of national  '\n 'law referred  to  in  paragraph  5.  However,  in  a  duly  justified  '\n 'situation  of  urgency,  the  use  of  such  system  may  be commenced  '\n 'without  an  authorisation  provided  that  such  authorisation  is  '\n 'requested  without  undue  delay,  at  the  latest within 24 hours. If such '\n 'authorisation is rejected, the use shall be stopped with immediate effect '\n 'and all the data, as well as the  results  and  outputs  of  that  use  '\n 'shall  be  immediately  discarded  and  deleted.')>]>]\nThe  competent  judicial  authority  or  an  independent  administrative  authority  whose  decision  is  binding  shall  grant  the authorisation only where it is satisfied, on the basis of objective evidence or clear indications presented to it, that the use of the 'real-time' remote biometric identification system concerned is necessary for, and proportionate to, achieving one of the\nobjectives  specified  in  paragraph  1,  first  subparagraph,  point  (h),  as  identified  in  the  request  and,  in  particular,  remains limited to what is strictly necessary concerning the period of time as well as the geographic and personal scope. In deciding on the request, that authority shall take into account the elements referred to in paragraph 2. No decision that produces an adverse legal effect on a person may be taken based solely on the output of the 'real-time' remote biometric identification system.\n[<Paragraph children=[<RawText children=(\"Without  prejudice  to  paragraph  3,  each  use  of  a  'real-time'  \"\n 'remote  biometric  identification  system  in  publicly accessible  spaces  '\n 'for  law  enforcement  purposes  shall  be  notified  to  the  relevant  '\n 'market  surveillance  authority  and  the national data protection authority '\n 'in accordance with the national rules referred to in paragraph 5. The '\n 'notification shall, as a  minimum, contain  the information  specified  '\n 'under  paragraph  6  and  shall  not  include  sensitive  operational  data.')>]>]\n[<Paragraph children=[<RawText children=('A Member State may decide to provide for the possibility to fully or '\n \"partially authorise the use of 'real-time' remote biometric  identification  \"\n 'systems  in  publicly  accessible  spaces  for  the  purposes  of  law  '\n 'enforcement  within  the  limits  and under the conditions listed in '\n 'paragraph 1, first subparagraph, point (h), and paragraphs 2 and 3. Member '\n 'States concerned shall  lay  down  in  their  national  law  the  necessary  '\n 'detailed  rules  for  the  request,  issuance  and  exercise  of,  as  well  '\n 'as supervision and reporting relating to, the authorisations referred to in '\n 'paragraph 3. Those rules shall also specify in respect of  which  of  the  '\n 'objectives  listed  in  paragraph  1,  first  subparagraph,  point  (h),  '\n 'including  which  of  the  criminal  offences referred  to in point  '\n '(h)(iii)  thereof,  the  competent  authorities  may  be  authorised  to '\n 'use  those  systems  for  the  purposes  of law enforcement.  Member States '\n 'shall notify  those  rules  to  the  Commission  at  the  latest  30  days  '\n 'following  the  adoption thereof. Member States may introduce, in accordance '\n 'with Union law, more restrictive laws on the use of remote biometric '\n 'identification  systems.')>]>]\n[<Paragraph children=[<RawText children=('National market surveillance authorities and the national data protection '\n 'authorities of Member States that have been notified of  the use of '\n \"'real-time'  remote biometric identification systems in publicly accessible \"\n 'spaces for law enforcement purposes  pursuant  to  paragraph  4  shall  '\n 'submit  to  the  Commission  annual  reports  on  such  use.  For  that  '\n 'purpose,  the Commission shall provide Member States and national market '\n 'surveillance and data protection authorities with a template, including  '\n 'information  on  the  number  of  the  decisions  taken  by  competent  '\n 'judicial  authorities  or  an  independent administrative  authority  whose  '\n 'decision  is  binding  upon  requests  for  authorisations  in  accordance  '\n 'with  paragraph  3  and their  result.')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  shall  publish  annual  reports  on  the  use  of  '\n 'real-time  remote  biometric  identification  systems  in publicly  '\n 'accessible  spaces  for  law  enforcement  purposes,  based  on  aggregated  '\n 'data  in  Member  States  on  the  basis  of  the annual reports referred to '\n 'in paragraph 6. Those annual reports shall not include sensitive operational '\n 'data of the related law enforcement activities.')>]>]\n[<Paragraph children=[<RawText children=('This  Article  shall  not  affect  the  prohibitions  that  apply  where  '\n 'an  AI  practice  infringes  other  Union  law.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_18",
    "chunk_content": "HIGH-RISK AI SYSTEMS\nSECTION 1"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_19",
    "chunk_content": "Classification  of  AI  systems  as  high-risk\nArticle  6"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_20",
    "chunk_content": "Classification  rules  for  high-risk  AI  systems\n[<Paragraph children=[<RawText children=('Irrespective  of  whether  an  AI  system  is  placed  on  the  market  or  '\n 'put  into  service  independently  of  the  products referred to in points '\n '(a) and (b), that AI system shall be considered to be high-risk where both '\n 'of the following conditions are  fulfilled:')>]>]\n(a) the AI system is intended to be used as a safety component of a product, or the AI system is itself a product, covered by the  Union  harmonisation  legislation  listed  in  Annex  I;\n(b) the  product  whose  safety  component  pursuant  to  point  (a)  is  the  AI  system,  or  the  AI  system  itself  as  a  product,  is required to undergo a third-party conformity assessment, with a view to the placing on the market or the putting into service  of  that  product  pursuant  to  the  Union  harmonisation  legislation  listed  in  Annex  I.\n[<Paragraph children=[<RawText children=('In  addition  to  the  high-risk  AI  systems  referred  to  in  paragraph  '\n '1,  AI  systems  referred  to  in  Annex  III  shall  be considered  to  be  '\n 'high-risk.')>]>]\n[<Paragraph children=[<RawText children=('By derogation from paragraph 2, an AI system referred to in Annex III shall '\n 'not be considered to be high-risk where it does  not  pose  a  significant  '\n 'risk  of  harm  to  the  health,  safety  or  fundamental  rights  of  '\n 'natural  persons,  including  by  not materially  influencing  the  outcome  '\n 'of  decision  making.')>]>]\nThe first  subparagraph  shall  apply  where  any of  the  following  conditions  is  fulfilled:\n(a) the  AI  system  is  intended  to  perform  a  narrow  procedural  task;\n(b) the  AI  system  is  intended  to  improve  the  result  of  a  previously  completed  human  activity;\n(c) the AI system is intended to detect decision-making patterns or deviations from prior decision-making patterns and is not  meant  to replace  or  influence  the  previously completed  human  assessment,  without  proper  human  review;  or\n(d) the  AI  system  is  intended  to  perform  a  preparatory  task  to  an  assessment  relevant  for  the  purposes  of  the  use  cases listed  in  Annex  III.\nNotwithstanding the first  subparagraph,  an  AI  system  referred  to  in  Annex  III  shall  always  be  considered  to  be  high-risk where the AI system performs profiling  of  natural  persons.\n[<Paragraph children=[<RawText children=('A provider  who considers that an AI system referred to in Annex III is not '\n 'high-risk  shall document its assessment before that system is placed on the '\n 'market or put into service. Such provider shall be subject to the '\n 'registration obligation set out in Article 49(2). Upon request of national '\n 'competent authorities, the provider shall provide the documentation of the  '\n 'assessment.')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  shall,  after  consulting  the  European  Artificial  '\n \"Intelligence  Board  (the  'Board'),  and  no  later  than 2 February 2026, \"\n 'provide guidelines specifying the practical implementation of this Article '\n 'in line with Article 96 together with  a  comprehensive  list  of  '\n 'practical  examples  of  use  cases  of  AI  systems  that  are  high-risk  '\n 'and  not  high-risk.')>]>]\n[<Paragraph children=[<RawText children=('The Commission is empowered to adopt delegated acts in accordance with '\n 'Article 97 in order to amend paragraph 3, second subparagraph, of  this '\n 'Article by adding new conditions to those laid down therein, or by modifying '\n 'them, where there is concrete and reliable evidence of the existence of AI '\n 'systems that fall under the scope of Annex III, but do not pose a  '\n 'significant  risk  of  harm  to  the  health,  safety  or  fundamental  '\n 'rights  of  natural  persons.')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  shall  adopt  delegated  acts  in  accordance  with  '\n 'Article  97  in  order  to  amend  paragraph  3,  second subparagraph,  of  '\n 'this  Article  by  deleting  any  of  the  conditions  laid  down  therein,  '\n 'where  there  is  concrete  and  reliable evidence that this is necessary to '\n 'maintain the level of protection of health, safety and fundamental rights '\n 'provided for by this  Regulation.')>]>]\n[<Paragraph children=[<RawText children=('Any  amendment  to  the  conditions  laid  down  in  paragraph  3,  second  '\n 'subparagraph,  adopted  in  accordance  with paragraphs 6 and 7 of this '\n 'Article shall not decrease the overall level of protection of health, safety '\n 'and fundamental rights provided for by this Regulation and shall ensure '\n 'consistency with the delegated acts adopted pursuant to Article 7(1), and '\n 'take  account of  market  and  technological  developments.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_21",
    "chunk_content": "Amendments to Annex III\n[<Paragraph children=[<RawText children=('The Commission is empowered to adopt delegated acts in accordance with '\n 'Article 97 to amend Annex III by adding or  modifying  use-cases  of  '\n 'high-risk  AI  systems  where  both  of  the  following  conditions  are  '\n 'fulfilled:')>]>]\n(a) the  AI  systems  are  intended  to  be  used  in  any of  the  areas  listed  in  Annex  III;\n(b) the  AI  systems pose  a  risk of  harm  to health  and  safety,  or  an  adverse  impact  on  fundamental  rights,  and  that  risk  is equivalent to, or greater than, the risk of harm or of adverse impact posed by the high-risk AI systems already referred to  in  Annex  III.\n[<Paragraph children=[<RawText children=('When assessing  the  condition  under  paragraph  1,  point  (b),  the  '\n 'Commission  shall  take  into  account  the  following criteria:')>]>]\n(a) the  intended  purpose  of  the  AI  system;\n(b) the  extent  to  which  an  AI  system  has  been  used  or  is  likely  to  be  used;\n(c) the  nature  and  amount  of  the  data  processed  and  used  by  the  AI  system,  in  particular  whether  special  categories  of personal  data  are  processed;\n(d) the  extent  to  which  the  AI  system  acts  autonomously  and  the  possibility  for  a  human  to  override  a  decision  or recommendations that may lead to potential harm;\n(e) the extent to which the use of an AI system has already caused harm to health and safety, has had an adverse impact on fundamental rights or has given rise to significant concerns in relation to the likelihood of such harm or adverse impact, as demonstrated, for example, by reports or documented allegations submitted to national competent authorities or by other  reports,  as  appropriate;\n(f) the potential extent of such harm or such adverse impact, in particular in terms of its intensity and its ability to affect multiple  persons  or  to  disproportionately  affect  a  particular  group  of  persons;\n(g) the  extent  to  which  persons  who  are  potentially  harmed  or  suffer  an  adverse  impact  are  dependent  on  the  outcome produced with an AI system, in particular because for practical or legal reasons it is not reasonably possible to opt-out from that outcome;\n(h) the  extent  to  which  there  is  an  imbalance  of  power,  or  the  persons  who  are  potentially  harmed  or  suffer  an  adverse impact  are  in  a  vulnerable  position  in  relation  to  the  deployer  of  an  AI  system,  in  particular  due  to  status,  authority, knowledge, economic or social circumstances, or age;\n(i) the extent to which the outcome produced involving an AI system is easily corrigible or reversible, taking into account the technical solutions available to correct or reverse it, whereby outcomes having an adverse impact on health, safety or fundamental rights, shall  not  be  considered  to  be  easily corrigible  or  reversible;\n(j) the magnitude and likelihood of benefit of the deployment of the AI system for individuals, groups, or society at large, including  possible  improvements in product  safety;\n(k) the  extent  to  which  existing  Union  law  provides  for:\n(i) effective  measures  of  redress  in  relation  to  the  risks  posed  by  an  AI  system,  with  the  exclusion  of  claims  for damages;\n(ii) effective  measures  to  prevent  or  substantially  minimise  those  risks.\n[<Paragraph children=[<RawText children=('The Commission is empowered to adopt delegated acts in accordance with '\n 'Article 97 to amend the list in Annex III by removing high-risk AI systems '\n 'where both of  the  following conditions  are fulfilled:')>]>]\n(a) the high-risk AI system concerned no longer poses any significant risks to fundamental rights, health or safety, taking into  account  the  criteria  listed  in  paragraph  2;\n(b) the deletion does not decrease the overall level of protection of health, safety and fundamental rights under Union law."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_22",
    "chunk_content": "Compliance with the requirements\n[<Paragraph children=[<RawText children=('High-risk AI systems shall comply with the requirements laid down in this '\n 'Section, taking into account their intended purpose  as  well  as  the  '\n 'generally  acknowledged  state  of  the  art  on  AI  and  AI-related  '\n 'technologies.  The  risk  management system  referred  to  in  Article  9  '\n 'shall  be  taken  into  account  when  ensuring  compliance  with  those  '\n 'requirements.')>]>]\n[<Paragraph children=[<RawText children=('Where a product contains an AI system, to which the requirements of this '\n 'Regulation as well as requirements of the Union harmonisation legislation '\n 'listed in Section A of Annex I apply, providers shall be responsible for '\n 'ensuring that their product is fully compliant with all applicable '\n 'requirements under applicable Union harmonisation legislation. In ensuring '\n 'the compliance of high-risk AI systems referred to in paragraph 1 with the '\n 'requirements set out in this Section, and in order to ensure consistency, '\n 'avoid duplication and minimise additional burdens, providers shall have a '\n 'choice of integrating, as appropriate,  the  necessary  testing  and  '\n 'reporting  processes,  information  and  documentation  they  provide  with  '\n 'regard  to their  product  into  documentation  and  procedures  that  '\n 'already  exist  and  are  required  under  the  Union  harmonisation '\n 'legislation  listed  in  Section  A  of  Annex  I.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_23",
    "chunk_content": "Risk management system\n[<Paragraph children=[<RawText children=('A risk management system shall be established, implemented, documented and '\n 'maintained in relation to high-risk AI systems.')>]>]\n[<Paragraph children=[<RawText children=('The risk management system shall be understood as a continuous iterative '\n 'process planned and run throughout the entire  lifecycle  of a  high-risk  '\n 'AI  system,  requiring  regular  systematic review  and  updating.  It  '\n 'shall  comprise  the  following steps:')>]>]\n(a) the identification and analysis of the known and the reasonably foreseeable risks that the high-risk AI system can pose to health, safety or  fundamental rights when the high-risk AI system is used in accordance with its intended purpose;\n(b) the estimation and evaluation of the risks that may emerge when the high-risk AI system is used in accordance with its intended  purpose,  and  under  conditions  of  reasonably  foreseeable  misuse;\n(c) the evaluation of other risks possibly arising, based on the analysis of data gathered from the post-market monitoring system  referred  to  in  Article  72;\n(d) the adoption of appropriate and targeted risk management measures designed to address the risks identified pursuant to point  (a).\n[<Paragraph children=[<RawText children=('The risks referred to in this Article shall concern only those which may be '\n 'reasonably mitigated or eliminated through the  development or design  of  '\n 'the  high-risk  AI  system,  or  the  provision  of  adequate  technical  '\n 'information.')>]>]\n[<Paragraph children=[<RawText children=('The risk management measures referred to in paragraph 2, point (d), shall '\n 'give due consideration to the effects and possible  interaction  resulting  '\n 'from  the  combined  application  of  the  requirements  set  out  in  this  '\n 'Section,  with  a  view  to minimising  risks  more  effectively  while  '\n 'achieving  an  appropriate  balance  in  implementing  the  measures  to  '\n 'fulfil  those requirements.')>]>]\n[<Paragraph children=[<RawText children=('The  risk  management  measures  referred  to  in  paragraph  2,  point  '\n '(d),  shall  be  such  that  the  relevant  residual  risk associated  with  '\n 'each hazard,  as  well  as  the  overall  residual  risk  of  the  '\n 'high-risk  AI  systems  is  judged  to  be  acceptable.')>]>]\nIn  identifying  the  most  appropriate  risk  management  measures,  the  following  shall  be  ensured:\n(a) elimination  or  reduction  of  risks  identified  and  evaluated  pursuant  to  paragraph  2  in  as  far  as  technically  feasible through adequate design and  development of  the  high-risk  AI  system;\n(b) where  appropriate,  implementation  of  adequate  mitigation  and  control  measures  addressing  risks  that  cannot  be eliminated;\n(c) provision of  information  required  pursuant  to  Article  13  and,  where  appropriate,  training  to  deployers.\nWith a view to eliminating or reducing risks related to the use of the high-risk AI system, due consideration shall be given to the technical knowledge, experience, education, the training to be expected by the deployer, and the presumable context in  which  the  system  is  intended  to  be  used.\n[<Paragraph children=[<RawText children=('High-risk AI systems shall be tested for the purpose of identifying the most '\n 'appropriate and targeted risk management measures. Testing shall ensure that '\n 'high-risk AI systems perform consistently for their intended purpose and '\n 'that they are in compliance with the requirements set out in  this  Section.')>]>]\n[<Paragraph children=[<RawText children=('Testing  procedures  may  include  testing  in  real-world  conditions  in  '\n 'accordance  with  Article  60.')>]>]\n[<Paragraph children=[<RawText children=('The  testing  of  high-risk  AI  systems  shall  be  performed,  as  '\n 'appropriate,  at  any  time  throughout  the  development process, and, in '\n 'any event, prior to their being placed on the market or put into service. '\n 'Testing shall be carried out against prior defined metrics and probabilistic '\n 'thresholds that are appropriate to the intended purpose of the high-risk AI '\n 'system.')>]>]\n[<Paragraph children=[<RawText children=('When  implementing  the  risk  management  system  as  provided  for  in  '\n 'paragraphs  1  to  7,  providers  shall  give consideration  to whether  in  '\n 'view  of  its  intended  purpose  the  high-risk  AI  system  is  likely  '\n 'to  have  an  adverse  impact  on persons under  the  age  of  18  and,  as  '\n 'appropriate,  other  vulnerable  groups.')>]>]\n[<Paragraph children=[<RawText children=('For providers of high-risk AI systems that are subject to requirements '\n 'regarding internal risk management processes under other relevant provisions '\n 'of Union law, the aspects provided in paragraphs 1 to 9 may be part of, or '\n 'combined with, the  risk  management  procedures  established  pursuant  to  '\n 'that  law.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_24",
    "chunk_content": "Data and data governance\n[<Paragraph children=[<RawText children=('High-risk AI systems which make use of techniques involving the training of '\n 'AI models with data shall be developed on  the  basis  of  training,  '\n 'validation  and  testing  data  sets  that  meet  the  quality  criteria  '\n 'referred  to  in  paragraphs  2  to  5 whenever such data sets are  used.')>]>]\n[<Paragraph children=[<RawText children=('Training, validation and testing data sets shall be subject to data '\n 'governance and management practices appropriate for  the  intended  purpose  '\n 'of  the  high-risk  AI  system.  Those  practices  shall  concern  in  '\n 'particular:')>]>]\n(a) the  relevant  design  choices;\n(b) data  collection  processes  and  the  origin  of  data,  and  in  the  case  of  personal  data,  the  original  purpose  of  the  data collection;\n(c) relevant  data-preparation  processing  operations,  such  as  annotation,  labelling,  cleaning,  updating,  enrichment  and aggregation;\n(d) the formulation of assumptions, in particular with respect to the information that the data are supposed to measure and represent;\n(e) an  assessment of  the  availability,  quantity  and  suitability  of  the  data  sets  that  are  needed;\n(f) examination in view of possible biases that are likely to affect the health and safety of persons, have a negative impact on fundamental rights or lead to discrimination prohibited under Union law, especially where data outputs influence inputs  for  future  operations;\n(g) appropriate measures to detect, prevent  and  mitigate  possible  biases  identified  according  to  point  (f);\n(h) the identification of relevant data gaps or shortcomings that prevent compliance with this Regulation, and how those gaps  and  shortcomings  can  be  addressed.\n[<Paragraph children=[<RawText children=('Training, validation and testing data sets shall be relevant, sufficiently '\n 'representative, and to the best extent possible, free of errors and complete '\n 'in view of the intended purpose. They shall have the appropriate statistical '\n 'properties, including, where applicable, as regards the persons or groups of '\n 'persons in relation to whom the high-risk AI system is intended to be used. '\n 'Those characteristics of the data sets may be met at the level of individual '\n 'data sets or at the level of a combination thereof.')>]>]\n[<Paragraph children=[<RawText children=('Data sets shall take into account, to the extent required by the intended '\n 'purpose, the characteristics or elements that are  particular  to  the  '\n 'specific  geographical,  contextual,  behavioural  or  functional  setting  '\n 'within  which  the  high-risk  AI system  is  intended  to  be  used.')>]>]\n[<Paragraph children=[<RawText children=('To the extent that it is strictly necessary for  the purpose of ensuring '\n 'bias detection and correction in relation to the high-risk AI systems in '\n 'accordance with paragraph (2), points (f) and (g) of this Article, the '\n 'providers of such systems may exceptionally process special categories of '\n 'personal data, subject to appropriate safeguards for  the fundamental rights '\n 'and freedoms of natural persons. In addition to the provisions set out in '\n 'Regulations (EU) 2016/679 and (EU) 2018/1725 and Directive  (EU)  2016/680,  '\n 'all  the  following  conditions  must  be  met  in  order  for  such  '\n 'processing  to  occur:')>]>]\n(a) the  bias  detection  and  correction  cannot  be  effectively  fulfilled  by  processing  other  data,  including  synthetic  or anonymised data;\n(b) the  special  categories  of  personal  data  are  subject  to  technical  limitations  on  the  re-use  of  the  personal  data,  and state-of-the-art  security  and  privacy-preserving  measures,  including  pseudonymisation;\n(c) the special categories of personal data are subject to measures to ensure that the personal data processed are secured, protected, subject to suitable safeguards, including strict controls and documentation of the access, to avoid misuse and ensure  that  only  authorised  persons  have  access  to  those  personal  data  with  appropriate  confidentiality obligations;\n(d) the  special  categories  of  personal  data  are  not  to  be  transmitted,  transferred  or  otherwise  accessed  by other  parties;\n(e) the special categories of personal data are deleted once the bias has been corrected or the personal data has reached the end  of  its  retention  period,  whichever  comes  first;\n(f) the  records  of  processing  activities  pursuant  to  Regulations  (EU)  2016/679  and  (EU)  2018/1725  and  Directive  (EU) 2016/680 include the reasons why the processing of special categories of personal data was strictly necessary to detect and correct  biases,  and  why that  objective  could  not  be  achieved  by  processing  other  data.\n[<Paragraph children=[<RawText children=('For the development of high-risk AI systems not using techniques involving '\n 'the training of AI models, paragraphs 2 to  5  apply only  to  the  testing  '\n 'data  sets.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_25",
    "chunk_content": "Technical documentation\n[<Paragraph children=[<RawText children=('The technical documentation of a high-risk AI system shall be drawn up '\n 'before that system is placed on the market or put  into  service  and  '\n 'shall  be  kept  up-to  date.')>]>]\nThe technical documentation shall be drawn up in such a way as to demonstrate that the high-risk AI system complies with the  requirements  set  out  in  this  Section  and  to  provide  national  competent  authorities  and  notified  bodies  with  the necessary  information  in  a  clear  and  comprehensive  form  to  assess  the  compliance  of  the  AI  system  with  those requirements. It shall contain, at a minimum, the elements set out in Annex IV. SMEs, including start-ups, may provide the elements of the technical documentation specified in Annex IV in a simplified manner. To that end, the Commission shall establish  a  simplified  technical  documentation  form  targeted  at  the  needs  of  small  and  microenterprises.  Where  an  SME, including  a  start-up,  opts  to  provide  the  information  required  in  Annex  IV  in  a  simplified  manner,  it  shall  use  the  form referred  to  in  this  paragraph.  Notified  bodies  shall  accept  the  form  for  the  purposes  of  the  conformity  assessment.\n[<Paragraph children=[<RawText children=('Where a high-risk  AI  system  related  to  a  product  covered  by  the  '\n 'Union  harmonisation  legislation  listed  in  Section A  of  Annex  I  is  '\n 'placed  on  the  market  or  put  into  service,  a  single  set  of  '\n 'technical  documentation  shall  be  drawn  up containing all  the  '\n 'information  set  out  in  paragraph  1,  as  well  as  the  information  '\n 'required  under  those  legal  acts.')>]>]\n[<Paragraph children=[<RawText children=('The Commission is empowered to adopt delegated acts in accordance with '\n 'Article 97 in order  to amend Annex IV, where  necessary,  to  ensure  '\n 'that,  in  light  of  technical  progress,  the  technical  documentation  '\n 'provides  all  the  information necessary  to  assess  the  compliance  of  '\n 'the  system with  the  requirements  set  out  in  this  Section.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_26",
    "chunk_content": "Record-keeping\n[<Paragraph children=[<RawText children=('High-risk  AI  systems  shall  technically  allow  for  the  automatic  '\n 'recording  of  events  (logs)  over  the  lifetime  of  the system.')>]>]\n[<Paragraph children=[<RawText children=('In order to ensure a level of traceability of the functioning of a high-risk '\n 'AI system that is appropriate to the intended purpose of  the  system,  '\n 'logging  capabilities  shall  enable  the  recording  of  events  relevant  '\n 'for:')>]>]\n(a) identifying situations that may result in the high-risk AI system presenting a risk within the meaning of Article 79(1) or in  a  substantial  modification;\n(b) facilitating  the  post-market  monitoring  referred  to  in  Article  72;  and\n(c) monitoring  the  operation  of  high-risk  AI  systems  referred  to  in  Article  26(5).\n[<Paragraph children=[<RawText children=('For high-risk AI systems referred to in point 1 (a), of Annex III, the '\n 'logging capabilities shall provide, at a minimum:')>]>]\n(a) recording  of  the  period  of  each  use  of  the  system  (start  date  and  time  and  end  date  and  time  of  each  use);\n(b) the  reference  database  against  which  input  data  has  been  checked  by  the  system;\n(c) the  input  data  for  which  the  search  has  led  to  a  match;\n(d) the  identification  of  the  natural  persons  involved  in  the  verification  of  the  results,  as  referred  to  in  Article  14(5)."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_27",
    "chunk_content": "Transparency and provision of  information to deployers\n[<Paragraph children=[<RawText children=('High-risk AI systems shall be designed and developed in such a way as to '\n 'ensure that their operation is sufficiently transparent to enable deployers '\n \"to interpret a system's output and use it appropriately. An appropriate type \"\n 'and degree of transparency  shall  be  ensured  with  a  view  to  '\n 'achieving  compliance  with  the  relevant  obligations  of  the  provider  '\n 'and deployer set out  in  Section  3.')>]>]\n[<Paragraph children=[<RawText children=('High-risk AI systems shall be accompanied by instructions for use in an '\n 'appropriate digital format or otherwise that include  concise,  complete,  '\n 'correct  and  clear  information  that  is  relevant,  accessible  and  '\n 'comprehensible  to  deployers.')>]>]\n[<Paragraph children=[<RawText children=('The instructions  for  use  shall  contain  at  least  the  following  '\n 'information:')>]>]\n(a) the  identity  and  the  contact  details  of  the  provider  and,  where  applicable,  of  its  authorised  representative;\n(b) the  characteristics,  capabilities  and  limitations  of  performance  of  the  high-risk  AI  system,  including:\n(i) its  intended  purpose;\n(ii) the level of accuracy, including its metrics, robustness and cybersecurity referred to in Article 15 against which the high-risk  AI  system  has  been  tested  and  validated  and  which  can  be  expected,  and  any  known  and  foreseeable circumstances that  may  have  an  impact  on  that expected  level  of  accuracy,  robustness  and  cybersecurity;\n(iii) any  known  or  foreseeable  circumstance,  related  to  the  use  of  the  high-risk  AI  system  in  accordance  with  its intended purpose or under conditions of reasonably foreseeable misuse, which may lead to risks to the health and safety  or  fundamental  rights  referred  to  in  Article  9(2);\n(iv) where  applicable,  the  technical  capabilities  and  characteristics  of  the  high-risk  AI  system  to  provide  information that  is  relevant  to  explain  its  output;\n(v) when  appropriate,  its  performance  regarding  specific  persons  or  groups  of  persons  on  which  the  system  is intended  to  be  used;\n(vi) when  appropriate,  specifications  for  the  input  data,  or  any  other  relevant  information  in  terms  of  the  training, validation  and  testing  data  sets  used,  taking  into  account  the  intended  purpose  of  the  high-risk  AI  system;\n(vii) where  applicable,  information  to  enable  deployers  to  interpret  the  output  of  the  high-risk  AI  system  and  use  it appropriately;\n(c) the  changes  to  the  high-risk  AI  system  and  its  performance  which  have  been  pre-determined  by  the  provider  at  the moment of the initial  conformity  assessment,  if  any;\n(d) the human oversight measures referred to in Article 14, including the technical measures put in place to facilitate the interpretation  of  the  outputs  of  the  high-risk  AI  systems  by  the  deployers;\n(e) the computational and hardware resources needed, the expected lifetime of the high-risk AI system and any necessary maintenance and care measures, including their frequency, to ensure the proper functioning of that AI system, including as  regards  software  updates;\n(f) where  relevant,  a  description  of  the  mechanisms  included  within  the  high-risk  AI  system  that  allows  deployers  to properly collect,  store  and  interpret  the  logs  in  accordance  with  Article  12."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_28",
    "chunk_content": "Human oversight\n[<Paragraph children=[<RawText children=('High-risk  AI  systems  shall  be  designed  and  developed  in  such  a  '\n 'way,  including  with  appropriate  human-machine interface  tools,  that  '\n 'they can  be  effectively  overseen  by  natural  persons  during  the  '\n 'period  in  which  they  are  in  use.')>]>]\n[<Paragraph children=[<RawText children=('Human oversight shall aim to prevent or minimise the risks to health, safety '\n 'or fundamental rights that may emerge when a high-risk AI system is used in '\n 'accordance with its intended purpose or under conditions of reasonably '\n 'foreseeable misuse,  in  particular  where  such  risks  persist  despite  '\n 'the  application  of other  requirements  set  out  in  this  Section.')>]>]\n[<Paragraph children=[<RawText children=('The oversight measures shall be commensurate with the risks, level of '\n 'autonomy and context of use of the high-risk AI  system,  and  shall  be  '\n 'ensured  through  either  one  or  both  of  the  following  types  of  '\n 'measures:')>]>]\n(a) measures identified and built, when technically feasible, into the high-risk AI system by the provider before it is placed on the  market or  put  into  service;\n(b) measures identified by the provider before placing the high-risk AI system on the market or putting it into service and that  are  appropriate  to  be  implemented  by  the  deployer.\n[<Paragraph children=[<RawText children=('For the purpose of implementing paragraphs 1, 2 and 3, the high-risk AI '\n 'system shall be provided to the deployer in such  a  way  that  natural  '\n 'persons  to whom  human  oversight  is  assigned  are  enabled,  as  '\n 'appropriate  and  proportionate:')>]>]\n(a) to properly understand the relevant capacities and limitations of the high-risk AI system and be able to duly monitor its operation,  including  in  view  of  detecting and  addressing  anomalies,  dysfunctions  and  unexpected  performance;\n(b) to remain aware of the possible tendency of automatically relying or over-relying on the output produced by a high-risk AI system (automation bias), in particular for high-risk AI systems used to provide information or recommendations for decisions  to  be  taken  by  natural  persons;\n(c) to  correctly  interpret  the  high-risk  AI  system's  output,  taking  into  account,  for  example,  the  interpretation  tools  and methods available;\n(d) to decide, in any particular situation, not to use the high-risk AI system or  to otherwise disregard, override or reverse the  output  of  the  high-risk  AI  system;\n(e) to  intervene  in  the  operation  of  the  high-risk  AI  system  or  interrupt  the  system  through  a  'stop'  button  or  a  similar procedure that allows the  system  to come  to a  halt  in  a  safe  state.\n[<Paragraph children=[<RawText children=('For high-risk AI systems referred to in point 1(a) of Annex III, the '\n 'measures referred to in paragraph 3 of this Article shall be such as to '\n 'ensure that, in addition, no action or decision is taken by the deployer on '\n 'the basis of the identification resulting  from  the  system  unless  that  '\n 'identification  has  been  separately  verified  and  confirmed  by  at  '\n 'least  two  natural persons with the  necessary competence, training and  '\n 'authority.')>]>]\nThe requirement for a separate verification by at least two natural persons shall not apply to high-risk AI systems used for the  purposes  of  law  enforcement,  migration,  border  control  or  asylum,  where  Union  or  national  law  considers  the application  of  this  requirement  to  be  disproportionate."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_29",
    "chunk_content": "Accuracy, robustness and cybersecurity\n[<Paragraph children=[<RawText children=('High-risk AI systems shall be designed and developed in such a way that they '\n 'achieve an appropriate level of accuracy, robustness,  and  cybersecurity,  '\n 'and  that  they  perform  consistently  in  those  respects  throughout  '\n 'their  lifecycle.')>]>]\n[<Paragraph children=[<RawText children=('To  address  the  technical  aspects  of  how  to  measure  the  '\n 'appropriate  levels  of  accuracy  and  robustness  set  out  in paragraph 1 '\n 'and any other relevant performance metrics, the Commission shall, in '\n 'cooperation with relevant stakeholders and  organisations  such  as  '\n 'metrology  and  benchmarking  authorities,  encourage,  as  appropriate,  '\n 'the  development  of benchmarks and measurement methodologies.')>]>]\n[<Paragraph children=[<RawText children=('The levels of accuracy and the relevant accuracy metrics of high-risk AI '\n 'systems shall be declared in the accompanying instructions  of  use.')>]>]\n[<Paragraph children=[<RawText children=('High-risk AI systems shall be as resilient as possible regarding errors, '\n 'faults or inconsistencies that may occur within the system or the '\n 'environment in which the system operates, in particular due to their '\n 'interaction with natural persons or other  systems.  Technical  and  '\n 'organisational  measures  shall  be  taken  in  this  regard.')>]>]\nThe  robustness  of  high-risk  AI  systems  may  be  achieved  through  technical  redundancy  solutions,  which  may  include backup or  fail-safe  plans.\nHigh-risk AI systems that continue to learn after being placed on the market or put into service shall be developed in such a way as to eliminate or reduce as far as possible the risk of possibly biased outputs influencing input for future operations (feedback loops), and as to ensure that any such feedback loops are duly addressed with appropriate mitigation measures.\n[<Paragraph children=[<RawText children=('High-risk  AI  systems  shall  be  resilient  against  attempts  by  '\n 'unauthorised  third  parties  to  alter  their  use,  outputs  or '\n 'performance by exploiting system vulnerabilities.')>]>]\nThe  technical  solutions  aiming  to  ensure  the  cybersecurity  of  high-risk  AI  systems  shall  be  appropriate  to  the  relevant circumstances  and  the  risks.\nThe technical solutions to address AI specific vulnerabilities shall include, where appropriate, measures to prevent, detect, respond  to,  resolve  and  control  for  attacks  trying  to  manipulate  the  training  data  set  (data  poisoning),  or  pre-trained components  used  in  training  (model  poisoning),  inputs  designed  to  cause  the  AI  model  to  make  a  mistake  (adversarial examples or  model evasion), confidentiality  attacks  or  model  flaws."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_30",
    "chunk_content": "Obligations of providers of high-risk AI systems\nProviders  of  high-risk  AI  systems  shall:\n(a) ensure  that  their  high-risk  AI  systems  are  compliant  with  the  requirements  set  out  in  Section  2;\n(b) indicate on the high-risk AI system or, where that is not possible, on its packaging or its accompanying documentation, as  applicable,  their  name,  registered  trade  name or  registered  trade mark, the  address at which they can be contacted;\n(c) have  a  quality  management system  in place  which complies  with  Article  17;\n(d) keep the  documentation  referred  to in  Article  18;\n(e) when  under  their  control,  keep  the  logs  automatically  generated  by  their  high-risk  AI  systems  as  referred  to  in Article  19;\n(f) ensure that the high-risk AI system undergoes the relevant conformity assessment procedure as referred to in Article 43, prior  to  its  being  placed  on  the  market  or  put  into  service;\n(g) draw up an EU declaration of conformity in accordance with Article  47;\n(h) affix  the  CE  marking  to  the  high-risk  AI  system  or,  where  that  is  not  possible,  on  its  packaging  or  its  accompanying documentation, to indicate conformity with this Regulation,  in  accordance  with  Article  48;\n(i) comply with the registration  obligations  referred  to  in  Article  49(1);\n(j) take  the  necessary corrective  actions  and  provide  information  as  required  in  Article  20;\n(k) upon a reasoned request of a national competent authority, demonstrate the conformity of the high-risk AI system with the  requirements  set  out  in  Section  2;\n(l) ensure  that  the  high-risk  AI  system  complies  with  accessibility  requirements  in  accordance  with  Directives  (EU) 2016/2102 and (EU) 2019/882."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_31",
    "chunk_content": "Quality management system\n[<Paragraph children=[<RawText children=('Providers of high-risk AI systems shall put a quality management system in '\n 'place that ensures compliance with this Regulation. That system shall be '\n 'documented in a systematic and orderly manner in the form of written '\n 'policies, procedures and instructions,  and  shall  include  at  least  the  '\n 'following  aspects:')>]>]\n(a) a strategy for regulatory compliance, including compliance with conformity assessment procedures and procedures for the  management of modifications  to the high-risk  AI  system;\n(b) techniques, procedures and systematic actions to be used for  the design, design control and design verification of the high-risk  AI  system;\n(c) techniques, procedures and systematic actions to be used for the development, quality control and quality assurance of the  high-risk  AI  system;\n(d) examination, test and validation procedures to be carried out before, during and after the development of the high-risk AI  system,  and  the  frequency  with  which they  have  to  be  carried  out;\n(e) technical  specifications,  including  standards,  to  be  applied  and,  where  the  relevant  harmonised  standards  are  not applied in full or do not cover all of the relevant requirements set out in Section 2, the means to be used to ensure that the  high-risk  AI  system  complies  with  those  requirements;\n(f) systems and procedures for data management, including data acquisition, data collection, data analysis, data labelling, data storage, data filtration, data mining, data aggregation, data retention and any other operation regarding the data that is performed before and for  the purpose of the placing on the market or  the putting into service of high-risk AI systems;\n(g) the  risk  management  system  referred  to  in  Article  9;\n(h) the setting-up, implementation and maintenance of a post-market monitoring system, in accordance with Article 72;\n(i) procedures related to the  reporting  of a  serious  incident  in  accordance  with  Article  73;\n(j) the  handling  of  communication  with  national  competent  authorities,  other  relevant  authorities,  including  those providing  or  supporting  the  access  to  data,  notified  bodies,  other  operators,  customers  or  other  interested  parties;\n(k) systems  and  procedures  for  record-keeping  of all  relevant  documentation  and  information;\n(l) resource  management,  including  security-of-supply  related measures;\n(m) an accountability framework setting out the responsibilities of  the management and other staff with regard to all the aspects  listed  in  this  paragraph.\n[<Paragraph children=[<RawText children=('The  implementation  of  the  aspects  referred  to  in  paragraph  1  '\n \"shall  be  proportionate  to  the  size  of  the  provider's organisation.  \"\n 'Providers shall,  in  any event,  respect  the  degree  of  rigour  and  '\n 'the  level  of  protection  required  to  ensure  the compliance of  their  '\n 'high-risk  AI  systems  with  this  Regulation.')>]>]\n[<Paragraph children=[<RawText children=('Providers  of  high-risk  AI  systems  that  are  subject  to  obligations  '\n 'regarding  quality  management  systems  or  an equivalent function under '\n 'relevant sectoral Union law may include the aspects listed in paragraph 1 as '\n 'part of the quality management systems pursuant to that law.')>]>]\n[<Paragraph children=[<RawText children=('For providers that are financial institutions subject to requirements '\n 'regarding their internal governance, arrangements or  processes  under  '\n 'Union  financial  services  law,  the  obligation  to  put  in  place  a  '\n 'quality  management  system,  with  the exception of paragraph 1, points '\n '(g), (h) and (i) of this Article, shall be deemed to be fulfilled by '\n 'complying with the rules on internal  governance  arrangements  or  '\n 'processes  pursuant  to  the  relevant  Union  financial  services  law.  '\n 'To  that  end,  any harmonised standards referred to in  Article  40  shall  '\n 'be  taken  into  account.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_32",
    "chunk_content": "Documentation keeping\n[<Paragraph children=[<RawText children=('The provider shall, for a period ending 10 years after  the high-risk AI '\n 'system has been placed on the market or put into  service,  keep  at  the  '\n 'disposal  of  the  national  competent  authorities:')>]>]\n(a) the  technical  documentation  referred  to  in  Article  11;\n(b) the  documentation  concerning the  quality  management system  referred  to  in  Article  17;\n(c) the  documentation concerning the changes approved by notified bodies,  where applicable;\n(d) the  decisions  and  other  documents  issued  by  the  notified  bodies,  where  applicable;\n(e) the  EU  declaration  of  conformity  referred  to  in  Article  47.\n[<Paragraph children=[<RawText children=('Each Member State shall determine conditions under which the documentation '\n 'referred to in paragraph 1 remains at the disposal of the national competent '\n 'authorities for the period indicated in that paragraph for the cases when a '\n 'provider or  its  authorised  representative  established  on  its  '\n 'territory  goes  bankrupt  or  ceases  its  activity  prior  to  the  end  '\n 'of  that period.')>]>]\n[<Paragraph children=[<RawText children=('Providers that are financial institutions subject to requirements regarding '\n 'their internal governance, arrangements or processes under Union financial '\n 'services law shall maintain the technical documentation as part of the '\n 'documentation kept under  the  relevant  Union  financial  services  law.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_33",
    "chunk_content": "Automatically generated logs\n[<Paragraph children=[<RawText children=('Providers  of  high-risk  AI  systems  shall  keep  the  logs  referred  to  '\n 'in  Article  12(1),  automatically  generated  by  their high-risk AI '\n 'systems, to the extent such logs are under their control. Without prejudice '\n 'to applicable Union or national law, the logs shall be kept for a period '\n 'appropriate to the intended purpose of  the high-risk AI system, of at least '\n 'six months, unless provided otherwise in the applicable Union or national '\n 'law, in particular in Union law on the protection of personal data.')>]>]\n[<Paragraph children=[<RawText children=('Providers that are financial institutions subject to requirements regarding '\n 'their internal governance, arrangements or processes under Union financial '\n 'services law shall maintain the logs automatically generated by their '\n 'high-risk AI systems as  part  of  the  documentation  kept  under  the  '\n 'relevant  financial  services  law.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_34",
    "chunk_content": "Corrective actions and duty of  information\n[<Paragraph children=[<RawText children=('Providers of high-risk AI systems which consider or have reason to consider '\n 'that a high-risk AI system that they have placed  on  the  market  or  put  '\n 'into  service  is  not  in  conformity  with  this  Regulation  shall  '\n 'immediately  take  the  necessary corrective actions to bring that system '\n 'into conformity, to withdraw it, to disable it, or to recall it, as '\n 'appropriate. They shall inform  the  distributors  of  the  high-risk  AI  '\n 'system  concerned  and,  where  applicable,  the  deployers,  the  '\n 'authorised representative  and  importers  accordingly.')>]>]\n[<Paragraph children=[<RawText children=('Where the high-risk AI system presents a risk within the meaning of Article '\n '79(1) and the provider becomes aware of that  risk,  it  shall  immediately  '\n 'investigate  the  causes,  in  collaboration  with  the  reporting  '\n 'deployer,  where  applicable,  and inform  the  market  surveillance  '\n 'authorities  competent  for  the  high-risk  AI  system  concerned  and,  '\n 'where  applicable,  the notified body that issued a certificate for that '\n 'high-risk AI system in accordance with Article 44, in particular, of the '\n 'nature of  the  non-compliance  and  of any relevant  corrective  action  '\n 'taken.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_35",
    "chunk_content": "Cooperation with competent authorities\n[<Paragraph children=[<RawText children=('Providers of high-risk AI systems shall, upon a reasoned request by a '\n 'competent authority, provide that authority all the  information  and  '\n 'documentation  necessary  to  demonstrate  the  conformity  of  the  '\n 'high-risk  AI  system  with  the requirements  set  out  in  Section  2,  '\n 'in  a  language  which  can  be  easily  understood  by  the  authority  in  '\n 'one  of  the  official languages  of  the  institutions  of  the  Union  as  '\n 'indicated  by  the  Member  State  concerned.')>]>]\n[<Paragraph children=[<RawText children=('Upon a reasoned request by a competent authority, providers shall also give '\n 'the requesting competent authority, as applicable, access to the '\n 'automatically generated logs of  the high-risk AI system referred to in '\n 'Article 12(1), to the extent such  logs  are  under  their  control.')>]>]\n[<Paragraph children=[<RawText children=('Any information obtained by a competent authority pursuant to this Article '\n 'shall be treated in accordance with the confidentiality obligations  set  '\n 'out  in  Article  78.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_36",
    "chunk_content": "Authorised representatives of providers of high-risk AI systems\n[<Paragraph children=[<RawText children=('Prior  to  making  their  high-risk  AI  systems  available  on  the  Union  '\n 'market,  providers  established  in  third  countries shall,  by  written  '\n 'mandate,  appoint  an  authorised  representative  which is  established  '\n 'in  the  Union.')>]>]\n[<Paragraph children=[<RawText children=('The provider shall enable its authorised representative to perform the tasks '\n 'specified in the mandate received from the provider.')>]>]\n[<Paragraph children=[<RawText children=('The  authorised  representative  shall  perform  the  tasks  specified  in  '\n 'the  mandate  received  from  the  provider.  It  shall provide a copy of '\n 'the mandate to the market surveillance authorities upon request, in one of '\n 'the official languages of the institutions of  the Union, as indicated by '\n 'the competent authority. For  the purposes of  this Regulation, the mandate '\n 'shall empower the authorised representative to carry out the  following '\n 'tasks:')>]>]\n(a) verify  that  the  EU  declaration  of  conformity  referred  to  in  Article  47  and  the  technical  documentation  referred  to  in Article 11 have been drawn up and that an appropriate conformity assessment procedure has been carried out by the provider;\n(b) keep at  the  disposal  of  the  competent  authorities  and  national  authorities  or  bodies  referred  to  in  Article  74(10),  for a period of 10 years after the high-risk AI system has been placed on the market or put into service, the contact details of the provider  that appointed the authorised representative, a copy of the EU declaration of conformity referred to in Article  47,  the  technical  documentation  and,  if  applicable,  the  certificate  issued  by  the  notified  body;\n(c) provide  a  competent  authority,  upon  a  reasoned  request,  with  all  the  information  and  documentation,  including  that referred to in point (b) of this subparagraph, necessary to demonstrate the conformity of a high-risk AI system with the requirements set out in Section 2, including access to the logs, as referred to in Article 12(1), automatically generated by the  high-risk  AI  system,  to  the  extent  such  logs  are  under  the  control  of  the  provider;\n(d) cooperate with competent authorities, upon a reasoned request, in any action the latter take in relation to the high-risk AI  system,  in  particular  to  reduce  and  mitigate  the  risks  posed  by  the  high-risk  AI  system;\n(e) where applicable, comply with the registration obligations referred to in Article 49(1), or, if  the registration is carried out  by  the  provider  itself,  ensure  that  the  information  referred  to  in  point  3  of  Section  A  of  Annex  VIII  is  correct.\nThe mandate shall empower the authorised representative to be addressed, in addition to or instead of the provider, by the competent authorities,  on  all  issues  related  to  ensuring  compliance  with  this  Regulation.\n[<Paragraph children=[<RawText children=('The authorised representative shall terminate the mandate if it considers or '\n 'has reason to consider the provider to be acting contrary to its obligations '\n 'pursuant to this Regulation. In such a case, it shall immediately inform the '\n 'relevant market surveillance authority, as well as, where applicable, the '\n 'relevant notified body, about the termination of the mandate and the '\n 'reasons  therefor.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_37",
    "chunk_content": "Obligations of  importers\n[<Paragraph children=[<RawText children=('Before placing a high-risk AI system on the market, importers shall ensure '\n 'that the system is in conformity with this Regulation  by verifying  that:')>]>]\n(a) the  relevant  conformity  assessment  procedure  referred  to  in  Article  43  has  been  carried  out  by  the  provider  of  the high-risk  AI  system;\n(b) the  provider  has  drawn  up  the  technical  documentation  in  accordance  with  Article  11  and  Annex  IV;\n(c) the  system  bears  the  required  CE  marking  and  is  accompanied  by  the  EU  declaration  of  conformity  referred  to  in Article  47  and  instructions  for  use;\n(d) the  provider  has  appointed  an  authorised  representative  in  accordance  with  Article  22(1).\n[<Paragraph children=[<RawText children=('Where  an  importer  has  sufficient  reason  to  consider  that  a  '\n 'high-risk  AI  system  is  not  in  conformity  with  this Regulation, or is '\n 'falsified, or accompanied by falsified documentation, it shall not place the '\n 'system on the market until it has been  brought  into  conformity.  Where  '\n 'the  high-risk  AI  system  presents  a  risk  within  the  meaning  of  '\n 'Article  79(1),  the importer shall inform the provider of  the system, the '\n 'authorised representative and the market surveillance authorities to that  '\n 'effect.')>]>]\n[<Paragraph children=[<RawText children=('Importers shall indicate their name, registered trade name or registered '\n 'trade mark, and the address at which they can be  contacted on  the  '\n 'high-risk  AI  system  and  on  its  packaging  or  its  accompanying  '\n 'documentation,  where  applicable.')>]>]\n[<Paragraph children=[<RawText children=('Importers shall ensure that, while a high-risk AI system is under their '\n 'responsibility, storage or transport conditions, where applicable,  do  not  '\n 'jeopardise  its  compliance  with  the  requirements  set  out  in  Section  '\n '2.')>]>]\n[<Paragraph children=[<RawText children=('Importers shall keep, for a period of 10 years after the high-risk AI system '\n 'has been placed on the market or put into service,  a  copy of  the  '\n 'certificate  issued  by  the  notified  body,  where  applicable,  of  the  '\n 'instructions  for  use,  and  of  the  EU declaration  of  conformity  '\n 'referred  to  in  Article  47.')>]>]\n[<Paragraph children=[<RawText children=('Importers  shall  provide  the  relevant  competent  authorities,  upon  a  '\n 'reasoned  request,  with  all  the  necessary information and documentation, '\n 'including that referred to in paragraph 5, to demonstrate the conformity of '\n 'a high-risk AI system with the requirements set out in Section 2 in a '\n 'language which can be easily understood by them. For this purpose, they '\n 'shall  also  ensure  that  the  technical  documentation  can  be  made  '\n 'available  to  those  authorities.')>]>]\n[<Paragraph children=[<RawText children=('Importers shall cooperate with the relevant competent authorities in any '\n 'action those authorities take in relation to a  high-risk  AI  system  '\n 'placed  on  the  market  by  the  importers,  in  particular  to  reduce  '\n 'and  mitigate  the  risks  posed  by  it.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_38",
    "chunk_content": "Obligations of distributors\n[<Paragraph children=[<RawText children=('Before  making  a  high-risk  AI  system  available  on  the  market,  '\n 'distributors  shall  verify  that  it  bears  the  required  CE marking, '\n 'that it is accompanied by a copy of the EU declaration of conformity '\n 'referred to in Article 47 and instructions for use, and that the provider '\n 'and the importer of that system, as applicable, have complied with their '\n 'respective obligations as laid  down in  Article  16,  points  (b)  and  '\n '(c)  and  Article  23(3).')>]>]\n[<Paragraph children=[<RawText children=('Where  a  distributor  considers  or  has  reason  to  consider,  on  the  '\n 'basis  of  the  information  in  its  possession,  that a  high-risk  AI  '\n 'system  is  not  in  conformity  with  the  requirements  set  out  in  '\n 'Section  2,  it  shall  not  make  the  high-risk  AI system available on '\n 'the market until the system has been brought into conformity with those '\n 'requirements. Furthermore, where the high-risk AI system presents a risk '\n 'within the meaning of Article 79(1), the distributor shall inform the '\n 'provider or  the  importer  of  the  system,  as  applicable,  to  that  '\n 'effect.')>]>]\n[<Paragraph children=[<RawText children=('Distributors  shall  ensure  that,  while  a  high-risk  AI  system  is  '\n 'under  their  responsibility,  storage  or  transport conditions, where '\n 'applicable, do not jeopardise the compliance of  the system with the '\n 'requirements set out in Section 2.')>]>]\n[<Paragraph children=[<RawText children=('A distributor that considers or has reason to consider, on the basis of the '\n 'information in its possession, a high-risk AI system which it has made '\n 'available on the market not to be in conformity with the requirements set '\n 'out in Section 2, shall take the corrective actions necessary to bring that '\n 'system into conformity with those requirements, to withdraw it or recall '\n 'it,  or  shall  ensure  that  the  provider,  the  importer  or  any  '\n 'relevant  operator,  as  appropriate,  takes  those  corrective  actions. '\n 'Where the high-risk AI system presents a risk within the meaning of Article '\n '79(1), the distributor shall immediately inform the provider or importer of '\n 'the system and the authorities competent for the high-risk AI system '\n 'concerned, giving details, in  particular,  of  the  non-compliance  and  '\n 'of  any corrective  actions  taken.')>]>]\n[<Paragraph children=[<RawText children=('Upon a reasoned request from a relevant competent authority, distributors of '\n 'a high-risk AI system shall provide that authority with all the information '\n 'and documentation regarding their actions pursuant to paragraphs 1 to 4 '\n 'necessary to demonstrate the conformity of  that system with  the  '\n 'requirements  set out  in  Section  2.')>]>]\n[<Paragraph children=[<RawText children=('Distributors shall cooperate with the relevant competent authorities in any '\n 'action those authorities take in relation to a high-risk AI system made '\n 'available on the market by the distributors, in particular to reduce or '\n 'mitigate the risk posed by it.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_39",
    "chunk_content": "Responsibilities along the AI value chain\n[<Paragraph children=[<RawText children=('Any distributor, importer, deployer or other third-party shall be considered '\n 'to be a provider of a high-risk AI system for  the  purposes of  this '\n 'Regulation and shall be subject to the obligations of  the provider under '\n 'Article 16, in any of  the following  circumstances:')>]>]\n(a) they put their  name or  trademark on a high-risk AI system already placed on the market or  put into service, without prejudice  to  contractual  arrangements  stipulating  that  the  obligations  are  otherwise  allocated;\n(b) they make a substantial modification to a high-risk AI system that has already been placed on the market or has already been put into service  in  such  a  way  that  it  remains  a  high-risk  AI  system pursuant  to  Article  6;\n(c) they modify the intended purpose of an AI system, including a general-purpose AI system, which has not been classified as high-risk and has already been placed on the market or put into service in such a way that the AI system concerned becomes a high-risk AI system in  accordance with Article 6.\n[<Paragraph children=[<RawText children=('Where  the  circumstances  referred  to  in  paragraph  1  occur,  the  '\n 'provider  that  initially  placed  the  AI  system  on  the market or put it '\n 'into service shall no longer be considered to be a provider of that specific '\n 'AI system for  the purposes of this  Regulation.  That  initial  provider  '\n 'shall  closely  cooperate  with  new  providers  and  shall  make  '\n 'available  the  necessary information and provide the reasonably expected '\n 'technical access and other assistance that are required for the fulfilment '\n 'of the  obligations  set  out  in  this  Regulation,  in  particular  '\n 'regarding  the  compliance  with  the  conformity  assessment  of high-risk  '\n 'AI  systems.  This  paragraph  shall  not  apply  in  cases  where  the  '\n 'initial  provider  has  clearly  specified  that  its  AI system is not to '\n 'be changed into a high-risk AI system and therefore does not fall under  the '\n 'obligation to hand over  the documentation.')>]>]\n[<Paragraph children=[<RawText children=('In  the  case  of  high-risk  AI  systems  that  are  safety  components  '\n 'of  products  covered  by  the  Union  harmonisation legislation listed in '\n 'Section A of Annex I, the product manufacturer shall be considered to be the '\n 'provider of the high-risk AI  system,  and  shall  be  subject  to  the  '\n 'obligations  under  Article  16  under  either  of  the  following  '\n 'circumstances:')>]>]\n(a) the high-risk AI system is placed on the market together with the product under the name or trademark of the product manufacturer;\n(b) the high-risk AI system is put into service under the name or trademark of the product manufacturer after the product has  been  placed  on  the  market.\n[<Paragraph children=[<RawText children=('The provider of a high-risk AI system and the third party that supplies an '\n 'AI system, tools, services, components, or processes that are used or '\n 'integrated in a high-risk AI system shall, by written agreement, specify the '\n 'necessary information, capabilities,  technical access and other assistance '\n 'based on the generally acknowledged state of  the art, in order  to enable '\n 'the provider of the high-risk AI system to fully comply with the obligations '\n 'set out in this Regulation. This paragraph shall not  apply  to  third  '\n 'parties  making  accessible  to  the  public  tools,  services,  processes,  '\n 'or  components,  other  than general-purpose  AI  models,  under  a  free  '\n 'and  open-source  licence.')>]>]\nThe AI Office may develop and recommend voluntary model terms for contracts between providers of high-risk AI systems and  third  parties  that  supply  tools,  services,  components  or  processes  that  are  used  for  or  integrated  into  high-risk  AI systems.  When  developing  those  voluntary  model  terms,  the  AI  Office  shall  take  into  account  possible  contractual requirements applicable in specific sectors or business cases. The voluntary model terms shall be published and be available free  of  charge  in  an  easily  usable  electronic  format.\n[<Paragraph children=[<RawText children=('Paragraphs 2 and 3 are without prejudice to the need to observe and protect '\n 'intellectual property rights, confidential business  information  and  '\n 'trade  secrets  in  accordance  with  Union  and  national  law.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_40",
    "chunk_content": "Obligations of deployers of high-risk AI systems\n[<Paragraph children=[<RawText children=('Deployers  of  high-risk  AI  systems  shall  take  appropriate  technical  '\n 'and  organisational  measures  to  ensure  they  use such  systems  in  '\n 'accordance  with  the  instructions  for  use  accompanying  the  systems,  '\n 'pursuant  to  paragraphs  3  and  6.')>]>]\n[<Paragraph children=[<RawText children=('Deployers  shall  assign  human  oversight  to  natural  persons  who  have  '\n 'the  necessary  competence,  training  and authority,  as  well  as  the  '\n 'necessary  support.')>]>]\n[<Paragraph children=[<RawText children=('The obligations set out  in paragraphs  1  and  2,  are  without  prejudice  '\n 'to  other  deployer  obligations  under  Union  or national law and to the '\n \"deployer's freedom to organise its own resources and activities for the \"\n 'purpose of implementing the human oversight measures indicated by the '\n 'provider.')>]>]\n[<Paragraph children=[<RawText children=('Without  prejudice  to  paragraphs  1  and  2,  to  the  extent  the  '\n 'deployer  exercises  control  over  the  input  data,  that deployer  shall  '\n 'ensure  that  input  data  is  relevant  and  sufficiently  representative  '\n 'in  view  of  the  intended  purpose  of  the high-risk  AI  system.')>]>]\n[<Paragraph children=[<RawText children=('Deployers shall monitor the operation of the high-risk AI system on the '\n 'basis of the instructions for use and, where relevant,  inform  providers  '\n 'in  accordance  with  Article  72.  Where  deployers  have  reason  to  '\n 'consider  that  the  use  of  the high-risk AI system in accordance with the '\n 'instructions may result in that AI system presenting a risk within the '\n 'meaning of Article  79(1),  they  shall,  without  undue  delay,  inform  '\n 'the  provider  or  distributor  and  the  relevant  market  surveillance '\n 'authority,  and  shall  suspend  the  use  of  that  system.  Where  '\n 'deployers  have  identified  a  serious  incident,  they  shall  also '\n 'immediately inform first the provider, and then the importer or distributor '\n 'and the relevant market surveillance authorities of  that  incident.  If  '\n 'the  deployer  is  not  able  to  reach  the  provider,  Article  73  shall  '\n 'apply mutatis  mutandis .  This  obligation shall  not  cover  sensitive  '\n 'operational  data  of  deployers  of  AI  systems  which  are  law  '\n 'enforcement  authorities.')>]>]\nFor  deployers  that  are  financial  institutions  subject  to  requirements  regarding  their  internal  governance,  arrangements  or processes under Union financial services law, the monitoring obligation set out in the first subparagraph shall be deemed to be fulfilled by complying with the rules on internal governance arrangements, processes and mechanisms pursuant to the relevant  financial  service  law.\n[<Paragraph children=[<RawText children=('Deployers of high-risk AI systems shall keep the logs automatically '\n 'generated by that high-risk AI system to the extent such logs are under '\n 'their control, for a period appropriate to the intended purpose of the '\n 'high-risk AI system, of at least six months,  unless  provided  otherwise  '\n 'in  applicable  Union  or  national  law,  in  particular  in  Union  law  '\n 'on  the  protection  of personal  data.')>]>]\nDeployers  that  are  financial  institutions  subject  to  requirements  regarding  their  internal  governance,  arrangements  or processes  under  Union  financial  services  law  shall  maintain  the  logs  as  part  of  the  documentation  kept  pursuant  to  the relevant  Union  financial  service  law.\n[<Paragraph children=[<RawText children=('Before putting into service or using a high-risk AI system at the workplace, '\n \"deployers who are employers shall inform workers'  representatives  and  \"\n 'the  affected  workers  that  they  will  be  subject  to  the  use  of  '\n 'the  high-risk  AI  system.  This information  shall  be  provided,  where  '\n 'applicable,  in  accordance  with  the  rules  and  procedures  laid  down  '\n 'in  Union  and national  law  and  practice  on  information  of  workers  '\n 'and  their  representatives.')>]>]\n[<Paragraph children=[<RawText children=('Deployers of high-risk AI systems that are public authorities, or Union '\n 'institutions, bodies, offices  or agencies  shall comply with the '\n 'registration obligations referred to in Article 49. When such deployers find '\n 'that the high-risk AI system that they envisage using has not been '\n 'registered in the EU database referred to in Article 71, they shall not use '\n 'that system and shall  inform  the  provider  or  the  distributor.')>]>]\n[<Paragraph children=[<RawText children=('Where  applicable,  deployers  of  high-risk  AI  systems  shall  use  the  '\n 'information  provided  under  Article  13  of  this Regulation to comply '\n 'with their obligation to carry out a data protection impact assessment under '\n 'Article 35 of Regulation (EU)  2016/679 or  Article  27  of  Directive  '\n '(EU)  2016/680.')>]>]\n[<Paragraph children=[<RawText children=('Without  prejudice  to  Directive  (EU)  2016/680,  in  the  framework  of  '\n 'an  investigation  for  the  targeted  search  of a  person  suspected  or  '\n 'convicted  of  having  committed  a  criminal  offence,  the  deployer  of  '\n 'a  high-risk  AI  system  for post-remote biometric identification shall  '\n 'request  an  authorisation, ex  ante ,  or  without  undue  delay  and  no  '\n 'later  than  48 hours, by a judicial authority or an administrative '\n 'authority whose decision is binding and subject to judicial review, for the '\n 'use of that system, except when it is used for the initial identification of '\n 'a potential suspect based on objective and verifiable facts directly linked '\n 'to the offence. Each use shall be limited to what is strictly necessary for  '\n 'the investigation of a specific criminal  offence.')>]>]\nIf  the  authorisation  requested  pursuant  to  the  first  subparagraph  is  rejected,  the  use  of  the  post-remote  biometric identification  system  linked  to  that  requested  authorisation  shall  be  stopped  with  immediate  effect  and  the  personal  data linked  to  the  use  of  the  high-risk  AI  system  for  which  the  authorisation  was  requested  shall  be  deleted.\nIn no case shall such high-risk AI system for post-remote biometric identification be used for law enforcement purposes in an  untargeted  way,  without  any  link  to  a  criminal  offence,  a  criminal  proceeding,  a  genuine  and  present  or  genuine  and foreseeable threat of a criminal offence, or the search for a specific missing person. It shall be ensured that no decision that produces an adverse legal effect on a person may be taken by the law enforcement authorities based solely on the output of such  post-remote biometric  identification  systems.\nThis paragraph is without prejudice to Article 9 of Regulation (EU) 2016/679 and Article 10 of Directive (EU) 2016/680 for  the  processing  of  biometric  data.\nRegardless of the purpose or deployer, each use of such high-risk AI systems shall be documented in the relevant police file and shall be made available to the relevant market surveillance authority and the national data protection authority upon request,  excluding  the  disclosure  of  sensitive  operational  data  related  to  law  enforcement.  This  subparagraph  shall  be without prejudice  to the  powers  conferred  by  Directive  (EU)  2016/680  on  supervisory  authorities.\nDeployers shall submit annual reports to the relevant market surveillance and national data protection authorities on their use  of  post-remote  biometric  identification  systems,  excluding  the  disclosure  of  sensitive  operational  data  related  to  law enforcement. The reports may be aggregated to cover  more than one deployment.\nMember States may introduce, in accordance with  Union  law,  more restrictive  laws on  the  use  of  post-remote biometric identification  systems.\n[<Paragraph children=[<RawText children=('Without prejudice to Article 50 of  this  Regulation, deployers of high-risk '\n 'AI systems referred to  in Annex III that make decisions or assist in making '\n 'decisions related to natural persons shall inform the natural persons that '\n 'they are subject to the use of the high-risk AI system. For high-risk AI '\n 'systems used for law enforcement purposes Article 13 of Directive (EU)  '\n '2016/680 shall  apply.')>]>]\n[<Paragraph children=[<RawText children=('Deployers shall cooperate with the relevant competent authorities in any '\n 'action those authorities take in relation to the  high-risk  AI  system  in  '\n 'order  to  implement  this  Regulation.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_41",
    "chunk_content": "Fundamental rights impact assessment for high-risk AI systems\n[<Paragraph children=[<RawText children=('Prior  to  deploying  a  high-risk  AI  system  referred  to  in  Article  '\n '6(2),  with  the  exception  of  high-risk  AI  systems intended to be used '\n 'in the area listed in point 2 of Annex III, deployers that are bodies '\n 'governed by public law, or are private entities providing public services, '\n 'and deployers of high-risk AI systems referred to in points 5 (b) and (c) of '\n 'Annex III, shall perform an assessment of  the impact on fundamental rights '\n 'that the use of such system may produce. For  that purpose, deployers shall  '\n 'perform  an  assessment  consisting  of:')>]>]\n(a) a description of the deployer's processes in which the high-risk AI system will be used in line with its intended purpose;\n(b) a description of the period of time within which, and the frequency with which, each high-risk AI system is intended to be  used;\n(c) the  categories  of  natural  persons  and  groups  likely  to  be  affected  by  its  use  in  the  specific  context;\n(d) the specific risks of harm likely to have an impact on the categories of natural persons or groups of persons identified pursuant  to  point  (c)  of  this  paragraph,  taking  into  account  the  information  given  by  the  provider  pursuant  to Article  13;\n(e) a  description  of  the  implementation  of  human  oversight  measures,  according  to  the  instructions  for  use;\n(f) the  measures  to  be  taken  in  the  case  of  the  materialisation  of  those  risks,  including  the  arrangements  for  internal governance  and  complaint  mechanisms.\n[<Paragraph children=[<RawText children=('The  obligation  laid  down  in  paragraph  1  applies  to  the  first  use  '\n 'of  the  high-risk  AI  system.  The  deployer  may,  in similar cases, rely '\n 'on previously conducted fundamental rights impact assessments or existing '\n 'impact assessments carried out  by  provider.  If,  during  the  use  of  '\n 'the  high-risk  AI  system,  the  deployer  considers  that  any  of  the  '\n 'elements  listed  in paragraph 1 has changed or is no longer up to date, the '\n 'deployer shall take the necessary steps to update the information.')>]>]\n[<Paragraph children=[<RawText children=('Once  the  assessment  referred  to  in  paragraph  1  of  this  Article  '\n 'has  been  performed,  the  deployer  shall  notify  the market surveillance '\n 'authority of its results, submitting the filled-out template referred to in '\n 'paragraph 5 of  this Article as part  of  the  notification.  In  the  case  '\n 'referred  to  in  Article  46(1),  deployers  may  be  exempt  from  that  '\n 'obligation  to  notify.')>]>]\n[<Paragraph children=[<RawText children=('If  any  of  the  obligations  laid  down  in  this  Article  is  already  '\n 'met  through  the  data  protection  impact  assessment conducted pursuant '\n 'to Article 35 of Regulation (EU) 2016/679 or Article 27 of Directive (EU) '\n '2016/680, the fundamental rights  impact  assessment  referred  to  in  '\n 'paragraph  1  of  this  Article  shall  complement  that  data  protection  '\n 'impact assessment.')>]>]\n[<Paragraph children=[<RawText children=('The AI Office shall develop a template for a questionnaire, including '\n 'through an automated tool, to facilitate deployers in  complying  with  '\n 'their  obligations  under  this  Article  in  a  simplified  manner.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_42",
    "chunk_content": "Notifying authorities\n[<Paragraph children=[<RawText children=('Each Member State shall designate or establish at least one notifying '\n 'authority responsible for setting up and carrying out the necessary '\n 'procedures for the assessment, designation and notification of conformity '\n 'assessment bodies and for their monitoring.  Those procedures shall  be  '\n 'developed  in  cooperation  between  the  notifying  authorities  of all  '\n 'Member  States.')>]>]\n[<Paragraph children=[<RawText children=('Member  States  may  decide  that  the  assessment  and  monitoring  '\n 'referred  to  in  paragraph  1  is  to  be  carried  out  by a  national  '\n 'accreditation  body  within  the  meaning  of,  and  in  accordance  with,  '\n 'Regulation  (EC)  No  765/2008.')>]>]\n[<Paragraph children=[<RawText children=('Notifying authorities shall be established, organised and operated in such a '\n 'way that no conflict of interest arises with conformity assessment bodies, '\n 'and that  the objectivity  and  impartiality of  their  activities  are  '\n 'safeguarded.')>]>]\n[<Paragraph children=[<RawText children=('Notifying  authorities  shall  be  organised  in  such  a  way  that  '\n 'decisions  relating  to  the  notification  of  conformity assessment  '\n 'bodies  are  taken  by competent  persons  different  from  those  who  '\n 'carried  out  the  assessment  of  those  bodies.')>]>]\n[<Paragraph children=[<RawText children=('Notifying authorities shall offer or provide neither any activities that '\n 'conformity assessment bodies perform, nor any consultancy  services  on  a  '\n 'commercial  or  competitive  basis.')>]>]\n[<Paragraph children=[<RawText children=('Notifying  authorities  shall  safeguard  the  confidentiality  of  the  '\n 'information  that  they  obtain,  in  accordance  with Article  78.')>]>]\n[<Paragraph children=[<RawText children=('Notifying  authorities  shall  have  an  adequate  number  of  competent  '\n 'personnel  at  their  disposal  for  the  proper performance of their tasks. '\n 'Competent personnel shall have the necessary expertise, where applicable, '\n 'for their function, in fields  such  as  information  technologies,  AI  '\n 'and  law,  including  the  supervision  of  fundamental  rights.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_43",
    "chunk_content": "Application of a conformity assessment body for notification\n[<Paragraph children=[<RawText children=('Conformity assessment bodies shall submit an application for notification to '\n 'the notifying authority of the Member State  in  which  they  are  '\n 'established.')>]>]\n[<Paragraph children=[<RawText children=('The  application  for  notification  shall  be  accompanied  by  a  '\n 'description  of  the  conformity  assessment  activities,  the conformity '\n 'assessment module or modules and the types of AI systems for which the '\n 'conformity assessment body claims to be competent, as well as by an '\n 'accreditation certificate, where one exists, issued by a national '\n 'accreditation body attesting that  the  conformity  assessment  body  '\n 'fulfils  the  requirements  laid  down  in  Article  31.')>]>]\nAny valid document related to existing designations of the applicant notified body under any other Union harmonisation legislation  shall  be  added.\n[<Paragraph children=[<RawText children=('Where  the  conformity  assessment  body  concerned  cannot  provide  an  '\n 'accreditation  certificate,  it  shall  provide  the notifying authority '\n 'with all the documentary evidence necessary for the verification, '\n 'recognition and regular monitoring of its  compliance  with  the  '\n 'requirements  laid  down  in  Article  31.')>]>]\n[<Paragraph children=[<RawText children=('For  notified  bodies  which  are  designated  under  any  other  Union  '\n 'harmonisation  legislation,  all  documents  and certificates  linked  to  '\n 'those  designations  may  be  used  to  support  their  designation  '\n 'procedure  under  this  Regulation,  as appropriate. The notified body shall '\n 'update the documentation referred to in paragraphs 2 and 3 of this Article '\n 'whenever relevant changes occur, in order  to enable the authority '\n 'responsible for  notified  bodies to monitor and verify continuous '\n 'compliance with all  the  requirements  laid  down in  Article  31.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_44",
    "chunk_content": "Notification procedure\n[<Paragraph children=[<RawText children=('Notifying authorities may notify only conformity assessment bodies which '\n 'have satisfied the requirements laid down in  Article  31.')>]>]\n[<Paragraph children=[<RawText children=('Notifying authorities shall notify the Commission and the other Member '\n 'States, using the electronic notification tool developed and managed by the '\n 'Commission, of each conformity assessment body referred to in paragraph 1.')>]>]\n[<Paragraph children=[<RawText children=('The  notification  referred  to  in  paragraph  2  of  this  Article  shall  '\n 'include  full  details  of  the  conformity  assessment activities, the '\n 'conformity assessment module or modules, the types of AI systems concerned, '\n 'and the relevant attestation of competence. Where a notification is not '\n 'based on an accreditation certificate as referred to in Article 29(2), the '\n 'notifying authority  shall  provide  the  Commission  and  the  other  '\n 'Member  States  with  documentary  evidence  which  attests  to  the '\n 'competence  of  the  conformity  assessment  body  and  to  the  '\n 'arrangements  in  place  to  ensure  that  that  body  will  be monitored '\n 'regularly  and  will  continue  to  satisfy  the  requirements  laid  down  '\n 'in  Article  31.')>]>]\n[<Paragraph children=[<RawText children=('The conformity assessment body concerned may perform the activities of a '\n 'notified body only where no objections are raised by the Commission or the '\n 'other Member States within two weeks of a notification by a notifying '\n 'authority where it  includes an accreditation certificate referred to in '\n 'Article 29(2), or  within two months of a notification by the notifying '\n 'authority  where  it  includes  documentary evidence  referred  to  in  '\n 'Article  29(3).')>]>]\n[<Paragraph children=[<RawText children=('Where objections are raised, the Commission shall, without delay, enter into '\n 'consultations with the relevant Member States  and  the  conformity  '\n 'assessment  body.  In  view  thereof,  the  Commission  shall  decide  '\n 'whether  the  authorisation  is justified.  The  Commission  shall  address  '\n 'its  decision  to  the  Member  State  concerned  and  to  the  relevant  '\n 'conformity assessment  body.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_45",
    "chunk_content": "Requirements relating to notified bodies\n[<Paragraph children=[<RawText children=('A notified  body  shall  be  established  under  the  national  law of  a  '\n 'Member  State  and  shall  have  legal  personality.')>]>]\n[<Paragraph children=[<RawText children=('Notified  bodies  shall  satisfy  the  organisational,  quality  '\n 'management,  resources  and  process  requirements  that  are necessary  to  '\n 'fulfil  their  tasks,  as  well  as  suitable  cybersecurity  requirements.')>]>]\n[<Paragraph children=[<RawText children=('The  organisational  structure,  allocation  of  responsibilities,  '\n 'reporting  lines  and  operation  of  notified  bodies  shall ensure '\n 'confidence in their  performance, and in the results of  the conformity '\n 'assessment activities that the notified bodies conduct.')>]>]\n[<Paragraph children=[<RawText children=('Notified  bodies  shall  be  independent  of  the  provider  of  a  '\n 'high-risk  AI  system  in  relation  to  which  they  perform conformity  '\n 'assessment  activities.  Notified  bodies  shall  also  be  independent  of  '\n 'any  other  operator  having  an  economic interest  in  high-risk  AI  '\n 'systems  assessed,  as  well  as  of  any competitors  of  the  provider.  '\n 'This  shall  not  preclude  the  use  of assessed high-risk AI systems that '\n 'are necessary for  the operations of  the conformity assessment body, or  '\n 'the use of such high-risk  AI  systems  for  personal  purposes.')>]>]\n[<Paragraph children=[<RawText children=('Neither  a  conformity  assessment  body,  its  top-level  management  nor  '\n 'the  personnel  responsible  for  carrying  out  its conformity assessment '\n 'tasks shall be directly involved in the design, development, marketing or '\n 'use of high-risk AI systems, nor shall they represent the parties engaged in '\n 'those activities. They shall not engage in any activity that might conflict '\n 'with their  independence  of  judgement  or  integrity  in  relation  to  '\n 'conformity  assessment  activities  for  which  they  are  notified. This  '\n 'shall,  in  particular,  apply  to  consultancy  services.')>]>]\n[<Paragraph children=[<RawText children=('Notified bodies shall be organised and operated so as to safeguard the '\n 'independence, objectivity and impartiality of their activities. Notified '\n 'bodies shall document and implement a structure and procedures to safeguard '\n 'impartiality and to promote and apply the principles of  impartiality  '\n 'throughout  their  organisation,  personnel  and  assessment  activities.')>]>]\n[<Paragraph children=[<RawText children=('Notified  bodies  shall  have  documented  procedures  in  place  ensuring  '\n 'that  their  personnel,  committees,  subsidiaries, subcontractors  and  '\n 'any  associated  body  or  personnel  of  external  bodies  maintain,  in  '\n 'accordance  with  Article  78,  the confidentiality  of  the  information  '\n 'which  comes  into  their  possession  during  the  performance  of  '\n 'conformity  assessment activities, except when its disclosure is required by '\n 'law. The staff of notified bodies shall be bound to observe professional '\n 'secrecy with regard to all information obtained in carrying out their  tasks '\n 'under  this Regulation, except in relation to the notifying  authorities  '\n 'of  the  Member  State  in  which  their  activities  are  carried  out.')>]>]\n[<Paragraph children=[<RawText children=('Notified  bodies  shall  have  procedures  for  the  performance  of  '\n 'activities  which  take  due  account  of  the  size  of a  provider,  the  '\n 'sector  in  which  it  operates,  its  structure,  and  the  degree  of  '\n 'complexity  of  the  AI  system  concerned.')>]>]\n[<Paragraph children=[<RawText children=('Notified bodies shall take out appropriate liability insurance for their '\n 'conformity assessment activities, unless liability is assumed by the Member '\n 'State in which they are established in accordance with national law or that '\n 'Member State is itself directly  responsible  for  the  conformity  '\n 'assessment.')>]>]\n[<Paragraph children=[<RawText children=('Notified  bodies  shall  be  capable  of  carrying  out  all  their  tasks  '\n 'under  this  Regulation  with  the  highest  degree  of professional  '\n 'integrity  and  the  requisite  competence  in  the  specific  field,  '\n 'whether  those  tasks  are  carried  out  by  notified bodies  themselves  '\n 'or  on  their  behalf  and  under  their  responsibility.')>]>]\n[<Paragraph children=[<RawText children=('Notified bodies shall have sufficient  internal  competences to be able '\n 'effectively to evaluate the tasks  conducted by external parties on their '\n 'behalf. The notified body shall have permanent availability of sufficient '\n 'administrative, technical, legal and scientific personnel who possess '\n 'experience and knowledge relating to the relevant types of AI systems, data '\n 'and data  computing,  and  relating  to  the  requirements  set  out  in  '\n 'Section  2.')>]>]\n[<Paragraph children=[<RawText children=('Notified  bodies  shall  participate  in  coordination  activities  as  '\n 'referred  to  in  Article  38.  They  shall  also  take  part directly,  or  '\n 'be  represented  in,  European  standardisation  organisations,  or  ensure  '\n 'that  they  are  aware  and  up  to  date  in respect  of  relevant  '\n 'standards.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_46",
    "chunk_content": "Presumption of conformity with requirements relating to notified bodies\nWhere a conformity assessment body demonstrates its conformity with the criteria laid down in the relevant harmonised standards or parts thereof, the references of which have been published in the Official Journal of the European Union ,  it  shall be presumed to comply with the requirements set out in Article 31 in so far as the applicable harmonised standards cover those  requirements."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_47",
    "chunk_content": "Subsidiaries of  notified  bodies  and  subcontracting\n[<Paragraph children=[<RawText children=('Where  a  notified  body  subcontracts  specific  tasks  connected  with  '\n 'the  conformity  assessment  or  has  recourse  to a  subsidiary,  it  '\n 'shall  ensure  that  the  subcontractor  or  the  subsidiary  meets  the  '\n 'requirements  laid  down  in  Article  31,  and shall  inform  the  '\n 'notifying  authority  accordingly.')>]>]\n[<Paragraph children=[<RawText children=('Notified  bodies  shall  take  full  responsibility  for  the  tasks  '\n 'performed  by  any  subcontractors  or  subsidiaries.')>]>]\n[<Paragraph children=[<RawText children=('Activities  may  be  subcontracted  or  carried  out  by  a  subsidiary  '\n 'only  with  the  agreement  of  the  provider.  Notified bodies  shall  '\n 'make  a  list  of  their  subsidiaries  publicly  available.')>]>]\n[<Paragraph children=[<RawText children=('The relevant documents concerning the assessment of  the qualifications of  '\n 'the subcontractor or  the subsidiary and the work carried out by them under '\n 'this Regulation shall be kept at the disposal of the notifying authority for '\n 'a period of five  years  from  the  termination  date  of  the  '\n 'subcontracting.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_48",
    "chunk_content": "Operational obligations of notified bodies\n[<Paragraph children=[<RawText children=('Notified  bodies  shall  verify  the  conformity  of  high-risk  AI  '\n 'systems  in  accordance  with  the  conformity  assessment procedures set '\n 'out  in  Article  43.')>]>]\n[<Paragraph children=[<RawText children=('Notified bodies shall avoid unnecessary burdens for providers when '\n 'performing their activities, and take due account of  the  size  of  the  '\n 'provider,  the  sector  in  which  it  operates,  its  structure  and  the  '\n 'degree  of  complexity of  the  high-risk  AI system concerned, in '\n 'particular  in view of minimising administrative burdens and compliance '\n 'costs for  micro- and small enterprises within the meaning of Recommendation '\n '2003/361/EC. The notified body shall, nevertheless, respect the degree of '\n 'rigour and the level of protection required for  the compliance of the '\n 'high-risk AI system with the requirements of this Regulation.')>]>]\n[<Paragraph children=[<RawText children=('Notified  bodies  shall  make  available  and  submit  upon  request  all  '\n \"relevant  documentation,  including  the  providers' documentation,  to  \"\n 'the  notifying  authority  referred  to  in  Article  28  to  allow  that  '\n 'authority  to  conduct  its  assessment, designation,  notification  and  '\n 'monitoring  activities,  and  to  facilitate  the  assessment  outlined  in  '\n 'this  Section.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_49",
    "chunk_content": "Identification numbers and lists  of  notified  bodies\n[<Paragraph children=[<RawText children=('The Commission shall assign a single identification number to each notified '\n 'body, even where a body is notified under more than one Union act.')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  shall  make  publicly  available  the  list  of  the  '\n 'bodies  notified  under  this  Regulation,  including  their identification '\n 'numbers and the activities for which they have been notified. The Commission '\n 'shall ensure that the list is kept up to  date.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_50",
    "chunk_content": "Changes to notifications\n[<Paragraph children=[<RawText children=('The  notifying  authority  shall  notify  the  Commission  and  the  other  '\n 'Member  States  of  any  relevant  changes  to  the notification  of  a  '\n 'notified  body  via  the  electronic  notification  tool  referred  to  in  '\n 'Article  30(2).')>]>]\n[<Paragraph children=[<RawText children=('The procedures laid down in Articles  29  and  30  shall  apply  to  '\n 'extensions  of  the  scope  of  the  notification.')>]>]\nFor changes to the notification other  than extensions of its scope, the procedures laid down in paragraphs (3) to (9) shall apply.\n[<Paragraph children=[<RawText children=('Where a notified body decides to cease its conformity assessment activities, '\n 'it shall inform the notifying authority and the  providers  concerned  as  '\n 'soon  as  possible  and,  in  the  case  of  a  planned  cessation,  at  '\n 'least  one  year  before  ceasing  its activities. The certificates of the '\n 'notified body may remain valid for a period of nine months after cessation '\n \"of the notified body's activities, on condition that another notified body \"\n 'has confirmed in writing that it will assume responsibilities for the '\n 'high-risk AI systems covered by those certificates. The latter notified body '\n 'shall complete a full assessment of the high-risk AI  systems  affected  by  '\n 'the  end  of  that  nine-month-period  before  issuing  new  certificates  '\n 'for  those  systems.  Where  the notified  body  has  ceased  its  '\n 'activity,  the  notifying  authority  shall  withdraw  the  designation.')>]>]\n[<Paragraph children=[<RawText children=('Where a notifying authority has sufficient reason to consider  that a '\n 'notified body no longer meets the requirements laid down in Article 31, or '\n 'that it is failing to fulfil its obligations, the notifying authority shall '\n 'without delay investigate the matter  with the utmost diligence. In that '\n 'context, it shall inform the notified body concerned about the objections '\n 'raised and give it the possibility to make its views known. If the notifying '\n 'authority comes to the conclusion that the notified body no longer meets the '\n 'requirements laid down in Article 31 or that it is failing to fulfil its '\n 'obligations, it shall restrict, suspend or withdraw the designation as '\n 'appropriate, depending on the seriousness of the failure to meet those '\n 'requirements or fulfil those  obligations.  It  shall  immediately  inform  '\n 'the  Commission  and  the  other  Member  States  accordingly.')>]>]\n[<Paragraph children=[<RawText children=('Where its designation has been suspended, restricted, or fully or partially '\n 'withdrawn, the notified body shall inform the  providers  concerned  within  '\n '10  days.')>]>]\n[<Paragraph children=[<RawText children=('In  the  event  of  the  restriction,  suspension  or  withdrawal  of  a  '\n 'designation,  the  notifying  authority  shall  take appropriate steps to '\n 'ensure that the files of the notified body concerned are kept, and to make '\n 'them available to notifying authorities  in  other  Member  States  and  to  '\n 'market  surveillance  authorities  at  their  request.')>]>]\n[<Paragraph children=[<RawText children=('In  the  event  of  the  restriction,  suspension  or  withdrawal  of  a  '\n 'designation,  the  notifying  authority  shall:')>]>]\n(a) assess  the  impact  on  the  certificates  issued  by  the  notified  body;\n(b) submit a report on its findings to the Commission and the other Member States within three months of having notified the  changes  to  the  designation;\n(c) require the notified body to suspend or withdraw, within a reasonable period of time determined by the authority, any certificates  which  were  unduly  issued,  in  order  to  ensure  the  continuing  conformity  of  high-risk  AI  systems  on  the market;\n(d) inform the Commission and the Member States about certificates the suspension or withdrawal of which it has required;\n(e) provide  the  national  competent  authorities  of  the  Member  State  in  which  the  provider  has  its  registered  place  of business with all relevant information about the certificates of which it has required the suspension or withdrawal; that authority shall take the appropriate measures, where necessary, to avoid a potential risk to health, safety or fundamental rights.\n[<Paragraph children=[<RawText children=('With  the  exception  of  certificates  unduly  issued,  and  where  a  '\n 'designation  has  been  suspended  or  restricted,  the certificates  shall  '\n 'remain  valid  in  one  of  the  following  circumstances:')>]>]\n(a) the notifying authority has confirmed, within one month of the suspension or restriction, that there is no risk to health, safety  or  fundamental  rights  in  relation  to  certificates  affected  by  the  suspension  or  restriction,  and  the  notifying authority  has  outlined  a  timeline  for  actions  to  remedy  the  suspension  or  restriction;  or\n(b) the notifying authority has confirmed that no certificates relevant to the suspension will be issued, amended or re-issued during the course of the suspension or restriction, and states whether the notified body has the capability of continuing to monitor and remain responsible for existing certificates issued for the period of the suspension or restriction; in the event  that  the  notifying  authority  determines  that  the  notified  body  does  not  have  the  capability  to  support  existing certificates  issued,  the  provider  of  the  system  covered  by  the  certificate  shall  confirm  in  writing  to  the  national competent authorities of the Member State in which it has its registered place of business, within three months of the suspension  or  restriction,  that  another  qualified  notified  body  is  temporarily  assuming  the  functions  of  the  notified body to monitor and remain responsible for  the certificates during the  period  of  suspension  or  restriction.\n[<Paragraph children=[<RawText children=('With the exception of certificates unduly issued, and where a designation '\n 'has been withdrawn, the certificates shall remain valid  for  a  period  of  '\n 'nine  months  under  the  following  circumstances:')>]>]\n(a) the national competent authority of the Member State in which the provider of the high-risk AI system covered by the certificate has its registered place of business has confirmed that there is no risk to health, safety or fundamental rights associated  with  the  high-risk  AI  systems  concerned;  and\n(b) another  notified  body has confirmed in writing that it will assume immediate responsibility for  those AI systems and completes its  assessment  within  12  months  of  the  withdrawal  of  the  designation.\nIn the circumstances referred to in the first subparagraph, the national competent authority of the Member State in which the  provider  of  the  system  covered  by  the  certificate  has  its  place  of  business  may  extend  the  provisional  validity  of  the certificates  for  additional  periods  of  three  months,  which  shall  not  exceed  12  months  in  total.\nThe national competent authority or the notified body assuming the functions of the notified body affected by the change of  designation shall  immediately inform the Commission, the other Member States and the other  notified bodies thereof."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_51",
    "chunk_content": "Challenge to the competence of notified bodies\n[<Paragraph children=[<RawText children=('The  Commission  shall,  where  necessary,  investigate  all  cases  where  '\n 'there  are  reasons  to  doubt  the  competence  of a  notified  body  or  '\n 'the  continued  fulfilment  by  a  notified  body  of  the  requirements  '\n 'laid  down  in  Article  31  and  of  its applicable  responsibilities.')>]>]\n[<Paragraph children=[<RawText children=('The  notifying  authority  shall  provide  the  Commission,  on  request,  '\n 'with  all  relevant  information  relating  to  the notification  or  the  '\n 'maintenance  of  the  competence  of  the  notified  body concerned.')>]>]\n[<Paragraph children=[<RawText children=('The Commission shall ensure that all sensitive information obtained in the '\n 'course of its investigations pursuant to this Article  is  treated  '\n 'confidentially  in  accordance  with  Article  78.')>]>]\n[<Paragraph children=[<RawText children=('Where  the  Commission  ascertains  that  a  notified  body  does  not  '\n 'meet  or  no  longer  meets  the  requirements  for  its notification, it '\n 'shall inform the notifying Member State accordingly and request it to take '\n 'the necessary corrective measures, including the suspension or withdrawal of '\n 'the notification if necessary. Where the Member State fails to take the '\n 'necessary corrective measures, the Commission may, by means of an '\n 'implementing act, suspend, restrict or withdraw the designation. That  '\n 'implementing act  shall  be  adopted  in  accordance  with  the  '\n 'examination  procedure  referred  to  in  Article  98(2).')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_52",
    "chunk_content": "Coordination of notified bodies\n[<Paragraph children=[<RawText children=('The  Commission  shall  ensure  that,  with  regard  to  high-risk  AI  '\n 'systems,  appropriate  coordination  and  cooperation between notified  '\n 'bodies  active  in  the  conformity  assessment  procedures  pursuant  to '\n 'this  Regulation  are  put  in place  and properly operated  in  the  form  '\n 'of  a  sectoral  group  of  notified  bodies.')>]>]\n[<Paragraph children=[<RawText children=('Each notifying authority shall ensure  that the bodies  notified  by it '\n 'participate in  the  work of a  group  referred to in paragraph 1,  directly '\n 'or  through  designated  representatives.')>]>]\n[<Paragraph children=[<RawText children=('The Commission shall provide for  the  exchange of  knowledge and best '\n 'practices  between  notifying authorities.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_53",
    "chunk_content": "Conformity assessment bodies of  third countries\nConformity  assessment  bodies  established  under  the  law  of  a  third  country  with  which  the  Union  has  concluded  an agreement may be authorised to carry out the activities of notified bodies under  this Regulation, provided that they meet the  requirements  laid  down  in  Article  31  or  they  ensure  an  equivalent  level  of  compliance."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_54",
    "chunk_content": "Standards, conformity assessment, certificates,  registration\nArticle  40"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_55",
    "chunk_content": "Harmonised standards and standardisation deliverables\n[<Paragraph children=[<RawText children=('High-risk  AI  systems  or  general-purpose  AI  models  which  are  in  '\n 'conformity  with  harmonised  standards  or  parts thereof  the  references  '\n 'of  which  have  been  published  in  the Official  Journal  of  the  '\n 'European  Union in  accordance  with Regulation (EU) No 1025/2012 shall be '\n 'presumed to be in conformity with the requirements set out in Section 2 of '\n 'this Chapter or, as applicable, with the obligations set out in of Chapter '\n 'V, Sections 2 and 3, of this Regulation, to the extent that those  '\n 'standards  cover  those  requirements  or  obligations.')>]>]\n[<Paragraph children=[<RawText children=('In accordance with Article 10 of Regulation (EU) No 1025/2012, the '\n 'Commission shall issue, without undue delay, standardisation requests  '\n 'covering all  requirements  set out  in  Section  2  of  this  Chapter  '\n 'and,  as  applicable,  standardisation requests covering obligations set out '\n 'in Chapter V, Sections 2 and 3, of  this Regulation. The standardisation '\n 'request shall also ask for deliverables on reporting and documentation '\n \"processes to improve AI systems' resource performance, such as reducing  \"\n \"the  high-risk  AI  system's  consumption  of  energy  and  of  other  \"\n 'resources  during  its  lifecycle,  and  on  the energy-efficient  '\n 'development  of  general-purpose  AI  models.  When  preparing  a  '\n 'standardisation  request,  the  Commission shall  consult  the  Board  and  '\n 'relevant  stakeholders,  including  the  advisory  forum.')>]>]\nWhen  issuing  a  standardisation  request  to  European  standardisation  organisations,  the  Commission  shall  specify  that standards have to be clear, consistent, including with the standards developed in the various sectors for products covered by the  existing  Union  harmonisation  legislation  listed  in  Annex  I,  and  aiming  to  ensure  that  high-risk  AI  systems  or general-purpose  AI  models  placed  on  the  market  or  put  into  service  in  the  Union  meet  the  relevant  requirements  or obligations  laid  down  in  this  Regulation.\nThe Commission shall request the European standardisation organisations to provide evidence of their best efforts to fulfil the  objectives  referred  to  in  the  first  and  the  second  subparagraph  of  this  paragraph  in  accordance  with  Article  24  of Regulation  (EU)  No  1025/2012.\n[<Paragraph children=[<RawText children=('The  participants  in  the  standardisation  process  shall  seek  to  '\n 'promote  investment  and  innovation  in  AI,  including through  '\n 'increasing  legal  certainty,  as  well  as  the  competitiveness  and  '\n 'growth  of  the  Union  market,  to  contribute  to strengthening global '\n 'cooperation on standardisation and taking into account existing '\n 'international standards in the field of AI  that  are  consistent  with  '\n 'Union values,  fundamental  rights  and  interests,  and  to  enhance  '\n 'multi-stakeholder  governance ensuring a balanced representation of '\n 'interests and the effective participation of all relevant stakeholders in '\n 'accordance with Articles  5,  6,  and  7  of  Regulation  (EU)  No  '\n '1025/2012.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_56",
    "chunk_content": "Common specifications\n[<Paragraph children=[<RawText children=('The Commission may adopt, implementing acts establishing common '\n 'specifications for  the requirements set out in Section 2 of this Chapter '\n 'or, as applicable, for the obligations set out in Sections 2 and 3 of '\n 'Chapter V where the following conditions  have  been  fulfilled:')>]>]\n(a) the  Commission  has  requested,  pursuant  to  Article  10(1)  of  Regulation  (EU)  No  1025/2012,  one  or  more  European standardisation organisations to draft a harmonised standard for the requirements set out in Section 2 of this Chapter, or,  as  applicable,  for  the  obligations  set  out  in  Sections  2  and  3  of  Chapter  V,  and:\n(i) the  request  has  not  been  accepted  by  any of  the  European  standardisation  organisations;  or\n(ii) the  harmonised  standards  addressing  that  request  are  not  delivered  within  the  deadline  set  in  accordance  with Article  10(1)  of  Regulation  (EU)  No  1025/2012;  or\n(iii) the  relevant  harmonised  standards  insufficiently  address  fundamental  rights  concerns;  or\n(iv) the  harmonised  standards  do  not  comply  with  the  request;  and\n(b) no  reference  to  harmonised  standards  covering  the  requirements  referred  to  in  Section  2  of  this  Chapter  or,  as applicable, the obligations referred to in Sections 2 and 3 of Chapter V has been published in the Official Journal of  the European Union in accordance with Regulation (EU) No 1025/2012, and no such reference is expected to be published within  a  reasonable  period.\nWhen drafting the common specifications, the Commission shall consult the advisory forum referred to in Article 67.\nThe  implementing  acts  referred  to  in  the  first  subparagraph  of  this  paragraph  shall  be  adopted  in  accordance  with  the examination procedure referred  to  in  Article  98(2).\n[<Paragraph children=[<RawText children=('Before preparing a draft implementing act, the Commission shall inform the '\n 'committee referred to in Article 22 of Regulation  (EU)  No  1025/2012  '\n 'that  it  considers  the  conditions  laid  down  in  paragraph  1  of  '\n 'this  Article  to  be  fulfilled.')>]>]\n[<Paragraph children=[<RawText children=('High-risk AI systems or general-purpose AI models which are in conformity '\n 'with the common specifications referred to in paragraph 1, or parts of those '\n 'specifications, shall be presumed to be in conformity with the requirements '\n 'set out in Section 2 of this Chapter or, as applicable, to comply with the '\n 'obligations referred to in Sections 2 and 3 of Chapter V, to the  extent  '\n 'those  common  specifications  cover  those  requirements  or  those  '\n 'obligations.')>]>]\n[<Paragraph children=[<RawText children=('Where  a  harmonised  standard  is  adopted  by  a  European  '\n 'standardisation  organisation  and  proposed  to  the Commission for the '\n 'publication of its reference in the Official Journal of the European Union , '\n 'the Commission shall assess the harmonised  standard  in  accordance  with  '\n 'Regulation  (EU)  No  1025/2012.  When  reference  to  a  harmonised  '\n 'standard  is published  in  the Official  Journal  of  the  European  Union '\n ',  the  Commission  shall  repeal  the  implementing  acts  referred  to  in '\n 'paragraph 1, or parts thereof which cover the same requirements set out in '\n 'Section 2 of this Chapter or, as applicable, the same obligations  set out  '\n 'in  Sections  2  and  3  of  Chapter  V.')>]>]\n[<Paragraph children=[<RawText children=('Where  providers  of  high-risk  AI  systems  or  general-purpose  AI  '\n 'models  do  not  comply  with  the  common specifications  referred  to  in  '\n 'paragraph  1,  they  shall  duly  justify  that  they  have  adopted  '\n 'technical  solutions  that  meet  the requirements referred to in Section 2 '\n 'of this Chapter or, as applicable, comply with the obligations set out in '\n 'Sections 2 and 3  of  Chapter  V  to  a  level  at  least  equivalent  '\n 'thereto.')>]>]\n[<Paragraph children=[<RawText children=('Where  a  Member  State  considers  that  a  common  specification  does  '\n 'not  entirely  meet  the  requirements  set  out  in Section  2  or,  as  '\n 'applicable,  comply  with  obligations  set  out  in  Sections  2  and  3  '\n 'of  Chapter  V,  it  shall  inform  the Commission thereof with a detailed '\n 'explanation. The Commission shall assess that information and, if '\n 'appropriate, amend the  implementing act establishing  the  common  '\n 'specification  concerned.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_57",
    "chunk_content": "Presumption of conformity with certain requirements\n[<Paragraph children=[<RawText children=('High-risk  AI  systems  that  have  been  trained  and  tested  on  data  '\n 'reflecting  the  specific  geographical,  behavioural, contextual or '\n 'functional setting within which they are intended to be used shall be '\n 'presumed to comply with the relevant requirements  laid  down  in  Article  '\n '10(4).')>]>]\n[<Paragraph children=[<RawText children=('High-risk  AI  systems  that  have  been  certified  or  for  which  a  '\n 'statement  of  conformity  has  been  issued  under a  cybersecurity  '\n 'scheme  pursuant  to  Regulation  (EU)  2019/881  and  the  references  of  '\n 'which  have  been  published  in  the Official Journal of the European Union '\n 'shall be presumed to comply with the cybersecurity requirements set out in '\n 'Article 15 of  this  Regulation  in  so  far  as  the  cybersecurity  '\n 'certificate  or  statement  of  conformity  or  parts  thereof  cover  those '\n 'requirements.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_58",
    "chunk_content": "Conformity assessment\n[<Paragraph children=[<RawText children=('For  high-risk  AI  systems  listed  in  point  1  of  Annex  III,  where,  '\n 'in  demonstrating  the  compliance  of  a  high-risk  AI system with the '\n 'requirements set out in Section 2, the provider has applied harmonised '\n 'standards referred to in Article 40, or,  where  applicable,  common  '\n 'specifications  referred  to  in  Article  41,  the  provider  shall  opt  '\n 'for  one  of  the  following conformity assessment procedures based on:')>]>]\n(a) the  internal  control  referred  to  in  Annex  VI;  or\n(b) the  assessment  of  the  quality  management  system  and  the  assessment  of  the  technical  documentation,  with  the involvement of a  notified  body,  referred  to  in  Annex  VII.\nIn  demonstrating  the  compliance  of  a  high-risk  AI  system  with  the  requirements  set  out  in  Section  2,  the  provider  shall follow  the  conformity  assessment  procedure  set  out  in  Annex  VII  where:\n(a) harmonised standards referred to in Article 40 do not exist, and common specifications referred to in Article 41 are not available;\n(b) the  provider  has  not  applied,  or  has  applied  only  part  of,  the  harmonised  standard;\n(c) the  common specifications  referred  to  in point  (a)  exist,  but  the  provider  has  not  applied  them;\n(d) one or more of the harmonised standards referred to in point (a) has been published with a restriction, and only on the part  of  the  standard  that  was  restricted.\nFor  the  purposes  of  the  conformity  assessment  procedure  referred  to  in  Annex  VII,  the  provider  may  choose  any  of  the notified bodies. However, where the high-risk AI system is intended to be put into service by law enforcement, immigration or asylum authorities or by Union institutions, bodies, offices or agencies, the market surveillance authority referred to in Article  74(8)  or  (9),  as  applicable,  shall  act  as  a  notified  body.\n[<Paragraph children=[<RawText children=('For high-risk AI systems referred to in points 2 to 8 of Annex III, '\n 'providers shall follow the conformity assessment procedure based on internal '\n 'control as referred to in Annex VI, which does not provide for  the '\n 'involvement of a notified body.')>]>]\n[<Paragraph children=[<RawText children=('For high-risk AI systems covered by the Union harmonisation legislation '\n 'listed in Section A of Annex I, the provider shall  follow the  relevant '\n 'conformity assessment procedure as required under  those legal acts. The '\n 'requirements set out in Section 2 of this Chapter shall apply to those '\n 'high-risk AI systems and shall be part of that assessment. Points 4.3., '\n '4.4., 4.5. and the  fifth  paragraph  of  point  4.6  of  Annex  VII  shall  '\n 'also  apply.')>]>]\nFor  the  purposes  of  that  assessment,  notified  bodies  which  have  been  notified  under  those  legal  acts  shall  be  entitled  to control the conformity of the high-risk AI systems with the requirements set out in Section 2, provided that the compliance of those notified bodies with requirements laid down in Article 31(4), (5), (10) and (11) has been assessed in the context of the  notification  procedure  under  those  legal  acts.\nWhere a legal act listed in Section A of Annex I enables the product manufacturer to opt out from a third-party conformity assessment, provided that that manufacturer has applied all harmonised standards covering all the relevant requirements, that  manufacturer  may  use  that  option  only  if  it  has  also  applied  harmonised  standards  or,  where  applicable,  common specifications  referred  to  in  Article  41,  covering  all  requirements  set  out  in  Section  2  of  this  Chapter.\n[<Paragraph children=[<RawText children=('High-risk  AI  systems  that  have  already  been  subject  to  a  '\n 'conformity  assessment  procedure  shall  undergo  a  new conformity '\n 'assessment procedure in the event of a substantial modification, regardless '\n 'of whether  the modified system is intended  to  be  further  distributed  '\n 'or  continues  to  be  used  by  the  current  deployer.')>]>]\nFor high-risk AI systems that continue to learn after being placed on the market or put into service, changes to the high-risk AI  system  and  its  performance  that  have  been  pre-determined  by  the  provider  at  the  moment  of  the  initial  conformity assessment and are part of the information contained in the technical documentation referred to in point 2(f) of Annex IV, shall  not  constitute  a  substantial  modification.\n[<Paragraph children=[<RawText children=('The Commission is empowered to adopt delegated acts in accordance with '\n 'Article 97 in order to amend Annexes VI and VII  by  updating  them  in  '\n 'light  of  technical  progress.')>]>]\n[<Paragraph children=[<RawText children=('The Commission is empowered to adopt delegated acts in accordance with '\n 'Article 97 in order to amend paragraphs 1 and 2 of  this  Article  in  '\n 'order  to  subject  high-risk  AI  systems  referred  to  in  points  2  to  '\n '8  of  Annex  III  to  the  conformity assessment procedure referred to in '\n 'Annex VII or parts thereof. The Commission shall adopt such delegated acts '\n 'taking into account  the  effectiveness  of  the  conformity  assessment  '\n 'procedure  based  on  internal  control  referred  to  in  Annex  VI  in '\n 'preventing or minimising the risks to health and safety and protection of '\n 'fundamental rights posed by such systems, as well as  the  availability  of  '\n 'adequate  capacities  and  resources  among  notified  bodies.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_59",
    "chunk_content": "Certificates\n[<Paragraph children=[<RawText children=('Certificates  issued  by  notified  bodies  in  accordance  with  Annex  '\n 'VII  shall  be  drawn-up  in  a  language  which  can  be easily  understood '\n 'by the  relevant  authorities  in  the  Member  State  in  which  the  '\n 'notified  body  is  established.')>]>]\n[<Paragraph children=[<RawText children=('Certificates  shall  be  valid  for  the  period  they  indicate,  which  '\n 'shall  not  exceed  five  years  for  AI  systems  covered  by Annex I, and '\n 'four years for AI systems covered by Annex III. At the request of the '\n 'provider, the validity of a certificate may be  extended  for  further  '\n 'periods,  each  not  exceeding  five  years  for  AI  systems  covered  by  '\n 'Annex  I,  and  four  years  for  AI systems  covered  by  Annex  III,  '\n 'based  on  a  re-assessment  in  accordance  with  the  applicable  '\n 'conformity  assessment procedures. Any supplement to a certificate shall '\n 'remain valid, provided that the certificate which it supplements is valid.')>]>]\n[<Paragraph children=[<RawText children=('Where a notified body finds that an AI system no longer meets the '\n 'requirements set out in Section 2, it shall, taking account of the principle '\n 'of proportionality, suspend or  withdraw the certificate issued or impose '\n 'restrictions on it, unless compliance with those requirements is ensured by '\n 'appropriate corrective action taken by the provider of the system within an  '\n 'appropriate deadline  set  by  the  notified  body.  The  notified  body  '\n 'shall  give  reasons  for  its  decision.')>]>]\nAn appeal procedure against decisions of the notified bodies, including on conformity certificates issued, shall be available."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_60",
    "chunk_content": "Information obligations of notified bodies\n[<Paragraph children=[<RawText children='Notified  bodies  shall  inform  the  notifying  authority of  the  following:'>]>]\n(a) any  Union  technical  documentation  assessment  certificates,  any  supplements  to  those  certificates,  and  any  quality management system approvals issued in accordance with the requirements of Annex VII;\n(b) any refusal, restriction, suspension or withdrawal of a Union technical documentation assessment certificate or a quality management system approval issued in accordance with the requirements of Annex VII;\n(c) any circumstances affecting the scope  of or  conditions  for  notification;\n(d) any  request  for  information  which  they  have  received  from  market  surveillance  authorities  regarding  conformity assessment  activities;\n(e) on  request,  conformity  assessment  activities  performed  within  the  scope  of  their  notification  and  any  other  activity performed, including  cross-border  activities  and  subcontracting.\n[<Paragraph children=[<RawText children='Each notified  body  shall  inform  the  other  notified  bodies  of:'>]>]\n(a) quality  management  system  approvals  which  it  has  refused,  suspended  or  withdrawn,  and,  upon  request,  of  quality system  approvals  which it  has  issued;\n(b) Union  technical  documentation  assessment  certificates  or  any  supplements  thereto  which  it  has  refused,  withdrawn, suspended or otherwise restricted, and, upon request, of the certificates and/or supplements thereto which it has issued.\n[<Paragraph children=[<RawText children=('Each  notified  body  shall  provide  the  other  notified  bodies  '\n 'carrying  out  similar  conformity  assessment  activities covering  the  '\n 'same  types  of  AI  systems  with  relevant  information  on  issues  '\n 'relating  to  negative  and,  on  request,  positive conformity assessment '\n 'results.')>]>]\n[<Paragraph children=[<RawText children=('Notified bodies shall safeguard the confidentiality of the information that '\n 'they obtain, in accordance with Article 78.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_61",
    "chunk_content": "Derogation from conformity assessment procedure\n[<Paragraph children=[<RawText children=('By  way  of  derogation  from  Article  43  and  upon  a  duly  justified  '\n 'request,  any  market  surveillance  authority  may authorise the placing on '\n 'the market or the putting into service of specific high-risk AI systems '\n 'within the territory of the Member  State  concerned,  for  exceptional  '\n 'reasons  of  public  security  or  the  protection  of  life  and  health  '\n 'of  persons, environmental  protection  or  the  protection  of  key  '\n 'industrial  and  infrastructural  assets.  That  authorisation  shall  be  '\n 'for a  limited  period  while  the  necessary  conformity  assessment  '\n 'procedures  are  being  carried  out,  taking  into  account  the '\n 'exceptional reasons justifying the derogation. The completion of those '\n 'procedures shall be undertaken without undue delay.')>]>]\n[<Paragraph children=[<RawText children=('In a duly justified situation of urgency for exceptional reasons of public '\n 'security or in the case of specific, substantial and  imminent  threat  to  '\n 'the  life  or  physical  safety  of  natural  persons,  law-enforcement  '\n 'authorities  or  civil  protection authorities  may  put  a  specific  '\n 'high-risk  AI  system  into  service  without  the  authorisation  referred  '\n 'to  in  paragraph  1, provided that such authorisation is requested during '\n 'or after the use without undue delay. If the authorisation referred to in '\n 'paragraph 1  is  refused,  the  use  of  the  high-risk  AI  system  shall  '\n 'be  stopped  with  immediate  effect  and  all  the  results  and outputs  '\n 'of  such  use  shall  be  immediately  discarded.')>]>]\n[<Paragraph children=[<RawText children=('The authorisation referred to in paragraph 1 shall be issued only if the '\n 'market surveillance authority concludes that the  high-risk  AI  system  '\n 'complies  with  the  requirements  of  Section  2.  The  market  '\n 'surveillance  authority  shall  inform  the Commission and the other Member '\n 'States of any authorisation issued pursuant to paragraphs 1 and 2. This '\n 'obligation shall not  cover  sensitive  operational  data  in  relation  to  '\n 'the  activities  of  law-enforcement  authorities.')>]>]\n[<Paragraph children=[<RawText children=('Where, within 15 calendar days of receipt of the information referred to in '\n 'paragraph 3, no objection has been raised by either  a  Member  State  or  '\n 'the  Commission  in  respect  of  an  authorisation  issued  by  a  market  '\n 'surveillance  authority  of a  Member State in  accordance  with  paragraph  '\n '1,  that  authorisation  shall  be  deemed  justified.')>]>]\n[<Paragraph children=[<RawText children=('Where,  within  15  calendar  days  of  receipt  of  the  notification  '\n 'referred  to  in  paragraph  3,  objections  are  raised  by a Member State '\n 'against an authorisation issued by a market surveillance authority of '\n 'another Member State, or where the Commission considers the authorisation to '\n 'be contrary to Union law, or the conclusion of the Member States regarding '\n 'the compliance of the system as referred to in paragraph 3 to be unfounded, '\n 'the Commission shall, without delay, enter  into consultations  with  the  '\n 'relevant  Member  State.  The  operators  concerned  shall  be  consulted  '\n 'and  have  the  possibility  to present  their  views.  Having  regard  '\n 'thereto,  the  Commission  shall  decide  whether  the  authorisation  is  '\n 'justified.  The Commission shall address  its  decision  to  the  Member  '\n 'State  concerned  and  to the  relevant  operators.')>]>]\n[<Paragraph children=[<RawText children=('Where  the  Commission  considers  the  authorisation  unjustified,  it  '\n 'shall  be  withdrawn  by  the  market  surveillance authority of  the  '\n 'Member  State  concerned.')>]>]\n[<Paragraph children=[<RawText children=('For  high-risk  AI  systems  related  to  products  covered  by  Union  '\n 'harmonisation  legislation  listed  in  Section  A  of Annex I,  only  the  '\n 'derogations  from  the  conformity  assessment  established  in  that  '\n 'Union  harmonisation  legislation  shall apply.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_62",
    "chunk_content": "EU declaration of conformity\n[<Paragraph children=[<RawText children=('The provider shall draw up a written machine readable, physical or '\n 'electronically signed EU declaration of conformity for  each  high-risk  AI  '\n 'system,  and  keep  it  at  the  disposal  of  the  national  competent  '\n 'authorities  for  10  years  after  the high-risk AI system has been placed '\n 'on the market or put into service. The EU declaration of conformity shall '\n 'identify the high-risk AI system for which it has been drawn up. A copy of '\n 'the EU declaration of conformity shall be submitted to the relevant  '\n 'national  competent  authorities  upon  request.')>]>]\n[<Paragraph children=[<RawText children=('The EU declaration of conformity shall state that the high-risk AI system '\n 'concerned meets the requirements set out in Section 2. The EU declaration of '\n 'conformity shall contain the information set out in Annex V, and shall be '\n 'translated into a language that can be easily understood by the national '\n 'competent authorities of the Member States in which the high-risk AI  '\n 'system  is  placed  on  the  market  or  made  available.')>]>]\n[<Paragraph children=[<RawText children=('Where  high-risk  AI  systems  are  subject  to  other  Union  '\n 'harmonisation  legislation  which  also  requires  an  EU declaration of '\n 'conformity, a single EU declaration of conformity shall be drawn up in '\n 'respect of all Union law applicable to the  high-risk  AI  system.  The  '\n 'declaration  shall  contain  all  the  information  required  to  identify  '\n 'the  Union  harmonisation legislation  to  which  the  declaration  relates.')>]>]\n[<Paragraph children=[<RawText children=('By  drawing  up  the  EU  declaration  of  conformity,  the  provider  '\n 'shall  assume  responsibility  for  compliance  with  the requirements  set  '\n 'out  in  Section  2.  The  provider  shall  keep  the  EU  declaration  of  '\n 'conformity  up-to-date  as  appropriate.')>]>]\n[<Paragraph children=[<RawText children=('The Commission is empowered to adopt delegated acts in accordance with '\n 'Article 97 in order to amend Annex V by updating the content of the EU '\n 'declaration of conformity set out in that Annex, in order to introduce '\n 'elements that become necessary  in  light  of  technical  progress.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_63",
    "chunk_content": "CE marking\n[<Paragraph children=[<RawText children=('The CE marking shall be subject  to the general principles  set out  in  '\n 'Article  30  of  Regulation  (EC)  No  765/2008.')>]>]\n[<Paragraph children=[<RawText children=('For high-risk AI systems provided digitally, a digital CE marking shall be '\n 'used, only if it can easily be accessed via the interface  from which that '\n 'system is accessed or  via an easily accessible machine-readable code or '\n 'other electronic means.')>]>]\n[<Paragraph children=[<RawText children=('The CE marking shall be affixed visibly, legibly and indelibly for high-risk '\n 'AI systems. Where that is not possible or not  warranted  on  account  of  '\n 'the  nature  of  the  high-risk  AI  system,  it  shall  be  affixed  to  '\n 'the  packaging  or  to  the accompanying documentation, as appropriate.')>]>]\n[<Paragraph children=[<RawText children=('Where applicable, the CE marking shall be followed by the identification '\n 'number of the notified body responsible for the conformity assessment '\n 'procedures set out in Article 43. The identification number of the notified '\n 'body shall be affixed by the body itself or, under its instructions, by the '\n \"provider or by the provider's authorised representative. The identification \"\n 'number  shall  also  be  indicated  in  any  promotional  material  which  '\n 'mentions  that  the  high-risk  AI  system  fulfils  the requirements  for  '\n 'CE  marking.')>]>]\n[<Paragraph children=[<RawText children=('Where high-risk AI systems are subject to other Union law which also '\n 'provides for the affixing of the CE marking, the CE marking shall indicate '\n 'that  the  high-risk  AI  system  also  fulfil  the  requirements  of  that  '\n 'other  law.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_64",
    "chunk_content": "Registration\n[<Paragraph children=[<RawText children=('Before placing on the market or putting into service a high-risk AI system '\n 'listed in Annex III, with the exception of high-risk  AI  systems  referred  '\n 'to  in  point  2  of  Annex  III,  the  provider  or,  where  applicable,  '\n 'the  authorised  representative shall  register  themselves  and  their  '\n 'system  in  the  EU  database  referred  to  in  Article  71.')>]>]\n[<Paragraph children=[<RawText children=('Before placing on the market or putting into service an AI system for which '\n 'the provider has concluded that it is not high-risk  according  to  Article  '\n '6(3),  that  provider  or,  where  applicable,  the  authorised  '\n 'representative  shall  register themselves  and  that  system  in  the  EU  '\n 'database  referred  to  in  Article  71.')>]>]\n[<Paragraph children=[<RawText children=('Before  putting  into  service  or  using  a  high-risk  AI  system  listed  '\n 'in  Annex  III,  with  the  exception  of  high-risk  AI systems listed in '\n 'point 2 of Annex III, deployers that are public authorities, Union '\n 'institutions, bodies, offices or agencies or persons acting on their behalf '\n 'shall register themselves, select the system and register its use in the EU '\n 'database referred to in  Article  71.')>]>]\n[<Paragraph children=[<RawText children=('For  high-risk  AI  systems  referred  to  in  points  1,  6  and  7  of  '\n 'Annex  III,  in  the  areas  of  law  enforcement,  migration, asylum  and  '\n 'border  control  management,  the  registration  referred  to  in  '\n 'paragraphs  1,  2  and  3  of  this  Article  shall  be  in a secure '\n 'non-public section of the EU database referred to in Article 71 and shall '\n 'include only the following information, as applicable,  referred  to  in:')>]>]\n(a) Section  A,  points  1  to  10,  of  Annex  VIII,  with  the  exception  of  points  6,  8  and  9;\n(b) Section  B,  points  1  to  5,  and  points  8  and  9  of  Annex  VIII;\n(c) Section  C,  points  1  to  3,  of  Annex  VIII;\n(d) points  1,  2,  3  and  5,  of  Annex  IX.\nOnly  the  Commission  and  national  authorities  referred  to  in  Article  74(8)  shall  have  access  to  the  respective  restricted sections  of  the  EU  database  listed  in  the  first  subparagraph  of  this  paragraph.\n[<Paragraph children=[<RawText children=('High-risk  AI  systems  referred  to  in  point  2  of  Annex  III  shall  '\n 'be  registered  at  national  level.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_65",
    "chunk_content": "Transparency obligations for  providers and deployers of certain AI systems\n[<Paragraph children=[<RawText children=('Providers shall ensure that AI systems intended to interact directly with '\n 'natural persons are designed and developed in such  a  way  that  the  '\n 'natural  persons  concerned  are  informed  that  they  are  interacting  '\n 'with  an  AI  system,  unless  this  is obvious from the point of  view of '\n 'a  natural  person who  is  reasonably  well-informed,  observant  and  '\n 'circumspect,  taking into account the circumstances and the context of use. '\n 'This obligation shall not apply to AI systems authorised by law to detect, '\n 'prevent, investigate or prosecute criminal offences, subject to appropriate '\n 'safeguards for the rights and freedoms of third  parties,  unless  those  '\n 'systems  are  available  for  the  public  to  report  a  criminal  offence.')>]>]\n[<Paragraph children=[<RawText children=('Providers  of  AI  systems,  including  general-purpose  AI  systems,  '\n 'generating  synthetic  audio,  image,  video  or  text content,  shall  '\n 'ensure  that  the  outputs  of  the  AI  system  are  marked  in  a  '\n 'machine-readable  format  and  detectable  as artificially generated or '\n 'manipulated. Providers shall ensure their technical solutions are effective, '\n 'interoperable, robust and reliable as far as this is technically feasible, '\n 'taking into account the specificities and limitations of various types of '\n 'content, the  costs  of  implementation  and  the  generally  acknowledged  '\n 'state  of  the  art,  as  may  be  reflected  in  relevant  technical '\n 'standards. This obligation shall not apply to the extent the AI systems '\n 'perform an assistive function for standard editing or do not substantially '\n 'alter  the input data provided by the deployer or the semantics thereof, or '\n 'where authorised by law to detect,  prevent,  investigate  or  prosecute  '\n 'criminal  offences.')>]>]\n[<Paragraph children=[<RawText children=('Deployers  of  an  emotion  recognition  system  or  a  biometric  '\n 'categorisation  system  shall  inform  the  natural  persons exposed thereto '\n 'of  the  operation  of  the  system,  and  shall  process  the  personal  '\n 'data  in  accordance  with  Regulations  (EU) 2016/679 and (EU) 2018/1725 '\n 'and Directive (EU) 2016/680, as applicable. This obligation shall not apply '\n 'to AI systems used  for  biometric  categorisation  and  emotion  '\n 'recognition,  which  are  permitted  by  law  to  detect,  prevent  or  '\n 'investigate criminal  offences,  subject  to  appropriate  safeguards  for  '\n 'the  rights  and  freedoms  of  third  parties,  and  in  accordance  with '\n 'Union law.')>]>]\n[<Paragraph children=[<RawText children=('Deployers of an AI system that generates or manipulates image, audio or '\n 'video content constituting a deep fake, shall disclose  that  the  content  '\n 'has  been  artificially  generated  or  manipulated.  This  obligation  '\n 'shall  not  apply  where  the  use  is authorised by law to detect, prevent, '\n 'investigate or prosecute criminal offence. Where the content forms part of '\n 'an evidently artistic, creative, satirical, fictional or analogous work or '\n 'programme, the transparency obligations set out in this paragraph are '\n 'limited to disclosure of the existence of such generated or manipulated '\n 'content in an appropriate manner that does not hamper  the  display or  '\n 'enjoyment of  the  work.')>]>]\nDeployers of an AI system that generates or manipulates text which is published with the purpose of informing the public on matters of public interest shall disclose that the text has been artificially generated or manipulated. This obligation shall not  apply  where  the  use  is  authorised  by  law  to  detect,  prevent,  investigate  or  prosecute  criminal  offences  or  where  the AI-generated  content  has  undergone  a  process  of  human  review  or  editorial  control  and  where  a  natural  or  legal  person holds  editorial  responsibility  for  the  publication  of  the  content.\n[<Paragraph children=[<RawText children=('The information referred to in paragraphs 1 to 4 shall be provided to the '\n 'natural persons concerned in a clear and distinguishable manner at the '\n 'latest at the time of  the first interaction or exposure. The information '\n 'shall conform to the applicable  accessibility  requirements.')>]>]\n[<Paragraph children=[<RawText children=('Paragraphs  1  to  4  shall  not  affect  the  requirements  and  '\n 'obligations  set  out  in  Chapter  III,  and  shall  be  without prejudice  '\n 'to  other  transparency obligations  laid  down  in  Union  or  national  '\n 'law  for  deployers  of  AI  systems.')>]>]\n[<Paragraph children=[<RawText children=('The AI Office shall encourage and facilitate the drawing up of codes of '\n 'practice at Union level to facilitate the effective implementation  of  the  '\n 'obligations  regarding  the  detection  and  labelling  of  artificially  '\n 'generated  or  manipulated  content. The Commission may adopt implementing '\n 'acts to approve those codes of practice in accordance with the procedure '\n 'laid down in Article 56 (6). If  it  deems  the  code is  not  adequate,  '\n 'the  Commission  may adopt an implementing act  specifying common rules  '\n 'for  the  implementation  of  those  obligations  in  accordance  with  the  '\n 'examination  procedure  laid  down  in Article  98(2).')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_66",
    "chunk_content": "Classification of  general-purpose  AI  models as general-purpose AI models with systemic risk\n[<Paragraph children=[<RawText children=('A general-purpose AI model shall be classified as a general-purpose AI model '\n 'with systemic risk if it meets any of the following  conditions:')>]>]\n(a) it  has  high  impact  capabilities  evaluated  on  the  basis  of  appropriate  technical  tools  and  methodologies,  including indicators  and  benchmarks;\n(b) based  on  a  decision  of  the  Commission, ex  officio or  following  a  qualified  alert  from  the  scientific  panel,  it  has capabilities  or  an  impact  equivalent  to  those  set  out  in  point  (a)  having  regard  to  the  criteria  set  out  in  Annex  XIII.\n[<Paragraph children=[<RawText children=('A general-purpose AI model shall be presumed to have high impact '\n 'capabilities pursuant to paragraph 1, point (a), when the cumulative  amount '\n 'of  computation  used  for  its  training  measured  in  floating  point  '\n 'operations  is  greater  than 10 25 .')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  shall  adopt  delegated  acts  in  accordance  with  '\n 'Article  97  to  amend  the  thresholds  listed  in paragraphs 1 and 2 of '\n 'this Article, as well as to supplement benchmarks and indicators in light of '\n 'evolving technological developments, such as algorithmic improvements or '\n 'increased hardware efficiency, when necessary, for these thresholds to '\n 'reflect  the  state  of  the  art.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_67",
    "chunk_content": "Procedure\n[<Paragraph children=[<RawText children=('Where a general-purpose AI model meets the condition referred to in Article '\n '51(1), point (a), the relevant provider shall notify the Commission without '\n 'delay and in any event within two weeks after that requirement is met or it '\n 'becomes known  that  it  will  be  met.  That  notification  shall  include  '\n 'the  information  necessary  to  demonstrate  that  the  relevant '\n 'requirement has been met. If the Commission becomes aware of a '\n 'general-purpose AI model presenting systemic risks of which it  has  not  '\n 'been  notified,  it  may  decide  to  designate  it  as  a  model  with  '\n 'systemic  risk.')>]>]\n[<Paragraph children=[<RawText children=('The  provider  of  a  general-purpose  AI  model  that  meets  the  '\n 'condition  referred  to  in  Article  51(1),  point  (a),  may present, with '\n 'its notification, sufficiently substantiated arguments to demonstrate that, '\n 'exceptionally, although it meets that requirement, the general-purpose AI '\n 'model does not present, due to its specific characteristics, systemic risks '\n 'and therefore should  not  be  classified  as  a  general-purpose  AI  '\n 'model  with  systemic  risk.')>]>]\n[<Paragraph children=[<RawText children=('Where  the  Commission  concludes  that  the  arguments  submitted  '\n 'pursuant  to  paragraph  2  are  not  sufficiently substantiated and the '\n 'relevant provider  was not able to demonstrate that the general-purpose AI '\n 'model does not present, due to its specific characteristics, systemic risks, '\n 'it shall reject those arguments, and the general-purpose AI model shall be '\n 'considered  to  be  a  general-purpose  AI  model  with  systemic  risk.')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  may  designate  a  general-purpose  AI  model  as  '\n 'presenting  systemic  risks, ex  officio or  following a qualified alert '\n 'from the scientific panel pursuant to Article 90(1), point (a), on the basis '\n 'of criteria set out in Annex XIII.')>]>]\nThe  Commission is  empowered to adopt  delegated  acts  in  accordance  with  Article  97  in  order  to  amend  Annex  XIII  by specifying  and  updating  the  criteria  set  out  in  that  Annex.\n[<Paragraph children=[<RawText children=('Upon a reasoned request of a provider whose model has been designated as a '\n 'general-purpose AI model with systemic risk pursuant to paragraph 4, the '\n 'Commission shall take the request into account and may decide to reassess '\n 'whether the general-purpose AI model can still be considered to present '\n 'systemic risks on the basis of the criteria set out in Annex XIII. Such a '\n 'request shall contain objective, detailed and new reasons that have arisen '\n 'since the designation decision. Providers may request  reassessment  at  '\n 'the  earliest  six  months  after  the  designation  decision.  Where  the  '\n 'Commission,  following  its reassessment, decides to maintain the '\n 'designation as a general-purpose AI model with systemic risk, providers may '\n 'request reassessment  at  the  earliest  six  months  after  that  decision.')>]>]\n[<Paragraph children=[<RawText children=('The Commission shall ensure that a list of general-purpose AI models with '\n 'systemic risk is published and shall keep that  list  up  to  date,  '\n 'without  prejudice  to  the  need  to  observe  and  protect  intellectual  '\n 'property  rights  and  confidential business  information  or  trade  '\n 'secrets  in  accordance  with  Union  and  national  law.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_68",
    "chunk_content": "Obligations for  providers of general-purpose AI models\n[<Paragraph children=[<RawText children='Providers  of  general-purpose  AI  models  shall:'>]>]\n(a) draw up and keep up-to-date the technical documentation of the model, including its training and testing process and the results of its evaluation, which shall contain, at a minimum, the information set out in Annex XI for the purpose of providing  it,  upon  request,  to  the  AI  Office  and  the  national  competent  authorities;\n(b) draw up, keep up-to-date and make available information and documentation to providers of AI systems who intend to integrate  the  general-purpose  AI  model  into  their  AI  systems.  Without  prejudice  to  the  need  to  observe  and  protect intellectual  property  rights  and  confidential  business  information  or  trade  secrets  in  accordance  with  Union  and national  law,  the  information  and  documentation  shall:\n(i) enable  providers  of  AI  systems  to  have  a  good  understanding  of  the  capabilities  and  limitations  of  the general-purpose AI  model and to comply with their obligations pursuant to this  Regulation;  and\n(ii) contain,  at  a  minimum,  the  elements  set  out  in  Annex  XII;\n(c) put in place a policy to comply with Union law on copyright and related rights, and in particular to identify and comply with,  including  through  state-of-the-art  technologies,  a  reservation  of  rights  expressed  pursuant  to  Article  4(3)  of Directive  (EU)  2019/790;\n(d) draw  up  and  make  publicly  available  a  sufficiently  detailed  summary  about  the  content  used  for  training  of  the general-purpose  AI  model,  according  to  a  template  provided  by  the  AI  Office.\n[<Paragraph children=[<RawText children=('The obligations set out in paragraph 1, points (a) and (b), shall not apply '\n 'to providers of AI models that are released under  a  free  and  '\n 'open-source  licence  that  allows  for  the  access,  usage,  '\n 'modification,  and  distribution  of  the  model,  and whose parameters, '\n 'including the weights, the information on the model architecture, and the '\n 'information on model usage, are  made  publicly  available.  This  '\n 'exception  shall  not  apply  to  general-purpose  AI  models  with  '\n 'systemic  risks.')>]>]\n[<Paragraph children=[<RawText children=('Providers  of  general-purpose  AI  models  shall  cooperate  as  necessary  '\n 'with  the  Commission  and  the  national competent authorities in  the  '\n 'exercise  of  their  competences  and  powers  pursuant  to  this  '\n 'Regulation.')>]>]\n[<Paragraph children=[<RawText children=('Providers  of  general-purpose  AI  models  may  rely  on  codes  of  '\n 'practice  within  the  meaning  of  Article  56  to demonstrate  compliance  '\n 'with  the  obligations  set  out  in  paragraph  1  of  this  Article,  '\n 'until  a  harmonised  standard  is published. Compliance with European '\n 'harmonised standards grants providers the presumption of conformity to the '\n 'extent that  those  standards  cover  those  obligations.  Providers  of  '\n 'general-purpose  AI  models  who  do  not  adhere to an  approved code of '\n 'practice or do not comply with a European harmonised standard shall '\n 'demonstrate alternative adequate means of compliance for  assessment by the  '\n 'Commission.')>]>]\n[<Paragraph children=[<RawText children=('For the purpose of facilitating compliance with Annex XI, in particular '\n 'points 2 (d) and (e) thereof, the Commission is empowered to adopt delegated '\n 'acts  in  accordance  with  Article  97  to  detail  measurement  and  '\n 'calculation  methodologies with  a  view  to  allowing  for  comparable  '\n 'and  verifiable  documentation.')>]>]\n[<Paragraph children=[<RawText children=('The Commission is empowered to adopt delegated acts in accordance with '\n 'Article 97(2) to amend Annexes XI and XII in  light  of  evolving  '\n 'technological  developments.')>]>]\n[<Paragraph children=[<RawText children=('Any  information  or  documentation  obtained  pursuant  to  this  Article,  '\n 'including  trade  secrets,  shall  be  treated  in accordance with the '\n 'confidentiality obligations  set out  in  Article  78.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_69",
    "chunk_content": "Authorised representatives of providers of general-purpose AI models\n[<Paragraph children=[<RawText children=('Prior  to placing a general-purpose AI model on the Union market, providers '\n 'established in third countries shall, by written  mandate,  appoint  an  '\n 'authorised  representative  which is  established  in  the  Union.')>]>]\n[<Paragraph children=[<RawText children=('The provider shall enable its authorised representative to perform the tasks '\n 'specified in the mandate received from the provider.')>]>]\n[<Paragraph children=[<RawText children=('The  authorised  representative  shall  perform  the  tasks  specified  in  '\n 'the  mandate  received  from  the  provider.  It  shall provide  a  copy  '\n 'of  the  mandate  to  the  AI  Office  upon  request,  in  one  of  the  '\n 'official  languages  of  the  institutions  of  the Union.  For  the  '\n 'purposes  of  this  Regulation,  the  mandate  shall  empower  the  '\n 'authorised  representative  to  carry  out  the following  tasks:')>]>]\n(a) verify  that  the  technical  documentation  specified  in  Annex  XI  has  been  drawn  up  and  all  obligations  referred  to  in Article  53  and,  where  applicable,  Article  55  have  been  fulfilled  by  the  provider;\n(b) keep  a  copy  of  the  technical  documentation  specified  in  Annex  XI  at  the  disposal  of  the  AI  Office  and  national competent authorities, for a period of 10 years after the general-purpose AI model has been placed on the market, and the  contact  details  of  the  provider  that  appointed  the  authorised  representative;\n(c) provide the AI Office, upon a reasoned request, with all the information and documentation, including that referred to in  point  (b),  necessary  to  demonstrate  compliance  with  the  obligations  in  this  Chapter;\n(d) cooperate with the AI Office and competent authorities, upon a reasoned request, in any action they take in relation to the general-purpose AI model, including when the model is integrated into AI systems placed on the market or put into service  in  the  Union.\n[<Paragraph children=[<RawText children=('The mandate shall empower the authorised representative to be addressed, in '\n 'addition to or instead of the provider, by the  AI  Office  or  the  '\n 'competent  authorities,  on  all  issues  related  to  ensuring  compliance  '\n 'with  this  Regulation.')>]>]\n[<Paragraph children=[<RawText children=('The authorised representative shall terminate the mandate if it considers or '\n 'has reason to consider the provider to be acting contrary to its obligations '\n 'pursuant to this Regulation. In such a case, it shall also immediately '\n 'inform the AI Office about the  termination  of  the  mandate and  the  '\n 'reasons  therefor.')>]>]\n[<Paragraph children=[<RawText children=('The obligation set out in this Article shall not apply to providers of '\n 'general-purpose AI models that are released under a  free  and  open-source  '\n 'licence  that  allows  for  the  access,  usage,  modification,  and  '\n 'distribution  of  the  model,  and  whose parameters,  including  the  '\n 'weights,  the  information  on  the  model  architecture,  and  the  '\n 'information  on  model  usage,  are made publicly available,  unless  the  '\n 'general-purpose  AI  models  present  systemic  risks.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_70",
    "chunk_content": "Obligations of providers of general-purpose AI models with systemic risk\n[<Paragraph children=[<RawText children=('In addition to the obligations listed in Articles 53 and 54, providers of '\n 'general-purpose AI models with systemic risk shall:')>]>]\n(a) perform model evaluation in accordance with standardised protocols and tools reflecting the state of the art, including conducting and documenting adversarial testing of the model with a view to identifying and mitigating systemic risks;\n(b) assess and mitigate possible systemic risks at Union level, including their sources, that may stem from the development, the  placing  on  the  market,  or  the  use  of  general-purpose  AI  models  with  systemic  risk;\n(c) keep track of, document, and report, without undue delay, to the AI Office and, as appropriate, to national competent authorities,  relevant  information  about  serious  incidents  and  possible  corrective  measures  to  address  them;\n(d) ensure  an  adequate  level  of  cybersecurity  protection  for  the  general-purpose  AI  model  with  systemic  risk  and  the physical  infrastructure  of  the  model.\n[<Paragraph children=[<RawText children=('Providers  of  general-purpose  AI  models  with  systemic  risk  may  rely  '\n 'on  codes  of  practice  within  the  meaning  of Article  56  to  '\n 'demonstrate  compliance  with  the  obligations  set  out  in  paragraph  1  '\n 'of  this  Article,  until  a  harmonised standard is published. Compliance '\n 'with European harmonised standards grants providers the presumption of '\n 'conformity to the extent that those standards cover those obligations. '\n 'Providers of general-purpose AI models with systemic risks who do not  '\n 'adhere  to  an  approved  code  of  practice  or  do  not  comply  with  a  '\n 'European  harmonised  standard  shall  demonstrate alternative  adequate  '\n 'means  of  compliance  for  assessment  by  the  Commission.')>]>]\n[<Paragraph children=[<RawText children=('Any  information  or  documentation  obtained  pursuant  to  this  Article,  '\n 'including  trade  secrets,  shall  be  treated  in accordance with the '\n 'confidentiality obligations  set out  in  Article  78.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_71",
    "chunk_content": "Codes of practice\n[<Paragraph children=[<RawText children=('The AI Office shall encourage and facilitate the drawing up of codes of '\n 'practice at Union level in order to contribute to  the  proper  application  '\n 'of  this  Regulation,  taking  into  account  international  approaches.')>]>]\n[<Paragraph children=[<RawText children=('The AI Office and the Board shall aim to ensure that the codes of practice '\n 'cover at least the obligations provided for in Articles  53  and  55,  '\n 'including  the  following  issues:')>]>]\n(a) the  means to ensure that the information referred to in Article 53(1), points (a) and (b), is kept  up to  date in  light of market and technological developments;\n(b) the  adequate  level  of  detail  for  the  summary  about  the  content  used  for  training;\n(c) the identification of the type and nature of the systemic risks at Union level, including their sources, where appropriate;\n(d) the  measures,  procedures  and  modalities  for  the  assessment  and  management  of  the  systemic  risks  at  Union  level, including  the  documentation  thereof,  which shall  be  proportionate  to  the  risks,  take  into  consideration  their  severity and  probability  and  take  into  account  the  specific  challenges  of  tackling  those  risks  in  light  of  the  possible  ways  in which such risks may emerge and materialise along the AI value chain.\n[<Paragraph children=[<RawText children=('The  AI  Office  may  invite  all  providers  of  general-purpose  AI  '\n 'models,  as  well  as  relevant  national  competent authorities, to '\n 'participate in the drawing-up of codes of practice. Civil society '\n 'organisations, industry, academia and other relevant  stakeholders,  such  '\n 'as  downstream  providers  and  independent  experts,  may  support  the  '\n 'process.')>]>]\n[<Paragraph children=[<RawText children=('The AI Office and the Board shall aim to ensure that the codes of practice '\n 'clearly set out their specific objectives and contain  commitments  or  '\n 'measures,  including  key  performance  indicators  as  appropriate,  to  '\n 'ensure  the  achievement  of those  objectives,  and  that  they  take  due  '\n 'account  of  the  needs  and  interests  of  all  interested  parties,  '\n 'including  affected persons,  at  Union  level.')>]>]\n[<Paragraph children=[<RawText children=('The AI Office shall aim to ensure that participants to the codes of practice '\n 'report  regularly to the AI Office  on  the implementation of  the '\n 'commitments and the measures taken and their outcomes, including as measured '\n 'against the key performance indicators as appropriate. Key performance '\n 'indicators and reporting commitments shall reflect differences in size  and  '\n 'capacity  between  various  participants.')>]>]\n[<Paragraph children=[<RawText children=('The AI Office and the Board shall regularly monitor and evaluate the '\n 'achievement of  the objectives of  the codes of practice by the participants '\n 'and their contribution to the proper application of this Regulation. The AI '\n 'Office and the Board shall  assess  whether  the  codes  of  practice  '\n 'cover  the  obligations  provided  for  in  Articles  53  and  55,  and  '\n 'shall  regularly monitor and evaluate the achievement of their objectives. '\n 'They shall publish their assessment of the adequacy of the codes of  '\n 'practice.')>]>]\nThe Commission may, by way of an implementing act, approve a code of practice and give it a general validity within the Union. That implementing act shall be adopted in accordance with the examination procedure referred to in Article 98(2).\n[<Paragraph children=[<RawText children=('The AI Office may invite all providers of general-purpose AI models to '\n 'adhere to the codes of practice. For providers of general-purpose AI models '\n 'not presenting systemic risks this adherence may be limited to the '\n 'obligations provided for in Article  53,  unless  they  declare  explicitly  '\n 'their  interest  to  join  the  full  code.')>]>]\n[<Paragraph children=[<RawText children=('The AI Office shall, as appropriate, also encourage and facilitate the '\n 'review and adaptation of the codes of practice, in particular  in  light  '\n 'of  emerging  standards.  The  AI  Office  shall  assist  in  the  '\n 'assessment  of  available  standards.')>]>]\n[<Paragraph children=[<RawText children=('Codes of practice shall be ready at the latest by 2 May 2025. The AI Office '\n 'shall take the necessary steps, including inviting  providers  pursuant  to  '\n 'paragraph  7.')>]>]\nIf,  by  2  August  2025,  a  code  of  practice  cannot  be  finalised,  or  if  the  AI  Office  deems  it  is  not  adequate  following  its assessment under paragraph 6 of this Article, the Commission may provide, by means of implementing acts, common rules for the implementation of the obligations provided for in Articles 53 and 55, including the issues set out in paragraph 2 of this Article. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 98(2)."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_72",
    "chunk_content": "AI regulatory sandboxes\n[<Paragraph children=[<RawText children=('Member States shall ensure that their competent authorities establish at '\n 'least one AI regulatory sandbox at national level,  which  shall  be  '\n 'operational  by  2  August  2026.  That  sandbox  may  also  be  '\n 'established  jointly  with  the  competent authorities of other Member '\n 'States. The Commission may provide technical support, advice and tools for '\n 'the establishment and operation  of  AI  regulatory  sandboxes.')>]>]\nThe obligation under  the first  subparagraph may also be fulfilled  by participating in an existing sandbox in so far as that participation provides an  equivalent  level  of  national  coverage  for  the  participating  Member  States.\n[<Paragraph children=[<RawText children=('Additional AI regulatory sandboxes at regional or local level, or '\n 'established jointly with the competent authorities of other  Member States '\n 'may also be  established.')>]>]\n[<Paragraph children=[<RawText children=('The European Data Protection Supervisor may also establish an AI regulatory '\n 'sandbox for Union institutions, bodies, offices  and  agencies,  and  may  '\n 'exercise  the  roles  and  the  tasks  of  national  competent  authorities  '\n 'in  accordance  with  this Chapter.')>]>]\n[<Paragraph children=[<RawText children=('Member  States  shall  ensure  that  the  competent  authorities  referred  '\n 'to  in  paragraphs  1  and  2  allocate  sufficient resources to comply with '\n 'this Article effectively and in a timely manner. Where appropriate, national '\n 'competent authorities shall cooperate with other relevant authorities, and '\n 'may allow for the involvement of other actors within the AI ecosystem. This '\n 'Article shall not affect other regulatory sandboxes established under Union '\n 'or national law. Member States shall ensure an appropriate level of '\n 'cooperation between the authorities supervising those other sandboxes and '\n 'the national competent authorities.')>]>]\n[<Paragraph children=[<RawText children=('AI  regulatory  sandboxes  established  under  paragraph  1  shall  provide  '\n 'for  a  controlled  environment  that  fosters innovation  and  facilitates  '\n 'the  development,  training,  testing  and  validation  of  innovative  AI  '\n 'systems  for  a  limited  time before  their  being  placed  on  the  '\n 'market  or  put  into  service  pursuant  to  a  specific  sandbox  plan  '\n 'agreed  between  the providers  or  prospective  providers  and  the  '\n 'competent  authority.  Such  sandboxes  may  include  testing  in  real  '\n 'world conditions  supervised  therein.')>]>]\n[<Paragraph children=[<RawText children=('Competent  authorities  shall  provide,  as  appropriate,  guidance,  '\n 'supervision  and  support  within  the  AI  regulatory sandbox with a view '\n 'to identifying risks, in particular to fundamental rights, health and '\n 'safety, testing, mitigation measures, and their effectiveness in relation to '\n 'the obligations and requirements of this Regulation and, where relevant, '\n 'other Union and national  law  supervised  within  the  sandbox.')>]>]\n[<Paragraph children=[<RawText children=('Competent authorities shall provide providers and prospective providers '\n 'participating in the AI regulatory sandbox with  guidance  on  regulatory '\n 'expectations  and  how  to  fulfil  the  requirements  and  obligations  '\n 'set  out  in  this  Regulation.')>]>]\nUpon request of  the  provider  or  prospective  provider  of  the  AI  system,  the  competent  authority  shall  provide  a  written proof of  the  activities  successfully  carried  out  in  the  sandbox.  The  competent  authority  shall  also  provide  an  exit  report detailing  the  activities  carried  out  in  the  sandbox  and  the  related  results  and  learning  outcomes.  Providers  may  use  such documentation  to  demonstrate  their  compliance  with  this  Regulation  through  the  conformity  assessment  process  or relevant  market  surveillance  activities.  In  this  regard,  the  exit  reports  and  the  written  proof  provided  by  the  national competent  authority  shall  be  taken  positively  into  account  by  market  surveillance  authorities  and  notified  bodies,  with a  view  to  accelerating  conformity  assessment  procedures  to  a  reasonable  extent.\n[<Paragraph children=[<RawText children=('Subject to the confidentiality provisions in Article 78, and with the '\n 'agreement of the provider or prospective provider, the  Commission  and  '\n 'the  Board  shall  be  authorised  to  access  the  exit  reports  and  '\n 'shall  take  them  into  account,  as appropriate, when exercising their '\n 'tasks under this Regulation. If both the provider or prospective provider '\n 'and the national competent  authority  explicitly  agree,  the  exit  '\n 'report  may  be  made  publicly  available  through  the  single  '\n 'information platform referred  to  in  this  Article.')>]>]\n[<Paragraph children=[<RawText children=('The establishment of AI regulatory sandboxes shall  aim to contribute to '\n 'the  following objectives:')>]>]\n(a) improving legal  certainty  to  achieve  regulatory  compliance  with  this  Regulation  or,  where  relevant,  other  applicable Union and national law;\n(b) supporting  the  sharing  of  best  practices  through  cooperation  with  the  authorities  involved  in  the  AI  regulatory sandbox;\n(c) fostering  innovation  and  competitiveness  and  facilitating  the  development  of  an  AI  ecosystem;\n(d) contributing  to  evidence-based  regulatory  learning;\n(e) facilitating and accelerating access to the Union market for AI systems, in particular when provided by SMEs, including start-ups.\n[<Paragraph children=[<RawText children=('National competent authorities shall ensure that, to the extent the '\n 'innovative AI systems involve the processing of personal data or otherwise '\n 'fall under the supervisory remit of other national authorities or competent '\n 'authorities providing or supporting access to data, the national data '\n 'protection authorities and those other national or competent authorities are '\n 'associated with the operation of the AI regulatory sandbox and involved in '\n 'the supervision of those aspects to the extent of their  respective  tasks  '\n 'and  powers.')>]>]\n[<Paragraph children=[<RawText children=('The  AI  regulatory  sandboxes  shall  not  affect  the  supervisory  or  '\n 'corrective  powers  of  the  competent  authorities supervising the '\n 'sandboxes, including at regional or local level. Any significant risks to '\n 'health and safety and fundamental rights  identified  during  the  '\n 'development  and  testing  of  such  AI  systems  shall  result  in  an  '\n 'adequate  mitigation.  National competent authorities shall have the power '\n 'to temporarily or permanently suspend the testing process, or the '\n 'participation in  the  sandbox  if  no  effective  mitigation  is  '\n 'possible,  and  shall  inform  the  AI  Office  of  such  decision.  '\n 'National  competent authorities  shall  exercise  their  supervisory  '\n 'powers  within  the  limits  of  the  relevant  law,  using  their  '\n 'discretionary  powers when implementing legal provisions in respect of a '\n 'specific AI regulatory sandbox project, with the objective of supporting '\n 'innovation  in  AI  in  the  Union.')>]>]\n[<Paragraph children=[<RawText children=('Providers and prospective providers participating in the AI regulatory '\n 'sandbox shall remain liable under applicable Union and national liability '\n 'law for any damage inflicted on third parties as a result of the '\n 'experimentation taking place in the sandbox. However, provided that the '\n 'prospective providers observe the specific plan and the terms and conditions '\n 'for their participation and follow in good faith the guidance given by the '\n 'national competent authority, no administrative fines shall be imposed by '\n 'the authorities for infringements of this Regulation. Where other competent '\n 'authorities responsible for other  Union  and  national  law  were  '\n 'actively  involved  in  the  supervision  of  the  AI  system  in  the  '\n 'sandbox  and  provided guidance for  compliance, no administrative  fines  '\n 'shall  be  imposed  regarding  that  law.')>]>]\n[<Paragraph children=[<RawText children=('The AI regulatory sandboxes shall be designed and implemented in such a way '\n 'that, where relevant, they facilitate cross-border  cooperation  between  '\n 'national  competent  authorities.')>]>]\n[<Paragraph children=[<RawText children=('National  competent authorities  shall  coordinate their  activities  and  '\n 'cooperate  within  the  framework of  the  Board.')>]>]\n[<Paragraph children=[<RawText children=('National competent authorities shall inform the AI Office and the Board of '\n 'the establishment of a sandbox, and may ask them for support and guidance. '\n 'The AI Office shall make publicly available a list of planned and existing '\n 'sandboxes and keep it  up  to  date  in  order  to  encourage  more  '\n 'interaction  in  the  AI  regulatory  sandboxes  and  cross-border  '\n 'cooperation.')>]>]\n[<Paragraph children=[<RawText children=('National competent authorities shall submit annual reports to the AI Office '\n 'and to the Board, from one year after the  establishment  of  the  AI  '\n 'regulatory  sandbox  and  every  year  thereafter  until  its  termination,  '\n 'and  a  final  report.  Those reports  shall  provide  information  on  the  '\n 'progress  and  results  of  the  implementation  of  those  sandboxes,  '\n 'including  best practices, incidents, lessons learnt and recommendations on '\n 'their setup and, where relevant, on the application and possible revision  '\n 'of  this  Regulation,  including  its  delegated  and  implementing  acts,  '\n 'and  on  the  application  of  other  Union  law supervised by the competent '\n 'authorities within the sandbox. The national competent authorities shall '\n 'make those annual reports  or  abstracts  thereof  available  to  the  '\n 'public,  online.  The  Commission  shall,  where  appropriate,  take  the  '\n 'annual reports  into  account  when  exercising  its  tasks  under  this  '\n 'Regulation.')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  shall  develop  a  single  and  dedicated  interface  '\n 'containing  all  relevant  information  related  to  AI regulatory sandboxes '\n 'to allow stakeholders to interact with AI regulatory sandboxes and to raise '\n 'enquiries with competent authorities,  and  to  seek  non-binding  guidance  '\n 'on  the  conformity  of  innovative  products,  services,  business  models '\n 'embedding AI technologies, in accordance with Article 62(1), point (c). The '\n 'Commission shall proactively coordinate with national  competent  '\n 'authorities,  where  relevant.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_73",
    "chunk_content": "Detailed arrangements for, and functioning of, AI regulatory sandboxes\n[<Paragraph children=[<RawText children=('In  order  to  avoid  fragmentation  across  the  Union,  the  Commission  '\n 'shall  adopt  implementing  acts  specifying  the detailed arrangements for '\n 'the establishment, development, implementation, operation and supervision of '\n 'the AI regulatory sandboxes. The implementing acts shall include  common '\n 'principles  on the following issues:')>]>]\n(a) eligibility  and  selection  criteria  for  participation  in  the  AI  regulatory  sandbox;\n(b) procedures for  the application, participation, monitoring,  exiting from and termination of  the AI regulatory sandbox, including  the  sandbox  plan  and  the  exit  report;\n(c) the  terms  and  conditions  applicable  to  the  participants.\nThose implementing acts shall  be  adopted  in  accordance  with  the  examination procedure  referred  to in  Article  98(2).\n[<Paragraph children=[<RawText children='The implementing acts referred  to in paragraph 1  shall  ensure:'>]>]\n(a) that  AI  regulatory  sandboxes  are  open  to  any  applying  provider  or  prospective  provider  of  an  AI  system  who  fulfils eligibility  and  selection  criteria,  which  shall  be  transparent  and  fair,  and  that  national  competent  authorities  inform applicants  of  their  decision  within  three  months  of  the  application;\n(b) that AI regulatory sandboxes allow broad and equal access and keep up with demand for participation; providers and prospective  providers  may  also  submit  applications  in  partnerships  with  deployers  and  other  relevant  third  parties;\n(c) that  the  detailed  arrangements  for,  and  conditions  concerning  AI  regulatory  sandboxes  support,  to  the  best  extent possible,  flexibility  for  national  competent  authorities  to  establish  and  operate  their  AI  regulatory  sandboxes;\n(d) that  access  to  the  AI  regulatory  sandboxes  is  free  of  charge  for  SMEs,  including  start-ups,  without  prejudice  to exceptional costs  that  national  competent  authorities  may  recover  in  a  fair  and  proportionate  manner;\n(e) that  they  facilitate  providers  and  prospective  providers,  by  means  of  the  learning  outcomes  of  the  AI  regulatory sandboxes, in complying with conformity assessment obligations under  this Regulation and the voluntary application of  the  codes  of  conduct  referred  to  in  Article  95;\n(f) that AI regulatory sandboxes facilitate the involvement of other relevant actors within the AI ecosystem, such as notified bodies  and  standardisation  organisations,  SMEs,  including  start-ups,  enterprises,  innovators,  testing  and  experimentation  facilities,  research  and  experimentation  labs  and  European  Digital  Innovation  Hubs,  centres  of  excellence, individual  researchers,  in  order  to  allow  and  facilitate  cooperation  with  the  public  and  private  sectors;\n(g) that  procedures,  processes  and  administrative  requirements  for application,  selection,  participation  and  exiting  the  AI regulatory  sandbox  are  simple,  easily  intelligible,  and  clearly  communicated  in  order  to  facilitate  the  participation  of SMEs, including start-ups, with limited legal and administrative capacities and are streamlined across the Union, in order to  avoid  fragmentation  and  that  participation  in  an  AI  regulatory  sandbox  established  by  a  Member  State,  or  by  the European Data Protection Supervisor is mutually and uniformly recognised and carries the same legal effects across the Union;\n(h) that participation in the AI regulatory sandbox is limited to a period that is appropriate to the complexity and scale of the  project  and  that  may  be  extended  by  the  national  competent  authority;\n(i) that AI regulatory sandboxes facilitate the development of tools and infrastructure for testing, benchmarking, assessing and  explaining  dimensions  of  AI  systems  relevant  for  regulatory  learning,  such  as  accuracy,  robustness  and cybersecurity,  as  well  as  measures  to  mitigate  risks  to  fundamental  rights  and  society  at  large.\n[<Paragraph children=[<RawText children=('Prospective  providers  in  the  AI  regulatory  sandboxes,  in  particular  '\n 'SMEs  and  start-ups,  shall  be  directed,  where relevant,  to  '\n 'pre-deployment  services  such  as  guidance  on  the  implementation  of  '\n 'this  Regulation,  to  other  value-adding services  such  as  help  with  '\n 'standardisation  documents  and  certification,  testing  and  '\n 'experimentation  facilities,  European Digital  Innovation  Hubs  and  '\n 'centres  of  excellence.')>]>]\n[<Paragraph children=[<RawText children=('Where  national  competent  authorities  consider  authorising  testing  in  '\n 'real  world  conditions  supervised  within  the framework  of  an  AI  '\n 'regulatory  sandbox  to  be  established  under  this  Article,  they  '\n 'shall  specifically  agree  the  terms  and conditions  of  such  testing  '\n 'and,  in  particular,  the  appropriate  safeguards  with  the  '\n 'participants,  with  a  view  to  protecting fundamental rights, health and '\n 'safety. Where appropriate, they shall cooperate with other  national '\n 'competent authorities with  a  view  to  ensuring  consistent  practices  '\n 'across  the  Union.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_74",
    "chunk_content": "Further processing of personal data for developing certain AI systems in the public interest in the AI regulatory sandbox\n[<Paragraph children=[<RawText children=('In  the  AI  regulatory  sandbox,  personal  data  lawfully  collected  for  '\n 'other  purposes  may  be  processed  solely  for  the purpose of developing, '\n 'training and testing certain AI systems in the sandbox when all of the '\n 'following conditions are met:')>]>]\n(a) AI  systems  shall  be  developed  for  safeguarding  substantial  public  interest  by  a  public  authority or  another  natural  or legal  person  and  in  one  or  more  of  the  following  areas:\n(i) public  safety  and  public  health,  including  disease  detection,  diagnosis  prevention,  control  and  treatment  and improvement of health care systems;\n(ii) a high level of protection and improvement of the quality of the environment, protection of biodiversity, protection against  pollution,  green  transition  measures,  climate  change  mitigation  and  adaptation  measures;\n(iii) energy sustainability;\n(iv) safety  and  resilience  of  transport  systems  and  mobility,  critical  infrastructure  and  networks;\n(v) efficiency  and  quality of  public  administration  and  public  services;\n(b) the  data  processed  are  necessary  for  complying  with  one  or  more  of  the  requirements  referred  to  in  Chapter  III, Section  2  where  those  requirements  cannot  effectively  be  fulfilled  by  processing  anonymised,  synthetic  or  other non-personal data;\n(c) there are effective monitoring mechanisms to identify if any high risks to the rights and freedoms of the data subjects, as referred  to  in  Article  35  of  Regulation  (EU)  2016/679  and  in  Article  39  of  Regulation  (EU)  2018/1725,  may  arise during  the  sandbox  experimentation,  as  well  as  response  mechanisms  to  promptly  mitigate  those  risks  and,  where necessary,  stop the  processing;\n(d) any personal data to be processed in the context of  the sandbox are in a functionally separate, isolated and protected data processing environment under the control of the prospective provider and only authorised persons have access to those  data;\n(e) providers  can  further  share  the  originally  collected  data  only  in  accordance  with  Union  data  protection  law;  any personal  data  created  in  the  sandbox  cannot  be  shared  outside  the  sandbox;\n(f) any processing of personal data in the context of the sandbox neither leads to measures or decisions affecting the data subjects  nor  does  it  affect  the  application  of  their  rights  laid  down  in  Union  law  on  the  protection  of  personal  data;\n(g) any  personal  data  processed  in  the  context  of  the  sandbox  are  protected  by  means  of  appropriate  technical  and organisational  measures  and  deleted  once  the  participation  in  the  sandbox  has  terminated  or  the  personal  data  has reached  the  end  of  its  retention  period;\n(h) the logs of the processing of personal data in the context of the sandbox are kept for the duration of the participation in the  sandbox,  unless  provided  otherwise  by  Union  or  national  law;\n(i) a  complete  and  detailed  description  of  the  process  and  rationale  behind  the  training,  testing  and  validation  of  the  AI system  is  kept  together  with  the  testing  results  as  part  of  the  technical  documentation  referred  to  in  Annex  IV;\n(j) a  short  summary of  the  AI  project  developed  in  the  sandbox,  its  objectives  and  expected  results  is  published  on  the website of the competent authorities; this obligation shall not cover sensitive operational data in relation to the activities of  law  enforcement,  border  control,  immigration  or  asylum  authorities.\n[<Paragraph children=[<RawText children=('For  the  purposes of  the  prevention,  investigation, detection or  '\n 'prosecution  of criminal offences  or  the execution of criminal  '\n 'penalties,  including  safeguarding  against  and  preventing  threats  to  '\n 'public  security,  under  the  control  and responsibility of  law '\n 'enforcement authorities, the processing of personal data in AI regulatory '\n 'sandboxes shall be based on a  specific  Union  or  national  law  and  '\n 'subject  to  the  same  cumulative  conditions  as  referred  to  in  '\n 'paragraph  1.')>]>]\n[<Paragraph children=[<RawText children=('Paragraph  1  is  without  prejudice  to  Union  or  national  law  which  '\n 'excludes  processing  of  personal  data  for  other purposes  than  those  '\n 'explicitly  mentioned  in  that  law,  as  well  as  to  Union  or  '\n 'national  law  laying  down  the  basis  for  the processing of personal '\n 'data which is necessary for the purpose of developing, testing or training '\n 'of innovative AI systems or any other legal  basis,  in  compliance  with  '\n 'Union  law  on  the  protection  of  personal  data.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_75",
    "chunk_content": "Testing of high-risk AI systems in real world conditions outside AI regulatory sandboxes\n[<Paragraph children=[<RawText children=('Testing  of  high-risk  AI  systems  in  real  world  conditions  outside  '\n 'AI  regulatory  sandboxes  may  be  conducted  by providers  or  '\n 'prospective  providers  of  high-risk  AI  systems  listed  in  Annex  III,  '\n 'in  accordance  with  this  Article  and  the real-world  testing  plan  '\n 'referred  to  in  this  Article,  without  prejudice  to  the  prohibitions  '\n 'under  Article  5.')>]>]\nThe Commission shall, by means of implementing acts, specify the detailed elements of the real-world testing plan. Those implementing acts shall be  adopted  in  accordance  with  the  examination procedure  referred  to in  Article  98(2).\nThis paragraph shall be without prejudice to Union or national law on the testing in real world conditions of high-risk AI systems  related  to  products  covered  by  Union  harmonisation  legislation  listed  in  Annex  I.\n[<Paragraph children=[<RawText children=('Providers or prospective providers may conduct testing of high-risk AI '\n 'systems referred to in Annex III in real world conditions  at  any  time  '\n 'before  the  placing  on  the  market  or  the  putting  into  service  of  '\n 'the  AI  system  on  their  own  or  in partnership  with  one  or  more  '\n 'deployers  or  prospective  deployers.')>]>]\n[<Paragraph children=[<RawText children=('The testing of high-risk AI systems in real world conditions under this '\n 'Article shall be without prejudice to any ethical review  that  is  '\n 'required  by  Union  or  national  law.')>]>]\n[<Paragraph children=[<RawText children=('Providers or  prospective providers may conduct the testing in real world '\n 'conditions only where all of  the following conditions  are  met:')>]>]\n(a) the provider or prospective provider has drawn up a real-world testing plan and submitted it to the market surveillance authority  in  the  Member  State  where  the  testing  in  real  world  conditions  is  to  be  conducted;\n(b) the market surveillance authority in the Member State where the testing in real world conditions is to be conducted has approved the testing in real world conditions and the real-world testing plan; where the market surveillance authority has not provided an answer within 30 days, the testing in real world conditions and the real-world testing plan shall be understood to have been approved; where national law does not provide for a tacit approval, the testing in real world conditions  shall  remain  subject  to  an  authorisation;\n(c) the provider or prospective provider, with the exception of providers or prospective providers of high-risk AI systems referred  to  in  points  1,  6  and  7  of  Annex  III  in  the  areas  of  law  enforcement,  migration,  asylum  and  border  control management,  and  high-risk  AI  systems  referred  to  in  point  2  of  Annex  III  has  registered  the  testing  in  real  world conditions  in  accordance  with  Article  71(4)  with  a  Union-wide  unique  single  identification  number  and  with  the information specified in Annex IX; the provider or prospective provider of high-risk AI systems referred to in points 1, 6 and 7 of Annex III in the areas of law enforcement, migration, asylum and border control management, has registered the testing in real-world conditions in the secure non-public section of the EU database according to Article 49(4), point (d), with a Union-wide unique single identification number and with the information specified therein; the provider or prospective provider of high-risk AI systems referred to in point 2 of Annex III has registered the testing in real-world conditions  in  accordance  with  Article  49(5);\n(d) the provider or prospective provider conducting the testing in real world conditions is established in the Union or has appointed a legal representative  who  is  established  in  the  Union;\n(e) data  collected  and  processed  for  the  purpose  of  the  testing  in  real  world  conditions  shall  be  transferred  to  third countries  only  provided  that  appropriate  and  applicable  safeguards  under  Union  law are  implemented;\n(f) the  testing  in  real  world  conditions  does  not  last  longer  than  necessary  to  achieve  its  objectives  and  in  any  case  not longer than six months, which may be extended for an additional period of six months, subject to prior notification by the provider or prospective provider to the market surveillance authority, accompanied by an explanation of the need for  such  an  extension;\n(g) the subjects of the testing in real world conditions who are persons belonging to vulnerable groups due to their age or disability,  are  appropriately  protected;\n(h) where a provider or prospective provider organises the testing in real world conditions in cooperation with one or more deployers or prospective deployers, the latter have been informed of all aspects of the testing that are relevant to their decision  to  participate,  and  given  the  relevant  instructions  for  use  of  the  AI  system  referred  to  in  Article  13;  the provider or prospective provider and the deployer or prospective deployer shall conclude an agreement specifying their roles  and  responsibilities  with  a  view  to  ensuring  compliance  with  the  provisions  for  testing  in  real  world  conditions under  this  Regulation  and  under  other  applicable  Union  and  national  law;\n(i) the subjects of the testing in real world conditions have given informed consent in accordance with Article 61, or in the case  of  law  enforcement,  where the  seeking of  informed consent would prevent the AI system from being tested, the testing  itself  and  the  outcome  of  the  testing  in  the  real  world  conditions  shall  not  have  any  negative  effect  on  the subjects,  and  their  personal  data  shall  be  deleted  after  the  test  is  performed;\n(j) the  testing  in  real  world  conditions  is  effectively  overseen  by  the  provider  or  prospective  provider,  as  well  as  by deployers  or  prospective  deployers  through  persons  who  are  suitably  qualified  in  the  relevant  field  and  have  the necessary capacity,  training  and  authority  to  perform  their  tasks;\n(k) the  predictions,  recommendations  or  decisions  of  the  AI  system  can  be  effectively  reversed  and  disregarded.\n[<Paragraph children=[<RawText children=('Any subjects  of  the  testing  in  real  world  conditions,  or  their  '\n 'legally  designated  representative,  as  appropriate,  may, without any '\n 'resulting detriment and without having to provide any justification, '\n 'withdraw from the testing at any time by revoking  their  informed  consent  '\n 'and  may  request  the  immediate  and  permanent  deletion  of  their  '\n 'personal  data.  The withdrawal  of  the  informed  consent  shall  not  '\n 'affect  the  activities  already carried  out.')>]>]\n[<Paragraph children=[<RawText children=('In  accordance  with  Article  75,  Member  States  shall  confer  on  '\n 'their  market  surveillance  authorities  the  powers  of requiring  '\n 'providers  and  prospective  providers  to  provide  information,  of  '\n 'carrying  out  unannounced  remote  or  on-site inspections, and of '\n 'performing checks on the conduct of the testing in real world conditions and '\n 'the related high-risk AI systems.  Market  surveillance  authorities  shall  '\n 'use  those  powers  to  ensure  the  safe  development  of  testing  in  '\n 'real  world conditions.')>]>]\n[<Paragraph children=[<RawText children=('Any serious incident identified in the course of the testing in real world '\n 'conditions shall be reported to the national market surveillance authority '\n 'in accordance with Article 73. The provider or  prospective provider shall '\n 'adopt immediate mitigation measures or, failing that, shall suspend the '\n 'testing in real world conditions until such mitigation takes place, or '\n 'otherwise  terminate  it.  The  provider  or  prospective  provider  shall  '\n 'establish  a  procedure  for  the  prompt  recall  of  the  AI system  upon '\n 'such  termination  of  the  testing  in  real  world  conditions.')>]>]\n[<Paragraph children=[<RawText children=('Providers or prospective providers shall notify the national market '\n 'surveillance authority in the Member State where the  testing  in  real  '\n 'world  conditions  is  to  be  conducted  of  the  suspension  or  '\n 'termination  of  the  testing  in  real  world conditions  and  of  the  '\n 'final  outcomes.')>]>]\n[<Paragraph children=[<RawText children=('The provider or prospective provider shall be liable under applicable Union '\n 'and national liability law for any damage caused in  the  course  of  their  '\n 'testing  in  real  world  conditions.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_76",
    "chunk_content": "Informed consent to participate in testing in real world conditions outside AI regulatory sandboxes\n[<Paragraph children=[<RawText children=('For the purpose of testing in real world conditions under Article 60, '\n 'freely-given informed consent shall be obtained from  the  subjects  of  '\n 'testing  prior  to  their  participation  in  such  testing  and  after  '\n 'their  having  been  duly  informed  with concise,  clear,  relevant,  and  '\n 'understandable  information  regarding:')>]>]\n(a) the nature and objectives of the testing in real world conditions and the possible inconvenience that may be linked to their  participation;\n(b) the conditions under which the testing in real world conditions is to be conducted, including the expected duration of the  subject  or  subjects'  participation;\n(c) their rights, and the guarantees regarding their participation, in particular their right to refuse to participate in, and the right to withdraw from, testing in real world conditions at any time without any resulting detriment and without having to  provide  any  justification;\n(d) the  arrangements  for  requesting  the  reversal  or  the  disregarding  of  the  predictions,  recommendations  or  decisions  of the  AI  system;\n(e) the Union-wide unique single identification number of the testing in real world conditions in accordance with Article 60(4) point (c), and the contact details of the provider or its legal representative from whom further information can be obtained.\n[<Paragraph children=[<RawText children=('The informed consent shall be dated and documented and a copy shall be given '\n 'to the subjects of testing or their legal representative.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_77",
    "chunk_content": "Measures for  providers and deployers, in particular SMEs, including start-ups\n[<Paragraph children=[<RawText children='Member States shall undertake the  following actions:'>]>]\n(a) provide  SMEs,  including  start-ups,  having  a  registered  office  or  a  branch  in  the  Union,  with  priority  access  to  the  AI regulatory  sandboxes,  to  the  extent  that  they  fulfil  the  eligibility  conditions  and  selection  criteria;  the  priority  access shall not preclude other SMEs, including start-ups, other than those referred to in this paragraph from access to the AI regulatory  sandbox,  provided  that  they  also  fulfil  the  eligibility  conditions  and  selection  criteria;\n(b) organise specific awareness raising and training activities on the application of this Regulation tailored to the needs of SMEs including start-ups,  deployers  and,  as  appropriate,  local  public  authorities;\n(c) utilise existing dedicated channels and where appropriate, establish new ones for communication with SMEs including start-ups,  deployers,  other  innovators  and,  as  appropriate,  local  public  authorities  to  provide  advice  and  respond  to queries  about  the  implementation  of  this  Regulation,  including  as  regards  participation  in  AI  regulatory  sandboxes;\n(d) facilitate  the  participation  of  SMEs  and  other  relevant  stakeholders  in  the  standardisation  development  process.\n[<Paragraph children=[<RawText children=('The specific interests and needs of the SME providers, including start-ups, '\n 'shall be taken into account when setting the fees  for  conformity  '\n 'assessment  under  Article  43,  reducing  those  fees  proportionately  to  '\n 'their  size,  market  size  and  other relevant  indicators.')>]>]\n[<Paragraph children=[<RawText children='The AI Office  shall  undertake  the  following actions:'>]>]\n(a) provide  standardised  templates  for  areas  covered  by  this  Regulation,  as  specified  by  the  Board  in  its  request;\n(b) develop and maintain a single information platform providing easy to use information in relation to this Regulation for all  operators  across  the  Union;\n(c) organise appropriate communication campaigns to raise awareness about the obligations arising from this Regulation;\n(d) evaluate  and  promote  the  convergence of  best  practices  in  public  procurement  procedures  in  relation  to  AI  systems."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_78",
    "chunk_content": "Derogations for specific operators\n[<Paragraph children=[<RawText children=('Microenterprises  within  the  meaning  of  Recommendation  2003/361/EC  may '\n 'comply  with  certain  elements  of  the quality  management  system  '\n 'required  by  Article  17  of  this  Regulation  in  a  simplified  manner,  '\n 'provided  that  they  do  not have  partner  enterprises  or  linked  '\n 'enterprises  within  the  meaning  of  that  Recommendation.  For  that  '\n 'purpose,  the Commission shall develop guidelines on the elements of the '\n 'quality management system which may be complied with in a  simplified  '\n 'manner  considering  the  needs  of  microenterprises,  without  affecting  '\n 'the  level  of  protection  or  the  need  for compliance with the '\n 'requirements in  respect of  high-risk  AI  systems.')>]>]\n[<Paragraph children=[<RawText children=('Paragraph  1  of  this  Article  shall  not  be  interpreted  as  exempting  '\n 'those  operators  from  fulfilling  any  other requirements or obligations '\n 'laid down in this Regulation, including those established in Articles 9, 10, '\n '11, 12, 13, 14, 15, 72 and 73.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_79",
    "chunk_content": "AI Office\n[<Paragraph children=[<RawText children=('The Commission shall develop Union expertise and capabilities in  the  '\n 'field  of  AI  through  the  AI  Office.')>]>]\n[<Paragraph children=[<RawText children=('Member States shall facilitate  the  tasks  entrusted  to  the  AI  Office,  '\n 'as  reflected  in  this  Regulation.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_80",
    "chunk_content": "Establishment  and structure of  the European Artificial Intelligence Board\n[<Paragraph children=[<RawText children=(\"A European Artificial  Intelligence  Board  (the  'Board')  is  hereby  \"\n 'established.')>]>]\n[<Paragraph children=[<RawText children=('The Board shall be composed of one representative per Member State. The '\n 'European Data Protection Supervisor shall participate as observer. The AI '\n \"Office shall also attend the Board's meetings, without taking part in the \"\n 'votes. Other national and Union authorities, bodies or experts may be '\n 'invited to the meetings by the Board on a case by case basis, where the '\n 'issues  discussed  are  of  relevance  for  them.')>]>]\n[<Paragraph children=[<RawText children=('Each representative  shall  be  designated  by  their  Member  State  for  '\n 'a  period  of  three  years,  renewable  once.')>]>]\n[<Paragraph children=[<RawText children='Member States shall ensure  that  their  representatives  on  the  Board:'>]>]\n(a) have the relevant competences and powers in their Member State so as to contribute actively to the achievement of the Board's  tasks  referred  to  in  Article  66;\n(b) are designated as a single contact point vis-à-vis the Board and, where appropriate, taking into account Member States' needs,  as  a  single  contact  point  for  stakeholders;\n(c) are empowered to facilitate consistency and coordination between national competent authorities in their Member State as regards the implementation of this Regulation, including through the collection of relevant data and information for the  purpose  of  fulfilling  their  tasks  on  the  Board.\n[<Paragraph children=[<RawText children=('The  designated  representatives  of  the  Member  States  shall  adopt  '\n \"the  Board's  rules  of  procedure  by  a  two-thirds majority.  The  rules  \"\n 'of  procedure  shall,  in  particular,  lay  down  procedures  for  the  '\n 'selection  process,  the  duration  of  the mandate  of,  and  '\n 'specifications  of  the  tasks  of,  the  Chair,  detailed  arrangements  '\n \"for  voting,  and  the  organisation  of  the Board's  activities  and  \"\n 'those  of  its  sub-groups.')>]>]\n[<Paragraph children=[<RawText children=('The Board shall establish two standing sub-groups to provide a platform for '\n 'cooperation and exchange among market surveillance authorities and notifying '\n 'authorities about issues related to market surveillance and notified bodies '\n 'respectively.')>]>]\nThe  standing  sub-group  for  market  surveillance  should  act  as  the  administrative  cooperation  group  (ADCO)  for  this Regulation within  the  meaning  of  Article  30  of  Regulation  (EU)  2019/1020.\nThe  Board  may  establish  other  standing  or  temporary  sub-groups  as  appropriate  for  the  purpose  of  examining  specific issues. Where appropriate, representatives of the advisory forum referred to in Article 67 may be invited to such sub-groups or  to  specific  meetings  of  those  subgroups  as  observers.\n[<Paragraph children=[<RawText children=('The Board shall  be  organised  and  operated  so  as  to  safeguard  the  '\n 'objectivity  and  impartiality of  its  activities.')>]>]\n[<Paragraph children=[<RawText children=('The  Board  shall  be  chaired  by  one  of  the  representatives  of  the  '\n 'Member  States.  The  AI  Office  shall  provide  the secretariat for  the '\n 'Board, convene the meetings upon request of the Chair, and prepare the '\n 'agenda in accordance with the tasks  of  the  Board  pursuant  to  this  '\n 'Regulation  and  its  rules  of  procedure.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_81",
    "chunk_content": "Tasks  of  the  Board\nThe Board shall advise and assist the Commission and the Member States in order to facilitate the consistent and effective application  of  this  Regulation.  To  that  end,  the  Board  may  in  particular:\n(a) contribute to the coordination among national competent authorities responsible for the application of this Regulation and, in cooperation with and subject to the agreement of the market surveillance authorities concerned, support joint activities  of  market  surveillance  authorities  referred  to  in  Article  74(11);\n(b) collect  and  share  technical  and  regulatory  expertise  and  best  practices  among  Member  States;\n(c) provide  advice  on  the  implementation  of  this  Regulation,  in  particular  as  regards  the  enforcement  of  rules  on general-purpose  AI  models;\n(d) contribute  to  the  harmonisation  of  administrative  practices  in  the  Member  States,  including  in  relation  to  the derogation  from  the  conformity  assessment  procedures  referred  to  in  Article  46,  the  functioning  of  AI  regulatory sandboxes, and testing  in  real  world  conditions  referred  to  in  Articles  57,  59  and  60;\n(e) at the request of the Commission or on its own initiative, issue recommendations and written opinions on any relevant matters  related  to  the  implementation  of  this  Regulation  and  to  its  consistent  and  effective  application,  including:\n(i) on the development and application of codes of conduct and codes of practice pursuant to this Regulation, as well as  of  the  Commission's  guidelines;\n(ii) the  evaluation  and  review  of  this  Regulation  pursuant  to  Article  112,  including  as  regards  the  serious  incident reports referred to in Article 73, and the functioning of the EU database referred to in Article 71, the preparation of  the  delegated  or  implementing  acts,  and  as  regards  possible  alignments  of  this  Regulation  with  the  Union harmonisation legislation  listed  in  Annex  I;\n(iii) on technical  specifications  or  existing  standards  regarding  the  requirements  set  out  in  Chapter  III,  Section  2;\n(iv) on  the  use  of  harmonised  standards  or  common  specifications  referred  to  in  Articles  40  and  41;\n(v) trends,  such  as  European  global  competitiveness  in  AI,  the  uptake  of  AI  in  the  Union,  and  the  development  of digital  skills;\n(vi) trends  on  the  evolving  typology  of  AI  value  chains,  in  particular  on  the  resulting  implications  in  terms  of accountability;\n(vii) on  the  potential  need  for  amendment  to  Annex  III  in  accordance  with  Article  7,  and  on  the  potential  need  for possible  revision  of  Article  5  pursuant  to  Article  112,  taking  into  account  relevant  available  evidence  and  the latest  developments  in  technology;\n(f) support  the  Commission  in  promoting  AI  literacy,  public  awareness  and  understanding  of  the  benefits,  risks, safeguards  and  rights  and  obligations  in  relation  to  the  use  of  AI  systems;\n(g) facilitate  the  development  of  common  criteria  and  a  shared  understanding  among  market  operators  and  competent authorities of  the  relevant  concepts  provided for  in  this  Regulation,  including  by contributing  to the  development of benchmarks;\n(h) cooperate, as appropriate, with other Union institutions, bodies, offices and agencies, as well as relevant Union expert groups and networks, in particular in the fields of product safety, cybersecurity, competition, digital and media services, financial  services,  consumer  protection,  data  and  fundamental  rights  protection;\n(i) contribute  to  effective  cooperation  with  the  competent  authorities  of  third  countries  and  with  international organisations;\n(j) assist  national  competent  authorities  and  the  Commission  in  developing  the  organisational  and  technical  expertise required for  the implementation of this Regulation, including by contributing to the assessment of training needs for staff  of  Member  States  involved  in  implementing  this  Regulation;\n(k) assist  the  AI  Office  in  supporting  national  competent  authorities  in  the  establishment  and  development  of  AI regulatory  sandboxes,  and  facilitate  cooperation  and  information-sharing  among  AI  regulatory  sandboxes;\n(l) contribute  to,  and  provide  relevant  advice  on,  the  development  of  guidance  documents;\n(m) advise  the  Commission  in  relation  to  international  matters  on  AI;\n(n) provide  opinions  to  the  Commission  on  the  qualified  alerts  regarding  general-purpose  AI  models;\n(o) receive  opinions  by  the  Member  States  on  qualified  alerts  regarding  general-purpose  AI  models,  and  on  national experiences  and  practices  on  the  monitoring  and  enforcement  of  AI  systems,  in  particular  systems  integrating  the general-purpose  AI  models."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_82",
    "chunk_content": "Advisory forum\n[<Paragraph children=[<RawText children=('An advisory forum shall be established to provide technical expertise and '\n 'advise the Board and the Commission, and to  contribute  to  their  tasks  '\n 'under  this  Regulation.')>]>]\n[<Paragraph children=[<RawText children=('The  membership  of  the  advisory  forum  shall  represent  a  balanced  '\n 'selection  of  stakeholders,  including  industry, start-ups,  SMEs,  civil  '\n 'society  and  academia.  The  membership  of  the  advisory  forum  shall  '\n 'be  balanced  with  regard  to commercial and non-commercial interests and, '\n 'within the category of commercial interests, with regard to SMEs and other '\n 'undertakings.')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  shall  appoint  the  members  of  the  advisory  forum,  '\n 'in  accordance  with  the  criteria  set  out  in paragraph 2,  from amongst '\n 'stakeholders with recognised expertise in  the field of  AI.')>]>]\n[<Paragraph children=[<RawText children=('The term of office of the members of the advisory forum shall be two years, '\n 'which may be extended by up to no more than  four  years.')>]>]\n[<Paragraph children=[<RawText children=('The  Fundamental  Rights  Agency,  ENISA,  the  European  Committee  for  '\n 'Standardization  (CEN),  the  European Committee  for  Electrotechnical  '\n 'Standardization  (CENELEC),  and  the  European  Telecommunications  '\n 'Standards  Institute (ETSI)  shall  be  permanent  members  of  the  '\n 'advisory  forum.')>]>]\n[<Paragraph children=[<RawText children=('The  advisory  forum  shall  draw  up  its  rules  of  procedure.  It  '\n 'shall  elect  two  co-chairs  from  among  its  members,  in accordance with '\n 'criteria  set  out  in  paragraph  2.  The  term  of office  of  the  '\n 'co-chairs  shall  be  two years,  renewable  once.')>]>]\n[<Paragraph children=[<RawText children=('The  advisory  forum  shall  hold  meetings  at  least  twice  a  year.  '\n 'The  advisory  forum  may  invite  experts  and  other stakeholders  to  '\n 'its  meetings.')>]>]\n[<Paragraph children=[<RawText children=('The advisory forum may prepare opinions, recommendations and written '\n 'contributions at the request of the Board or the  Commission.')>]>]\n[<Paragraph children=[<RawText children=('The  advisory  forum  may  establish  standing  or  temporary  sub-groups  '\n 'as  appropriate  for  the  purpose  of  examining specific  questions  '\n 'related  to  the  objectives  of  this  Regulation.')>]>]\n[<Paragraph children=[<RawText children=('The advisory forum shall  prepare an  annual  report on  its  activities.  '\n 'That  report  shall  be  made  publicly  available.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_83",
    "chunk_content": "Scientific  panel  of  independent  experts\n[<Paragraph children=[<RawText children=('The Commission shall, by means of an implementing act, make provisions on '\n 'the establishment of a scientific panel of  independent  experts  (the  '\n \"'scientific  panel')  intended  to  support  the  enforcement  activities  \"\n 'under  this  Regulation.  That implementing act shall  be  adopted in  '\n 'accordance  with  the  examination procedure  referred  to in  Article  '\n '98(2).')>]>]\n[<Paragraph children=[<RawText children=('The  scientific  panel  shall  consist  of  experts  selected  by  the  '\n 'Commission  on  the  basis  of  up-to-date  scientific  or technical '\n 'expertise in the field of AI necessary for the tasks set out in paragraph 3, '\n 'and shall be able to demonstrate meeting all  of  the  following  '\n 'conditions:')>]>]\n(a) having  particular  expertise  and  competence  and  scientific  or  technical  expertise  in  the  field  of  AI;\n(b) independence from any provider of AI  systems or general-purpose AI models;\n(c) an  ability  to  carry  out  activities  diligently,  accurately  and  objectively.\nThe Commission, in consultation with the Board, shall determine the number of experts on the panel in accordance with the  required  needs  and  shall  ensure  fair  gender  and  geographical  representation.\n[<Paragraph children=[<RawText children=('The scientific  panel  shall  advise  and  support  the  AI  Office,  in  '\n 'particular  with  regard  to  the  following  tasks:')>]>]\n(a) supporting the implementation and enforcement of this Regulation as regards general-purpose AI models and systems, in  particular  by:\n(i) alerting  the  AI  Office  of  possible  systemic  risks  at  Union  level  of  general-purpose  AI  models,  in  accordance  with Article  90;\n(ii) contributing  to  the  development  of  tools  and  methodologies  for  evaluating  capabilities  of  general-purpose  AI models and systems, including  through benchmarks;\n(iii) providing advice on the  classification  of  general-purpose  AI  models  with  systemic  risk;\n(iv) providing  advice  on  the  classification  of  various  general-purpose  AI  models  and  systems;\n(v) contributing  to  the  development of  tools  and  templates;\n(b) supporting  the  work of  market  surveillance  authorities,  at  their  request;\n(c) supporting cross-border market surveillance activities as referred to in Article 74(11), without prejudice to the powers of  market  surveillance  authorities;\n(d) supporting  the  AI  Office  in  carrying  out  its  duties  in  the  context  of  the  Union  safeguard  procedure  pursuant  to Article  81.\n[<Paragraph children=[<RawText children=('The  experts  on  the  scientific  panel  shall  perform  their  tasks  '\n 'with  impartiality  and  objectivity,  and  shall  ensure  the '\n 'confidentiality of information and data obtained in carrying out their tasks '\n 'and activities. They shall neither seek nor take instructions  from  anyone  '\n 'when  exercising  their  tasks  under  paragraph  3.  Each  expert  shall  '\n 'draw  up  a  declaration  of interests,  which shall be made publicly '\n 'available. The AI Office shall establish systems and procedures to actively '\n 'manage and prevent  potential  conflicts  of  interest.')>]>]\n[<Paragraph children=[<RawText children=('The implementing act referred to in paragraph 1 shall include provisions on '\n 'the conditions, procedures and detailed arrangements for the scientific '\n 'panel and its members to issue alerts, and to request the assistance of the '\n 'AI Office for the performance of  the  tasks  of  the  scientific  panel.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_84",
    "chunk_content": "Access to the pool of experts by the Member States\n[<Paragraph children=[<RawText children=('Member  States  may  call  upon  experts  of  the  scientific  panel  to  '\n 'support  their  enforcement  activities  under  this Regulation.')>]>]\n[<Paragraph children=[<RawText children=('The Member States may be required to pay fees for the advice and support '\n 'provided by the experts. The structure and the level of fees as well as the '\n 'scale and structure of recoverable costs shall be set out in the '\n 'implementing act referred to in Article 68(1), taking into account the '\n 'objectives of the adequate implementation of this Regulation, '\n 'cost-effectiveness and the  necessity of  ensuring  effective  access  to  '\n 'experts  for  all  Member  States.')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  shall  facilitate  timely  access  to  the  experts  by  '\n 'the  Member  States,  as  needed,  and  ensure  that  the combination of '\n 'support activities carried out by Union AI testing support pursuant to '\n 'Article 84 and experts pursuant to this  Article  is  efficiently  '\n 'organised  and  provides  the  best  possible  added  value.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_85",
    "chunk_content": "National competent authorities\nArticle  70"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_86",
    "chunk_content": "Designation of national competent authorities and single points of contact\n[<Paragraph children=[<RawText children=('Each Member State shall establish or designate as national competent '\n 'authorities at least one notifying authority and at  least  one  market  '\n 'surveillance  authority  for  the  purposes  of  this  Regulation.  Those  '\n 'national  competent authorities  shall exercise  their  powers  '\n 'independently,  impartially  and  without  bias  so  as  to  safeguard  the  '\n 'objectivity of  their  activities  and tasks, and to ensure the application '\n 'and implementation of this Regulation. The members of those authorities '\n 'shall refrain from any action incompatible with their duties. Provided that '\n 'those principles are observed, such activities and tasks may be performed by '\n 'one or  more designated authorities,  in  accordance  with  the  '\n 'organisational needs  of  the  Member  State.')>]>]\n[<Paragraph children=[<RawText children=('Member  States  shall  communicate  to  the  Commission  the  identity  of  '\n 'the  notifying  authorities  and  the  market surveillance authorities and '\n 'the tasks of  those authorities, as well as any subsequent changes thereto. '\n 'Member States shall make publicly available information on how competent '\n 'authorities and single points of contact can be contacted, through '\n 'electronic communication means by 2 August 2025. Member States shall '\n 'designate a market surveillance authority to act as the single point of '\n 'contact for this Regulation, and shall notify the Commission of the identity '\n 'of the single point of contact. The Commission shall make a list of  the '\n 'single points  of  contact  publicly  available.')>]>]\n[<Paragraph children=[<RawText children=('Member States shall ensure that their  national competent authorities are '\n 'provided with adequate technical, financial and human resources, and with '\n 'infrastructure to fulfil their tasks effectively under this Regulation. In '\n 'particular, the national competent authorities shall have a sufficient '\n 'number of personnel permanently available whose competences and expertise '\n 'shall  include  an  in-depth  understanding  of  AI  technologies,  data  '\n 'and  data  computing,  personal  data  protection, cybersecurity,  '\n 'fundamental  rights,  health  and  safety  risks  and  knowledge  of  '\n 'existing  standards  and  legal  requirements. Member States shall assess '\n 'and, if necessary, update competence and resource requirements referred to '\n 'in this paragraph on an  annual  basis.')>]>]\n[<Paragraph children=[<RawText children=('National  competent  authorities  shall  take  appropriate  measures  to  '\n 'ensure  an  adequate  level  of  cybersecurity.')>]>]\n[<Paragraph children=[<RawText children=('When  performing  their  tasks,  the  national  competent  authorities  '\n 'shall  act  in  accordance  with  the  confidentiality obligations  set  '\n 'out  in  Article  78.')>]>]\n[<Paragraph children=[<RawText children=('By 2 August 2025, and once every two years thereafter, Member States shall '\n 'report to the Commission on the status of  the  financial  and  human  '\n 'resources  of  the  national  competent  authorities,  with  an  assessment  '\n 'of  their  adequacy.  The Commission shall transmit  that information to '\n 'the  Board for  discussion  and  possible  recommendations.')>]>]\n[<Paragraph children=[<RawText children=('The Commission shall facilitate the exchange  of experience  between  '\n 'national  competent  authorities.')>]>]\n[<Paragraph children=[<RawText children=('National  competent  authorities  may  provide  guidance  and  advice  on  '\n 'the  implementation  of  this  Regulation,  in particular  to SMEs including '\n 'start-ups, taking into account the guidance and advice of the Board and the '\n 'Commission, as appropriate. Whenever national competent authorities intend '\n 'to provide guidance and advice with regard to an AI system in  areas  '\n 'covered  by  other  Union  law,  the  national  competent  authorities  '\n 'under  that  Union  law  shall  be  consulted,  as appropriate.')>]>]\n[<Paragraph children=[<RawText children=('Where  Union  institutions,  bodies,  offices  or  agencies  fall  within  '\n 'the  scope  of  this  Regulation,  the  European  Data Protection '\n 'Supervisor  shall  act  as  the  competent  authority  for  their  '\n 'supervision.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_87",
    "chunk_content": "EU database for high-risk AI systems listed  in Annex III\n[<Paragraph children=[<RawText children=('The  Commission  shall,  in  collaboration  with  the  Member  States,  set  '\n 'up  and  maintain  an  EU  database  containing information  referred  to  '\n 'in  paragraphs  2  and  3  of  this  Article  concerning  high-risk  AI  '\n 'systems  referred  to  in  Article  6(2) which are registered in accordance '\n 'with Articles 49 and 60 and AI systems that are not considered as high-risk '\n 'pursuant to Article  6(3)  and  which  are  registered  in  accordance  '\n 'with  Article  6(4)  and  Article  49.  When  setting  the  functional '\n 'specifications  of  such  database,  the  Commission  shall  consult  the  '\n 'relevant  experts,  and  when  updating  the  functional specifications  of  '\n 'such  database,  the  Commission  shall  consult  the  Board.')>]>]\n[<Paragraph children=[<RawText children=('The  data  listed  in  Sections  A  and  B  of  Annex  VIII  shall  be  '\n 'entered  into  the  EU  database  by  the  provider  or,  where applicable,  '\n 'by  the  authorised  representative.')>]>]\n[<Paragraph children=[<RawText children=('The data listed in Section C of Annex VIII shall be entered into the EU '\n 'database by the deployer who is, or who acts on behalf of,  a  public  '\n 'authority,  agency or  body,  in  accordance  with  Article  49(3)  and  '\n '(4).')>]>]\n[<Paragraph children=[<RawText children=('With the exception of the section referred to in Article 49(4) and Article '\n '60(4), point (c), the information contained in the EU database registered in '\n 'accordance with Article 49 shall be accessible and publicly available in a '\n 'user-friendly manner. The information should be easily navigable and '\n 'machine-readable. The information registered in accordance with Article 60 '\n 'shall be accessible only to market surveillance authorities and the '\n 'Commission, unless the prospective provider or provider has  given  consent  '\n 'for  also  making  the  information  accessible  the  public.')>]>]\n[<Paragraph children=[<RawText children=('The EU database shall contain personal data only in so far as necessary for '\n 'collecting and processing information in accordance with this Regulation. '\n 'That information shall include the names and contact details of natural '\n 'persons who are responsible for registering the system and have the legal '\n 'authority to represent the provider or the deployer, as applicable.')>]>]\n[<Paragraph children=[<RawText children=('The Commission shall be the controller of the EU database. It shall make '\n 'available to providers, prospective providers and deployers adequate '\n 'technical and administrative support. The EU database shall comply with the '\n 'applicable accessibility requirements.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_88",
    "chunk_content": "Post-market monitoring by providers and post-market monitoring plan for high-risk AI systems\n[<Paragraph children=[<RawText children=('Providers  shall  establish  and  document  a  post-market  monitoring  '\n 'system  in  a  manner  that  is  proportionate  to  the nature  of  the  AI  '\n 'technologies  and  the  risks  of  the  high-risk  AI  system.')>]>]\n[<Paragraph children=[<RawText children=('The  post-market  monitoring  system  shall  actively  and  systematically  '\n 'collect,  document  and  analyse  relevant  data which may be provided by '\n 'deployers or which may be collected through other sources on the performance '\n 'of high-risk AI systems throughout their lifetime, and which allow the '\n 'provider to evaluate the continuous compliance of AI systems with the '\n 'requirements set out in Chapter III, Section 2. Where relevant, post-market '\n 'monitoring shall include an analysis of the interaction  with  other  AI  '\n 'systems.  This  obligation  shall  not  cover  sensitive  operational  data  '\n 'of  deployers  which  are law-enforcement authorities.')>]>]\n[<Paragraph children=[<RawText children=('The post-market monitoring system shall be based on a post-market monitoring '\n 'plan. The post-market monitoring plan shall be part of the technical '\n 'documentation referred to in Annex IV. The Commission shall adopt an '\n 'implementing act laying down detailed provisions establishing a template for '\n 'the post-market monitoring plan and the list of elements to be included  in  '\n 'the  plan  by  2  February  2026.  That  implementing  act  shall  be  '\n 'adopted  in  accordance  with  the  examination procedure referred  to in  '\n 'Article  98(2).')>]>]\n[<Paragraph children=[<RawText children=('For  high-risk  AI  systems  covered  by  the  Union  harmonisation  '\n 'legislation  listed  in  Section  A  of  Annex  I,  where a  post-market  '\n 'monitoring  system  and  plan  are  already  established  under  that  '\n 'legislation,  in  order  to  ensure  consistency, avoid  duplications  and  '\n 'minimise  additional  burdens,  providers  shall  have  a  choice  of  '\n 'integrating,  as  appropriate,  the necessary elements described in '\n 'paragraphs 1, 2 and 3 using the template referred in paragraph 3 into '\n 'systems and plans already  existing  under  that  legislation,  provided  '\n 'that  it  achieves  an  equivalent  level  of  protection.')>]>]\nThe first subparagraph of this paragraph shall also apply to high-risk AI systems referred to in point 5 of Annex III placed on the market or put into service by financial institutions that are subject to requirements under Union financial services law regarding their  internal  governance,  arrangements  or  processes."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_89",
    "chunk_content": "Reporting of serious incidents\n[<Paragraph children=[<RawText children=('Providers  of  high-risk  AI  systems  placed  on  the  Union  market  '\n 'shall  report  any  serious  incident  to  the  market surveillance  '\n 'authorities  of  the  Member  States  where  that  incident  occurred.')>]>]\n[<Paragraph children=[<RawText children=('The  report  referred  to  in  paragraph  1  shall  be  made  immediately  '\n 'after  the  provider  has  established  a  causal  link between the AI '\n 'system and the serious incident or the reasonable likelihood of such a link, '\n 'and, in any event, not later than 15 days after  the  provider  or,  where  '\n 'applicable,  the  deployer,  becomes  aware  of  the  serious  incident.')>]>]\nThe period for the reporting referred to in the first subparagraph shall take account of the severity of the serious incident.\n[<Paragraph children=[<RawText children=('Notwithstanding  paragraph  2  of  this  Article,  in  the  event  of  a  '\n 'widespread  infringement  or  a  serious  incident  as defined in Article 3, '\n 'point (49)(b), the report referred to in paragraph 1 of this Article shall '\n 'be provided immediately, and not  later  than  two  days  after  the  '\n 'provider  or,  where  applicable,  the  deployer  becomes  aware  of  that  '\n 'incident.')>]>]\n[<Paragraph children=[<RawText children=('Notwithstanding paragraph 2, in the event of the death of a person, the '\n 'report shall be provided immediately after the provider or the deployer has '\n 'established, or as soon as it suspects, a causal relationship between the '\n 'high-risk AI system and the  serious  incident,  but  not  later  than  10  '\n 'days  after  the  date  on  which  the  provider  or,  where  applicable,  '\n 'the  deployer becomes aware of  the  serious  incident.')>]>]\n[<Paragraph children=[<RawText children=('Where necessary  to  ensure  timely  reporting,  the  provider  or,  where  '\n 'applicable,  the  deployer,  may  submit  an  initial report  that  is  '\n 'incomplete,  followed  by  a  complete  report.')>]>]\n[<Paragraph children=[<RawText children=('Following the reporting of a serious incident pursuant to paragraph 1, the '\n 'provider shall, without delay, perform the necessary investigations in '\n 'relation to the serious incident and the AI system concerned. This shall '\n 'include a risk assessment of  the  incident,  and  corrective  action.')>]>]\nThe provider shall cooperate with the competent authorities, and where relevant with the notified body concerned, during the investigations referred to in the first subparagraph, and shall not perform any investigation which involves altering the AI system concerned in a way which may affect any subsequent evaluation of the causes of the incident, prior to informing the  competent  authorities  of  such  action.\n[<Paragraph children=[<RawText children=('Upon receiving a notification related to a serious incident referred to in '\n 'Article 3, point (49)(c), the relevant market surveillance authority shall '\n 'inform the national public authorities or bodies referred  to in Article '\n '77(1). The Commission shall  develop  dedicated guidance to facilitate '\n 'compliance  with the obligations set out  in paragraph 1  of  this  '\n 'Article.  That guidance shall  be  issued  by  2  August  2025,  and  shall  '\n 'be  assessed  regularly.')>]>]\n[<Paragraph children=[<RawText children=('The market surveillance authority shall take appropriate measures, as '\n 'provided for  in Article 19 of Regulation (EU) 2019/1020, within seven days '\n 'from the date it received the notification referred to in paragraph 1 of '\n 'this Article, and shall follow  the  notification  procedures  as  provided  '\n 'in  that  Regulation.')>]>]\n[<Paragraph children=[<RawText children=('For high-risk AI systems referred to in Annex III that are placed on the '\n 'market or put into service by providers that are subject to Union '\n 'legislative instruments laying down reporting obligations equivalent to '\n 'those set out in this Regulation, the notification  of  serious  incidents  '\n 'shall  be  limited  to  those  referred  to  in  Article  3,  point  '\n '(49)(c).')>]>]\n[<Paragraph children=[<RawText children=('For high-risk AI systems which are safety components of devices, or are '\n 'themselves devices, covered by Regulations (EU) 2017/745 and (EU) 2017/746, '\n 'the notification of serious incidents shall be limited to those referred to '\n 'in Article 3, point  (49)(c)  of  this  Regulation,  and  shall  be  made  '\n 'to  the  national  competent  authority  chosen  for  that  purpose  by  the '\n 'Member States where the incident occurred.')>]>]\n[<Paragraph children=[<RawText children=('National  competent  authorities  shall  immediately  notify  the  '\n 'Commission  of  any  serious  incident,  whether  or  not they have  taken  '\n 'action  on  it,  in  accordance  with  Article  20  of  Regulation  (EU)  '\n '2019/1020.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_90",
    "chunk_content": "Market surveillance and control of AI systems in the Union market\n[<Paragraph children=[<RawText children=('Regulation  (EU)  2019/1020 shall apply to AI systems covered by this '\n 'Regulation. For  the purposes of  the effective enforcement of  this  '\n 'Regulation:')>]>]\n(a) any reference to an economic operator under Regulation (EU) 2019/1020 shall be understood as including all operators identified  in  Article  2(1)  of  this  Regulation;\n(b) any  reference  to  a  product  under  Regulation  (EU)  2019/1020  shall  be  understood  as  including  all  AI  systems  falling within  the  scope  of  this  Regulation.\n[<Paragraph children=[<RawText children=('As  part  of  their  reporting  obligations  under  Article  34(4)  of  '\n 'Regulation  (EU)  2019/1020,  the  market  surveillance authorities  shall  '\n 'report  annually  to  the  Commission  and  relevant  national  competition  '\n 'authorities  any  information identified in the course of market '\n 'surveillance activities that may be of potential interest for the '\n 'application of Union law on competition rules. They shall also annually '\n 'report to the Commission about the use of prohibited practices that occurred '\n 'during that  year  and  about  the  measures  taken.')>]>]\n[<Paragraph children=[<RawText children=('For  high-risk  AI  systems  related  to  products  covered  by  the  Union  '\n 'harmonisation  legislation  listed  in  Section  A  of Annex I, the market '\n 'surveillance authority for the purposes of this Regulation shall be the '\n 'authority responsible for market surveillance  activities  designated  '\n 'under  those  legal  acts.')>]>]\nBy  derogation  from  the  first  subparagraph,  and  in  appropriate  circumstances,  Member  States  may  designate  another relevant  authority  to  act  as  a  market  surveillance  authority,  provided  they  ensure  coordination  with  the  relevant  sectoral market surveillance authorities responsible for  the  enforcement of  the Union harmonisation legislation listed in Annex I.\n[<Paragraph children=[<RawText children=('The procedures referred to in Articles 79 to 83 of this Regulation shall not '\n 'apply to AI systems related to products covered by the  Union  '\n 'harmonisation  legislation  listed  in  section  A of  Annex  I,  where  '\n 'such  legal  acts  already  provide  for procedures  ensuring  an  '\n 'equivalent  level  of  protection  and  having  the  same  objective.  In  '\n 'such  cases,  the  relevant  sectoral procedures shall  apply  instead.')>]>]\n[<Paragraph children=[<RawText children=('Without prejudice to the powers of market surveillance authorities under '\n 'Article 14 of Regulation (EU) 2019/1020, for  the  purpose of ensuring the '\n 'effective enforcement of  this Regulation, market surveillance authorities '\n 'may exercise the powers referred  to in  Article  14(4),  points  (d)  and  '\n '(j),  of  that  Regulation  remotely,  as  appropriate.')>]>]\n[<Paragraph children=[<RawText children=('For high-risk AI systems placed on the market, put into service, or used by '\n 'financial institutions regulated by Union financial  services  law,  the  '\n 'market  surveillance  authority  for  the  purposes  of  this  Regulation  '\n 'shall  be  the  relevant  national authority responsible for the financial '\n 'supervision of those institutions under that legislation in so far as the '\n 'placing on the market,  putting  into  service,  or  the  use  of  the  AI  '\n 'system  is  in  direct  connection  with  the  provision  of  those  '\n 'financial services.')>]>]\n[<Paragraph children=[<RawText children=('By  way  of  derogation  from  paragraph  6,  in  appropriate  '\n 'circumstances,  and  provided  that  coordination  is  ensured, another '\n 'relevant authority may be identified by the Member State as market '\n 'surveillance authority for the purposes of this Regulation.')>]>]\nNational  market  surveillance  authorities  supervising  regulated  credit  institutions  regulated  under  Directive  2013/36/EU, which are participating in the Single Supervisory Mechanism established by Regulation (EU) No 1024/2013, should report, without delay, to the European Central Bank any information identified in the course of their market surveillance activities that  may  be  of  potential  interest  for  the  prudential  supervisory  tasks  of  the  European  Central  Bank  specified  in  that Regulation.\n[<Paragraph children=[<RawText children=('For  high-risk  AI  systems  listed  in  point  1  of  Annex  III  to  this  '\n 'Regulation,  in  so  far  as  the  systems  are  used  for  law enforcement '\n 'purposes, border  management and justice and democracy, and for high-risk AI '\n 'systems listed in points 6, 7 and 8 of Annex III to this Regulation, Member '\n 'States shall designate as market surveillance authorities for the purposes '\n 'of this Regulation either the competent data protection supervisory '\n 'authorities under Regulation (EU) 2016/679 or Directive (EU)  2016/680,  or  '\n 'any  other  authority  designated  pursuant  to  the  same  conditions  '\n 'laid  down  in  Articles  41  to  44  of Directive  (EU)  2016/680.  Market  '\n 'surveillance  activities  shall  in  no  way  affect  the  independence  of  '\n 'judicial  authorities,  or otherwise  interfere  with  their  activities  '\n 'when  acting  in  their  judicial  capacity.')>]>]\n[<Paragraph children=[<RawText children=('Where  Union  institutions,  bodies,  offices  or  agencies  fall  within  '\n 'the  scope  of  this  Regulation,  the  European  Data Protection  '\n 'Supervisor  shall  act  as  their  market  surveillance  authority,  except  '\n 'in  relation  to  the  Court  of  Justice  of  the European Union acting in '\n 'its judicial  capacity.')>]>]\n[<Paragraph children=[<RawText children=('Member States shall facilitate coordination between market surveillance '\n 'authorities designated under this Regulation and other relevant national '\n 'authorities or bodies which supervise the application of Union harmonisation '\n 'legislation listed in  Annex  I,  or  in  other  Union  law,  that  might  '\n 'be  relevant  for  the  high-risk  AI  systems  referred  to  in  Annex  '\n 'III.')>]>]\n[<Paragraph children=[<RawText children=('Market  surveillance  authorities  and  the  Commission  shall  be  able  '\n 'to  propose  joint  activities,  including  joint investigations, to be '\n 'conducted by either market surveillance authorities or market surveillance '\n 'authorities jointly with the Commission,  that  have  the  aim  of  '\n 'promoting  compliance,  identifying  non-compliance,  raising  awareness  '\n 'or  providing guidance in relation to this Regulation with respect to '\n 'specific categories of high-risk AI systems that are found to present a '\n 'serious risk across two or more Member States in accordance with Article 9 '\n 'of Regulation (EU) 2019/1020. The AI Office shall  provide  coordination  '\n 'support  for  joint  investigations.')>]>]\n[<Paragraph children=[<RawText children=('Without prejudice to the powers provided for under Regulation (EU) '\n '2019/1020, and where relevant and limited to what  is  necessary  to  '\n 'fulfil  their  tasks,  the  market  surveillance  authorities  shall  be  '\n 'granted  full  access  by  providers  to  the documentation as well as the '\n 'training, validation  and  testing  data  sets  used  for  the  development  '\n 'of  high-risk  AI  systems, including, where appropriate and subject to '\n 'security safeguards, through application programming interfaces (API) or '\n 'other relevant  technical  means  and  tools  enabling  remote  access.')>]>]\n[<Paragraph children=[<RawText children=('Market surveillance authorities shall be granted access to the source code '\n 'of the high-risk AI system upon a reasoned request  and  only  when  both  '\n 'of  the  following  conditions  are  fulfilled:')>]>]\n(a) access  to  source  code  is  necessary  to  assess  the  conformity of  a  high-risk  AI  system  with  the  requirements  set  out  in Chapter III,  Section  2;  and\n(b) testing  or  auditing  procedures  and  verifications  based  on  the  data  and  documentation  provided  by  the  provider  have been  exhausted  or  proved  insufficient.\n[<Paragraph children=[<RawText children=('Any information or documentation obtained by market surveillance authorities '\n 'shall be treated in accordance with the  confidentiality  obligations  set  '\n 'out  in  Article  78.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_91",
    "chunk_content": "Mutual assistance,  market surveillance and control of general-purpose AI systems\n[<Paragraph children=[<RawText children=('Where an AI system is  based  on  a  general-purpose  AI  model,  and  the  '\n 'model  and  the  system  are  developed  by  the same provider,  the  AI  '\n 'Office  shall  have  powers  to  monitor  and  supervise  compliance  of  '\n 'that  AI  system  with  obligations under this Regulation. To carry out its '\n 'monitoring and supervision tasks, the AI Office shall have all the powers of '\n 'a market surveillance  authority  provided  for  in  this  Section  and  '\n 'Regulation  (EU)  2019/1020.')>]>]\n[<Paragraph children=[<RawText children=('Where the relevant market surveillance authorities have sufficient reason to '\n 'consider general-purpose AI systems that can be used directly  by  '\n 'deployers  for  at  least one  purpose  that  is  classified  as  high-risk  '\n 'pursuant  to  this  Regulation  to  be non-compliant  with  the  '\n 'requirements  laid  down  in  this  Regulation,  they  shall  cooperate  '\n 'with  the  AI  Office  to  carry  out compliance evaluations, and shall  '\n 'inform  the  Board  and  other  market surveillance  authorities  '\n 'accordingly.')>]>]\n[<Paragraph children=[<RawText children=('Where a market surveillance authority is unable to conclude its '\n 'investigation of the high-risk AI system because of its inability to access '\n 'certain information related to the general-purpose AI model despite having '\n 'made all appropriate efforts to obtain that information, it may submit a '\n 'reasoned request to the AI Office, by which access to that information shall '\n 'be enforced. In that case, the AI Office shall supply to the applicant '\n 'authority without delay, and in any event within 30 days, any  information  '\n 'that  the  AI  Office  considers  to  be  relevant  in  order  to  '\n 'establish  whether  a  high-risk  AI  system  is non-compliant.  Market  '\n 'surveillance  authorities  shall  safeguard  the  confidentiality  of  the  '\n 'information  that  they  obtain  in accordance with Article  78  of  this  '\n 'Regulation.  The  procedure  provided  for  in  Chapter  VI  of  Regulation  '\n '(EU)  2019/1020 shall  apply mutatis  mutandis .')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_92",
    "chunk_content": "Supervision of  testing  in  real  world  conditions  by market surveillance  authorities\n[<Paragraph children=[<RawText children=('Market surveillance authorities shall have competences and powers to ensure '\n 'that testing in real world conditions is in accordance with this  '\n 'Regulation.')>]>]\n[<Paragraph children=[<RawText children=('Where  testing  in  real  world  conditions  is  conducted  for  AI  '\n 'systems  that  are  supervised  within  an  AI  regulatory sandbox under '\n 'Article 58, the market surveillance authorities shall verify the compliance '\n 'with Article 60 as part of  their supervisory  role  for  the  AI  '\n 'regulatory  sandbox.  Those  authorities  may,  as  appropriate,  allow  '\n 'the  testing  in  real  world conditions  to be  conducted  by the  '\n 'provider  or  prospective  provider,  in  derogation  from  the  conditions  '\n 'set out  in  Article 60(4),  points  (f)  and  (g).')>]>]\n[<Paragraph children=[<RawText children=('Where a market surveillance authority has been informed by the prospective '\n 'provider, the provider or any third party of a serious incident or has other '\n 'grounds for considering that the conditions set out in Articles 60 and 61 '\n 'are not met, it may take either  of  the  following  decisions  on  its  '\n 'territory,  as  appropriate:')>]>]\n(a) to  suspend  or  terminate  the  testing  in  real  world  conditions;\n(b) to require  the  provider  or  prospective  provider and  the deployer or  prospective deployer  to modify  any aspect of  the testing  in  real  world  conditions.\n[<Paragraph children=[<RawText children=('Where a market surveillance authority has taken a decision referred to in '\n 'paragraph 3 of this Article, or has issued an objection within the meaning '\n 'of Article 60(4), point (b), the decision or  the objection shall indicate '\n 'the grounds therefor and how the provider or  prospective  provider  can  '\n 'challenge  the  decision  or  objection.')>]>]\n[<Paragraph children=[<RawText children=('Where  applicable,  where  a  market  surveillance  authority  has  taken  '\n 'a  decision  referred  to  in  paragraph  3,  it  shall communicate the '\n 'grounds therefor  to the market surveillance authorities of other Member '\n 'States in which the AI system has  been  tested  in  accordance  with  the  '\n 'testing  plan.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_93",
    "chunk_content": "Powers of authorities protecting fundamental rights\n[<Paragraph children=[<RawText children=('National  public  authorities  or  bodies  which  supervise  or  enforce  '\n 'the  respect  of  obligations  under  Union  law protecting  fundamental  '\n 'rights,  including  the  right  to  non-discrimination,  in  relation  to  '\n 'the  use  of  high-risk  AI  systems referred  to  in  Annex  III  shall  '\n 'have  the  power  to  request  and  access  any  documentation  created  or  '\n 'maintained  under  this Regulation in accessible language and format when '\n 'access to that documentation is necessary for effectively fulfilling their '\n 'mandates within the limits of their jurisdiction. The relevant public '\n 'authority or body shall inform the market surveillance authority of  the  '\n 'Member  State  concerned  of any such  request.')>]>]\n[<Paragraph children=[<RawText children=('By 2 November 2024, each Member State shall identify the public authorities '\n 'or bodies referred to in paragraph 1 and make a  list  of  them  publicly  '\n 'available.  Member  States  shall  notify  the  list  to  the  Commission  '\n 'and  to  the  other  Member States,  and  shall  keep  the  list  up  to  '\n 'date.')>]>]\n[<Paragraph children=[<RawText children=('Where  the  documentation  referred  to  in  paragraph  1  is  insufficient  '\n 'to  ascertain  whether  an  infringement  of obligations  under  Union  law  '\n 'protecting  fundamental  rights  has  occurred,  the  public  authority  or  '\n 'body  referred  to  in paragraph  1  may  make  a  reasoned  request  to  '\n 'the  market  surveillance  authority,  to  organise  testing  of  the  '\n 'high-risk  AI system through technical means. The market surveillance '\n 'authority shall organise the testing with the close involvement of the  '\n 'requesting  public  authority or  body  within  a  reasonable  time  '\n 'following  the  request.')>]>]\n[<Paragraph children=[<RawText children=('Any information or documentation obtained by the national public authorities '\n 'or bodies referred to in paragraph 1 of this Article pursuant to this '\n 'Article shall be treated in accordance with the confidentiality obligations '\n 'set out in Article 78.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_94",
    "chunk_content": "Confidentiality\n[<Paragraph children=[<RawText children=('The Commission, market surveillance authorities and notified bodies and any '\n 'other natural or legal person involved in  the  application  of  this  '\n 'Regulation  shall,  in  accordance  with  Union  or  national  law,  '\n 'respect  the  confidentiality  of information and data obtained  in  '\n 'carrying  out  their  tasks  and  activities  in  such  a  manner  as  to  '\n 'protect,  in  particular:')>]>]\n(a) the  intellectual  property  rights  and  confidential  business  information  or  trade  secrets  of  a  natural  or  legal  person, including  source  code,  except  in  the  cases  referred  to  in  Article  5  of  Directive  (EU)  2016/943  of  the  European Parliament  and  of  the  Council ( 57 );\n(b) the effective implementation of  this Regulation, in particular  for  the purposes of  inspections, investigations or audits;\n(c) public  and  national  security  interests;\n(d) the  conduct of  criminal  or  administrative  proceedings;\n(e) information classified  pursuant  to  Union  or  national  law.\n[<Paragraph children=[<RawText children=('The authorities involved in the application of this Regulation pursuant to '\n 'paragraph 1 shall request only data that is strictly necessary for the '\n 'assessment of the risk posed by AI systems and for the exercise of their '\n 'powers in accordance with this Regulation and with Regulation (EU) '\n '2019/1020. They shall put in place adequate and effective cybersecurity '\n 'measures to protect the security and confidentiality of the information and '\n 'data obtained, and shall delete the data collected as soon as it  is  no  '\n 'longer  needed for  the purpose for  which it was obtained, in accordance '\n 'with applicable Union or  national law.')>]>]\n[<Paragraph children=[<RawText children=('Without  prejudice  to  paragraphs  1  and  2,  information  exchanged  on  '\n 'a  confidential  basis  between  the  national competent authorities or '\n 'between national competent authorities and the Commission shall not be '\n 'disclosed without prior consultation  of  the  originating  national  '\n 'competent  authority  and  the  deployer  when  high-risk  AI  systems  '\n 'referred  to  in point 1, 6 or 7 of Annex III are used by law enforcement, '\n 'border control, immigration or asylum authorities and when such disclosure  '\n 'would  jeopardise  public  and  national  security  interests.  This  '\n 'exchange  of  information  shall  not  cover  sensitive operational  data  '\n 'in  relation  to  the  activities  of  law  enforcement,  border  control,  '\n 'immigration  or  asylum  authorities.')>]>]\nWhen the law enforcement, immigration or asylum authorities are providers of high-risk AI systems referred to in point 1, 6  or  7  of  Annex  III,  the  technical  documentation  referred  to  in  Annex  IV  shall  remain  within  the  premises  of  those authorities.  Those  authorities  shall  ensure  that  the  market  surveillance  authorities  referred  to  in  Article  74(8)  and  (9),  as applicable,  can,  upon  request,  immediately  access  the  documentation  or  obtain  a  copy  thereof.  Only  staff  of  the  market surveillance authority holding the appropriate level of security clearance shall be allowed to access that documentation or any copy thereof.\n[<Paragraph children=[<RawText children=('Paragraphs 1, 2 and 3 shall not affect the rights or obligations of the '\n 'Commission, Member States and their relevant authorities,  as  well  as  '\n 'those  of  notified  bodies,  with  regard  to  the  exchange  of  '\n 'information  and  the  dissemination  of warnings, including in the context '\n 'of cross-border cooperation, nor shall they affect the obligations of the '\n 'parties concerned to  provide  information  under  criminal  law of  the  '\n 'Member  States.')>]>]\n[<Paragraph children=[<RawText children=('The Commission and Member States may exchange, where necessary and in '\n 'accordance with relevant provisions of international and trade agreements, '\n 'confidential information with regulatory authorities of third countries with '\n 'which they have  concluded  bilateral  or  multilateral  confidentiality  '\n 'arrangements  guaranteeing  an  adequate  level  of  confidentiality.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_95",
    "chunk_content": "Procedure at national level for dealing with AI systems  presenting a risk\n[<Paragraph children=[<RawText children=(\"AI systems presenting a risk shall be understood as a 'product presenting a \"\n \"risk' as defined in Article 3, point 19 of Regulation  (EU)  2019/1020,  in  \"\n 'so  far  as  they  present  risks  to  the  health  or  safety,  or  to  '\n 'fundamental  rights,  of  persons.')>]>]\n[<Paragraph children=[<RawText children=('Where the market surveillance authority of a Member State has sufficient '\n 'reason to consider an AI system to present a risk as referred to in '\n 'paragraph 1 of this Article, it shall carry out an evaluation of the AI '\n 'system concerned in respect of its compliance with all the requirements and '\n 'obligations laid down in this Regulation. Particular attention shall be '\n 'given to AI systems presenting a risk to vulnerable groups. Where risks to '\n 'fundamental rights are identified, the market surveillance authority shall '\n 'also inform and fully cooperate with the relevant national public '\n 'authorities or bodies referred to in Article 77(1).  The  relevant  '\n 'operators  shall  cooperate  as  necessary  with  the  market  surveillance  '\n 'authority  and  with  the  other national  public  authorities  or  bodies  '\n 'referred  to  in  Article  77(1).')>]>]\n( 57 ) Directive (EU) 2016/943 of the European Parliament and of the Council of 8 June 2016 on the protection of undisclosed know-how and business information  (trade  secrets)  against  their  unlawful  acquisition,  use  and  disclosure  (OJ  L  157,  15.6.2016,  p.  1).\nWhere,  in  the  course  of  that  evaluation,  the  market  surveillance  authority  or,  where  applicable  the  market  surveillance authority in cooperation with the national public authority referred to in Article 77(1), finds that the AI system does not comply with the requirements and obligations laid down in this Regulation, it shall without undue delay require the relevant operator to take all appropriate corrective actions to bring the AI system into compliance, to withdraw the AI system from the  market,  or  to  recall  it  within  a  period  the  market  surveillance  authority  may  prescribe,  and  in  any  event  within  the shorter  of  15  working  days,  or  as  provided  for  in  the  relevant  Union  harmonisation  legislation.\nThe  market  surveillance  authority  shall  inform  the  relevant  notified  body  accordingly.  Article  18  of  Regulation  (EU) 2019/1020 shall apply to the measures referred to in the  second  subparagraph  of  this  paragraph.\n[<Paragraph children=[<RawText children=('Where the market surveillance authority considers that the non-compliance is '\n 'not restricted to its national territory, it shall inform the Commission and '\n 'the other Member States without undue delay of the results of the evaluation '\n 'and of the actions  which it  has  required  the  operator  to  take.')>]>]\n[<Paragraph children=[<RawText children=('The operator shall ensure that all appropriate corrective action is taken in '\n 'respect of all the AI systems concerned that it  has  made  available  on  '\n 'the  Union  market.')>]>]\n[<Paragraph children=[<RawText children=('Where  the  operator  of  an  AI  system  does  not  take  adequate  '\n 'corrective  action  within  the  period  referred  to  in paragraph 2, the '\n 'market surveillance authority shall take all appropriate provisional '\n \"measures to prohibit or restrict the AI system's  being  made  available  \"\n 'on  its  national  market  or  put  into  service,  to  withdraw  the  '\n 'product  or  the  standalone  AI system  from  that  market  or  to  recall  '\n 'it.  That  authority  shall  without  undue  delay  notify  the  Commission  '\n 'and  the  other Member States of  those  measures.')>]>]\n[<Paragraph children=[<RawText children=('The notification referred to in paragraph 5 shall include all available '\n 'details, in particular  the information necessary for  the  identification  '\n 'of  the non-compliant AI system, the origin of  the AI system and the supply '\n 'chain, the nature of  the non-compliance alleged and the risk involved, the '\n 'nature and duration of the national measures taken and the arguments put  '\n 'forward  by  the  relevant  operator.  In  particular,  the  market  '\n 'surveillance  authorities  shall  indicate  whether  the non-compliance is '\n 'due to one or  more of  the  following:')>]>]\n(a) non-compliance with the prohibition of  the AI  practices  referred  to  in  Article  5;\n(b) a  failure  of  a  high-risk  AI  system  to  meet  requirements  set  out  in  Chapter  III,  Section  2;\n(c) shortcomings  in  the  harmonised  standards  or  common  specifications  referred  to  in  Articles  40  and  41  conferring a  presumption of  conformity;\n(d) non-compliance with Article 50.\n[<Paragraph children=[<RawText children=('The market surveillance  authorities  other  than  the  market  '\n 'surveillance  authority of  the  Member  State  initiating  the procedure '\n 'shall, without undue delay, inform the Commission and the other Member '\n 'States of any measures adopted and of any additional information at their '\n 'disposal relating to the non-compliance of the AI system concerned, and, in '\n 'the event of disagreement  with  the  notified  national  measure,  of  '\n 'their  objections.')>]>]\n[<Paragraph children=[<RawText children=('Where, within three months of receipt of the notification referred to in '\n 'paragraph 5 of this Article, no objection has been raised by either a market '\n 'surveillance authority of a Member State or by the Commission in respect of '\n 'a provisional measure  taken  by  a  market  surveillance  authority  of  '\n 'another  Member  State,  that  measure  shall  be  deemed  justified.  This '\n 'shall be without prejudice to the procedural rights of the concerned '\n 'operator in accordance with Article 18 of Regulation (EU)  2019/1020.  The  '\n 'three-month  period  referred  to  in  this  paragraph  shall  be  reduced  '\n 'to  30  days  in  the  event  of non-compliance with the prohibition of  the '\n 'AI  practices  referred  to  in  Article  5  of  this  Regulation.')>]>]\n[<Paragraph children=[<RawText children=('The  market  surveillance  authorities  shall  ensure  that  appropriate  '\n 'restrictive  measures  are  taken  in  respect  of  the product or the AI '\n 'system concerned, such as withdrawal of the product or the AI system from '\n 'their market, without undue delay.')>]>]\nArticle  80"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_96",
    "chunk_content": "Procedure for dealing with AI systems classified by the provider as non-high-risk in application of Annex III\n[<Paragraph children=[<RawText children=('Where a market surveillance authority has sufficient reason to consider that '\n 'an AI system classified by the provider as non-high-risk pursuant to Article '\n '6(3) is indeed high-risk, the market surveillance authority shall carry out '\n 'an evaluation of the AI system concerned in respect of its classification as '\n 'a high-risk AI system based on the conditions set out in Article 6(3)  and  '\n 'the  Commission  guidelines.')>]>]\n[<Paragraph children=[<RawText children=('Where,  in  the  course  of  that  evaluation,  the  market  surveillance  '\n 'authority  finds  that  the  AI  system  concerned  is high-risk, it shall '\n 'without undue delay require the relevant provider to take all necessary '\n 'actions to bring the AI system into compliance with the requirements and '\n 'obligations laid down in this Regulation, as well as take appropriate '\n 'corrective action within  a  period  the  market  surveillance  authority  '\n 'may  prescribe.')>]>]\n[<Paragraph children=[<RawText children=('Where  the  market  surveillance  authority  considers  that  the  use  of  '\n 'the  AI  system  concerned  is  not  restricted  to  its national territory, '\n 'it  shall  inform the  Commission and the other Member States without undue '\n 'delay of  the results of  the evaluation  and  of  the  actions  which  it  '\n 'has  required  the  provider  to  take.')>]>]\n[<Paragraph children=[<RawText children=('The  provider  shall  ensure  that  all  necessary  action  is  taken  to  '\n 'bring  the  AI  system  into  compliance  with  the requirements and '\n 'obligations laid down in this Regulation. Where the provider of an AI system '\n 'concerned does not bring the AI system into compliance with those '\n 'requirements and obligations within the period referred to in paragraph 2 of '\n 'this Article,  the  provider  shall  be  subject  to  fines  in  accordance  '\n 'with  Article  99.')>]>]\n[<Paragraph children=[<RawText children=('The provider shall ensure that all appropriate corrective action is taken in '\n 'respect of all the AI systems concerned that it  has  made  available  on  '\n 'the  Union  market.')>]>]\n[<Paragraph children=[<RawText children=('Where the provider of the AI system concerned does not take adequate '\n 'corrective action within the period referred to in  paragraph  2  of  this  '\n 'Article,  Article  79(5)  to  (9)  shall  apply.')>]>]\n[<Paragraph children=[<RawText children=('Where,  in  the  course  of  the  evaluation  pursuant  to  paragraph  1  '\n 'of  this  Article,  the  market  surveillance  authority establishes that '\n 'the AI system was misclassified by the provider as non-high-risk in order to '\n 'circumvent the application of requirements  in  Chapter  III,  Section  2,  '\n 'the  provider  shall  be  subject  to  fines  in  accordance  with  Article  '\n '99.')>]>]\n[<Paragraph children=[<RawText children=('In exercising their power to monitor the application of this Article, and in '\n 'accordance with Article 11 of Regulation (EU)  2019/1020,  market  '\n 'surveillance  authorities  may  perform  appropriate  checks,  taking  into  '\n 'account  in  particular information stored in the  EU  database  referred  '\n 'to  in  Article  71  of  this  Regulation.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_97",
    "chunk_content": "Union safeguard procedure\n[<Paragraph children=[<RawText children=('Where, within three months of receipt of the notification referred to in '\n 'Article 79(5), or within 30 days in the case of non-compliance  with  the  '\n 'prohibition  of  the  AI  practices  referred  to  in  Article  5,  '\n 'objections  are  raised  by  the  market surveillance  authority  of  a  '\n 'Member  State  to  a  measure  taken  by  another  market  surveillance  '\n 'authority,  or  where  the Commission  considers  the  measure  to  be  '\n 'contrary  to  Union  law,  the  Commission  shall  without  undue  delay  '\n 'enter  into consultation with the market surveillance authority of the '\n 'relevant Member State and the operator or operators, and shall evaluate the '\n 'national measure. On the basis of the results of that evaluation, the '\n 'Commission shall, within six months, or within 60 days in the case of '\n 'non-compliance with the prohibition of the AI practices referred to in '\n 'Article 5, starting from the notification referred to in Article 79(5), '\n 'decide whether the national measure is justified and shall notify its '\n 'decision to the  market  surveillance  authority  of  the  Member  State  '\n 'concerned.  The  Commission  shall  also  inform  all  other  market '\n 'surveillance  authorities  of  its  decision.')>]>]\n[<Paragraph children=[<RawText children=('Where the Commission considers the measure taken by the relevant Member '\n 'State to be justified, all Member States shall  ensure  that  they  take  '\n 'appropriate  restrictive  measures  in  respect  of  the  AI  system  '\n 'concerned,  such  as  requiring  the withdrawal of the AI system from their '\n 'market without undue delay, and shall inform the Commission accordingly. '\n 'Where the Commission considers the national measure to be unjustified, the '\n 'Member State concerned shall withdraw the measure and shall  inform  the  '\n 'Commission  accordingly.')>]>]\n[<Paragraph children=[<RawText children=('Where  the  national  measure  is  considered  justified  and  the  '\n 'non-compliance  of  the  AI  system  is  attributed  to shortcomings in the '\n 'harmonised standards or common specifications referred to in Articles 40 and '\n '41 of this Regulation, the  Commission shall  apply  the  procedure  '\n 'provided  for  in  Article  11  of  Regulation  (EU)  No  1025/2012.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_98",
    "chunk_content": "Compliant AI systems which present a risk\n[<Paragraph children=[<RawText children=('Where,  having  performed  an  evaluation  under  Article  79,  after  '\n 'consulting  the  relevant  national  public  authority referred to in '\n 'Article 77(1), the market surveillance authority of a Member State finds '\n 'that although a high-risk AI system complies with this Regulation, it '\n 'nevertheless presents a risk to the health or safety of persons, to '\n 'fundamental rights, or to other aspects of public interest protection, it '\n 'shall require the relevant operator  to take all appropriate measures to '\n 'ensure that the AI system concerned, when placed on the market or put into '\n 'service, no longer presents that risk without undue delay,  within  a  '\n 'period  it  may  prescribe.')>]>]\n[<Paragraph children=[<RawText children=('The  provider  or  other  relevant  operator  shall  ensure  that  '\n 'corrective  action  is  taken  in  respect  of  all  the  AI  systems '\n 'concerned  that  it  has  made  available  on  the  Union  market  within  '\n 'the  timeline  prescribed  by  the  market  surveillance authority of  the  '\n 'Member  State  referred  to  in  paragraph  1.')>]>]\n[<Paragraph children=[<RawText children=('The  Member  States  shall  immediately  inform  the  Commission  and  the  '\n 'other  Member  States  of  a  finding  under paragraph 1. That information '\n 'shall include all available details, in particular the data necessary for '\n 'the identification of the AI system concerned, the origin and the supply '\n 'chain of the AI system, the nature of the risk involved and the nature and '\n 'duration  of  the  national  measures  taken.')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  shall  without  undue  delay  enter  into  consultation  '\n 'with  the  Member  States  concerned  and  the relevant  operators,  and  '\n 'shall  evaluate  the  national  measures  taken.  On  the  basis  of  the  '\n 'results  of  that  evaluation,  the Commission shall decide whether  the '\n 'measure  is  justified  and,  where  necessary,  propose  other  '\n 'appropriate  measures.')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  shall  immediately communicate  its  decision  to  the  '\n 'Member  States  concerned  and  to  the  relevant operators.  It  shall  '\n 'also  inform  the  other  Member  States.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_99",
    "chunk_content": "Formal non-compliance\n[<Paragraph children=[<RawText children=('Where the market surveillance authority of a Member State makes one of the '\n 'following findings, it shall require the relevant  provider  to  put  an  '\n 'end  to  the  non-compliance  concerned,  within  a  period  it  may  '\n 'prescribe:')>]>]\n(a) the  CE  marking  has  been  affixed  in  violation  of  Article  48;\n(b) the  CE  marking  has  not  been  affixed;\n(c) the  EU  declaration  of  conformity  referred  to  in  Article  47  has  not  been  drawn  up;\n(d) the  EU  declaration  of  conformity  referred  to  in  Article  47  has  not  been  drawn  up  correctly;\n(e) the  registration  in  the  EU  database  referred  to  in  Article  71  has  not  been  carried  out;\n(f) where applicable,  no  authorised  representative  has  been  appointed;\n(g) technical  documentation  is  not  available.\n[<Paragraph children=[<RawText children=('Where the non-compliance referred to in paragraph 1 persists, the market '\n 'surveillance authority of the Member State concerned shall  take  '\n 'appropriate  and  proportionate  measures  to  restrict  or  prohibit  the  '\n 'high-risk  AI  system  being  made available  on  the  market  or  to  '\n 'ensure  that  it  is  recalled  or  withdrawn  from  the  market  without  '\n 'delay.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_100",
    "chunk_content": "Union AI testing support structures\n[<Paragraph children=[<RawText children=('The Commission shall designate one or more Union AI testing support '\n 'structures to perform the tasks listed under Article  21(6)  of  Regulation  '\n '(EU)  2019/1020  in  the  area  of  AI.')>]>]\n[<Paragraph children=[<RawText children=('Without  prejudice  to  the  tasks  referred  to  in  paragraph  1,  Union  '\n 'AI  testing  support  structures  shall  also  provide independent technical '\n 'or scientific advice at the request of the Board, the Commission, or of '\n 'market surveillance authorities.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_101",
    "chunk_content": "Right to lodge a complaint with a market surveillance authority\nWithout prejudice to other administrative or judicial remedies, any natural or legal person having grounds to consider that there  has  been  an  infringement  of  the  provisions  of  this  Regulation  may  submit  complaints  to  the  relevant  market surveillance  authority.\nIn accordance with Regulation (EU) 2019/1020, such complaints shall be taken into account for the purpose of conducting market surveillance activities, and shall be handled in line with the dedicated procedures established therefor by the market surveillance  authorities."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_102",
    "chunk_content": "Right to explanation of  individual decision-making\n[<Paragraph children=[<RawText children=('Any affected person subject to a decision which is taken by the deployer on '\n 'the basis of the output from a high-risk AI system listed in Annex III, with '\n 'the exception of systems listed under point 2 thereof, and which produces '\n 'legal effects or similarly  significantly  affects  that  person  in  a  '\n 'way  that  they consider  to  have  an  adverse  impact on  their  health,  '\n 'safety or fundamental rights shall have the right to obtain from the '\n 'deployer clear and meaningful explanations of the role of the AI system  in  '\n 'the  decision-making  procedure  and  the  main  elements  of  the  '\n 'decision  taken.')>]>]\n[<Paragraph children=[<RawText children=('Paragraph  1  shall  not  apply  to  the  use  of  AI  systems  for  which  '\n 'exceptions  from,  or  restrictions  to,  the  obligation under  that  '\n 'paragraph  follow  from  Union  or  national  law  in  compliance  with  '\n 'Union  law.')>]>]\n[<Paragraph children=[<RawText children=('This Article shall apply only to the extent that the right referred to in '\n 'paragraph 1 is not otherwise provided for under Union law.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_103",
    "chunk_content": "Reporting of  infringements and protection of reporting persons\nDirective  (EU)  2019/1937 shall  apply  to the  reporting  of  infringements  of  this  Regulation  and  the  protection  of  persons reporting  such  infringements."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_104",
    "chunk_content": "SECTION 5\nSupervision,  investigation,  enforcement  and  monitoring  in  respect  of  providers  of  general-purpose  AI  models"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_105",
    "chunk_content": "Enforcement of  the obligations of providers of general-purpose AI models\n[<Paragraph children=[<RawText children=('The Commission shall have exclusive powers to supervise and enforce Chapter '\n 'V, taking into account the procedural guarantees  under  Article  94.  The  '\n 'Commission  shall  entrust  the  implementation  of  these  tasks  to  the  '\n 'AI  Office,  without prejudice to the powers of organisation of  the '\n 'Commission and the division of competences between Member States and the  '\n 'Union  based  on  the  Treaties.')>]>]\n[<Paragraph children=[<RawText children=('Without  prejudice  to  Article  75(3),  market  surveillance  authorities  '\n 'may  request  the  Commission  to  exercise  the powers laid down in this '\n 'Section, where that is necessary and proportionate to assist with the '\n 'fulfilment of their tasks under this  Regulation.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_106",
    "chunk_content": "Monitoring actions\n[<Paragraph children=[<RawText children=('For  the  purpose  of  carrying  out  the  tasks  assigned  to  it  under  '\n 'this  Section,  the  AI  Office  may  take  the  necessary actions to '\n 'monitor  the effective implementation and compliance with this Regulation by '\n 'providers of general-purpose AI models,  including  their  adherence  to  '\n 'approved  codes  of  practice.')>]>]\n[<Paragraph children=[<RawText children=('Downstream  providers  shall  have  the  right  to  lodge  a  complaint  '\n 'alleging  an  infringement  of  this  Regulation. A complaint shall be  '\n 'duly  reasoned  and  indicate  at  least:')>]>]\n(a) the  point  of  contact  of  the  provider  of  the  general-purpose  AI  model  concerned;\n(b) a  description  of  the  relevant  facts,  the  provisions  of  this  Regulation  concerned,  and  the  reason  why  the  downstream provider  considers  that  the  provider  of  the  general-purpose  AI  model  concerned  infringed  this  Regulation;\n(c) any  other  information  that  the  downstream  provider  that  sent  the  request  considers  relevant,  including,  where appropriate, information gathered on its  own  initiative."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_107",
    "chunk_content": "Alerts of  systemic  risks  by the  scientific  panel\n[<Paragraph children=[<RawText children=('The scientific  panel  may  provide  a  qualified  alert  to  the  AI  '\n 'Office  where  it  has  reason  to  suspect  that:')>]>]\n(a) a  general-purpose  AI  model  poses  concrete identifiable  risk  at  Union  level;  or\n(b) a  general-purpose  AI  model  meets  the  conditions  referred  to  in  Article  51.\n[<Paragraph children=[<RawText children=('Upon such qualified alert, the Commission, through the AI Office and after '\n 'having informed the Board, may exercise the powers laid down in this Section '\n 'for  the purpose of assessing the matter. The AI Office shall inform the '\n 'Board of any measure according to Articles  91  to  94.')>]>]\n[<Paragraph children=[<RawText children='A qualified  alert  shall  be  duly  reasoned  and  indicate  at  least:'>]>]\n(a) the  point  of  contact  of  the  provider  of  the  general-purpose  AI  model  with  systemic  risk  concerned;\n(b) a  description  of  the  relevant  facts  and  the  reasons  for  the  alert  by  the  scientific  panel;\n(c) any  other  information  that  the  scientific  panel  considers  to  be  relevant,  including,  where  appropriate,  information gathered  on  its  own  initiative."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_108",
    "chunk_content": "Power  to request  documentation and information\n[<Paragraph children=[<RawText children=('The Commission may request the provider of the general-purpose AI model '\n 'concerned to provide the documentation drawn up by the provider in '\n 'accordance with Articles 53 and 55, or any additional information that is '\n 'necessary for  the purpose of assessing  compliance  of  the  provider  '\n 'with  this  Regulation.')>]>]\n[<Paragraph children=[<RawText children=('Before sending the request for information, the AI Office may initiate a '\n 'structured dialogue with the provider of the general-purpose  AI  model.')>]>]\n[<Paragraph children=[<RawText children=('Upon a duly substantiated request from the scientific panel, the Commission '\n 'may issue a request for information to a provider of a general-purpose AI '\n 'model, where the access to information is necessary and proportionate for '\n 'the fulfilment of  the  tasks  of  the  scientific  panel  under  Article  '\n '68(2).')>]>]\n[<Paragraph children=[<RawText children=('The  request  for  information  shall  state  the  legal  basis  and  the  '\n 'purpose  of  the  request,  specify  what  information  is required, set a '\n 'period within which the information is to be provided, and indicate the '\n 'fines provided for in Article 101 for supplying  incorrect,  incomplete or  '\n 'misleading  information.')>]>]\n[<Paragraph children=[<RawText children=('The provider of the general-purpose AI model concerned, or its '\n 'representative shall supply the information requested. In the case of  legal '\n 'persons, companies or firms, or where the provider has no legal personality, '\n 'the persons authorised to represent  them  by  law  or  by  their  '\n 'statutes,  shall  supply  the  information  requested  on  behalf  of  the  '\n 'provider  of  the general-purpose AI model concerned. Lawyers duly '\n 'authorised to act may supply information on behalf of their clients. The '\n 'clients  shall  nevertheless  remain  fully  responsible  if  the  '\n 'information  supplied  is  incomplete,  incorrect  or  misleading.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_109",
    "chunk_content": "Power  to conduct evaluations\n[<Paragraph children=[<RawText children=('The AI Office,  after  consulting  the  Board,  may conduct evaluations  of  '\n 'the  general-purpose  AI  model  concerned:')>]>]\n(a) to assess compliance of the provider with obligations under this Regulation, where the information gathered pursuant to  Article  91  is  insufficient;  or\n(b) to  investigate  systemic  risks  at  Union  level  of  general-purpose  AI  models  with  systemic  risk,  in  particular  following a  qualified  alert  from  the  scientific  panel  in  accordance  with  Article  90(1),  point  (a).\n[<Paragraph children=[<RawText children=('The Commission may decide to appoint independent experts to carry out '\n 'evaluations on its behalf, including from the scientific  panel  '\n 'established  pursuant  to  Article  68.  Independent  experts  appointed  '\n 'for  this  task  shall  meet  the  criteria outlined  in  Article  68(2).')>]>]\n[<Paragraph children=[<RawText children=('For  the  purposes  of  paragraph  1,  the  Commission  may  request  '\n 'access  to  the  general-purpose  AI  model  concerned through APIs or  '\n 'further  appropriate  technical  means  and  tools,  including  source  '\n 'code.')>]>]\n[<Paragraph children=[<RawText children=('The  request  for  access  shall  state  the  legal  basis,  the  purpose  '\n 'and  reasons  of  the  request  and  set  the  period  within which the '\n 'access  is  to  be  provided,  and  the  fines  provided  for  in  Article  '\n '101  for  failure  to  provide  access.')>]>]\n[<Paragraph children=[<RawText children=('The providers of the general-purpose AI model concerned or its '\n 'representative shall supply the information requested. In the case of  legal '\n 'persons, companies or firms, or where the provider has no legal personality, '\n 'the persons authorised to represent  them  by  law  or  by  their  '\n 'statutes,  shall  provide  the  access  requested  on  behalf  of  the  '\n 'provider  of  the general-purpose  AI  model  concerned.')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  shall  adopt  implementing  acts  setting  out  the  '\n 'detailed  arrangements  and  the  conditions  for  the evaluations,  '\n 'including  the  detailed  arrangements  for  involving  independent  '\n 'experts,  and  the  procedure  for  the  selection thereof.  Those  '\n 'implementing  acts  shall  be  adopted  in  accordance  with  the  '\n 'examination  procedure  referred  to  in  Article 98(2).')>]>]\n[<Paragraph children=[<RawText children=('Prior to requesting access to the general-purpose AI model concerned, the AI '\n 'Office may initiate a structured dialogue with the provider of the '\n 'general-purpose AI model to gather more information on the internal testing '\n 'of the model, internal safeguards  for  preventing  systemic  risks,  and  '\n 'other  internal  procedures  and  measures  the  provider  has  taken  to  '\n 'mitigate such  risks.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_110",
    "chunk_content": "Power  to request  measures\n[<Paragraph children=[<RawText children='Where necessary and appropriate,  the Commission may request providers to:'>]>]\n(a) take  appropriate measures  to comply  with  the  obligations  set  out  in  Articles  53  and  54;\n(b) implement mitigation measures, where the evaluation carried out in accordance with Article 92 has given rise to serious and substantiated  concern  of a  systemic  risk  at  Union  level;\n(c) restrict  the  making  available  on  the  market,  withdraw  or  recall  the  model.\n[<Paragraph children=[<RawText children=('Before  a  measure  is  requested,  the  AI  Office  may  initiate  a  '\n 'structured  dialogue  with  the  provider  of  the general-purpose  AI  '\n 'model.')>]>]\n[<Paragraph children=[<RawText children=('If,  during  the  structured  dialogue  referred  to  in  paragraph  2,  '\n 'the  provider  of  the  general-purpose  AI  model  with systemic  risk  '\n 'offers  commitments  to  implement  mitigation  measures  to  address  a  '\n 'systemic  risk  at  Union  level,  the Commission may, by decision, make '\n 'those commitments binding and declare that there are no further grounds for '\n 'action.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_111",
    "chunk_content": "Procedural rights of economic operators of  the general-purpose AI model\nArticle  18  of  Regulation  (EU)  2019/1020  shall  apply mutatis  mutandis to  the  providers  of  the  general-purpose  AI  model, without prejudice  to more  specific  procedural  rights  provided  for  in  this  Regulation."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_112",
    "chunk_content": "Codes of conduct for  voluntary application of specific requirements\n[<Paragraph children=[<RawText children=('The  AI  Office  and  the  Member  States  shall  encourage  and  '\n 'facilitate  the  drawing  up  of  codes  of  conduct,  including related '\n 'governance mechanisms, intended to foster the voluntary application to AI '\n 'systems, other than high-risk AI systems, of some or all of the requirements '\n 'set out in Chapter III, Section 2 taking into account the available '\n 'technical solutions and industry  best  practices  allowing  for  the  '\n 'application  of  such  requirements.')>]>]\n[<Paragraph children=[<RawText children=('The  AI  Office  and  the  Member  States  shall  facilitate  the  drawing  '\n 'up  of  codes  of  conduct  concerning  the  voluntary application,  '\n 'including  by  deployers,  of  specific  requirements  to  all  AI  '\n 'systems,  on  the  basis  of  clear  objectives  and  key performance '\n 'indicators to measure  the achievement of  those  objectives,  including '\n 'elements  such  as,  but  not  limited  to:')>]>]\n(a) applicable  elements  provided  for  in  Union  ethical  guidelines  for  trustworthy  AI;\n(b) assessing and minimising the impact of AI systems on environmental sustainability, including as regards energy-efficient programming and techniques for  the efficient  design,  training  and  use  of  AI;\n(c) promoting AI literacy, in particular  that of  persons  dealing  with  the  development,  operation  and  use  of  AI;\n(d) facilitating an inclusive and diverse design of AI systems, including through the establishment of inclusive and diverse development teams and the promotion of stakeholders'  participation in that  process;\n(e) assessing  and  preventing  the  negative  impact  of  AI  systems  on  vulnerable  persons  or  groups  of  vulnerable  persons, including as  regards  accessibility  for  persons  with  a  disability,  as  well  as  on  gender  equality.\n[<Paragraph children=[<RawText children=('Codes  of  conduct  may  be  drawn  up  by  individual  providers  or  '\n 'deployers  of  AI  systems  or  by  organisations representing  them  or  '\n 'by  both,  including  with  the  involvement  of  any  interested  '\n 'stakeholders  and  their  representative organisations,  including  civil  '\n 'society  organisations  and  academia.  Codes  of  conduct  may  cover  one  '\n 'or  more  AI  systems taking  into  account  the  similarity  of  the  '\n 'intended  purpose  of  the  relevant  systems.')>]>]\n[<Paragraph children=[<RawText children=('The  AI  Office  and  the  Member  States  shall  take  into  account  the  '\n 'specific  interests  and  needs  of  SMEs,  including start-ups,  when  '\n 'encouraging  and  facilitating  the  drawing  up  of  codes  of  conduct.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_113",
    "chunk_content": "Guidelines from the Commission on the implementation of  this Regulation\n[<Paragraph children=[<RawText children=('The Commission shall develop guidelines  on the practical  implementation  '\n 'of  this  Regulation,  and  in particular  on:')>]>]\n(a) the  application  of  the  requirements  and  obligations  referred  to  in  Articles  8  to  15  and  in  Article  25;\n(b) the  prohibited  practices  referred  to  in  Article  5;\n(c) the  practical  implementation  of  the  provisions  related  to  substantial  modification;\n(d) the  practical  implementation  of  transparency obligations  laid  down  in  Article  50;\n(e) detailed information on the relationship of this Regulation with the Union harmonisation legislation listed in Annex I, as  well  as  with  other  relevant  Union  law,  including  as  regards  consistency  in  their  enforcement;\n(f) the  application  of  the  definition  of  an  AI  system  as  set  out  in  Article  3,  point  (1).\nWhen issuing such guidelines, the Commission shall pay particular attention to the needs of SMEs including start-ups, of local  public  authorities  and  of  the  sectors  most  likely  to  be  affected  by  this  Regulation.\nThe guidelines referred to in the first subparagraph of this paragraph shall take due account of the generally acknowledged state  of  the  art  on  AI,  as  well  as  of  relevant  harmonised  standards  and  common  specifications  that  are  referred  to  in Articles  40  and  41,  or  of  those  harmonised  standards  or  technical  specifications  that  are  set  out  pursuant  to  Union harmonisation law.\n[<Paragraph children=[<RawText children=('At the request of the Member States or the AI Office, or on its own '\n 'initiative, the Commission shall update guidelines previously  adopted when  '\n 'deemed necessary.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_114",
    "chunk_content": "Exercise  of  the  delegation\n[<Paragraph children=[<RawText children=('The power to adopt delegated acts is conferred on the Commission subject to '\n 'the conditions laid down in this Article.')>]>]\n[<Paragraph children=[<RawText children=('The power to adopt delegated acts referred to in Article 6(6) and (7), '\n 'Article 7(1) and (3), Article 11(3), Article 43(5) and  (6),  Article  '\n '47(5),  Article  51(3),  Article  52(4)  and  Article  53(5)  and  (6)  '\n 'shall  be  conferred  on  the  Commission  for a period of five years from 1 '\n 'August 2024. The Commission shall draw up a report in respect of the '\n 'delegation of power not  later  than  nine  months  before  the  end  of  '\n 'the  five-year  period.  The  delegation  of  power  shall  be  tacitly  '\n 'extended  for periods of an identical duration, unless the European '\n 'Parliament or the Council opposes such extension not later than three months '\n 'before the end of each period.')>]>]\n[<Paragraph children=[<RawText children=('The delegation of power referred to in Article 6(6) and (7), Article 7(1) '\n 'and (3), Article 11(3), Article 43(5) and (6), Article 47(5), Article 51(3), '\n 'Article 52(4) and Article 53(5) and (6) may be revoked at any time by the '\n 'European Parliament or by the Council. A decision of revocation shall put an '\n 'end to the delegation of power specified in that decision. It shall take '\n 'effect  the  day  following  that  of  its  publication  in  the Official  '\n 'Journal  of  the  European  Union or  at  a  later  date  specified '\n 'therein.  It  shall  not  affect  the  validity  of  any  delegated  acts  '\n 'already  in  force.')>]>]\n[<Paragraph children=[<RawText children=('Before adopting a delegated act, the Commission shall consult experts '\n 'designated by each Member State in accordance with  the  principles  laid  '\n 'down  in  the  Interinstitutional  Agreement  of  13  April  2016  on  '\n 'Better  Law-Making.')>]>]\n[<Paragraph children=[<RawText children=('As soon as it adopts a delegated act, the Commission shall notify it '\n 'simultaneously to the European Parliament and to the  Council.')>]>]\n[<Paragraph children=[<RawText children=('Any  delegated  act  adopted  pursuant  to  Article  6(6)  or  (7),  '\n 'Article  7(1)  or  (3),  Article  11(3),  Article  43(5)  or  (6), Article  '\n '47(5),  Article  51(3),  Article  52(4)  or  Article  53(5)  or  (6)  shall  '\n 'enter  into  force  only  if  no  objection  has  been expressed by either  '\n 'the European Parliament or  the Council within a period of three months of '\n 'notification of that act to the European Parliament and the Council or if, '\n 'before the expiry of that period, the European Parliament and the Council '\n 'have  both  informed  the  Commission  that  they  will  not  object.  That  '\n 'period  shall  be  extended  by  three  months  at  the initiative  of  the  '\n 'European  Parliament  or  of  the  Council.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_115",
    "chunk_content": "Committee procedure\n[<Paragraph children=[<RawText children=('The  Commission  shall  be  assisted  by  a  committee.  That  committee  '\n 'shall  be  a  committee  within  the  meaning  of Regulation  (EU)  No  '\n '182/2011.')>]>]\n[<Paragraph children=[<RawText children=('Where reference  is  made  to  this  paragraph,  Article  5  of  Regulation  '\n '(EU)  No  182/2011  shall  apply.')>]>]\nCHAPTER XII"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_116",
    "chunk_content": "Penalties\n[<Paragraph children=[<RawText children=('In accordance with the terms and conditions laid down in this Regulation, '\n 'Member States shall lay down the rules on penalties  and  other  '\n 'enforcement  measures,  which  may  also  include  warnings  and  '\n 'non-monetary  measures,  applicable  to infringements of  this  Regulation  '\n 'by operators,  and  shall  take all  measures  necessary  to ensure  that  '\n 'they  are  properly  and effectively implemented, thereby taking into '\n 'account the guidelines issued by the Commission pursuant to Article 96. The '\n 'penalties  provided for shall  be  effective,  proportionate  and  '\n 'dissuasive.  They shall  take  into account  the  interests  of  SMEs, '\n 'including  start-ups,  and  their  economic  viability.')>]>]\n[<Paragraph children=[<RawText children=('The Member States shall, without delay and at the latest by the date of '\n 'entry into application, notify the Commission of the rules on penalties and '\n 'of other enforcement measures referred to in paragraph 1, and shall notify '\n 'it, without delay, of any subsequent amendment to them.')>]>]\n[<Paragraph children=[<RawText children=('Non-compliance with  the  prohibition  of  the  AI  practices  referred  to  '\n 'in  Article  5  shall  be  subject  to  administrative fines of up to EUR 35 '\n '000 000 or, if the offender is an undertaking, up to 7 % of its total '\n 'worldwide annual turnover for the preceding financial  year,  whichever  is  '\n 'higher.')>]>]\n[<Paragraph children=[<RawText children=('Non-compliance with any of  the following  provisions related  to operators  '\n 'or  notified  bodies,  other  than  those  laid down in Articles 5, shall be '\n 'subject to administrative fines of up to EUR 15 000 000 or, if the offender '\n 'is an undertaking, up to  3 %  of  its  total  worldwide  annual  turnover  '\n 'for  the  preceding  financial  year,  whichever  is  higher:')>]>]\n(a) obligations  of  providers  pursuant  to  Article  16;\n(b) obligations  of  authorised  representatives  pursuant  to  Article  22;\n(c) obligations  of  importers  pursuant  to  Article  23;\n(d) obligations  of  distributors  pursuant  to  Article  24;\n(e) obligations  of  deployers  pursuant  to  Article  26;\n(f) requirements  and  obligations  of  notified  bodies  pursuant  to Article  31,  Article  33(1),  (3)  and  (4)  or  Article  34;\n(g) transparency obligations  for  providers  and  deployers  pursuant  to  Article  50.\n[<Paragraph children=[<RawText children=('The supply of incorrect, incomplete or misleading information to notified '\n 'bodies or national competent authorities in reply to a request shall be '\n 'subject to administrative fines of up to EUR 7 500 000 or, if the offender '\n 'is an undertaking, up to 1 %  of  its  total  worldwide  annual  turnover  '\n 'for  the  preceding  financial  year,  whichever  is  higher.')>]>]\n[<Paragraph children=[<RawText children=('In the case of SMEs, including start-ups, each fine referred to in this '\n 'Article shall be up to the percentages or amount referred  to  in  '\n 'paragraphs  3,  4  and  5,  whichever  thereof  is  lower.')>]>]\n[<Paragraph children=[<RawText children=('When deciding whether to impose an administrative fine and when deciding on '\n 'the amount of the administrative fine in each individual case, all relevant '\n 'circumstances of the specific situation shall be taken into account and, as '\n 'appropriate, regard  shall  be  given  to  the  following:')>]>]\n(a) the nature, gravity and duration of the infringement and of its consequences, taking into account the purpose of the AI system,  as  well  as,  where  appropriate,  the  number  of  affected  persons  and  the  level  of  damage  suffered  by  them;\n(b) whether administrative fines have already been applied by other market surveillance authorities to the same operator for the  same  infringement;\n(c) whether administrative fines have already been applied by other authorities to the same operator for  infringements of other Union or national law, when such infringements result from the same activity or omission constituting a relevant infringement of  this  Regulation;\n(d) the  size,  the  annual  turnover  and  market  share  of  the  operator  committing  the  infringement;\n(e) any other aggravating or mitigating factor applicable to the circumstances of the case, such as financial benefits gained, or  losses  avoided,  directly  or  indirectly,  from  the  infringement;\n(f) the degree of cooperation with the national competent authorities, in order to remedy the infringement and mitigate the possible  adverse  effects  of  the  infringement;\n(g) the degree of responsibility of the operator taking into account the technical and organisational measures implemented by it;\n(h) the manner in which the infringement became known to the national competent authorities, in particular whether, and if  so  to  what  extent,  the  operator  notified  the  infringement;\n(i) the  intentional  or  negligent  character  of  the  infringement;\n(j) any action  taken  by  the  operator  to  mitigate  the  harm  suffered  by  the  affected  persons.\n[<Paragraph children=[<RawText children=('Each Member State shall lay down rules on to what extent administrative '\n 'fines may be imposed on public authorities and bodies established  in  that  '\n 'Member  State.')>]>]\n[<Paragraph children=[<RawText children=('Depending  on  the  legal  system  of  the  Member  States,  the  rules  on  '\n 'administrative  fines  may  be  applied  in  such a manner that the fines '\n 'are imposed by competent national courts or by other bodies, as applicable '\n 'in those Member States. The application  of  such  rules  in  those  Member  '\n 'States  shall  have  an  equivalent  effect.')>]>]\n[<Paragraph children=[<RawText children=('The exercise of powers under this Article shall be subject to appropriate '\n 'procedural safeguards in accordance with Union and national law, including '\n 'effective  judicial  remedies  and  due  process.')>]>]\n[<Paragraph children=[<RawText children=('Member States shall, on an annual basis, report to the Commission about the '\n 'administrative fines they have issued during that  year,  in  accordance  '\n 'with  this  Article,  and  about  any  related  litigation  or  judicial  '\n 'proceedings.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_117",
    "chunk_content": "Administrative fines on Union institutions, bodies, offices and agencies\n[<Paragraph children=[<RawText children=('The European Data Protection Supervisor may impose administrative fines on '\n 'Union institutions, bodies, offices and agencies  falling  within  the  '\n 'scope  of  this  Regulation.  When  deciding  whether  to  impose  an  '\n 'administrative  fine  and  when deciding on the amount of the administrative '\n 'fine in each individual case, all relevant circumstances of the specific '\n 'situation shall  be  taken  into  account  and  due  regard  shall  be  '\n 'given  to  the  following:')>]>]\n(a) the nature, gravity and duration of the infringement and of its consequences, taking into account the purpose of the AI system concerned, as well as, where appropriate, the number of affected persons and the level of damage suffered by them;\n(b) the  degree  of  responsibility  of  the  Union  institution,  body,  office  or  agency,  taking  into  account  technical  and organisational  measures  implemented by them;\n(c) any action taken by the Union institution, body, office or agency to mitigate the damage suffered by affected persons;\n(d) the  degree  of  cooperation  with  the  European  Data  Protection  Supervisor  in  order  to  remedy  the  infringement  and mitigate  the  possible  adverse  effects  of  the  infringement,  including  compliance  with  any  of  the  measures  previously ordered  by  the  European  Data  Protection  Supervisor  against  the  Union  institution,  body,  office  or  agency  concerned with  regard  to  the  same  subject  matter;\n(e) any similar  previous  infringements by the  Union  institution,  body,  office  or  agency;\n(f) the  manner  in  which  the  infringement  became  known  to  the  European  Data  Protection  Supervisor,  in  particular whether,  and  if  so  to  what  extent,  the  Union  institution,  body,  office  or  agency  notified  the  infringement;\n(g) the  annual  budget  of  the  Union  institution,  body,  office  or  agency.\n[<Paragraph children=[<RawText children=('Non-compliance with  the  prohibition  of  the  AI  practices  referred  to  '\n 'in  Article  5  shall  be  subject  to  administrative fines  of  up  to  '\n 'EUR  1 500 000.')>]>]\n[<Paragraph children=[<RawText children=('The non-compliance of the AI system with any requirements or obligations '\n 'under  this Regulation, other  than those laid  down in  Article  5,  shall  '\n 'be  subject  to  administrative  fines  of  up  to  EUR  750 000.')>]>]\n[<Paragraph children=[<RawText children=('Before  taking  decisions  pursuant  to  this  Article,  the  European  '\n 'Data  Protection  Supervisor  shall  give  the  Union institution,  body,  '\n 'office  or  agency  which  is  the  subject  of  the  proceedings  '\n 'conducted  by  the  European  Data  Protection Supervisor  the  opportunity  '\n 'of  being  heard  on  the  matter  regarding  the  possible  infringement.  '\n 'The  European  Data Protection Supervisor shall base his or her decisions '\n 'only on elements and circumstances on which the parties concerned have  '\n 'been  able  to  comment.  Complainants,  if  any,  shall  be  associated  '\n 'closely  with  the  proceedings.')>]>]\n[<Paragraph children=[<RawText children=('The  rights  of  defence  of  the  parties  concerned  shall  be  fully  '\n 'respected  in  the  proceedings.  They  shall  be  entitled  to have  '\n \"access  to  the  European  Data  Protection  Supervisor's  file,  subject  \"\n 'to  the  legitimate  interest  of  individuals  or undertakings  in  the  '\n 'protection  of  their  personal  data  or  business  secrets.')>]>]\n[<Paragraph children=[<RawText children=('Funds collected by imposition of fines in this Article shall contribute to '\n 'the  general  budget of  the Union. The  fines shall  not  affect  the  '\n 'effective  operation  of  the  Union  institution,  body,  office  or  '\n 'agency  fined.')>]>]\n[<Paragraph children=[<RawText children=('The European Data Protection Supervisor shall, on an annual basis, notify '\n 'the Commission of the administrative fines it  has  imposed  pursuant  to  '\n 'this  Article  and  of  any  litigation  or  judicial  proceedings  it  has  '\n 'initiated.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_118",
    "chunk_content": "Fines for  providers  of  general-purpose AI models\n[<Paragraph children=[<RawText children=('The Commission may impose on providers of general-purpose AI models fines '\n 'not exceeding 3 % of their annual total worldwide turnover in the preceding '\n 'financial year or EUR 15 000 000, whichever is higher., when the Commission '\n 'finds that  the  provider  intentionally  or  negligently:')>]>]\n(a) infringed  the  relevant  provisions  of  this  Regulation;\n(b) failed  to  comply  with  a  request  for  a  document  or  for  information  pursuant  to  Article  91,  or  supplied  incorrect, incomplete or  misleading  information;\n(c) failed  to  comply  with  a  measure  requested  under  Article  93;\n(d) failed to make available to the Commission access to the general-purpose AI model or general-purpose AI model with systemic  risk  with  a  view  to  conducting  an  evaluation  pursuant  to  Article  92.\nIn fixing the amount of the fine or periodic penalty payment, regard shall be had to the nature, gravity and duration of the infringement, taking due account of the principles of proportionality and appropriateness. The Commission shall also into account  commitments  made  in  accordance  with  Article  93(3)  or  made  in  relevant  codes  of  practice  in  accordance  with Article  56.\n[<Paragraph children=[<RawText children=('Before adopting the decision pursuant to paragraph 1, the Commission shall '\n 'communicate its preliminary findings to the  provider  of  the  '\n 'general-purpose  AI  model  and  give  it  an  opportunity  to  be  heard.')>]>]\n[<Paragraph children=[<RawText children=('Fines  imposed  in  accordance  with  this  Article  shall  be  effective,  '\n 'proportionate  and  dissuasive.')>]>]\n[<Paragraph children=[<RawText children=('Information  on fines  imposed  under  this  Article  shall  also  be  '\n 'communicated  to  the  Board  as  appropriate.')>]>]\n[<Paragraph children=[<RawText children=('The Court of Justice of the European Union shall have unlimited jurisdiction '\n 'to review decisions of the Commission fixing  a  fine  under  this  '\n 'Article.  It  may  cancel,  reduce  or  increase  the  fine  imposed.')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  shall  adopt  implementing  acts  containing  detailed  '\n 'arrangements  and  procedural  safeguards  for proceedings in view of the '\n 'possible adoption of decisions pursuant to paragraph 1 of this Article. '\n 'Those implementing acts shall  be  adopted  in  accordance  with  the  '\n 'examination  procedure  referred  to  in  Article  98(2).')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_119",
    "chunk_content": "Amendment to Regulation (EC) No 300/2008\nIn  Article  4(3)  of  Regulation  (EC)  No  300/2008,  the  following  subparagraph  is  added:\n'When  adopting  detailed  measures  related  to  technical  specifications  and  procedures  for  approval  and  use  of  security equipment concerning Artificial  Intelligence  systems  within  the  meaning  of Regulation  (EU)  2024/1689  of  the European Parliament and of the Council (*), the requirements set out in Chapter III, Section 2, of that Regulation shall be taken into account.\n(*) Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 laying down harmonised rules on artificial intelligence and amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU)  2018/858,  (EU)  2018/1139  and  (EU)  2019/2144  and  Directives  2014/90/EU,  (EU)  2016/797  and  (EU) 2020/1828  (Artificial Intelligence Act) (OJ L, 2024/1689, 12.7.2024, ELI: http://data.europa.eu/eli/reg/ 2024/1689/oj).'."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_120",
    "chunk_content": "Amendment to Regulation (EU) No 167/2013\nIn  Article  17(5)  of  Regulation  (EU)  No  167/2013,  the  following  subparagraph  is  added:\n'When adopting delegated acts pursuant to the first subparagraph concerning artificial intelligence systems which are safety components  within  the  meaning  of  Regulation  (EU)  2024/1689  of  the  European  Parliament  and  of  the  Council (*),  the requirements  set  out  in  Chapter  III,  Section  2,  of  that  Regulation  shall  be  taken  into  account.\n(*) Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 laying down harmonised rules on artificial intelligence and amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU)  2018/858,  (EU)  2018/1139  and  (EU)  2019/2144  and  Directives  2014/90/EU,  (EU)  2016/797  and  (EU) 2020/1828  (Artificial Intelligence Act) (OJ L, 2024/1689, 12.7.2024, ELI: http://data.europa.eu/eli/reg/ 2024/1689/oj).'."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_121",
    "chunk_content": "Amendment to Regulation (EU) No 168/2013\nIn  Article  22(5)  of  Regulation  (EU)  No  168/2013,  the  following  subparagraph  is  added:\n'When adopting delegated acts pursuant to the first subparagraph concerning Artificial Intelligence systems which are safety components  within  the  meaning  of  Regulation  (EU)  2024/1689  of  the  European  Parliament  and  of  the  Council (*),  the requirements  set  out  in  Chapter  III,  Section  2,  of  that  Regulation  shall  be  taken  into  account.\n(*) Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 laying down harmonised rules on artificial intelligence and amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU)  2018/858,  (EU)  2018/1139  and  (EU)  2019/2144  and  Directives  2014/90/EU,  (EU)  2016/797  and  (EU) 2020/1828  (Artificial Intelligence Act) (OJ L, 2024/1689, 12.7.2024, ELI: http://data.europa.eu/eli/reg/ 2024/1689/oj).'."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_122",
    "chunk_content": "Amendment to Directive 2014/90/EU\nIn  Article  8  of  Directive  2014/90/EU,  the  following  paragraph  is  added:\n'5. For Artificial Intelligence systems which are safety components within the meaning of Regulation (EU) 2024/1689 of the European Parliament and of the Council (*), when carrying out its activities pursuant to paragraph 1 and when adopting technical  specifications  and  testing  standards  in  accordance  with  paragraphs  2  and  3,  the  Commission  shall  take  into account the  requirements  set out  in  Chapter  III,  Section  2,  of  that  Regulation.\n(*) Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 laying down harmonised rules on artificial intelligence and amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU)  2018/858,  (EU)  2018/1139  and  (EU)  2019/2144  and  Directives  2014/90/EU,  (EU)  2016/797  and  (EU) 2020/1828  (Artificial Intelligence Act) (OJ L, 2024/1689, 12.7.2024, ELI: http://data.europa.eu/eli/reg/ 2024/1689/oj).'.\nArticle  106"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_123",
    "chunk_content": "Amendment to Directive (EU) 2016/797\nIn  Article  5  of  Directive  (EU)  2016/797,  the  following  paragraph  is  added:\n'12. When  adopting  delegated  acts  pursuant  to  paragraph  1  and  implementing  acts  pursuant  to  paragraph  11 concerning Artificial Intelligence systems which are safety components within the meaning of Regulation (EU) 2024/1689 of the European Parliament and of the Council (*), the requirements set out in Chapter III, Section 2, of that Regulation shall be  taken  into  account.\n(*) Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 laying down harmonised rules on artificial intelligence and amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU)  2018/858,  (EU)  2018/1139  and  (EU)  2019/2144  and  Directives  2014/90/EU,  (EU)  2016/797  and  (EU) 2020/1828  (Artificial Intelligence Act) (OJ L, 2024/1689, 12.7.2024, ELI: http://data.europa.eu/eli/reg/ 2024/1689/oj).'."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_124",
    "chunk_content": "Amendment to Regulation (EU) 2018/858\nIn  Article  5  of  Regulation  (EU)  2018/858  the  following  paragraph  is  added:\n'4. When adopting  delegated  acts  pursuant  to  paragraph  3  concerning  Artificial  Intelligence  systems  which  are  safety components  within  the  meaning  of  Regulation  (EU)  2024/1689  of  the  European  Parliament  and  of  the  Council (*),  the requirements  set  out  in  Chapter  III,  Section  2,  of  that  Regulation  shall  be  taken  into  account.\n(*) Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 laying down harmonised rules on artificial intelligence and amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU)  2018/858,  (EU)  2018/1139  and  (EU)  2019/2144  and  Directives  2014/90/EU,  (EU)  2016/797  and  (EU) 2020/1828  (Artificial Intelligence Act) (OJ L, 2024/1689, 12.7.2024, ELI: http://data.europa.eu/eli/reg/ 2024/1689/oj).'."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_125",
    "chunk_content": "Amendments to Regulation (EU) 2018/1139\nRegulation  (EU)  2018/1139 is  amended  as  follows:\n(1) in  Article  17,  the  following  paragraph  is  added:\n'3. Without  prejudice  to  paragraph  2,  when  adopting  implementing  acts  pursuant  to  paragraph  1  concerning Artificial  Intelligence  systems which are safety components within the meaning of Regulation (EU) 2024/1689 of  the European Parliament and of the Council (*), the requirements set out in Chapter III, Section 2, of that Regulation shall be taken  into  account.\n(*) Regulation  (EU)  2024/1689  of  the  European  Parliament  and  of  the  Council  of  13  June  2024  laying  down harmonised rules on artificial intelligence and amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU) 2018/858, (EU) 2018/1139 and (EU) 2019/2144 and Directives 2014/90/EU, (EU) 2016/797 and  (EU)  2020/1828  (Artificial  Intelligence  Act)  (OJ  L,  2024/1689,  12.7.2024,  ELI:  http://data.europa. eu/eli/reg/2024/1689/oj).';\n(2) in  Article  19,  the  following  paragraph  is  added:\n'4. When adopting delegated acts pursuant to paragraphs 1 and 2 concerning Artificial Intelligence systems which are  safety  components  within  the  meaning  of  Regulation  (EU)  2024/1689,  the  requirements  set  out  in  Chapter  III, Section  2,  of  that  Regulation  shall  be  taken  into  account.';\n(3) in  Article  43,  the  following  paragraph  is  added:\n'4. When adopting implementing acts pursuant to paragraph 1 concerning Artificial Intelligence systems which are safety  components  within  the  meaning  of  Regulation  (EU)  2024/1689,  the  requirements  set  out  in  Chapter  III, Section  2,  of  that  Regulation  shall  be  taken  into  account.';\n(4) in  Article  47,  the  following  paragraph  is  added:\n'3. When adopting delegated acts pursuant to paragraphs 1 and 2 concerning Artificial Intelligence systems which are  safety  components  within  the  meaning  of  Regulation  (EU)  2024/1689,  the  requirements  set  out  in  Chapter  III, Section  2,  of  that  Regulation  shall  be  taken  into  account.';\n(5) in  Article  57,  the  following  subparagraph  is  added:\n'When adopting those implementing acts concerning Artificial Intelligence systems which are safety components within the meaning of Regulation (EU) 2024/1689, the requirements set out in Chapter III, Section 2, of that Regulation shall be  taken  into  account.';\n(6) in  Article  58,  the  following  paragraph  is  added:\n'3. When adopting delegated acts pursuant to paragraphs 1 and 2 concerning Artificial Intelligence systems which are  safety  components  within  the  meaning  of  Regulation  (EU)  2024/1689,  the  requirements  set  out  in  Chapter  III, Section  2,  of  that  Regulation  shall  be  taken  into  account.'."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_126",
    "chunk_content": "Amendment to Regulation (EU) 2019/2144\nIn  Article  11  of  Regulation  (EU)  2019/2144,  the  following  paragraph  is  added:\n'3. When adopting the implementing acts pursuant to paragraph 2, concerning artificial intelligence systems which are safety components within the meaning of Regulation (EU) 2024/1689 of the European Parliament and of the Council (*), the  requirements  set  out  in  Chapter  III,  Section  2,  of  that  Regulation  shall  be  taken  into  account.\n(*) Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 laying down harmonised rules on artificial intelligence and amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU)  2018/858,  (EU)  2018/1139  and  (EU)  2019/2144  and  Directives  2014/90/EU,  (EU)  2016/797  and  (EU) 2020/1828  (Artificial Intelligence Act) (OJ L, 2024/1689, 12.7.2024, ELI: http://data.europa.eu/eli/reg/ 2024/1689/oj).'."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_127",
    "chunk_content": "Amendment to Directive (EU) 2020/1828\nIn Annex I to Directive (EU) 2020/1828 of the European Parliament and of the Council ( 58 ),  the  following point is added:\n'(68) Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 laying down harmonised rules on artificial intelligence and amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU)  2018/858,  (EU)  2018/1139  and  (EU)  2019/2144  and  Directives  2014/90/EU,  (EU)  2016/797  and  (EU) 2020/1828  (Artificial Intelligence Act) (OJ L, 2024/1689, 12.7.2024, ELI: http://data.europa.eu/eli/reg/ 2024/1689/oj).'."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_128",
    "chunk_content": "AI systems already placed on the market or put into service and general-purpose AI models already placed on the marked\n[<Paragraph children=[<RawText children=('Without  prejudice  to  the  application  of  Article  5  as  referred  to  '\n 'in  Article  113(3),  point  (a),  AI  systems  which  are components of the '\n 'large-scale IT systems established by the legal acts listed in Annex X that '\n 'have been placed on the market or  put  into  service  before  2  August  '\n '2027  shall  be  brought  into  compliance  with  this  Regulation  by  31  '\n 'December  2030.')>]>]\nThe requirements laid down in this Regulation shall be taken into account in the evaluation of each large-scale IT system established by the legal acts listed in Annex X to be undertaken as provided for in those legal acts and where those legal acts are  replaced  or  amended.\n[<Paragraph children=[<RawText children=('Without prejudice to the application of Article 5 as referred to in Article '\n '113(3), point (a), this Regulation shall apply to operators of high-risk AI '\n 'systems, other than the systems referred to in paragraph 1 of this Article, '\n 'that have been placed on the market or put into service before 2 August '\n '2026, only if, as from that date, those systems are subject to significant '\n 'changes in  their  designs.  In  any case,  the  providers  and  deployers  '\n 'of  high-risk  AI  systems  intended  to  be  used  by  public authorities '\n 'shall take the necessary steps to comply with the requirements and '\n 'obligations of this Regulation by 2 August 2030.')>]>]\n[<Paragraph children=[<RawText children=('Providers  of  general-purpose  AI  models  that  have  been  placed  on  '\n 'the  market  before  2  August  2025  shall  take  the necessary  steps  in  '\n 'order  to  comply  with  the  obligations  laid  down  in  this  Regulation  '\n 'by  2  August  2027.')>]>]\n( 58 ) Directive (EU) 2020/1828 of the European Parliament and of the Council of 25 November 2020 on representative actions for the protection  of  the  collective  interests  of  consumers  and  repealing  Directive  2009/22/EC  (OJ  L  409,  4.12.2020,  p.  1)."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_129",
    "chunk_content": "Evaluation and review\n[<Paragraph children=[<RawText children=('The Commission shall assess the need for amendment of the list set out in '\n 'Annex III and of the list of prohibited AI practices laid down in Article 5, '\n 'once a year following the entry into force of this Regulation, and until the '\n 'end of the period of  the  delegation  of  power  laid  down  in  Article  '\n '97.  The  Commission  shall  submit  the  findings  of  that  assessment  '\n 'to  the European Parliament and the Council.')>]>]\n[<Paragraph children=[<RawText children=('By  2  August  2028  and  every  four  years  thereafter,  the  Commission  '\n 'shall  evaluate  and  report  to  the  European Parliament  and  to  the  '\n 'Council  on  the  following:')>]>]\n(a) the  need  for  amendments  extending existing  area  headings  or  adding  new  area  headings  in  Annex  III;\n(b) amendments to the list of  AI  systems  requiring additional  transparency  measures  in  Article  50;\n(c) amendments enhancing the effectiveness of  the  supervision  and  governance  system.\n[<Paragraph children=[<RawText children=('By 2 August 2029 and every four years thereafter, the Commission shall '\n 'submit a report on the evaluation and review of this Regulation to the '\n 'European Parliament and to the Council. The report shall include an '\n 'assessment with regard to the structure of enforcement and the possible need '\n 'for a Union agency to resolve any identified shortcomings. On the basis of '\n 'the  findings,  that  report  shall,  where  appropriate,  be  accompanied  '\n 'by  a  proposal  for  amendment  of  this  Regulation.  The reports  shall  '\n 'be  made  public.')>]>]\n[<Paragraph children=[<RawText children=('The reports referred  to  in  paragraph  2  shall  pay  specific  attention  '\n 'to  the  following:')>]>]\n(a) the status of  the financial, technical and human resources of the national competent authorities in order  to effectively perform the tasks  assigned  to  them  under  this  Regulation;\n(b) the  state  of  penalties,  in  particular  administrative  fines  as  referred  to  in  Article  99(1),  applied  by  Member  States  for infringements of  this  Regulation;\n(c) adopted harmonised standards and common specifications developed to support this Regulation;\n(d) the number of undertakings that enter the market after the entry into application of this Regulation, and how many of them are SMEs.\n[<Paragraph children=[<RawText children=('By 2 August 2028, the Commission shall evaluate the functioning of the AI '\n 'Office, whether  the AI Office has been given  sufficient  powers  and  '\n 'competences  to  fulfil  its  tasks,  and  whether  it  would  be  relevant  '\n 'and  needed  for  the  proper implementation  and  enforcement  of  this  '\n 'Regulation  to  upgrade  the  AI  Office  and  its  enforcement  '\n 'competences  and  to increase  its  resources.  The  Commission  shall  '\n 'submit  a  report  on  its  evaluation  to  the  European  Parliament  and  '\n 'to  the Council.')>]>]\n[<Paragraph children=[<RawText children=('By 2 August 2028 and every four years thereafter, the Commission shall '\n 'submit a report on the review of the progress on the development of '\n 'standardisation deliverables on the energy-efficient development of '\n 'general-purpose AI models, and asses the need for further measures or '\n 'actions, including binding measures or actions. The report shall be '\n 'submitted to the European Parliament and to the Council, and it shall  be  '\n 'made  public.')>]>]\n[<Paragraph children=[<RawText children=('By  2  August  2028  and  every  three  years  thereafter,  the  Commission  '\n 'shall  evaluate  the  impact  and  effectiveness  of voluntary codes  of  '\n 'conduct  to  foster  the  application  of  the  requirements  set  out  in  '\n 'Chapter  III,  Section  2  for  AI  systems other than high-risk AI systems '\n 'and possibly other additional requirements for AI systems other than '\n 'high-risk AI systems, including as  regards  environmental  sustainability.')>]>]\n[<Paragraph children=[<RawText children=('For the purposes of paragraphs 1 to 7, the Board, the Member States and '\n 'national competent authorities shall provide the  Commission with '\n 'information upon its request and without undue delay.')>]>]\n[<Paragraph children=[<RawText children=('In carrying out the evaluations and reviews referred to in paragraphs 1 to '\n '7, the Commission shall take into account the positions and findings of the '\n 'Board, of the European Parliament, of the Council, and of other relevant '\n 'bodies or sources.')>]>]\n[<Paragraph children=[<RawText children=('The Commission shall, if necessary, submit appropriate proposals to amend '\n 'this Regulation, in particular taking into account developments in '\n 'technology, the effect of AI systems on health and safety, and on '\n 'fundamental rights, and in light of  the  state  of  progress  in  the  '\n 'information  society.')>]>]\n[<Paragraph children=[<RawText children=('To guide the evaluations and reviews referred to in paragraphs 1 to 7 of '\n 'this Article, the AI Office shall undertake to develop an objective  and  '\n 'participative  methodology  for  the  evaluation  of  risk  levels  based  '\n 'on  the  criteria  outlined  in  the relevant  Articles  and  the  '\n 'inclusion  of  new  systems  in:')>]>]\n(a) the list  set out  in  Annex  III,  including  the  extension of existing area headings or  the addition of new area headings in that  Annex;\n(b) the  list  of  prohibited  practices  set  out  in  Article  5;  and\n(c) the  list  of  AI  systems  requiring  additional  transparency  measures  pursuant  to  Article  50.\n[<Paragraph children=[<RawText children=('Any amendment to this Regulation pursuant to paragraph  10, or  relevant  '\n 'delegated  or  implementing  acts,  which concerns  sectoral  Union  '\n 'harmonisation  legislation  listed  in  Section  B  of  Annex  I  shall  '\n 'take  into  account  the  regulatory specificities  of  each  sector,  and  '\n 'the  existing  governance,  conformity  assessment  and  enforcement  '\n 'mechanisms  and authorities  established  therein.')>]>]\n[<Paragraph children=[<RawText children=('By 2 August 2031, the Commission shall carry out an assessment of the '\n 'enforcement of this Regulation and shall report  on  it  to  the  European  '\n 'Parliament,  the  Council  and  the  European  Economic  and  Social  '\n 'Committee,  taking  into account the first years of application of this '\n 'Regulation. On the basis of the findings, that report shall, where '\n 'appropriate, be accompanied by a proposal for amendment of this Regulation '\n 'with regard to the structure of enforcement and the need for a  Union  '\n 'agency  to  resolve  any  identified  shortcomings.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_130",
    "chunk_content": "Entry into force and application\nThis  Regulation  shall  enter  into  force  on  the  twentieth  day  following  that  of  its  publication  in  the Official  Journal  of  the European  Union .\nIt  shall  apply  from  2  August  2026.\nHowever:\n(a) Chapters I  and  II  shall  apply  from  2  February  2025;\n(b) Chapter III Section 4, Chapter V, Chapter VII and Chapter XII and Article 78 shall apply from 2 August 2025, with the exception of  Article  101;\n(c) Article  6(1)  and  the  corresponding  obligations  in  this  Regulation  shall  apply  from  2  August  2027.\nThis  Regulation  shall  be  binding  in  its  entirety  and  directly  applicable  in  all  Member  States.\nDone at Brussels,  13  June  2024.\nFor  the  European  Parliament\nThe  President\nR.  METSOLA\nFor  the  Council\nThe  President\nM.  MICHEL"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_131",
    "chunk_content": "List  of  Union  harmonisation legislation\nSection  A.  List  of  Union  harmonisation  legislation  based  on  the  New  Legislative  Framework\n[<Paragraph children=[<RawText children=('Directive 2006/42/EC of the European Parliament and of the Council of 17 May '\n '2006 on machinery, and amending Directive  95/16/EC  (OJ  L  157,  '\n '9.6.2006,  p.  24);')>]>]\n[<Paragraph children=[<RawText children=('Directive  2009/48/EC  of  the  European  Parliament  and  of  the  Council  '\n 'of  18  June  2009  on  the  safety  of  toys  (OJ L  170,  30.6.2009,  p.  '\n '1);')>]>]\n[<Paragraph children=[<RawText children=('Directive 2013/53/EU of the European Parliament and of the Council of 20 '\n 'November 2013 on recreational craft and personal  watercraft  and  '\n 'repealing  Directive  94/25/EC  (OJ  L  354,  28.12.2013,  p.  90);')>]>]\n[<Paragraph children=[<RawText children=('Directive 2014/33/EU of the European Parliament and of the Council of 26 '\n 'February 2014 on the harmonisation of the  laws  of  the  Member  States  '\n 'relating  to  lifts  and  safety  components  for  lifts  (OJ  L  96,  '\n '29.3.2014,  p.  251);')>]>]\n[<Paragraph children=[<RawText children=('Directive 2014/34/EU of the European Parliament and of the Council of 26 '\n 'February 2014 on the harmonisation of the laws of the Member States relating '\n 'to equipment and protective systems intended for use in potentially '\n 'explosive atmospheres (OJ L 96, 29.3.2014, p. 309);')>]>]\n[<Paragraph children=[<RawText children=('Directive 2014/53/EU of the European Parliament and of the Council of 16 '\n 'April 2014 on the harmonisation of the laws of the Member States relating to '\n 'the making available on the market of radio equipment and repealing '\n 'Directive 1999/5/EC (OJ L 153, 22.5.2014, p. 62);')>]>]\n[<Paragraph children=[<RawText children=('Directive 2014/68/EU of the European Parliament and of the Council of 15 May '\n '2014 on the harmonisation of the laws  of  the  Member  States  relating  '\n 'to  the  making  available  on  the  market  of  pressure  equipment  (OJ  '\n 'L  189, 27.6.2014, p. 164);')>]>]\n[<Paragraph children=[<RawText children=('Regulation  (EU)  2016/424  of  the  European  Parliament  and  of  the  '\n 'Council  of  9  March  2016  on  cableway installations  and  repealing  '\n 'Directive  2000/9/EC  (OJ  L  81,  31.3.2016,  p.  1);')>]>]\n[<Paragraph children=[<RawText children=('Regulation (EU) 2016/425 of the European Parliament and of the Council of 9 '\n 'March 2016 on personal protective equipment and repealing Council Directive  '\n '89/686/EEC (OJ  L 81, 31.3.2016,  p. 51);')>]>]\n[<Paragraph children=[<RawText children=('Regulation (EU) 2016/426 of the European Parliament and of the Council of 9 '\n 'March 2016 on appliances burning gaseous  fuels  and  repealing  Directive  '\n '2009/142/EC  (OJ  L  81,  31.3.2016,  p.  99);')>]>]\n[<Paragraph children=[<RawText children=('Regulation  (EU)  2017/745  of  the  European  Parliament  and  of  the  '\n 'Council  of  5  April  2017  on  medical  devices, amending Directive '\n '2001/83/EC, Regulation (EC) No 178/2002 and Regulation (EC) No 1223/2009 and '\n 'repealing Council  Directives  90/385/EEC  and  93/42/EEC  (OJ  L  117,  '\n '5.5.2017,  p.  1);')>]>]\n[<Paragraph children=[<RawText children=('Regulation  (EU)  2017/746  of  the  European  Parliament  and  of  the  '\n 'Council  of  5  April  2017  on in  vitro diagnostic medical  devices  and  '\n 'repealing  Directive  98/79/EC  and  Commission  Decision  2010/227/EU  (OJ  '\n 'L  117,  5.5.2017, p.  176).')>]>]\nSection  B.  List  of  other  Union  harmonisation  legislation\n[<Paragraph children=[<RawText children=('Regulation (EC) No 300/2008 of the European Parliament and of the Council of '\n '11 March 2008 on common rules in  the  field  of  civil  aviation  security  '\n 'and  repealing  Regulation  (EC)  No  2320/2002  (OJ  L  97,  9.4.2008,  p.  '\n '72);')>]>]\n[<Paragraph children=[<RawText children=('Regulation (EU) No 168/2013 of the European Parliament and of the Council of '\n '15 January 2013 on the approval and market surveillance  of  two- or  '\n 'three-wheel  vehicles  and  quadricycles  (OJ  L  60,  2.3.2013,  p.  52);')>]>]\n[<Paragraph children=[<RawText children=('Regulation (EU) No 167/2013 of the European Parliament and of the Council of '\n '5 February 2013 on the approval and market surveillance  of agricultural  '\n 'and  forestry  vehicles  (OJ  L  60,  2.3.2013,  p.  1);')>]>]\n[<Paragraph children=[<RawText children=('Directive  2014/90/EU of  the  European Parliament and of  the Council  of '\n '23 July  2014 on  marine equipment  and repealing  Council  Directive  '\n '96/98/EC  (OJ  L  257,  28.8.2014,  p.  146);')>]>]\n[<Paragraph children=[<RawText children=('Directive (EU) 2016/797 of the European Parliament and of the Council of 11 '\n 'May 2016 on the interoperability of the  rail  system  within  the  '\n 'European  Union  (OJ  L  138,  26.5.2016,  p.  44);')>]>]\n[<Paragraph children=[<RawText children=('Regulation  (EU)  2018/858  of  the  European  Parliament  and  of  the  '\n 'Council  of  30  May  2018  on  the  approval  and market  surveillance  of  '\n 'motor  vehicles  and  their  trailers,  and  of  systems,  components  and  '\n 'separate  technical  units intended for such vehicles, amending Regulations '\n '(EC) No 715/2007 and (EC) No 595/2009 and repealing Directive 2007/46/EC (OJ '\n 'L 151, 14.6.2018, p. 1);')>]>]\n[<Paragraph children=[<RawText children=('Regulation (EU) 2019/2144 of the European Parliament and of the Council of '\n '27 November 2019 on type-approval requirements for  motor  vehicles and '\n 'their  trailers, and systems, components and separate technical units '\n 'intended for such vehicles, as regards their general safety and the '\n 'protection of vehicle occupants and vulnerable road users, amending '\n 'Regulation (EU) 2018/858 of the European Parliament and of the Council and '\n 'repealing Regulations (EC) No  78/2009,  (EC)  No  79/2009  and  (EC)  No  '\n '661/2009  of  the  European  Parliament  and  of  the  Council  and '\n 'Commission  Regulations  (EC)  No  631/2009,  (EU)  No  406/2010,  (EU)  No  '\n '672/2010,  (EU)  No  1003/2010, (EU)  No  1005/2010,  (EU)  No  1008/2010,  '\n '(EU)  No  1009/2010,  (EU)  No  19/2011,  (EU)  No  109/2011,  (EU) No '\n '458/2011, (EU) No 65/2012, (EU) No 130/2012, (EU) No 347/2012, (EU) No '\n '351/2012, (EU) No 1230/2012 and (EU)  2015/166 (OJ  L  325,  16.12.2019,  '\n 'p.  1);')>]>]\n[<Paragraph children=[<RawText children=('Regulation (EU) 2018/1139 of the European Parliament and of the Council of 4 '\n 'July 2018 on common rules in the field  of  civil  aviation  and  '\n 'establishing  a  European  Union  Aviation  Safety  Agency,  and  amending  '\n 'Regulations  (EC) No  2111/2005,  (EC)  No  1008/2008,  (EU)  No  996/2010,  '\n '(EU)  No  376/2014  and  Directives  2014/30/EU  and 2014/53/EU of the '\n 'European Parliament and of the Council, and repealing Regulations (EC) No '\n '552/2004 and (EC) No 216/2008 of the European Parliament and of the Council '\n 'and Council Regulation (EEC) No 3922/91 (OJ L 212, 22.8.2018, p. 1), in so '\n 'far as the design, production and placing on the market of aircrafts '\n 'referred to in Article 2(1), points (a) and (b) thereof, where it concerns '\n 'unmanned aircraft and their engines, propellers, parts and equipment to '\n 'control  them  remotely,  are  concerned.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_132",
    "chunk_content": "List  of  criminal  offences  referred  to  in  Article  5(1),  first  subparagraph,  point  (h)(iii)\nCriminal offences referred  to  in  Article  5(1),  first  subparagraph,  point  (h)(iii):\n[<Paragraph children=[<RawText children='terrorism,'>]>]\n[<Paragraph children=[<RawText children='trafficking in  human beings,'>]>]\n[<Paragraph children=[<RawText children='sexual exploitation of children, and  child pornography,'>]>]\n[<Paragraph children=[<RawText children='illicit  trafficking  in  narcotic  drugs  or  psychotropic  substances,'>]>]\n[<Paragraph children=[<RawText children='illicit  trafficking  in  weapons,  munitions  or  explosives,'>]>]\n[<Paragraph children=[<RawText children='murder, grievous bodily injury,'>]>]\n[<Paragraph children=[<RawText children='illicit  trade  in  human  organs  or  tissue,'>]>]\n[<Paragraph children=[<RawText children='illicit  trafficking  in  nuclear  or  radioactive  materials,'>]>]\n[<Paragraph children=[<RawText children='kidnapping, illegal restraint  or  hostage-taking,'>]>]\n[<Paragraph children=[<RawText children='crimes within the jurisdiction of  the  International  Criminal  Court,'>]>]\n[<Paragraph children=[<RawText children='unlawful seizure of aircraft or  ships,'>]>]\n[<Paragraph children=[<RawText children='rape,'>]>]\n[<Paragraph children=[<RawText children='environmental crime,'>]>]\n[<Paragraph children=[<RawText children='organised or armed robbery,'>]>]\n[<Paragraph children=[<RawText children='sabotage,'>]>]\n[<Paragraph children=[<RawText children=('participation in  a  criminal  organisation  involved  in  one  or  more  '\n 'of  the  offences  listed  above.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_133",
    "chunk_content": "High-risk AI systems referred to in Article 6(2)\nHigh-risk  AI  systems  pursuant  to  Article  6(2)  are  the  AI  systems  listed  in  any  of  the  following  areas:\n[<Paragraph children=[<RawText children=('Biometrics,  in  so  far  as  their  use  is  permitted  under  relevant  '\n 'Union  or  national  law:')>]>]\n(a) remote biometric identification  systems.\nThis shall not include AI systems intended to be used for biometric verification the sole purpose of which is to confirm that  a  specific  natural  person  is  the  person  he  or  she  claims  to  be;\n(b) AI  systems  intended  to  be  used  for  biometric  categorisation,  according  to  sensitive  or  protected  attributes  or characteristics  based  on  the  inference  of  those  attributes  or  characteristics;\n(c) AI  systems  intended  to  be  used  for  emotion  recognition.\n[<Paragraph children=[<RawText children=('Critical  infrastructure:  AI  systems  intended  to  be  used  as  safety '\n 'components  in  the  management  and  operation  of critical  digital  '\n 'infrastructure,  road  traffic,  or  in  the  supply  of  water,  gas,  '\n 'heating  or  electricity.')>]>]\n[<Paragraph children=[<RawText children='Education  and  vocational  training:'>]>]\n(a) AI systems intended to be used to determine access or admission or to assign natural persons to educational and vocational  training  institutions  at  all  levels;\n(b) AI systems intended to be used to evaluate learning outcomes, including when those outcomes are used to steer the  learning  process  of  natural  persons  in  educational  and  vocational  training  institutions  at  all  levels;\n(c) AI systems intended to be used for the purpose of assessing the appropriate level of education that an individual will receive or will be able to access, in the context of or within educational and vocational training institutions at  all  levels;\n(d) AI systems intended to be used for monitoring and detecting prohibited behaviour of students during tests in the context  of or  within  educational  and  vocational  training  institutions  at  all  levels.\n[<Paragraph children=[<RawText children=\"Employment, workers' management and access to self-employment:\">]>]\n(a) AI systems intended to be used for the recruitment or selection of natural persons, in particular to place targeted job  advertisements,  to  analyse  and  filter  job  applications,  and  to  evaluate  candidates;\n(b) AI systems intended to be used to make decisions affecting terms of work-related relationships, the promotion or termination of work-related contractual relationships, to allocate tasks based on individual behaviour or personal traits  or  characteristics  or  to  monitor  and  evaluate  the  performance  and  behaviour  of  persons  in  such relationships.\n[<Paragraph children=[<RawText children=('Access  to  and  enjoyment  of  essential  private  services  and  '\n 'essential  public  services  and  benefits:')>]>]\n(a) AI systems intended to be used by public authorities or on behalf of public authorities to evaluate the eligibility of natural persons for essential public assistance benefits and services, including healthcare services, as well as to grant,  reduce,  revoke,  or  reclaim  such  benefits  and  services;\n(b) AI systems intended to be used to evaluate the creditworthiness of natural persons or establish their credit score, with  the  exception  of  AI  systems  used  for  the  purpose  of  detecting  financial  fraud;\n(c) AI systems intended to be used for risk assessment and pricing in relation to natural persons in the case of  life and health  insurance;\n(d) AI systems intended to evaluate and classify emergency calls by natural persons or to be used to dispatch, or to establish  priority  in  the  dispatching  of,  emergency  first  response  services,  including  by  police,  firefighters  and medical  aid,  as  well  as  of  emergency  healthcare  patient  triage  systems.\n[<Paragraph children=[<RawText children=('Law enforcement, in so far as  their  use  is  permitted  under  relevant  '\n 'Union  or  national  law:')>]>]\n(a) AI systems intended to be used by or on behalf of law enforcement authorities, or by Union institutions, bodies, offices  or  agencies  in  support  of  law  enforcement  authorities  or  on  their  behalf  to  assess  the  risk  of  a  natural person becoming the victim of criminal offences;\n(b) AI systems intended to be used by or on behalf of  law enforcement authorities or by Union institutions, bodies, offices  or  agencies  in  support  of  law  enforcement  authorities  as  polygraphs  or  similar  tools;\n(c) AI systems intended to be used by or on behalf of law enforcement authorities, or by Union institutions, bodies, offices or agencies, in support of law enforcement authorities to evaluate the reliability of evidence in the course of  the  investigation  or  prosecution  of  criminal  offences;\n(d) AI  systems  intended  to  be  used  by  law  enforcement  authorities  or  on  their  behalf  or  by  Union  institutions, bodies,  offices  or  agencies  in  support of  law enforcement  authorities  for  assessing  the  risk of a  natural  person offending or re-offending not solely on the basis of the profiling of natural persons as referred to in Article 3(4) of  Directive  (EU)  2016/680,  or  to  assess  personality  traits  and  characteristics  or  past  criminal  behaviour  of natural  persons  or  groups;\n(e) AI systems intended to be used by or on behalf of  law enforcement authorities or by Union institutions, bodies, offices or agencies in support of law enforcement authorities for the profiling of natural persons as referred to in Article 3(4) of Directive (EU) 2016/680 in the course of the detection, investigation or prosecution of criminal offences.\n[<Paragraph children=[<RawText children=('Migration,  asylum  and  border  control  management,  in  so  far  as  '\n 'their  use  is  permitted  under  relevant  Union  or national  law:')>]>]\n(a) AI systems intended to be used by or on behalf of competent public authorities or by Union institutions, bodies, offices  or  agencies  as  polygraphs  or  similar  tools;\n(b) AI systems intended to be used by or on behalf of competent public authorities or by Union institutions, bodies, offices or agencies to assess a risk, including a security risk, a risk of irregular migration, or a health risk, posed by a  natural  person  who  intends  to  enter  or  who  has  entered  into  the  territory  of  a  Member  State;\n(c) AI systems intended to be used by or on behalf of competent public authorities or by Union institutions, bodies, offices or agencies to assist competent public authorities for the examination of applications for asylum, visa or residence permits and for associated complaints with regard to the eligibility of the natural persons applying for a  status,  including  related  assessments  of  the  reliability  of  evidence;\n(d) AI systems intended to be used by or on behalf of competent public authorities, or by Union institutions, bodies, offices  or  agencies,  in  the  context  of  migration,  asylum  or  border  control  management,  for  the  purpose  of detecting, recognising or identifying natural persons, with the exception of the verification of travel documents.\n[<Paragraph children=[<RawText children='Administration  of  justice  and  democratic  processes:'>]>]\n(a) AI  systems  intended  to  be  used  by  a  judicial  authority  or  on  their  behalf  to  assist  a  judicial  authority  in researching and interpreting facts and the law and in applying the law to a concrete set of facts, or to be used in a  similar  way  in  alternative  dispute  resolution;\n(b) AI  systems  intended  to  be  used  for  influencing  the  outcome  of  an  election  or  referendum  or  the  voting behaviour  of  natural  persons  in  the  exercise  of  their  vote  in  elections  or  referenda.  This  does  not  include  AI systems to the output of which natural persons are not directly exposed, such as tools used to organise, optimise or  structure  political  campaigns  from  an  administrative  or  logistical  point  of  view."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_134",
    "chunk_content": "Technical documentation referred to in Article 11(1)\nThe technical documentation referred to in Article 11(1) shall contain at least the following information, as applicable to the  relevant  AI  system:\n[<Paragraph children=[<RawText children='A general  description of  the  AI  system  including:'>]>]\n(a) its  intended purpose, the name of the provider and the version of the system reflecting its relation to previous versions;\n(b) how the AI system interacts with, or can be used to interact with, hardware or software, including with other AI systems,  that  are  not  part  of  the  AI  system  itself,  where  applicable;\n(c) the  versions  of  relevant  software  or  firmware,  and  any  requirements  related  to version  updates;\n(d) the  description  of  all  the  forms  in  which  the  AI  system  is  placed  on  the  market  or  put  into  service,  such  as software  packages embedded into hardware,  downloads, or  APIs;\n(e) the  description  of  the  hardware  on  which  the  AI  system  is  intended  to  run;\n(f) where  the  AI  system  is  a  component  of  products,  photographs  or  illustrations  showing  external  features,  the marking and internal layout of  those  products;\n(g) a  basic  description  of  the  user-interface  provided  to  the  deployer;\n(h) instructions for use for the deployer, and a basic description of the user-interface provided to the deployer, where applicable;\n[<Paragraph children=[<RawText children=('A detailed  description  of  the  elements  of  the  AI  system  and  of  '\n 'the  process  for  its  development,  including:')>]>]\n(a) the methods and steps performed for the development of the AI system, including, where relevant, recourse to pre-trained systems or  tools provided by third parties and how those were used, integrated or  modified by the provider;\n(b) the design specifications of the system, namely the general logic of the AI system and of the algorithms; the key design  choices  including  the  rationale  and  assumptions  made,  including  with  regard  to  persons  or  groups  of persons in respect of who, the system is intended to be used; the main classification choices; what the system is designed to optimise for, and the relevance of  the different parameters; the description of  the expected output and  output  quality  of  the  system;  the  decisions  about  any  possible  trade-off  made  regarding  the  technical solutions  adopted  to  comply  with  the  requirements  set  out  in  Chapter  III,  Section  2;\n(c) the description of the system architecture explaining how software components build on or feed into each other and integrate into the overall processing; the computational resources used to develop, train, test and validate the AI  system;\n(d) where  relevant,  the  data  requirements  in  terms  of  datasheets  describing  the  training  methodologies  and techniques and the training data sets used, including a general description of these data sets, information about their  provenance, scope and main characteristics; how the data was obtained and selected; labelling procedures (e.g.  for  supervised  learning),  data  cleaning  methodologies  (e.g.  outliers  detection);\n(e) assessment of the human oversight measures needed in accordance with Article 14, including an assessment of the  technical  measures  needed to facilitate the  interpretation  of  the  outputs  of AI  systems  by the  deployers, in accordance with Article 13(3),  point  (d);\n(f) where  applicable,  a  detailed  description  of  pre-determined  changes  to  the  AI  system  and  its  performance, together  with  all  the  relevant  information  related  to  the  technical  solutions  adopted  to  ensure  continuous compliance of  the  AI  system with  the  relevant  requirements  set  out  in  Chapter  III,  Section  2;\n(g) the validation and testing procedures used, including information about the validation and testing data used and their  main  characteristics;  metrics  used  to  measure  accuracy,  robustness  and  compliance  with  other  relevant requirements set out in Chapter III, Section 2, as well as potentially discriminatory impacts; test logs and all test reports dated and signed by the responsible persons, including with regard to pre-determined changes as referred to  under  point  (f);\n(h) cybersecurity  measures  put  in place;\n[<Paragraph children=[<RawText children=('Detailed information about the monitoring, functioning and control of the AI '\n 'system, in particular  with regard to: its  capabilities  and  limitations  '\n 'in  performance,  including  the  degrees  of  accuracy  for  specific  '\n 'persons  or  groups  of persons  on  which  the  system  is  intended  to  '\n 'be  used  and  the  overall  expected  level  of  accuracy  in  relation  '\n 'to  its intended purpose; the foreseeable unintended outcomes and sources of '\n 'risks to health and safety, fundamental rights and  discrimination  in  '\n 'view  of  the  intended  purpose  of  the  AI  system;  the  human  '\n 'oversight  measures  needed  in accordance  with  Article  14,  including  '\n 'the  technical  measures  put  in  place  to  facilitate  the  '\n 'interpretation  of  the outputs  of  AI  systems  by  the  deployers;  '\n 'specifications  on  input  data,  as  appropriate;')>]>]\n[<Paragraph children=[<RawText children=('A description of  the  appropriateness  of  the  performance  metrics  for  '\n 'the  specific  AI  system;')>]>]\n[<Paragraph children=[<RawText children=('A detailed  description  of  the  risk  management  system  in  accordance  '\n 'with  Article  9;')>]>]\n[<Paragraph children=[<RawText children=('A description of  relevant  changes made  by the  provider  to  the  system  '\n 'through  its  lifecycle;')>]>]\n[<Paragraph children=[<RawText children=('A  list  of  the  harmonised  standards  applied  in  full  or  in  part  '\n 'the  references  of  which  have  been  published  in  the Official Journal '\n 'of the European Union ;  where no such harmonised standards have been '\n 'applied, a detailed description of the solutions adopted to meet the '\n 'requirements set out in Chapter III, Section 2, including a list of other '\n 'relevant standards  and  technical  specifications  applied;')>]>]\n[<Paragraph children=[<RawText children=('A copy of  the  EU  declaration  of  conformity  referred  to  in  Article  '\n '47;')>]>]\n[<Paragraph children=[<RawText children=('A  detailed  description  of  the  system  in  place  to  evaluate  the  AI  '\n 'system  performance  in  the  post-market  phase  in accordance with Article '\n '72,  including  the  post-market  monitoring  plan  referred  to  in  '\n 'Article  72(3).')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_135",
    "chunk_content": "EU declaration of conformity\nThe EU declaration of conformity referred to in Article  47,  shall  contain  all  of  the  following  information:\n[<Paragraph children=[<RawText children=('AI system name and type and any additional unambiguous reference allowing '\n 'the identification and traceability of the  AI  system;')>]>]\n[<Paragraph children=[<RawText children=('The name and address of  the  provider  or,  where  applicable,  of  their  '\n 'authorised  representative;')>]>]\n[<Paragraph children=[<RawText children=('A statement that the EU declaration of conformity referred to in Article 47 '\n 'is issued under the sole responsibility of the  provider;')>]>]\n[<Paragraph children=[<RawText children=('A  statement  that  the  AI  system  is  in  conformity  with  this  '\n 'Regulation  and,  if  applicable,  with  any  other  relevant Union law that '\n 'provides for  the  issuing  of  the  EU  declaration  of  conformity  '\n 'referred  to  in  Article  47;')>]>]\n[<Paragraph children=[<RawText children=('Where  an  AI  system  involves  the  processing  of  personal  data,  a  '\n 'statement  that  that  AI  system  complies  with Regulations  (EU)  '\n '2016/679  and  (EU)  2018/1725  and  Directive  (EU)  2016/680;')>]>]\n[<Paragraph children=[<RawText children=('References  to  any  relevant  harmonised  standards  used  or  any  other  '\n 'common  specification  in  relation  to  which conformity is  declared;')>]>]\n[<Paragraph children=[<RawText children=('Where  applicable,  the  name  and  identification  number  of  the  '\n 'notified  body,  a  description  of  the  conformity assessment  procedure  '\n 'performed, and  identification  of  the  certificate  issued;')>]>]\n[<Paragraph children=[<RawText children=('The  place  and  date  of  issue  of  the  declaration,  the  name  and  '\n 'function  of  the  person  who  signed  it,  as  well  as  an indication  '\n 'for,  or  on  behalf of  whom,  that  person  signed,  a  signature.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_136",
    "chunk_content": "Conformity assessment procedure based on internal control\n[<Paragraph children=[<RawText children=('The conformity assessment procedure based on internal control is the '\n 'conformity assessment procedure based on points  2,  3  and  4.')>]>]\n[<Paragraph children=[<RawText children=('The  provider  verifies  that  the  established  quality  management  '\n 'system  is  in  compliance  with  the  requirements  of Article  17.')>]>]\n[<Paragraph children=[<RawText children=('The provider examines the information contained in the technical '\n 'documentation in order to assess the compliance of  the  AI  system  with  '\n 'the  relevant  essential  requirements  set  out  in  Chapter  III,  '\n 'Section  2.')>]>]\n[<Paragraph children=[<RawText children=('The provider also verifies that the design and development process of the AI '\n 'system and its post-market monitoring as  referred  to  in  Article  72  is  '\n 'consistent  with  the  technical  documentation.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_137",
    "chunk_content": "Conformity based on an assessment of  the quality management system and an assessment of  the technical  documentation\n[<Paragraph children=[<RawText children='Introduction'>]>]\nConformity  based  on  an  assessment  of  the  quality  management  system  and  an  assessment  of  the  technical documentation is the conformity assessment procedure based on points 2 to 5."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_138",
    "chunk_content": "2. Overview\nThe  approved  quality  management  system  for  the  design,  development  and  testing  of  AI  systems  pursuant  to Article 17 shall be examined in accordance with point 3 and shall be subject to surveillance as specified in point 5. The technical documentation of  the  AI  system shall  be  examined  in  accordance  with  point  4."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_139",
    "chunk_content": "3. Quality  management system\n3.1. The application  of  the  provider  shall  include:\n(a) the name and address of the provider and, if the application is lodged by an authorised representative, also their name and address;\n(b) the  list  of  AI  systems  covered  under  the  same  quality  management  system;\n(c) the  technical  documentation  for  each  AI  system  covered  under  the  same  quality  management  system;\n(d) the  documentation  concerning  the  quality  management  system  which  shall  cover  all  the  aspects  listed  under Article  17;\n(e) a  description  of  the  procedures  in  place  to  ensure  that  the  quality  management  system  remains  adequate  and effective;\n(f) a  written  declaration  that  the  same  application  has  not  been  lodged  with  any other  notified  body.\n3.2. The quality management system shall be assessed by the notified body, which shall determine whether it satisfies the requirements  referred  to  in  Article  17.\nThe decision  shall  be  notified  to  the  provider  or  its  authorised  representative.\nThe notification shall contain the conclusions of the assessment of the quality management system and the reasoned assessment  decision.\n3.3. The quality management system as approved shall continue to be implemented and maintained by the provider so that  it  remains  adequate  and  efficient.\n3.4. Any intended change to the approved quality management system or the list of AI systems covered by the latter shall be  brought  to  the  attention  of  the  notified  body  by  the  provider.\nThe  proposed  changes  shall  be  examined  by  the  notified  body,  which  shall  decide  whether  the  modified  quality management  system  continues  to  satisfy  the  requirements  referred  to  in  point  3.2  or  whether  a  reassessment  is necessary.\nThe  notified  body  shall  notify  the  provider  of  its  decision.  The  notification  shall  contain  the  conclusions  of  the examination of  the  changes and  the  reasoned  assessment  decision.\n[<Paragraph children=[<RawText children='Control  of  the  technical  documentation.'>]>]\n4.1. In  addition  to  the  application  referred  to  in  point  3,  an  application  with  a  notified  body  of  their  choice  shall  be lodged  by  the  provider  for  the  assessment  of  the  technical  documentation  relating  to  the  AI  system  which  the provider intends to place on the market or put into service and which is covered by the quality management system referred  to  under  point  3.\n4.2. The application  shall  include:\n(a) the  name  and  address  of  the  provider;\n(b) a  written  declaration  that  the  same  application  has  not  been  lodged  with  any other  notified  body;\n(c) the  technical  documentation  referred  to  in  Annex  IV.\n4.3. The  technical  documentation  shall  be  examined  by  the  notified  body.  Where  relevant,  and  limited  to  what  is necessary to fulfil its tasks, the notified body shall be granted full access to the training, validation, and testing data sets  used,  including,  where appropriate and subject to security safeguards, through API or other  relevant technical means and tools enabling remote access.\n4.4. In examining the technical documentation, the notified body may require that the provider supply further evidence or  carry  out  further  tests  so  as  to  enable  a  proper  assessment  of  the  conformity  of  the  AI  system  with  the requirements set out in Chapter III, Section 2. Where the notified body is not satisfied with the tests carried out by the  provider,  the  notified  body  shall  itself  directly  carry  out  adequate  tests,  as  appropriate.\n4.5. Where necessary to assess the conformity of  the high-risk AI  system with the requirements  set out in Chapter III, Section  2,  after  all  other  reasonable  means  to  verify  conformity  have  been  exhausted  and  have  proven  to  be insufficient, and upon a reasoned request, the notified body shall also be granted access to the training and trained models of the AI system, including its relevant parameters. Such access shall be subject to existing Union law on the protection  of  intellectual  property  and  trade  secrets.\n4.6. The decision of the notified body shall be notified to the provider or its authorised representative. The notification shall  contain  the  conclusions  of  the  assessment  of  the  technical  documentation  and  the  reasoned  assessment decision.\nWhere the AI system is in conformity with the requirements set out in Chapter III, Section 2, the notified body shall issue a Union technical documentation assessment certificate. The certificate shall indicate the name and address of the provider, the conclusions of the examination, the conditions (if any) for its validity and the data necessary for the identification  of  the  AI  system.\nThe certificate and its annexes shall contain all relevant information to allow the conformity of the AI system to be evaluated,  and  to  allow  for  control  of  the  AI  system  while  in  use,  where  applicable.\nWhere the AI system is not in conformity with the requirements set out in Chapter III, Section 2, the notified body shall  refuse  to  issue  a  Union  technical  documentation  assessment  certificate  and  shall  inform  the  applicant accordingly,  giving  detailed  reasons  for  its  refusal.\nWhere the AI system does not meet the requirement relating to the data used to train it, re-training of the AI system will  be  needed  prior  to  the  application  for  a  new  conformity  assessment.  In  this  case,  the  reasoned  assessment decision  of  the  notified  body  refusing  to  issue  the  Union  technical  documentation  assessment  certificate  shall contain  specific  considerations  on  the  quality  data  used  to  train  the  AI  system,  in  particular  on  the  reasons  for non-compliance.\n4.7. Any change to the AI system that could affect the compliance of the AI system with the requirements or its intended purpose  shall  be  assessed  by  the  notified  body  which  issued  the  Union  technical  documentation  assessment certificate.  The  provider  shall  inform  such  notified  body  of  its  intention  to  introduce  any  of  the  abovementioned changes, or if it otherwise becomes aware of the occurrence of such changes. The intended changes shall be assessed by the notified body, which shall decide whether those changes require a new conformity assessment in accordance with  Article  43(4)  or  whether  they  could  be  addressed  by  means  of  a  supplement  to  the  Union  technical documentation  assessment  certificate.  In  the  latter  case,  the  notified  body  shall  assess  the  changes,  notify  the provider  of  its  decision  and,  where  the  changes  are  approved,  issue  to  the  provider  a  supplement  to  the  Union technical  documentation  assessment  certificate.\n[<Paragraph children=[<RawText children='Surveillance  of  the  approved  quality  management  system.'>]>]\n5.1. The  purpose  of  the  surveillance  carried  out  by  the  notified  body  referred  to  in  Point  3  is  to  make  sure  that  the provider  duly complies  with  the  terms  and  conditions  of  the  approved  quality  management  system.\n5.2. For  assessment  purposes,  the  provider  shall  allow  the  notified  body  to  access  the  premises  where  the  design, development, testing of  the  AI  systems is  taking  place.  The  provider  shall  further  share  with  the  notified  body  all necessary  information.\n5.3. The notified  body shall carry out  periodic  audits to make sure that the provider  maintains and applies the quality management system and shall provide the provider with an audit report. In the context of those audits, the notified body  may  carry  out  additional  tests  of  the  AI  systems  for  which  a  Union  technical  documentation  assessment certificate  was  issued."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_140",
    "chunk_content": "Information to be submitted upon the registration of high-risk AI systems in accordance with Article  49\nSection  A  -  Information  to  be  submitted  by  providers  of  high-risk  AI  systems  in  accordance  with  Article  49(1) The  following  information  shall  be  provided  and  thereafter  kept  up  to  date  with  regard  to  high-risk  AI  systems  to  be registered  in  accordance  with  Article  49(1):\n[<Paragraph children=[<RawText children='The name, address and contact details  of  the  provider;'>]>]\n[<Paragraph children=[<RawText children=('Where submission of information is carried out by another person on behalf '\n 'of the provider, the name, address and contact  details  of  that  person;')>]>]\n[<Paragraph children=[<RawText children=('The name, address and contact details  of  the  authorised  representative,  '\n 'where  applicable;')>]>]\n[<Paragraph children=[<RawText children=('The AI system trade name and any additional unambiguous reference allowing '\n 'the identification and traceability of the  AI  system;')>]>]\n[<Paragraph children=[<RawText children=('A description of  the  intended  purpose of  the  AI system and of  the  '\n 'components and functions supported through this  AI  system;')>]>]\n[<Paragraph children=[<RawText children=('A basic  and  concise  description  of  the  information  used  by  the  '\n 'system  (data,  inputs)  and  its  operating  logic;')>]>]\n[<Paragraph children=[<RawText children=('The status  of  the  AI  system  (on  the  market,  or  in  service;  no  '\n 'longer  placed  on  the  market/in  service,  recalled);')>]>]\n[<Paragraph children=[<RawText children=('The  type,  number  and  expiry  date  of  the  certificate  issued  by  '\n 'the  notified  body  and  the  name  or  identification number of  that  '\n 'notified  body,  where  applicable;')>]>]\n[<Paragraph children=[<RawText children=('A scanned copy of  the certificate  referred  to in  point  8,  where  '\n 'applicable;')>]>]\n[<Paragraph children=[<RawText children=('Any Member States in which the AI system has been placed on the market, put '\n 'into service or made available in the Union;')>]>]\n[<Paragraph children=[<RawText children=('A copy of  the  EU  declaration  of  conformity  referred  to  in  Article  '\n '47;')>]>]\n[<Paragraph children=[<RawText children=('Electronic  instructions  for  use;  this  information  shall  not  be  '\n 'provided  for  high-risk  AI  systems  in  the  areas  of  law enforcement '\n 'or  migration,  asylum  and  border  control  management referred  to in  '\n 'Annex  III,  points  1,  6  and  7;')>]>]\n[<Paragraph children=[<RawText children='A URL for additional  information (optional).'>]>]\nSection  B  -  Information  to be  submitted  by  providers  of  high-risk  AI  systems  in  accordance  with  Article  49(2)\nThe following information shall  be provided and  thereafter kept up to date  with regard to AI  systems  to  be  registered  in accordance with Article 49(2):\n[<Paragraph children=[<RawText children='The name, address and contact details  of  the  provider;'>]>]\n[<Paragraph children=[<RawText children=('Where submission of information is carried out by another person on behalf '\n 'of the provider, the name, address and contact  details  of  that  person;')>]>]\n[<Paragraph children=[<RawText children=('The name, address and contact details  of  the  authorised  representative,  '\n 'where  applicable;')>]>]\n[<Paragraph children=[<RawText children=('The AI system trade name and any additional unambiguous reference allowing '\n 'the identification and traceability of the  AI  system;')>]>]\n[<Paragraph children=[<RawText children='A description of  the  intended  purpose  of  the  AI  system;'>]>]\n[<Paragraph children=[<RawText children=('The condition or conditions  under  Article  6(3)based  on which the  AI  '\n 'system  is  considered  to  be  not-high-risk;')>]>]\n[<Paragraph children=[<RawText children=('A  short  summary of  the  grounds  on  which  the  AI  system  is  '\n 'considered  to  be  not-high-risk  in  application  of  the procedure under '\n 'Article  6(3);')>]>]\n[<Paragraph children=[<RawText children=('The status  of  the  AI  system  (on  the  market,  or  in  service;  no  '\n 'longer  placed  on  the  market/in  service,  recalled);')>]>]\n[<Paragraph children=[<RawText children=('Any Member States in which the AI system has been placed on the market, put '\n 'into service or made available in the Union.')>]>]\nSection  C  -  Information  to  be  submitted  by  deployers  of  high-risk  AI  systems  in  accordance  with  Article  49(3)\nThe  following  information  shall  be  provided  and  thereafter  kept  up  to  date  with  regard  to  high-risk  AI  systems  to  be registered  in  accordance  with  Article  49(3):\n[<Paragraph children=[<RawText children='The name, address and contact details  of  the  deployer;'>]>]\n[<Paragraph children=[<RawText children=('The name, address and contact details  of  the  person  submitting  '\n 'information  on  behalf of  the  deployer;')>]>]\n[<Paragraph children=[<RawText children=('The URL of  the  entry of  the  AI  system  in  the  EU  database  by  its  '\n 'provider;')>]>]\n[<Paragraph children=[<RawText children=('A summary of the findings of the fundamental rights impact assessment '\n 'conducted in accordance with Article 27;')>]>]\n[<Paragraph children=[<RawText children=('A summary of the data protection impact assessment carried out in accordance '\n 'with Article 35 of Regulation (EU) 2016/679  or  Article  27  of  Directive  '\n '(EU)  2016/680  as  specified  in  Article  26(8)  of  this  Regulation,  '\n 'where applicable.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_141",
    "chunk_content": "Information to be submitted upon the registration of high-risk AI systems listed in Annex III in relation  to  testing  in  real  world  conditions  in  accordance  with  Article  60\nThe following information shall be provided and thereafter kept up to date with regard to testing in real world conditions to be  registered  in  accordance  with  Article  60:\n[<Paragraph children=[<RawText children=('A Union-wide unique single identification number  of  the  testing  in  '\n 'real  world conditions;')>]>]\n[<Paragraph children=[<RawText children=('The name and contact details of the provider or prospective provider and of '\n 'the deployers involved in the testing in real  world  conditions;')>]>]\n[<Paragraph children=[<RawText children=('A brief description of the AI system, its intended purpose, and other '\n 'information necessary for the identification of the  system;')>]>]\n[<Paragraph children=[<RawText children=('A summary of the main characteristics of  the  plan  for  testing  in  real  '\n 'world  conditions;')>]>]\n[<Paragraph children=[<RawText children=('Information  on  the  suspension  or  termination  of  the  testing  in  '\n 'real  world  conditions.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_142",
    "chunk_content": "ANNEX X\nUnion legislative  acts  on  large-scale  IT systems  in  the  area  of  Freedom,  Security  and  Justice"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_143",
    "chunk_content": "1. Schengen Information System\n(a) Regulation (EU) 2018/1860 of the European Parliament and of the Council of 28 November 2018 on the use of the  Schengen  Information  System  for  the  return  of  illegally  staying  third-country  nationals  (OJ  L  312, 7.12.2018, p. 1).\n(b) Regulation  (EU)  2018/1861  of  the  European  Parliament  and  of  the  Council  of  28  November  2018  on  the establishment,  operation  and  use  of  the  Schengen  Information  System  (SIS)  in  the  field  of  border  checks,  and amending the Convention implementing the Schengen Agreement, and amending and repealing Regulation (EC) No 1987/2006 (OJ L 312, 7.12.2018, p. 14).\n(c) Regulation  (EU)  2018/1862  of  the  European  Parliament  and  of  the  Council  of  28  November  2018  on  the establishment, operation and use of the Schengen Information System (SIS) in the field of police cooperation and judicial  cooperation  in  criminal  matters,  amending  and  repealing  Council  Decision  2007/533/JHA,  and repealing  Regulation  (EC)  No  1986/2006  of  the  European  Parliament  and  of  the  Council  and  Commission Decision  2010/261/EU (OJ L 312, 7.12.2018, p. 56)."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_144",
    "chunk_content": "2. Visa  Information  System\n(a) Regulation  (EU)  2021/1133  of  the  European  Parliament  and  of  the  Council  of  7  July  2021  amending Regulations (EU) No 603/2013, (EU) 2016/794, (EU) 2018/1862, (EU) 2019/816 and (EU) 2019/818 as regards the  establishment  of  the  conditions  for  accessing  other  EU  information  systems  for  the  purposes  of  the  Visa Information  System  (OJ  L  248,  13.7.2021,  p.  1).\n(b) Regulation  (EU)  2021/1134  of  the  European  Parliament  and  of  the  Council  of  7  July  2021  amending Regulations  (EC)  No  767/2008,  (EC)  No  810/2009,  (EU)  2016/399,  (EU)  2017/2226,  (EU)  2018/1240,  (EU) 2018/1860,  (EU)  2018/1861,  (EU)  2019/817  and  (EU)  2019/1896  of  the  European  Parliament  and  of  the Council  and  repealing  Council  Decisions  2004/512/EC  and  2008/633/JHA,  for  the  purpose  of  reforming  the Visa  Information  System  (OJ  L  248,  13.7.2021,  p.  11)."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_145",
    "chunk_content": "3. Eurodac\nRegulation (EU) 2024/1358 of the European Parliament and of the Council of 14 May 2024 on the establishment of 'Eurodac' for  the comparison of biometric data in order  to effectively apply Regulations (EU) 2024/1315 and (EU) 2024/1350  of  the  European  Parliament  and  of  the  Council  and  Council  Directive  2001/55/EC  and  to  identify illegally staying third-country nationals and stateless persons and on requests for the comparison with Eurodac data by Member States' law enforcement authorities and Europol for law enforcement purposes, amending Regulations (EU) 2018/1240 and (EU) 2019/818 of the European Parliament and of the Council and repealing Regulation (EU) No 603/2013 of the European Parliament and of the Council (OJ L, 2024/1358, 22.5.2024, ELI: http://data.europa. eu/eli/reg/2024/1358/oj)."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_146",
    "chunk_content": "4. Entry/Exit  System\nRegulation (EU) 2017/2226 of the European Parliament and of the Council of 30 November 2017 establishing an Entry/Exit System (EES) to register entry and exit data and refusal of entry data of  third-country nationals crossing the external borders of the Member States and determining the conditions for access to the EES for law enforcement purposes,  and  amending  the  Convention  implementing  the  Schengen  Agreement  and  Regulations  (EC) No 767/2008 and (EU) No 1077/2011 (OJ L 327, 9.12.2017, p. 20)."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_147",
    "chunk_content": "5. European Travel Information and Authorisation System\n(a) Regulation (EU) 2018/1240 of the European Parliament and of the Council of 12 September 2018 establishing a European  Travel  Information  and  Authorisation  System  (ETIAS)  and  amending  Regulations  (EU) No  1077/2011,  (EU)  No  515/2014,  (EU)  2016/399,  (EU)  2016/1624  and  (EU)  2017/2226  (OJ  L  236, 19.9.2018, p. 1).\n(b) Regulation  (EU)  2018/1241 of  the  European  Parliament  and  of  the  Council  of  12  September  2018  amending Regulation  (EU)  2016/794  for  the  purpose  of  establishing  a  European  Travel  Information  and  Authorisation System (ETIAS) (OJ L 236,  19.9.2018, p.  72).\n[<Paragraph children=[<RawText children=('European Criminal Records Information System on third-country nationals and '\n 'stateless  persons')>]>]\nRegulation  (EU)  2019/816  of  the  European  Parliament  and  of  the  Council  of  17  April  2019  establishing a  centralised  system  for  the  identification  of  Member  States  holding  conviction  information  on  third-country nationals and stateless persons (ECRIS-TCN) to supplement the European Criminal Records Information System and amending Regulation (EU) 2018/1726 (OJ L 135, 22.5.2019, p. 1).\n[<Paragraph children=[<RawText children='Interoperability'>]>]\n(a) Regulation  (EU)  2019/817  of  the  European  Parliament  and  of  the  Council  of  20  May  2019  on  establishing a framework for interoperability between EU information systems in the field of borders and visa and amending Regulations (EC) No 767/2008, (EU) 2016/399, (EU) 2017/2226, (EU) 2018/1240, (EU) 2018/1726 and (EU) 2018/1861  of  the  European  Parliament  and  of  the  Council  and  Council  Decisions  2004/512/EC  and 2008/633/JHA (OJ L 135, 22.5.2019, p. 27).\n(b) Regulation  (EU)  2019/818  of  the  European  Parliament  and  of  the  Council  of  20  May  2019  on  establishing a framework for interoperability between EU information systems in the field of police and judicial cooperation, asylum  and  migration  and  amending  Regulations  (EU)  2018/1726,  (EU)  2018/1862  and  (EU)  2019/816  (OJ L  135,  22.5.2019,  p.  85)."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_148",
    "chunk_content": "Section  1\nInformation to be provided by all providers of  general-purpose AI  models\nThe  technical  documentation  referred  to  in  Article  53(1),  point  (a)  shall  contain  at  least  the  following  information  as appropriate to  the  size  and  risk  profile  of  the  model:\n[<Paragraph children=[<RawText children='A general  description of  the  general-purpose  AI  model  including:'>]>]\n(a) the  tasks  that  the  model  is  intended  to  perform  and  the  type  and  nature  of  AI  systems  in  which  it  can  be integrated;\n(b) the  acceptable  use  policies  applicable;\n(c) the  date  of  release  and  methods  of  distribution;\n(d) the  architecture  and  number  of  parameters;\n(e) the  modality  (e.g.  text,  image)  and  format  of  inputs  and  outputs;\n(f) the  licence.\n[<Paragraph children=[<RawText children=('A detailed description of the elements of the model referred to in point 1, '\n 'and relevant information of the process for  the  development,  including  '\n 'the  following  elements:')>]>]\n(a) the technical means (e.g. instructions of use, infrastructure, tools) required for the general-purpose AI model to be  integrated  in  AI  systems;\n(b) the  design  specifications  of  the  model  and  training  process,  including  training  methodologies  and  techniques, the key design choices including the rationale and assumptions made; what the model is designed to optimise for and the  relevance  of  the  different  parameters,  as  applicable;\n(c) information  on  the  data  used  for  training,  testing  and  validation,  where  applicable,  including  the  type  and provenance of  data  and  curation  methodologies  (e.g.  cleaning,  filtering,  etc.),  the  number  of  data  points,  their scope and main characteristics; how the data was obtained and selected as well as all other measures to detect the unsuitability of  data  sources  and  methods  to  detect  identifiable  biases,  where  applicable;\n(d) the  computational resources  used  to  train  the  model  (e.g.  number  of  floating  point  operations),  training  time, and other  relevant  details  related  to  the  training;\n(e) known or estimated energy consumption of  the model.\nWith regard to point (e), where the energy consumption of the model is unknown, the energy consumption may be based  on  information  about  computational  resources  used."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_149",
    "chunk_content": "Section  2\nAdditional  information  to  be  provided  by  providers  of  general-purpose  AI  models  with  systemic  risk\n[<Paragraph children=[<RawText children=('A  detailed  description  of  the  evaluation  strategies,  including  '\n 'evaluation  results,  on  the  basis  of  available  public evaluation '\n 'protocols  and  tools  or  otherwise  of other  evaluation  methodologies.  '\n 'Evaluation  strategies  shall  include evaluation  criteria,  metrics  and  '\n 'the  methodology on  the  identification  of  limitations.')>]>]\n[<Paragraph children=[<RawText children=('Where applicable, a detailed description of the measures put in place for '\n 'the purpose of conducting internal and/or external  adversarial  testing  '\n '(e.g.  red  teaming),  model  adaptations,  including  alignment  and  '\n 'fine-tuning.')>]>]\n[<Paragraph children=[<RawText children=('Where applicable, a detailed  description of  the  system  architecture  '\n 'explaining  how  software  components  build  or feed  into  each  other  '\n 'and  integrate  into  the  overall  processing.')>]>]"
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_150",
    "chunk_content": "Transparency information referred to in Article 53(1), point (b) - technical documentation for providers of general-purpose AI models to downstream providers that integrate the model into their AI system\nThe information referred to in Article  53(1),  point  (b)  shall  contain  at  least  the  following:\n[<Paragraph children=[<RawText children='A general  description of  the  general-purpose  AI  model  including:'>]>]\n(a) the  tasks  that  the  model  is  intended  to  perform  and  the  type  and  nature  of  AI  systems  into  which  it  can  be integrated;\n(b) the  acceptable  use  policies  applicable;\n(c) the  date  of  release  and  methods  of  distribution;\n(d) how  the  model  interacts,  or  can  be  used  to  interact,  with  hardware  or  software  that  is  not  part  of  the  model itself,  where  applicable;\n(e) the  versions  of  relevant  software  related  to  the  use  of  the  general-purpose  AI  model,  where  applicable;\n(f) the  architecture  and  number  of  parameters;\n(g) the  modality  (e.g.  text,  image)  and  format  of  inputs  and  outputs;\n(h) the  licence  for  the  model.\n[<Paragraph children=[<RawText children=('A description of  the  elements  of  the  model  and  of  the  process  for  '\n 'its  development,  including:')>]>]\n(a) the technical means (e.g. instructions for use, infrastructure, tools) required for the general-purpose AI model to be  integrated  into  AI  systems;\n(b) the modality (e.g. text, image, etc.) and format of  the inputs and outputs and their  maximum size (e.g. context window length, etc.);\n(c) information  on  the  data  used  for  training,  testing  and  validation,  where  applicable,  including  the  type  and provenance of data  and  curation  methodologies."
  },
  {
    "document_name": "AI_ACT-with-image-refs",
    "chunk_id": "AI_ACT-with-image-refs_chunk_151",
    "chunk_content": "Criteria for the designation of general-purpose AI models with systemic risk referred to in Article 51\nFor the purpose of determining that a general-purpose AI model has capabilities or an impact equivalent to those set out in Article  51(1),  point  (a),  the  Commission  shall  take  into  account  the  following  criteria:\n(a) the  number of  parameters  of  the  model;\n(b) the  quality  or  size  of  the  data  set,  for  example  measured  through  tokens;\n(c) the  amount  of  computation  used  for  training  the  model,  measured  in  floating  point  operations  or  indicated  by a  combination  of  other  variables  such  as  estimated  cost  of  training,  estimated  time  required  for  the  training,  or estimated energy consumption for  the training;\n(d) the  input  and  output  modalities  of  the  model,  such  as  text  to  text  (large  language  models),  text  to  image, multi-modality, and the state of  the art thresholds for determining high-impact capabilities for each modality, and the  specific  type  of  inputs  and  outputs  (e.g.  biological  sequences);\n(e) the  benchmarks  and  evaluations  of  capabilities  of  the  model,  including  considering  the  number  of  tasks  without additional  training,  adaptability  to  learn  new,  distinct  tasks,  its  level  of  autonomy  and  scalability,  the  tools  it  has access  to;\n(f) whether  it  has  a  high  impact  on  the  internal  market  due  to  its  reach,  which  shall  be  presumed  when  it  has  been made available  to at  least  10 000  registered  business  users  established  in  the  Union;\n(g) the  number of  registered  end-users."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_0",
    "chunk_content": "Image\nSkadden, Arps, Slate, Meagher\n& Flom LLP and Affiliates"
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_1",
    "chunk_content": "The Americas\nBoston Chicago Houston Los Angeles New York Palo Alto São Paulo Toronto Washington, D.C.\nWilmington"
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_2",
    "chunk_content": "Europe\nBrussels Frankfurt London Moscow Munich\nParis"
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_3",
    "chunk_content": "Asia Pacific\nBeijing Hong Kong Seoul Shanghai Singapore\nTokyo"
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_4",
    "chunk_content": "General\n04  Which Entities Need to Comply With the CCPA?\n05  Who Is a California Resident?\n06  What Is Personal Information?\n09  What Does It Mean to 'Collect' and 'Sell' Personal Information?\n11  Required Training\n12  Summary of Information to Be Included in Privacy Policies\n13  The 'Business Purpose' Exception\n15  The Research Exception\n16  Exemptions From the CCPA\n18  Private Rights of Action and Enforcement by the Attorney General"
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_5",
    "chunk_content": "Compliance Guidelines\n21  General Steps\n22  Right to Access What Information a Business Has Collected\n24  Right to Request Deletion of Information Collected From Consumer\n26  Right to Request Disclosure of Information Collected and Shared\n28  Right to Disclosure of Categories of Information Sold\n30  Right to Opt Out of the Sale of Personal Information\n32  Right to Nondiscrimination\n34  Obligations if Personal Information Is Provided to a Service Provider\nImage\nOverview\nImplementing a data privacy compliance program can be a resource-intensive and time-consuming exercise.\nIn June 2018, California enacted the California Consumer Privacy Act (CCPA or the Act), which constitutes the broadest and most comprehensive privacy law in the United States to date. The CCPA goes into effect January 1, 2020.\nThe CCPA will affect any business collecting or storing data about California residents and may effectively set the floor for nationwide privacy protection, since most businesses will not want to maintain two privacy frameworks one for California consumers and one for all other individuals. In general, the CCPA gives California more information and control over how their personal information is being used, and requires businesses to be more transparent in their handling of that information.\nThe California Legislature passed the CCPA fairly quickly to avert a proposed ballot initiative in November 2018 that sought to impose even more stringent privacy regulations. The rush to pre-empt the ballot initiative left the CCPA with unintended ambiguities that will need to be resolved over time. This is in addition to the CCPA requirement that the state attorney general develop further guidance in certain key areas. To that end, the attorney general has already begun holding a series of public forums to solicit input. As California's 2018 legislative session drew to a close, the state passed its first amendment to the CCPA. In addition to clarifying some points in the law, the amendment delayed the requirement for the California attorney general to adopt implementing regulations, from January 1, 2020, to July 1, 2020. Enforcement actions may not be brought by the attorney general under the CCPA until the earlier of July 1, 2020, or six months after the publication of final regulations.\nGiven the CCPA's ambiguities and that the law is not effective until January 1, 2020, with any enforcement actions likely delayed until a few months after that, it may be tempting for companies to put off developing compliance programs and procedures until late 2019. However, as companies learned when seeking to come into compliance with the European Union's General Data Protection Regulation (GDPR), implementing a data privacy compliance program can be a resource-intensive and time-consuming exercise, especially for businesses with\ndecentralized methods for handling personal information. For companies that have gone through a GDPR compliance program, certain processes and procedures that were developed will have applicability to the CCPA. However, there is no one-to-one match correlation between the GDPR and the CCPA. While in many cases the GDPR imposes more onerous requirements, the CCPA has some unique requirements and also defines personal information more broadly.\nIn this CCPA compliance guide, we set forth steps that companies should be taking throughout 2019 to prepare for the CCPA. Although there are, as noted, ambiguities that need to be clarified and guidance to be issued by the attorney general, the steps outlined in this guide will be relevant regardless of any incremental changes to the CCPA in 2019.\nFinally, while this guide will be a useful tool for businesses, there can be no substitution for examining the wording of the CCPA itself, including the definitions, since many key provisions are embodied within the defined terms.\nImage\nImage\nWhich Entities Need to Comply With the CCPA?\nThe CCPA applies to any for-profit entity that (i) does business in California, (ii) collects personal information of California residents (or has such information collected on its behalf), (iii) determines on its own or jointly with others the purpose and means of processing that information, and (iv) meets one or more of the following criteria:\nhas annual gross revenues in excess of $25 million, adjusted for inflation;\nannually buys, receives for a commercial purpose, sells or shares the personal information of 50,000 or more consumers, households or devices; or\nderives 50 percent or more of its annual revenues from selling consumers' personal information.\nIn this guide, we refer to an entity that meet the foregoing criteria as a 'Business,' which is the term used in the CCPA.\nThe CCPA defines doing business in California broadly. Indeed, the sole exception is a case where 'every aspect' of commercial conduct 'takes place wholly outside of California.' 1 For example, if a California resident provided information while visiting a retail store in Florida that does not conduct business in California, the CCPA would not apply to that transaction unless the Florida business proceeded to sell that information in California.\nNote that the territorial reach of the CCPA is different from the approach used by the GDPR. For example, a California-based business that processes data for customers located in another country would not need to comply with the CCPA with respect to such customer data simply because the company is located in California.\nImage"
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_6",
    "chunk_content": "Who Is a California Resident?\nA California resident, referred to as a 'Consumer' in the CCPA, is anyone who meets the definition of 'resident' as defined under the California tax provisions. 2 While the CCPA uses the term 'Consumer,' Businesses should assume that employees are also swept up in the CCPA's requirements.\nIn general, the California tax provision defines a California resident as (i) every individual who is in California for other than a temporary or transitory purpose, and (ii) every individual who is domiciled in California but is outside California for a temporary or transitory purpose. Given this second prong, dividing a Consumer base between those who logged into a site from a computer in California and those who did not is not sufficient.\n1 Whether or not a purpose should be considered 'temporary or transitory in character' largely depends 'upon the facts and circumstances of each particular case.' Given the effort required to determine if a Consumer is only temporarily in or out of California, Businesses will likely adopt a broad approach to who is a Consumer.\nImage"
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_7",
    "chunk_content": "What Is Personal Information?\nPerhaps the most important definition in the CCPA is that of 'Personal Information,' since all of the CCPA requirements emanate from whether a Business is collecting or processing such information. The CCPA definition is very broad, surpassing in some respects what is covered by the GDPR. Given its importance, we have replicated the CCPA definition below, folding in cross-references where applicable. Note that the list of categories is not exhaustive and that any one 'match' satisfies the definition. For example, an email address that includes a full name and a company name ( e.g ., John. Doe@Acme.com) could be personal information on its own.\nPersonal Information means information that identifies, relates to, describes, is capable of being associated with or could reasonably be linked, directly or indirectly, with a particular consumer or household.\nPersonal Information includes, but is not limited to, the following if it identifies, relates to, describes, is capable of being associated with or could be reasonably linked, directly or indirectly, with a particular consumer or household:\n Identifiers such as a real name, alias, postal address, unique personal identifier, online identifier, Internet Protocol address, email address, account name, social security number, driver's license number, passport number or other similar identifiers.\nCompliance Guide Note: A 'unique personal identifier' means a persistent identifier that can be used to recognize a Consumer, a Family or a Device that is linked to a Consumer or Family, over time and across different services, including, but not limited to, a device identifier; an Internet Protocol address; cookies, beacons, pixel tags, mobile ad identifiers or similar technology; customer number, unique pseudonym or user alias; telephone numbers, or other forms of persistent or probabilistic identifiers that can be used to identify a particular consumer or device. 'Family' means a custodial parent or guardian and any minor children over which the parent or guardian has custody. 'Device' means any physical object that is capable of connecting to the Internet, directly or indirectly, or to another device.\nImage\nSignature, physical characteristics or description, telephone number, state identification card number, insurance policy number, employment, employment history, bank account number, credit card number, debit card number or any other financial information, medical information or health insurance information."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_8",
    "chunk_content": "Compliance Guide Note:\n-The foregoing categories of Personal Information are those described in subdivision (e) of Section 1798.80 (which deals with Personal Information that is no longer required and should be destroyed) and that do not otherwise overlap with the CCPA.\n-'Health insurance information' is defined as a Consumer's insurance policy number or subscriber identification number, any unique identifier used by a health insurer to identify the Consumer or any information in the Consumer's application and claims history, including any appeals records if the information is linked or reasonably linkable to a Consumer or household (including via a device, by a Business or by a service provider).\n Characteristics of protected classifications under California or federal law.\n Commercial information, including records of personal property, products or services purchased, obtained, or considered, or other purchasing or consuming histories or tendencies.\nImage\n Biometric information.\nCompliance Guide Note: 'Biometric information' is defined as an individual's physiological, biological or behavioral characteristics, including an individual's DNA, that can be used, singly or in combination with each other or with other identifying data, to establish individual identity. Biometric information includes, but is not limited to, imagery of the iris, retina, fingerprint, face, hand, palm, vein patterns and voice recordings, from which an identifier template, such as a faceprint, a minutiae template or a voiceprint, can be extracted, and keystroke patterns or rhythms, gait patterns or rhythms, and sleep, health or exercise data that contain identifying information.\n Internet or other electronic network activity information, including, but not limited to, browsing history, search history and information regarding a consumer's interaction with an internet website, app or advertisement.\nImage\n Geolocation data.\nImage\n Audio, electronic, visual, thermal, olfactory or similar information.\nImage\n Professional or employment-related information.\n1  Education information, defined as information that is not publicly available personally identifiable information as defined in the Family Educational Rights and Privacy Act. 3\n3 20 U.S.C. Section 1232g, 34 C.F.R. Part 99.\n\nImage\n\nInferences drawn from any of the information identified in this subdivision to create a profile about a consumer reflecting the consumer's preferences, characteristics, psychological trends, predispositions, behavior, attitudes, intelligence, abilities and aptitudes.\nNote that while the concept of 'household' is included in certain categories of Personal Information, that term is itself not defined. It remains unclear whether, for example, two unrelated individuals sharing an apartment would be deemed a 'household.' We expect further guidance from the attorney general as to how this term is to be understood."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_9",
    "chunk_content": "Exceptions to the Personal Information Definition\nInformation that is publicly available ( i.e. , lawfully made available from federal, state or local government records) is not covered by the CCPA provided the use is compatible with the purpose for which the data is maintained and made available in the government records. Biometric information collected about a Consumer without the Consumer's knowledge is not deemed 'publicly available.'\nAn important exception to the definition of Personal Information is information that is deidentified or part of aggregate consumer information.\nImage\n ' Deidentified ' means information that cannot reasonably identify, relate to, describe, be capable of being associated with or be linked, directly or indirectly, to a particular Consumer, provided that a Business that uses deidentified information (i) has implemented technical safeguards that prohibit reidentification of the consumer to whom the information may pertain, (ii) has implemented business processes that specifically prohibit reidentification of the information, (iii) has implemented business processes to prevent inadvertent release of deidentified information, and (iv) makes no attempt to reidentify the information. The challenge for many Businesses will be determining whether information cannot reasonably 'be capable of' being associated with a particular Consumer, directly or indirectly, particularly at a time when advances in data analytics are making it easier to recreate an individual's identity from disparate data elements.\n ' Aggregate consumer information ' is defined as information that relates to a group or category of Consumers, from which individual Consumer identities have been removed, and that is not linked or reasonably linkable to any Consumer or household, including via a device.\nImage\nWhat Does It Mean to 'Collect' and 'Sell' Personal Information?\nWhether or not information has been 'collected' triggers a number of CCPA requirements. Here, too, the CCPA adopts a broad definition.\nCollection is defined as 'buying, renting, gathering, obtaining, receiving, or accessing any personal information pertaining to a Consumer by any means.' Collecting also includes receiving information from a Consumer 'either actively or passively, or by observing the consumer's behavior.'\nA 'sale' of Personal Information under the CCPA is defined broadly to include the 'selling, renting, releasing, disclosing, disseminating, making available, transferring, or otherwise communicating orally, in writing, or by electronic or other means' the Personal Information of a Consumer to another business or third party 'for monetary or other valuable consideration.'\nThis broad definition suggests that if Personal Information is provided as part of a larger business relationship, a 'sale' may have occurred even if no amounts are paid directly for the data itself. In addition, a website may be 'selling' Personal Information by passing such information to third-party ad networks through cookies."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_10",
    "chunk_content": "The CCPA enumerates certain exceptions to what would be deemed a sale, including when:\n a Consumer uses or directs the Business to intentionally disclose Personal Information to a third party. An 'intentional' interaction occurs when the Consumer intends to interact with the third party via one or more deliberate actions. Hovering over a piece of content or closing it does not qualify as a 'deliberate action';\n a Business shares a Consumer identifier to alert a third party of a Consumer's opt-out decision;\n Personal Information is shared with a third party to perform a 'business purpose' (explained below) and:\n-the Business has provided notice of this sharing and the opt-out right (as described below); and\n-the third party does not further collect, sell or use the Personal Information except as necessary to perform the business purpose;\n the Personal Information is an asset that is part of a merger, acquisition, bankruptcy or other transaction in which the third party assumes control of all or part of the Business, provided the Business complies with the CCPA disclosure requirements relating to the disclosure of information collected or sold (discussed below). If the acquirer plans to alter how it will use or share the Personal Information in a manner materially inconsistent with the promises made at the time of collection, it must provide prior notice of the new practices to the Consumer and include a 'prominent and robust' notice so the Consumer can opt out. Note that the CCPA also warns Businesses that material, retroactive privacy policy changes must not violate California's Unfair Competition Law - a statement apparently designed to address Businesses that want to make significant changes to a privacy policy in light of an impending deal.\nImage"
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_11",
    "chunk_content": "Required Training\nA Business is required to ensure that individuals responsible for handling Consumer inquiries about the Business' privacy practices or CCPA compliance are informed about the requirements below, and how to direct Consumers to exercise these rights.\nA Business should establish a documented training program to satisfy this requirement:\n Ensure designated personnel understand how to instruct Consumers to exercise their rights under the CCPA related to:\n-disclosure of Personal Information collected by the Business;\n-disclosure of Personal Information sold by the Business; and\n-opting out of the sale of their Personal Information.\n Ensure designated personnel understand the general CCPA obligations of the business related to:\n-nondiscrimination related to Consumers who exercise their CCPA rights;\n-'- disclosure obligations of the business, including duties to make available two or more methods for Consumers to make requests, deliver the required information to a Consumer within 45 days (and when an extension exception may apply), confirm a Verifiable Consumer Request (defined on page 22), and identify by category the Personal Information collected, sold or disclosed about the Consumer for a business purpose in the preceding 12 months; and\n-general CCPA compliance obligations of the business, including duties to: provide a clear and conspicuous opt-out link; provide a description of Consumer opt-out rights; effectuate and comply with opt-out requests in business systems; respect opt-out requests for 12 months before requesting that the Consumer authorize a sale; and permit a designated person to opt out on the Consumer's behalf.\nImage"
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_12",
    "chunk_content": "Summary of Information to Be Included in Privacy Policies\nUnder the CCPA, certain information needs to be included in a Business' privacy policy and in any California-specific description of consumers' privacy rights. If a Business does not maintain such policies, this information needs to be included somewhere on its website. Note that this information must be updated at least once every 12 months. The following is required:\n one or more designated methods for submitting requests permitted under the CCPA;\n a description of a Consumer's rights to:\n-request disclosure of information collected;\n-request disclosure of information sold;\n-nondiscrimination relating to Consumers who exercise CCPA rights; and\n-opt out, along with a separate link to the 'Do Not Sell My Personal Information' opt-out page;\n a list of the categories (by reference to the CCPA enumerated category) of Personal Information the Business has collected about Consumers in the preceding 12 months; and\n two separate lists of categories (by reference to the CCPA enumerated category) of information the Business has (i) sold or (ii) disclosed for a business purpose, each within the preceding 12 months or, if the Business has not done so, disclosing that fact.\nImage"
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_13",
    "chunk_content": "The 'Business Purpose' Exception\nThe CCPA refers a number of times to the idea of a 'business purpose.' It is important to note that a 'business purpose' use is not exempt from CCPA requirements. Such use must still be disclosed to a Consumer upon a valid request and be disclosed in a Business' privacy policy. However, certain CCPA obligations do not apply when Personal Information is disclosed for a business purpose. For example, a Consumer cannot 'opt out' of a disclosure done for a business purpose, and the age restrictions discussed below do not apply to such disclosures.\nA 'business purpose' means the Personal Information is being used for the Business' or a service provider's operational purposes, or other purposes disclosead to the Consumer, where the use is (i) 'reasonably necessary and proportionate' to achieve the operational purpose for which it was collected or processed, or (ii) for another operational purpose that is compatible with the context in which it was collected.\nThe CCPA provides a list of what constitutes a 'business purpose.' Note that this list does not start with the word 'including,' suggesting it is exhaustive:\n auditing related to a current interaction with the Consumer (such as counting ad impressions and verifying positioning and quality of ad impressions);\n detecting security incidents, protecting against malicious, deceptive, fraudulent or illegal activity, and prosecuting those responsible for that activity;\n debugging errors that impair functionality;\n short-term, transient use, provided the Personal Information (i) is not disclosed to another third party, and (ii) is not used to build a profile about a Consumer or alter their individual experience outside the current interaction (for example, the contextual customization of ads);\nImage\n\nperforming services such as maintaining or servicing accounts, providing customer service, processing or fulfilling orders and transactions, verifying customer information, processing payments, providing financing, providing advertising or marketing services, providing analytic services, or providing similar services on behalf of the Business or service provider;\n undertaking internal research for technological development and demonstration; and\n undertaking activities to verify or maintain the quality or safety of, or upgrade or enhance, a Business' service or device.\nImage"
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_14",
    "chunk_content": "The Research Exception\nA Business may retain Personal Information despite a Consumer's valid deletion request where that action would render impossible or seriously impair research goals. The retained Personal Information must be necessary to engage in public or peer-reviewed scientific, historical or statistical research in the public interest.\nFor this exception to apply, the business must have initially obtained informed Consumer consent for this purpose, and the research must otherwise comply with all other applicable ethics and privacy laws. In addition, research with Personal Information must be:\n compatible with the business purpose for which the Personal Information was collected;\n subsequently pseudonymized and deidentified, or deidentified in the aggregate, such that the information cannot reasonably identify, relate to, describe, be capable of being associated with or be linked, directly or indirectly, to a particular Consumer;\n made subject to technical safeguards that prohibit reidentification of the Consumer to whom the information may pertain;\n subject to business processes that specifically prohibit reidentification of the information;\n made subject to business processes to prevent inadvertent release of deidentified information;\n protected from any reidentification attempts;\n used solely for research purposes that are compatible with the context in which the Personal Information was collected;\n not be used for any commercial purpose; and\n subjected by the business conducting the research to additional security controls limiting access to the research data to only those individuals in a business as are necessary to carry out the research purpose.\nImage"
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_15",
    "chunk_content": "Exemptions From the CCPA\nAlthough the CCPA contains a number of broad requirements, there are certain exceptions to its application that should be noted. Specifically, the obligations imposed by the CCPA do not restrict a Business' ability to:\n comply with federal, state or local laws;\n comply with a civil, criminal or regulatory inquiry, investigation, subpoena or summons by federal, state or local authorities;\n cooperate with law enforcement agencies concerning conduct or activity that the business, service provider or third party reasonably and in good faith believes may violate federal, state or local law;\n exercise or defend legal claims;\n collect, use, retain, sell or disclose consumer information that is deidentified or aggregate consumer information (see above for how 'deidentified' and 'aggregate consumer information' are defined); or\n collect or sell a consumer's Personal Information if every aspect of that commercial conduct takes place wholly outside of California.\nA Business also does not need to honor a request to disclose information collected or sold where it would violate an evidentiary privilege under California law. A Business can also provide the Personal Information of a Consumer to a person covered by an evidentiary privilege under California law, as part of a privileged communication.\nAdditionally, the CCPA does not apply to:\n medical information governed by the California Confidentiality of Medical Information Act (CMIA), or protected health information collected by a covered entity or business associate governed by the privacy, security and breach notification rules established pursuant to the Health Insurance Portability and Accountability Act (HIPAA) and the Health Information Technology for Economic and Clinical Health Act (HITECH);\n a provider of health care governed by the CMIA or a covered entity governed by HIPAA, to the extent the provider or covered entity maintains patient information in the same manner as it protects medical information or protected health information under HIPAA and HITECH;\n information collected as part of a clinical trial subject to the Federal Policy for the Protection of Human Subjects (also known as the Common rule) pursuant to good clinical practice guidelines issued by the International Council for Harmonisation or pursuant to human subject protection requirements of the U.S. Food and Drug Administration;\n the sale of Personal Information to or from a consumer reporting agency if the information is to be reported in, or used to generate, a consumer report, and use of that information is limited by the federal Fair Credit Reporting Act;\n personal information that is collected, processed, sold or disclosed pursuant to the federal Gramm-Leach-Bliley Act (GLB) and implementing regulations, or the California Financial Information Privacy Act (FIPA); and\n personal information that is collected, processed, sold or disclosed pursuant to the Driver's Privacy Protection Act of 1994 (DPPA).\nNote that the carve-outs for information collection under GLB, FIPA or DPPA do not apply to the right to bring a private action for a data security breach (as described below).\nImage"
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_16",
    "chunk_content": "Private Rights of Action and Enforcement by the Attorney General\nThe CCPA provides for both a limited private right of action for Consumers and more robust enforcement capabilities for the California attorney general.\n12"
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_17",
    "chunk_content": "Private Right of Action\nAlthough there is no broad private right of action for CCPA violations, a Consumer may bring such an action against a Business where the Consumer's nonencrypted or nonredacted personal information is subject to an unauthorized access and exfiltration, theft or disclosure. Significantly, for purposes of this private right of action, personal information is defined using the narrower definition for that term in the California law that deals with securing personal information 4 and not the very broad CCPA definition. Under the narrower definition, personal information is generally limited to name plus Social Security number, driver's license, financial account number (with passcode), medical information and health insurance information.\nIn order for a private right of action to arise under the CCPA, an incident must result from the Business' failure to implement and maintain 'reasonable security procedures and practices appropriate to the nature of that information.' Although the CCPA provides no guidance on what would be deemed 'reasonable,' California law already required reasonable data security measures, 5 and the attorney general's 2016 California Data Breach Report listed 20 data security controls from the Center for Internet Security that serve as a minimum baseline for an information security program. Businesses can assume that these standards would apply equally to the security requirements under the CCPA and should consider them in light of the nature of the Personal Information the Business holds.\nA Consumer may recover any of the following through a civil action:\n statutory damages in an amount of $100 to $750 per consumer per incident, or actual damages (whichever is greater);\nImage\n\nImage\ninjunctive or declaratory relief; and\n any other relief the court deems proper.\nIn assessing statutory damages, the CCPA directs a court to consider: (i) the nature and seriousness of the misconduct, (ii) the number of violations, (iii) the persistence of the misconduct, (iv) the length of time over which the misconduct occurred, (v) the willfulness of the defendant's misconduct, and (vi) the defendant's assets, liabilities and net worth.\nPrior to filing an action for statutory damages, the Consumer must provide the Business with 30 days' written notice identifying the specific provisions of the CCPA allegedly violated. If the violation is curable, the Business cures the violation within 30 days and provides the Consumer with an express written statement to that effect, and no additional violations have occurred, the Consumer may not initiate an action. However, no such notification is required if the Consumer suffered actual pecuniary damages. If a Business breaches its written statement to the Consumer and continues to violate the CCPA, the Consumer may initiate an action against the Business to enforce the written statement, along with all other remedies under the CCPA. It is important to note that the original draft of the CCPA seemed to allow a private right of action for any violation of the CCPA, in which case this notice provision made sense. However, a subsequent amendment clarified that the only private cause of action is for the security breach described above. It is not clear how this notice and cure provision would apply in the case of a security breach.\nThis private right of action will go into effect on January 1, 2020. Companies should carefully evaluate their security programs, particularly in light of the 2016 California Data Breach Report; monitor the compliance of their vendors; and consider what personal information is not encrypted or redacted."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_18",
    "chunk_content": "Attorney General Enforcement\nThe California attorney general has sole authority to bring civil actions based on general violations of the CCPA requirements. The attorney general is required to give a Business 30 days to cure a violation before an action can be brought. Once this period has passed, if the violation is not cured, the attorney general may seek:\nImage\n an injunction; and\nImage\n a civil penalty of no more than $2,500 for each violation, or $7,500 for each intentional violation of the CCPA.\nThese funds will be deposited in the newly created Consumer Privacy Fund, which is intended to offset costs incurred by the courts and the attorney general in connection with the CCPA.\nImage\nImage"
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_19",
    "chunk_content": "Create a Data Map\nIn order to comply with many of the CCPA's requirements, a Business must first have ready access to certain facts about the Personal Information it collects. This includes:\n what Personal Information it has collected about a Consumer (both by 'category' and specific information), taking into account the broad definition of 'collection' noted above;\n the source of that Personal Information ( e.g ., did the Business collect it directly or obtain it from a third party);\n-If from a third party, is there an agreement with that party as to Personal Information use or collection?;\n how that Personal Information was collected ( e.g ., as part of an online application, in the course of a sales transaction, as part of a marketing campaign, etc.);\n where that Personal Information is stored and when it is deleted;\n how Personal Information is used by the Business and who has the authority to determine or change that use;\n what Personal Information, if any, was 'sold' to a third party (including the identity of those third parties, the method of 'sale' and what rights they were granted in the Personal Information), taking into account the broad definition of a 'sale' noted above;\n whether the business knows, or can reasonably ascertain, the age of the Consumer; and\n whether the Consumer has any type of account with the Business.\nA best practice to gather and sort this information is by creating a 'data map' that traces what Personal Information is ingested by the company and how it is 'collected,' used, processed, stored and 'sold.' While there are a variety of ways to organize a data map, most Businesses will find that organizing this information in a way that mirrors how the Businesses itself is organized will capture the necessary data."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_20",
    "chunk_content": "Document Processes and Procedures\nWhile the CCPA does not require that a Businesses document its compliance processes and procedures, it is a best practice to do so. Most Businesses will find it challenging to comply with the CCPA's requirements without written policies and procedures in place. In addition, if a Business needs to defend its compliance activities in a litigation or enforcement action, it will be important to have documentation to show the steps the Business takes in general, and how it addressed the specific issue at hand."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_21",
    "chunk_content": "Right to Access What Information a Business Has Collected\nA Consumer has a right to request disclosure of the categories and specific pieces of Personal Information the Business has collected about the Consumer. The reference to 'categories' are those set forth in the definition of Personal Information.\nSubmission Options: The Business must make available to Consumers two or more designated methods for submitting requests, including, at a minimum, a toll-free telephone number, and if the Business maintains a website, a website address.\nVerifiable Consumer Request: Businesses must only provide this information after receipt of a Verifiable Consumer Request ( VCR ).\n-A 'Verifiable Consumer Request' means a request where a Business can verify that the Consumer making the request is the Consumer about whom the business has collected Personal Information or is a person authorized by the Consumer to act on such Consumer's behalf. The attorney general will need to promulgate guidance on what constitutes a VCR, although the Act suggests that a Business can deem a request from a Consumer who is already logged into a service to be verified.\nResponse Time: Business must respond to a VCR by mail or electronically within 45 days (which can be extended for an additional 45 days upon notice to the consumer). The Business needs to inform the Consumer of any such extension within 45 days of receipt of the request, together with the reasons for the delay. Note: In a different section, the CCPA states the response to any VCR can be extended for an additional 90 days. It is unclear whether this is in addition to the two 45 day periods noted here.\nPortability Format: The Personal Information, if provided electronically, should be in a portable and in a readily usable format that allows the consumer to transmit this information from one entity to another entity 'without hindrance.'\nMethod to Deliver the Information: If the Consumer has an account with the Business the Personal Information should be delivered through that account. If the Consumer does not have such an account, it can be delivered by mail or electronically at the Consumer's option. Note that a Business cannot require a consumer to create an account in order to submit a VCR.\nApplicable Time Period: There is no obligation to provide this information to a Consumer more than twice in a 12-month period, and the information provided need only cover the 12-month period prior to the VCR."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_22",
    "chunk_content": "Compliance Recommendations\nImage\n Create and make available to Consumers the Submission Options noted above.\n Establish a means to establish a request is a proper VCR. As noted, additional guidance is required from the attorney general as to what this will require.\n Create a process to readily access the specific Personal Information the Business has about each Consumer. This includes knowing what Personal Information is held and what 'category' it falls into; where it is stored; and having the ability to extract it.\n Create a tracking system to ensure compliance with the Response Time and that the request complies with the Applicable Time Period.\n Create a means to provide requested Personal Information in a portable and readily usable format.\n Create a tracking system of each access request and how it was handled to be able to demonstrate compliance."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_23",
    "chunk_content": "Right to Request Deletion of Information Collected From Consumer\nA Consumer has a right to request the Business delete Personal Information that the Business has collected about them. Note that the CCPA does not currently specify what actions are sufficient to constitute 'deletion.'\nSubmission Options: The required Submission Options are the same as noted in the 'right to access' section above.\nExceptions: Deletion is not required where the Personal Information is necessary to:\n-complete the transaction for which the Personal Information was collected; provide a good or service requested by the Consumer or reasonably anticipated within the context of a Business' ongoing relationship with the Consumer; or otherwise perform a contract between the Business and a Consumer;\n-detect security incidents, protect against malicious, deceptive, fraudulent or illegal activity, or prosecute those responsible for that activity;\n-debug and to identify and repair errors that impair functionality;\n-exercise or ensure free speech or other legal rights;\n-comply with the California Electronic Communications Privacy Act;\n-engage in certain research in the public interest that adheres to all other applicable ethics and privacy laws, when deletion is likely to render impossible or seriously impair such research, if the Consumer has provided informed consent;\n-undertake internal uses that are reasonably aligned with the expectations of the Consumer's relationship with the Business;\n-comply with a legal obligation; and\n-otherwise undertake internal uses in a lawful manner that are compatible with the context in which the Consumer provided the information.\nResponse Time: The Response Time is the same as noted in the 'right to access' section above.\nNotification to Service Providers: The Business must also direct any service provider to delete the applicable Personal Information.\nNotice to Consumers: The Business must inform Consumers of their right to request the deletion of their Personal Information."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_24",
    "chunk_content": "Compliance Recommendations\nImage\n Create and make available to Consumers the Submission Options noted above.\n Establish a means to determine whether a request is a proper VCR. As noted, additional guidance is required from the attorney general as to what this will require.\n Create a tracking system to ensure compliance with the Response Time.\n Establish a process to determine if one of the exceptions to the deletion right noted above applies.\n Create a process to readily access the specific Personal Information the Business has about each Consumer, and develop a means to delete that Personal Information.\n Provide notice to the Consumer about the right to request deletion and the process for making a request, either in a privacy policy or on the Business' website.\n Have the ability to identify service providers who might have received the Personal Information, and develop procedures to effectuate deletion by those providers.\n-Ensure that any agreements with service providers include this obligation.\n Create a tracking system of each deletion request and how it was handled to be able to demonstrate compliance."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_25",
    "chunk_content": "Right to Request Disclosure of Information Collected and Shared\nA Consumer who has made a proper VCR has a right to request a Business that has collected Personal Information about the Consumer to provide details relating to certain aspects of the Business' data practices. Specifically, a Consumer can request disclosure of: (i) categories of Personal Information collected about that Consumer in the prior 12 months, (ii) the categories of sources from which the Personal Information is collected, (iii) the business/commercial purpose for collecting and selling Personal Information, (iv) categories of third parties with whom the Business shares Personal Information, and (v) specific pieces of Personal Information collected about the Consumer. Note that the first and last categories overlap with the right to access described above.\nSubmission Options: The required Submission Options are the same as noted in the 'right to access' section above.\nResponse Time: The Response Time is the same as noted in the 'right to access' section above.\nApplicable Time Period: The Applicable Time Period is the same as noted in the 'right to access' section above.\nNotice to Consumers: The Business must provide a list of the categories of Personal Information it has collected about Consumers in the preceding 12 months either within its privacy policy or, if it does not have a privacy policy, on its website. This information needs to be updated once every 12 months.\nLimitations: A Business is not required to retain Personal Information about a Consumer collected for a single one-time transaction if that information would not normally be retained. Nor is it required to reidentify data that, in the ordinary course of business, is not maintained in a manner that would be considered Personal Information."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_26",
    "chunk_content": "Compliance Recommendations\nImage\n Create and make available to Consumers the Submission Options noted above.\n Establish a means to determine whether a request is a proper VCR. As noted, additional guidance is required from the attorney general as to what this will require.\n Create a process to readily access the specific Personal Information the Business has about each Consumer to satisfy this disclosure requirement.\n Create a tracking system to ensure compliance with the Response Time and that the request complies with the Applicable Time Period.\n Create and post a list of the categories of Personal Information collected about Consumers in the preceding 12 months either within the Business' privacy policy or, if the Business does not have a privacy policy, on its website. Establish a process to update this information once every 12 months.\n Create a tracking system of each disclosure request and how it was handled to be able to demonstrate compliance."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_27",
    "chunk_content": "Right to Disclosure of Categories of Information Sold\nA Consumer who has made a proper VCR has a right to request that a Business that sells the Consumer's Personal Information or discloses it for a business purpose provide an itemized list of the categories of Personal Information (i) collected about the Consumer, (ii) sold about the Consumer (including categories of third parties to whom the information was sold, by category or categories of Personal Information for each third party), and (iii) disclosed about the Consumer for a business purpose. Note the broad definitions of 'collected' and 'sold' discussed above.\nSubmission Options: The required Submission Options are the same as noted in the 'right to access' section above.\nApplicable Time Period: The Applicable Time Period is the same as noted in the 'right to access' section above.\nNotice to Consumers: Businesses must create and post either within the Business' privacy policy or, if the Business does not have a privacy policy, on its website: (i) a list of the categories of Consumers' Personal Information the Business has sold, or indicate it has not done so, and (ii) a separate list of the categories of Consumers' Personal Information the Business has disclosed for a business purpose, or indicate it has not done so. Establish a process to update this information once every 12 months."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_28",
    "chunk_content": "Compliance Recommendations\nImage\n Create and make available to Consumers the Submission Options noted above.\n Establish a means to determine whether a request is a proper VCR. As noted, additional guidance is required from the attorney general as to what this will require.\n Create a process to readily access the specific Personal Information the business has collected and sold about each Consumer to satisfy this disclosure requirement.\n Create a tracking system to ensure compliance with the Response Time and that the request complies with the Applicable Time Period.\n Create and post in the Business' privacy policy or on the Business' website if it does not have a privacy policy: (i) the categories of Consumers' Personal Information it has sold, or indicate it has not done so, and (ii) the categories of Consumers' Personal Information it has disclosed for a business purpose, or indicate it has not done so. This must be updated at least once every 12 months."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_29",
    "chunk_content": "Right to Opt Out of the Sale of Personal Information\nA Consumer has a right, at any time, to opt out of the sale of their Personal Information by a Business to third parties. A Consumer can authorize someone to opt out on their behalf, but the means to do this still needs to be specified by the attorney general."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_30",
    "chunk_content": "Notice to Consumers:\n-The Business must provide, on its homepage, a clear link titled 'Do Not Sell My Personal Information,' which links to an opt-out page. A Business is permitted to create a separate homepage for California Consumers with this link (and omit it from the general homepage) if it takes reasonable steps to ensure California Consumers are directed to the California homepage.\n-The foregoing link and a description of this right must also be disclosed in the Business' privacy policy and any California-specific description of Consumers' privacy rights.\nTraining: Individuals responsible for handling Consumer privacy inquiries and CCPA compliance must be trained on the opt-out right and how to direct consumers to exercise that right.\nRequesting New Consent: If a consumer has opted out, the Business cannot request authorization to sell the Consumer's Personal Information for 12 months.\nUse of Opt-Out Request Information: Personal Information collected from the Consumer's opt-out request can only be used to comply with that request.\nApplication to Third Parties: A third party that has received Personal Information from a Business may not sell that Information unless the Consumer has received explicit notice and an opportunity to opt out."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_31",
    "chunk_content": "Age Restrictions:\n-A Business with actual knowledge that a Consumer is between 13 and 16 cannot sell that Consumer's Personal Information without affirmative opt-in consent. A Business that willfully disregards a Consumer's age is deemed to have actual knowledge of the Consumer's age. The CCPA does not provide additional guidance on how willful disregard is determined or if knowledge is presumed for sites directed to children.\n-A Business with actual knowledge that a Consumer is under age 13 cannot sell that Consumer's Personal Information without affirmative opt-in consent of that Consumer's parent or guardian."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_32",
    "chunk_content": "Compliance Recommendations\nImage\n Develop a means of tagging, tracking and separately treating the Personal Information of Consumers who have exercised their opt-out rights.\n Prominently display the opt-out button on the business website once requirements are released by the attorney general.\n Determine what Consumer information is necessary to effectuate an opt-out.\n Develop a process allowing for a parent or guardian to opt in on behalf of a Consumer who falls within the age restrictions.\n Since a Business that willfully disregards the Consumers' age is deemed to have actual knowledge, Businesses may wish to develop a means of classifying a Consumer based on the Personal Information they have on them.\n Where a Business has purchased Personal Information, develop a verification mechanism to confirm Consumer notification consent prior to further sale of such data."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_33",
    "chunk_content": "Right to Nondiscrimination\nBusinesses may not discriminate against a Consumer who exercises their rights under the CCPA. Examples of discriminatory actions include: (i) denying goods or services to the Consumer, (ii) charging different prices (including offering discounts to those who do not opt out), (iii) varying the level or quality of goods or services, or (iv) suggesting the Consumer will receive a different price for goods or services, or different level or quality."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_34",
    "chunk_content": "Exceptions:\n-Businesses can charge different prices, or provide a different level or quality of goods or services, if that difference is reasonably related to the value provided to the Consumer by the Consumer's data.\n-Businesses may offer financial incentives for the collection, sale or deletion of Personal Information if the Business has notified the Consumer of the material terms of the incentive and obtained opt-in consent prior to enrollment. The Consumer has the right to withdraw this opt-in at any time.\n-Any financial incentive practice cannot be unjust, unreasonable, coercive or usurious in nature."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_35",
    "chunk_content": "Compliance Recommendations\nImage\n Note that this requirement does not have a parallel in the GDPR, and therefore even companies fully compliant with the GDPR will need to add processes to comply with it.\n Businesses should review their business practices as it relates to Personal Information to ensure they are not providing any incentives that would violate the nondiscrimination requirement. They should also put in place policies and procedures to ensure that such practices are not adopted in the future. For example, have all incentive programs relating to Personal Information reviewed by the legal department or a designated committee.\n If the Business plans to offer a permitted financial incentive for the collection, sale or deletion of Personal Information, ensure that the Consumer was notified of all material terms and direct the Consumer to the Business' opt-in page.\n-Establish a clear process for Consumers to revoke their opt-in decision, and ensure that decision is honored.\n Develop a means to tag and track users who have opted into financial incentives so their Personal Information can be treated separately compared to ones who have not."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_36",
    "chunk_content": "Obligations if Personal Information Is Provided to a Service Provider\nAlthough there is no specific CCPA provision dealing with the disclosure of Personal Information to a service provider, the definition of service provider incorporates certain requirements.\nSpecifically, by implication, a Business can only provide Personal Information to a service provider if:\n-the disclosure is for a business purpose and pursuant to a written contract; and\n-the contract prohibits the service provider from retaining, using or disclosing the Personal Information for any purpose other than for the specific purpose of performing the services specified in an agreement, or as otherwise permitted by the CCPA.\nA Business that discloses Personal Information to a service provider is not liable under the CCPA if the service provider uses it in violation of the CCPA, provided that at the time of disclosure it does not have actual knowledge, or reason to believe, that the service provider intends to violate the CCPA. Similarly, a service provider is not liable under the CCPA for the obligations of the Business for which it provides services. It is important to note that, in contrast to the GDPR, there is no separate set of standards for service providers as there is for 'data processors' under the GDPR."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_37",
    "chunk_content": "Compliance Recommendations\nImage\n Track and document any disclosure of Personal Information to a third party, and confirm that all such disclosures are for a business purpose.\n Ensure that there is a written agreement with each such third party. Note that if a Business and its service provider already have a data processing addendum in place to conform with the requirements imposed under the GDPR, that addendum will likely already satisfy any obligations under the CCPA.\n Ensure that these written agreements explicitly limit the use of the Personal Information to providing the specified services to the Business."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_38",
    "chunk_content": "Right to Refuse a Consumer Request\nA Business can refuse a request for the deletion or disclosure of Personal Information in two situations:\n-A Business can determine it has a basis not to comply with the Consumer's request provided it promptly informs the Consumer of that decision (and at least within the time periods required under the applicable CCPA provisions). That notice must explain the Business' rationale and any rights the Consumer may have to appeal that decision to the Business. Note that the CCPA does not seem to mandate that the Business provide an appeal right. In order to be able to invoke this exception, a Business should have a documented policy for when they will refuse a Consumer request and a mechanism to inform the Consumer of that decision within the required time frame.\n-A Business can determine that a request from a Consumer is 'manifestly unfounded or excessive, in particular because of their repetitive character.' In such a case, the Business can (i) refuse the request provided it promptly informs the Consumer of that decision (and at least within the time periods required under the applicable CCPA provisions), and (ii) can charge a reasonable fee to comply with the request, based on its costs. Although the Business bears the burden of demonstrating that a request is 'manifestly unfounded or excessive,' the CCPA offers no guidance on how that decision should be made. In order to be able to invoke this exception, Businesses should have a documented policy to determine when a request is excessive so it is not doing so on an ad hoc basis. The Business should also establish a policy as to whether it will charge for the request or refuse it, and if it does charge, have a method for determining a reasonable fee."
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_39",
    "chunk_content": "Stuart D. Levi\nPartner / New York 212.735.2750 stuart.levi@skadden.com"
  },
  {
    "document_name": "Cybersecurity_California_Privacy-with-image-refs",
    "chunk_id": "Cybersecurity_California_Privacy-with-image-refs_chunk_40",
    "chunk_content": "Daniel Healow\nAssociate / Palo Alto 650.470.3168 daniel.healow@skadden.com\nThis communication is provided by Skadden, Arps, Slate, Meagher & Flom LLP and its affiliates for educational and informational purposes only and is not intended and should not be construed as legal advice. This communication is considered advertising under applicable state laws.\nSkadden, Arps, Slate, Meagher & Flom LLP / Four Times Square / New York, NY 10036 / 212.735.3000 525 University Ave. / Palo Alto, CA 94301 / 650.470.4500\nskadden.com"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_0",
    "chunk_content": "EN\nImage"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_1",
    "chunk_content": "REGULATIONS\nREGULATION (EU) 2016/679 OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL of 27 April 2016\non the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation)\n(Text with EEA relevance)\nTHE EUROPEAN PARLIAMENT AND THE COUNCIL OF THE EUROPEAN UNION,\nHaving regard to the Treaty on the Functioning of the European Union, and in particular Article 16 thereof,\nHaving regard to the proposal from the European Commission,\nAfter  transmission of the draft legislative act to the national parliaments,\nHaving regard to the opinion of the European Economic and Social Committee ( 1 ),\nHaving regard to the opinion of the Committee of the Regions ( 2 ),\nActing in accordance with the ordinary legislative procedure  ( 3 ),\nWhereas:\n(1) The  protection  of  natural  persons  in  relation  to  the  processing  of  personal  data  is  a  fundamental  right. Article  8(1)  of  the  Charter  of  Fundamental  Rights  of  the  European  Union  (the  'Charter')  and  Article  16(1)  of  the Treaty on the Functioning of  the European Union (TFEU) provide that everyone has the right to the protection of personal data concerning him or her.\n(2) The  principles  of,  and  rules  on  the  protection  of  natural  persons  with  regard  to  the  processing  of  their  personal data  should,  whatever  their  nationality  or  residence,  respect  their  fundamental  rights  and  freedoms,  in  particular their  right  to  the  protection  of  personal  data.  This  Regulation  is  intended  to contribute to the  accomplishment of an  area  of  freedom,  security  and  justice  and  of  an  economic  union,  to  economic  and  social  progress,  to  the strengthening and the convergence of  the economies within the  internal  market, and  to the  well-being  of  natural persons.\n(3) Directive  95/46/EC  of  the  European  Parliament  and  of  the  Council  ( 4 )  seeks  to  harmonise  the  protection  of fundamental rights and freedoms of natural persons in respect of processing activities and to ensure the free flow of personal data between Member States.\nEN\n(4) The  processing  of  personal  data  should  be  designed  to  serve  mankind.  The  right  to  the  protection  of  personal data  is  not  an  absolute  right;  it  must  be  considered  in  relation  to  its  function  in  society  and  be  balanced  against other  fundamental  rights,  in  accordance  with  the  principle  of  proportionality.  This  Regulation  respects  all fundamental  rights  and  observes  the  freedoms  and  principles  recognised  in  the  Charter  as  enshrined  in  the Treaties,  in  particular  the  respect  for  private  and  family  life,  home  and  communications,  the  protection  of personal  data,  freedom  of  thought,  conscience  and  religion,  freedom  of  expression  and  information,  freedom  to conduct  a  business,  the  right  to  an  effective  remedy  and  to  a  fair  trial,  and  cultural,  religious  and  linguistic diversity.\n(5) The economic and social integration resulting from the functioning of the internal market has led to a substantial increase in cross-border  flows of personal data. The exchange of personal data between public and private actors, including  natural  persons,  associations  and  undertakings  across  the  Union  has  increased.  National  authorities  in the  Member States are being called upon by Union law to cooperate and exchange personal data so as to be able to perform their duties or carry out tasks on behalf of an authority in another Member State.\n(6) Rapid  technological  developments  and  globalisation  have  brought  new  challenges  for  the  protection  of  personal data.  The  scale  of  the  collection  and  sharing  of  personal  data  has  increased  significantly.  Technology  allows  both private  companies  and  public  authorities  to  make  use  of  personal  data  on  an  unprecedented  scale  in  order  to pursue  their  activities.  Natural  persons  increasingly  make  personal  information  available  publicly  and  globally. Technology  has  transformed  both  the  economy  and  social  life,  and  should  further  facilitate  the  free  flow  of personal data within the Union and the transfer to third countries and international organisations, while ensuring a high level of the protection of personal data.\n(7) Those  developments  require  a  strong  and  more  coherent  data  protection  framework  in  the  Union,  backed  by strong  enforcement,  given  the  importance  of  creating  the  trust  that  will  allow  the  digital  economy  to  develop across  the  internal  market.  Natural  persons  should  have  control  of  their  own  personal  data.  Legal  and  practical certainty for  natural persons, economic operators and public authorities should be enhanced.\n(8) Where this Regulation provides  for  specifications  or  restrictions  of  its  rules  by  Member  State  law,  Member  States may,  as  far  as  necessary  for  coherence  and  for  making  the  national  provisions  comprehensible  to  the  persons  to whom they apply, incorporate elements of this Regulation into their national law.\n(9) The objectives  and  principles  of  Directive  95/46/EC  remain  sound,  but  it  has  not  prevented  fragmentation  in  the implementation  of  data  protection  across  the  Union,  legal  uncertainty  or  a  widespread  public  perception  that there  are  significant  risks  to  the  protection  of  natural  persons,  in  particular  with  regard  to  online  activity. Differences  in  the  level  of  protection  of  the  rights  and  freedoms  of  natural  persons,  in  particular  the  right  to  the protection of personal data, with regard to the processing of personal data in the Member States may prevent the free  flow  of  personal  data  throughout  the  Union.  Those  differences  may  therefore  constitute  an  obstacle  to  the pursuit  of  economic  activities  at  the  level  of  the  Union,  distort  competition  and  impede  authorities  in  the discharge  of  their  responsibilities  under  Union  law.  Such  a  difference  in  levels  of  protection  is  due  to  the existence of differences in the implementation and application of Directive 95/46/EC.\n(10) In  order  to  ensure  a  consistent  and  high  level  of  protection  of  natural  persons  and  to  remove  the  obstacles  to flows  of  personal  data  within  the  Union,  the  level  of  protection  of  the  rights  and  freedoms  of  natural  persons with  regard  to  the  processing  of  such  data  should  be  equivalent  in  all  Member  States.  Consistent  and homogenous  application  of  the  rules  for  the  protection  of  the  fundamental  rights  and  freedoms  of  natural persons  with  regard  to  the  processing  of  personal  data  should  be  ensured  throughout  the  Union.  Regarding  the processing  of  personal  data  for  compliance  with  a  legal  obligation,  for  the  performance  of  a  task  carried  out  in the  public  interest  or  in  the  exercise  of  official  authority  vested  in  the  controller,  Member  States  should  be allowed  to  maintain  or  introduce  national  provisions  to  further  specify  the  application  of  the  rules  of  this Regulation.  In  conjunction  with  the  general  and  horizontal  law  on  data  protection  implementing  Directive 95/46/EC,  Member  States  have  several  sector-specific  laws  in  areas  that  need  more  specific  provisions.  This Regulation  also  provides  a  margin  of  manoeuvre  for  Member  States  to  specify  its  rules,  including  for  the processing of special categories of personal data ('sensitive  data').  To  that extent,  this  Regulation  does  not exclude Member  State  law  that  sets  out  the  circumstances  for  specific  processing  situations,  including  determining  more precisely the conditions under  which the processing of personal data is lawful.\nEN\n(11) Effective  protection  of  personal  data  throughout  the  Union requires  the  strengthening  and  setting  out  in  detail  of the  rights  of  data  subjects  and  the  obligations  of  those  who  process  and  determine  the  processing  of  personal data,  as  well  as  equivalent  powers  for  monitoring  and  ensuring  compliance  with  the  rules  for  the  protection  of personal data and equivalent sanctions for infringements in the Member States.\n(12) Article  16(2)  TFEU  mandates  the  European  Parliament  and  the  Council  to  lay  down  the  rules  relating  to  the protection  of  natural  persons  with  regard  to  the  processing  of  personal  data  and  the  rules  relating  to  the  free movement of personal data.\n(13) In  order  to  ensure  a  consistent  level  of  protection  for  natural  persons  throughout  the  Union  and  to  prevent divergences  hampering  the  free  movement  of  personal  data  within  the  internal  market,  a  Regulation  is  necessary to  provide  legal  certainty  and  transparency  for  economic  operators,  including  micro,  small  and  medium-sized enterprises,  and  to  provide  natural  persons  in  all  Member  States  with  the  same  level  of  legally  enforceable  rights and  obligations  and  responsibilities  for  controllers  and  processors,  to  ensure  consistent  monitoring  of  the processing  of  personal  data,  and  equivalent  sanctions  in  all  Member  States  as  well  as  effective  cooperation between  the  supervisory  authorities  of  different  Member  States.  The  proper  functioning  of  the  internal  market requires  that  the  free  movement  of  personal  data  within  the  Union  is  not  restricted  or  prohibited  for  reasons connected with the protection of natural persons with regard to the processing of personal data. To take account of  the  specific  situation  of  micro,  small  and  medium-sized  enterprises,  this  Regulation  includes  a  derogation  for organisations  with  fewer  than  250  employees  with  regard  to  record-keeping.  In  addition,  the  Union  institutions and  bodies,  and  Member  States  and  their  supervisory  authorities,  are  encouraged  to  take  account  of  the  specific needs  of  micro,  small  and  medium-sized  enterprises  in  the  application  of  this  Regulation.  The  notion  of  micro, small  and  medium-sized  enterprises  should  draw  from  Article  2  of  the  Annex  to  Commission  Recommendation 2003/361/EC ( 1 ).\n(14) The protection afforded by this Regulation should apply to natural persons, whatever their  nationality or  place of residence,  in  relation  to  the  processing  of  their  personal  data.  This  Regulation  does  not  cover  the  processing  of personal  data  which  concerns  legal  persons  and  in  particular  undertakings  established  as  legal  persons,  including the name and the form of the legal person and the contact details of the legal person.\n(15) In order  to prevent creating a serious risk of circumvention, the protection of natural persons should be technolo­ gically  neutral  and  should  not  depend  on  the  techniques  used.  The  protection  of  natural  persons  should  apply  to the  processing  of  personal  data  by  automated  means,  as  well  as  to  manual  processing,  if  the  personal  data  are contained  or  are  intended  to  be  contained  in  a  filing  system.  Files  or  sets  of  files,  as  well  as  their  cover  pages, which are not structured according to specific criteria should not fall within the scope of this Regulation.\n(16) This  Regulation  does  not  apply  to  issues  of  protection  of  fundamental  rights  and  freedoms  or  the  free  flow  of personal data related to activities which fall outside the scope of Union law, such as activities concerning national security.  This  Regulation  does  not  apply  to  the  processing  of  personal  data  by  the  Member  States  when  carrying out activities in relation to the common foreign and security policy of the Union.\n(17) Regulation  (EC)  No  45/2001  of  the  European  Parliament  and  of  the  Council  ( 2 )  applies  to  the  processing  of personal  data  by  the  Union  institutions,  bodies,  offices  and  agencies.  Regulation  (EC)  No  45/2001  and  other Union  legal  acts  applicable  to  such  processing  of  personal  data  should  be  adapted  to  the  principles  and  rules established  in  this  Regulation  and  applied  in  the  light  of  this  Regulation.  In  order  to  provide  a  strong  and coherent  data  protection  framework  in  the  Union,  the  necessary  adaptations  of  Regulation  (EC)  No  45/2001 should  follow  after  the  adoption  of  this  Regulation,  in  order  to  allow  application  at  the  same  time  as  this Regulation.\n(18) This  Regulation  does  not  apply  to  the  processing  of  personal  data  by  a  natural  person  in  the  course  of  a  purely personal or household activity and thus with no connection to a professional or commercial activity. Personal or\n( 1 ) Commission Recommendation of 6 May 2003 concerning the definition of micro, small and medium-sized enterprises (C(2003) 1422) (OJ L 124, 20.5.2003, p. 36).\n( 2 ) Regulation (EC) No 45/2001 of the European Parliament and of the Council of 18 December 2000 on the protection of individuals with regard to the processing of personal data by the Community institutions and bodies and on the free movement of such data (OJ L 8, 12.1.2001, p. 1).\nEN\nhousehold activities  could  include  correspondence  and  the  holding  of  addresses,  or  social  networking  and  online activity  undertaken  within  the  context  of  such  activities.  However,  this  Regulation  applies  to  controllers  or processors which provide the means for processing personal data for such personal or household activities.\n(19) The protection of natural persons with regard to the processing of personal data by competent authorities for  the purposes  of  the  prevention,  investigation,  detection  or  prosecution  of  criminal  offences  or  the  execution  of criminal penalties, including the safeguarding against and the prevention of  threats to public security and the free movement of  such  data,  is  the  subject  of  a  specific  Union  legal  act.  This  Regulation  should  not,  therefore,  apply to  processing  activities  for  those  purposes.  However,  personal  data  processed  by  public  authorities  under  this Regulation  should,  when  used  for  those  purposes,  be  governed  by  a  more  specific  Union  legal  act,  namely Directive  (EU)  2016/680  of  the  European  Parliament  and  of  the  Council  ( 1 ). Member  States  may  entrust competent  authorities  within  the  meaning  of  Directive  (EU)  2016/680  with  tasks  which  are  not  necessarily carried  out for  the  purposes of  the  prevention,  investigation, detection or  prosecution of criminal offences or  the execution of criminal penalties, including the safeguarding against and prevention of  threats to public security, so that  the  processing  of  personal  data  for  those  other  purposes,  in  so  far  as  it  is  within  the  scope  of  Union  law, falls  within the scope of  this Regulation.\nWith  regard  to  the  processing  of  personal  data  by  those  competent  authorities  for  purposes  falling  within  scope of  this  Regulation,  Member  States  should  be  able  to  maintain  or  introduce  more  specific  provisions  to  adapt  the application  of  the  rules  of  this  Regulation.  Such  provisions  may  determine  more  precisely  specific  requirements for  the  processing  of  personal  data  by  those  competent  authorities  for  those  other  purposes,  taking  into  account the  constitutional,  organisational  and  administrative  structure  of  the  respective  Member  State.  When  the processing  of  personal  data  by  private  bodies  falls  within  the  scope  of  this  Regulation,  this  Regulation  should provide  for  the  possibility  for  Member  States  under  specific  conditions  to  restrict  by  law  certain  obligations  and rights  when  such  a  restriction  constitutes  a  necessary  and  proportionate  measure  in  a  democratic  society  to safeguard  specific  important  interests  including  public  security  and  the  prevention,  investigation,  detection  or prosecution of criminal offences or  the execution of criminal penalties, including the safeguarding against and the prevention  of  threats  to  public  security.  This  is  relevant  for  instance  in  the  framework  of  anti-money  laundering or  the activities of forensic laboratories.\n(20) While  this  Regulation  applies,  inter  alia,  to  the  activities  of  courts  and  other  judicial  authorities,  Union  or Member  State  law  could  specify  the  processing  operations  and  processing  procedures  in  relation  to  the processing  of  personal  data  by  courts  and  other  judicial  authorities.  The  competence  of  the  supervisory authorities  should  not  cover  the  processing  of  personal  data  when  courts  are  acting  in  their  judicial  capacity,  in order  to  safeguard  the  independence  of  the  judiciary  in  the  performance  of  its  judicial  tasks,  including  decisionmaking.  It  should  be  possible  to  entrust  supervision  of  such  data  processing  operations  to  specific  bodies  within the  judicial  system  of  the  Member  State,  which  should,  in  particular  ensure  compliance  with  the  rules  of  this Regulation,  enhance  awareness  among  members  of  the  judiciary  of  their  obligations  under  this  Regulation  and handle complaints in relation to such data processing operations.\n(21) This  Regulation  is  without  prejudice  to  the  application  of  Directive  2000/31/EC  of  the  European  Parliament  and of  the  Council  ( 2 ),  in  particular  of  the  liability  rules  of  intermediary  service  providers  in  Articles  12  to  15  of  that Directive. That Directive seeks to contribute to the proper functioning of  the internal market by ensuring the free movement of information society services between Member States.\n(22) Any processing of personal data in the context of  the activities of an establishment of a controller or a processor in  the  Union should be carried out in accordance with this Regulation, regardless of whether  the processing itself takes  place  within  the  Union.  Establishment  implies  the  effective  and  real  exercise  of  activity  through  stable arrangements.  The  legal  form  of  such  arrangements,  whether  through  a  branch  or  a  subsidiary  with  a  legal personality, is not the determining factor in that respect.\nEN\n(23) In  order  to  ensure  that  natural  persons  are  not  deprived  of  the  protection  to  which  they  are  entitled  under  this Regulation,  the  processing  of  personal  data  of  data  subjects  who  are  in  the  Union  by  a  controller  or  a  processor not  established  in  the  Union  should  be  subject  to  this  Regulation  where  the  processing  activities  are  related  to offering  goods  or  services  to  such  data  subjects  irrespective  of  whether  connected  to  a  payment.  In  order  to determine  whether  such  a  controller  or  processor  is  offering  goods  or  services  to  data  subjects  who  are  in  the Union, it  should  be  ascertained  whether  it  is  apparent  that  the  controller  or  processor  envisages  offering  services to  data  subjects  in  one  or  more  Member  States  in  the  Union.  Whereas  the  mere  accessibility  of  the  controller's, processor's  or  an  intermediary's  website  in  the  Union,  of  an  email  address  or  of  other  contact  details,  or  the  use of  a  language  generally  used  in  the  third  country  where  the  controller  is  established,  is  insufficient  to  ascertain such intention,  factors  such  as  the  use  of  a  language  or  a  currency  generally  used  in  one  or  more  Member  States with  the  possibility  of  ordering  goods  and  services  in  that  other  language,  or  the  mentioning  of  customers  or users who are in the Union, may make it apparent that the controller envisages offering goods or services to data subjects in the Union.\n(24) The  processing  of  personal  data  of  data  subjects  who  are  in  the  Union  by  a  controller  or  processor  not established  in  the  Union  should  also  be  subject  to  this  Regulation  when  it  is  related  to  the  monitoring  of  the behaviour  of  such  data  subjects  in  so  far  as  their  behaviour  takes  place  within  the  Union.  In  order  to  determine whether  a  processing  activity  can  be  considered  to  monitor  the  behaviour  of  data  subjects,  it  should  be ascertained  whether  natural  persons  are  tracked  on  the  internet  including  potential  subsequent  use  of  personal data  processing  techniques  which  consist  of  profiling  a  natural  person,  particularly  in  order  to  take  decisions concerning her or him or for analysing or predicting her or his personal preferences, behaviours and attitudes.\n(25) Where  Member  State  law  applies  by  virtue  of  public  international  law,  this  Regulation  should  also  apply  to  a controller  not established in the Union, such as in a Member State's diplomatic mission or consular post.\n(26) The principles of data protection should apply to any information concerning an identified or  identifiable natural person. Personal data which have undergone pseudonymisation, which could be attributed to a natural person by the  use  of  additional  information  should  be  considered  to  be  information  on  an  identifiable  natural  person.  To determine  whether  a  natural  person  is  identifiable,  account  should  be  taken  of  all  the  means  reasonably  likely  to be used, such as singling out, either by the controller or by another  person to identify the natural person directly or  indirectly.  To  ascertain  whether  means  are  reasonably  likely  to  be  used  to  identify  the  natural  person,  account should  be  taken  of  all  objective  factors,  such  as  the  costs  of  and  the  amount  of  time  required  for  identification, taking  into  consideration  the  available  technology  at  the  time  of  the  processing  and  technological  developments. The  principles  of  data  protection  should  therefore  not  apply  to  anonymous  information,  namely  information which  does  not  relate  to  an  identified  or  identifiable  natural  person  or  to  personal  data  rendered  anonymous  in such  a  manner  that  the  data  subject  is  not  or  no  longer  identifiable.  This  Regulation  does  not  therefore  concern the processing of such anonymous information, including for statistical or research purposes.\n(27) This  Regulation  does  not  apply  to  the  personal  data  of  deceased  persons.  Member  States  may  provide  for  rules regarding the processing of personal data of deceased persons.\n(28) The  application  of  pseudonymisation  to  personal  data  can  reduce  the  risks  to  the  data  subjects  concerned  and help  controllers  and  processors  to  meet  their  data-protection  obligations.  The  explicit  introduction  of  'pseudony­ misation' in this Regulation is not intended to preclude any other measures of data protection.\n(29) In order  to create incentives to apply pseudonymisation when processing personal data, measures of pseudonymi­ sation  should,  whilst  allowing  general  analysis,  be  possible  within  the  same  controller  when  that  controller  has taken  technical  and  organisational  measures  necessary  to  ensure,  for  the  processing  concerned,  that  this Regulation  is  implemented,  and  that  additional  information  for  attributing  the  personal  data  to  a  specific  data subject  is  kept  separately.  The  controller  processing  the  personal  data  should  indicate  the  authorised  persons within the same controller.\nEN"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_2",
    "chunk_content": "REGULATIONS\n(30) Natural  persons  may  be  associated  with  online  identifiers  provided  by  their  devices,  applications,  tools  and protocols,  such  as  internet  protocol  addresses,  cookie  identifiers  or  other  identifiers  such  as  radio  frequency identification  tags.  This  may  leave  traces  which,  in  particular  when  combined  with  unique  identifiers  and  other information received by the servers, may be used to create profiles of the natural persons and identify them.\n(31) Public  authorities  to  which  personal  data  are  disclosed  in  accordance  with  a  legal  obligation  for  the  exercise  of their  official  mission,  such  as  tax  and  customs  authorities,  financial  investigation  units,  independent  adminis­ trative  authorities,  or  financial  market  authorities  responsible  for  the  regulation  and  supervision  of  securities markets  should  not  be  regarded  as  recipients  if  they  receive  personal  data  which  are  necessary  to  carry  out  a particular  inquiry  in  the  general  interest,  in  accordance  with  Union  or  Member  State  law.  The  requests  for disclosure  sent  by  the  public  authorities  should  always  be  in  writing,  reasoned  and  occasional  and  should  not concern the entirety of a filing system or lead to the interconnection of filing systems. The processing of personal data  by  those  public  authorities  should  comply  with  the  applicable  data-protection  rules  according  to  the purposes of the processing.\n(32) Consent  should  be  given  by  a  clear  affirmative  act  establishing  a  freely  given,  specific,  informed  and unambiguous indication of the data subject's agreement to the processing of personal data relating to him or her, such  as  by  a  written  statement,  including  by  electronic  means,  or  an  oral  statement.  This  could  include  ticking  a box  when  visiting  an  internet  website,  choosing  technical  settings  for  information  society  services  or  another statement  or  conduct  which  clearly  indicates  in  this  context  the  data  subject's  acceptance  of  the  proposed processing  of  his  or  her  personal  data.  Silence,  pre-ticked  boxes  or  inactivity  should  not  therefore  constitute consent.  Consent  should  cover  all  processing  activities  carried  out  for  the  same  purpose  or  purposes.  When  the processing  has  multiple  purposes,  consent  should  be  given  for  all  of  them.  If  the  data  subject's  consent  is  to  be given following a request by electronic means, the request must be clear, concise and not unnecessarily disruptive to the use of  the service for  which it is provided.\n(33) It  is  often  not  possible  to fully  identify  the  purpose  of  personal  data  processing  for scientific  research  purposes at the  time  of  data  collection.  Therefore,  data  subjects  should  be  allowed  to  give  their  consent  to  certain  areas  of scientific  research  when  in  keeping  with  recognised  ethical  standards  for  scientific  research.  Data  subjects  should have  the  opportunity  to  give  their  consent  only  to  certain  areas  of  research  or  parts  of  research  projects  to  the extent allowed by the intended purpose.\n(34) Genetic  data  should  be  defined  as  personal  data  relating  to  the  inherited  or  acquired  genetic  characteristics  of  a natural  person  which  result  from  the  analysis  of  a  biological  sample  from  the  natural  person  in  question,  in particular  chromosomal, deoxyribonucleic acid (DNA) or  ribonucleic acid (RNA) analysis, or  from the analysis of another element enabling equivalent information to be obtained.\n(35) Personal  data  concerning  health  should  include  all  data  pertaining  to  the  health  status  of  a  data  subject  which reveal information relating to the past, current or  future physical or  mental health status of  the data subject. This includes  information  about  the  natural  person  collected  in  the  course  of  the  registration  for,  or  the  provision  of, health  care  services  as  referred  to  in  Directive  2011/24/EU  of  the  European  Parliament  and  of  the  Council  ( 1 )  to that  natural  person;  a  number,  symbol  or  particular  assigned  to  a  natural  person  to  uniquely  identify  the  natural person  for  health  purposes;  information  derived  from  the  testing  or  examination  of  a  body  part  or  bodily substance,  including  from  genetic  data  and  biological  samples;  and  any  information  on,  for  example,  a  disease, disability,  disease  risk,  medical  history,  clinical  treatment  or  the  physiological  or  biomedical  state  of  the  data subject independent of its source, for example from a physician or other health professional, a hospital, a medical device or an in vitro diagnostic test.\n(36) The  main  establishment  of  a  controller  in  the  Union  should  be  the  place  of  its  central  administration  in  the Union,  unless  the  decisions  on  the  purposes  and  means  of  the  processing  of  personal  data  are  taken  in  another establishment  of  the  controller  in  the  Union,  in  which  case  that  other  establishment  should  be  considered  to  be\nEN\nthe  main  establishment.  The  main  establishment  of  a  controller  in  the  Union  should  be  determined  according  to objective  criteria  and  should  imply  the  effective  and  real  exercise  of  management  activities  determining  the  main decisions  as  to  the  purposes  and  means  of  processing  through  stable  arrangements.  That  criterion  should  not depend  on  whether  the  processing  of  personal  data  is  carried  out  at  that  location.  The  presence  and  use  of technical  means  and  technologies  for  processing  personal  data  or  processing  activities  do  not,  in  themselves, constitute  a  main  establishment  and  are  therefore  not  determining  criteria  for  a  main  establishment.  The  main establishment  of  the  processor  should  be  the  place  of  its  central  administration  in  the  Union  or,  if  it  has  no central  administration  in  the  Union,  the  place  where  the  main  processing  activities  take  place  in  the  Union.  In cases  involving  both  the  controller  and  the  processor,  the  competent  lead  supervisory  authority  should  remain the  supervisory  authority  of  the  Member  State  where  the  controller  has  its  main  establishment,  but  the supervisory  authority  of  the  processor  should  be  considered  to  be  a  supervisory  authority  concerned  and  that supervisory  authority  should  participate  in  the  cooperation  procedure  provided  for  by  this  Regulation.  In  any case,  the  supervisory  authorities  of  the  Member  State  or  Member  States  where  the  processor  has  one  or  more establishments  should  not  be  considered  to  be  supervisory  authorities  concerned  where  the  draft  decision concerns  only  the  controller.  Where  the  processing  is  carried  out  by  a  group  of  undertakings,  the  main establishment  of  the  controlling  undertaking  should  be  considered  to  be  the  main  establishment  of  the  group  of undertakings, except where the purposes and means of processing are determined by another undertaking.\n(37) A  group  of  undertakings  should  cover  a  controlling  undertaking  and  its  controlled  undertakings,  whereby  the controlling  undertaking  should  be  the  undertaking  which  can  exert  a  dominant  influence  over  the  other undertakings  by  virtue,  for  example,  of  ownership,  financial  participation  or  the  rules  which  govern  it  or  the power  to  have  personal  data  protection  rules  implemented.  An  undertaking  which  controls  the  processing  of personal  data  in  undertakings  affiliated  to  it  should  be  regarded,  together  with  those  undertakings,  as  a  group  of undertakings.\n(38) Children  merit  specific  protection  with  regard  to  their  personal  data,  as  they  may  be  less  aware  of  the  risks, consequences  and  safeguards  concerned  and  their  rights  in  relation  to  the  processing  of  personal  data.  Such specific  protection  should,  in  particular,  apply  to  the  use  of  personal  data  of  children  for  the  purposes  of marketing  or  creating  personality  or  user  profiles  and  the  collection  of  personal  data  with  regard  to  children when using services offered directly to a child. The consent of  the holder of parental responsibility should not be necessary in the context of preventive or counselling services offered directly to a child.\n(39) Any  processing  of  personal  data  should  be  lawful  and  fair.  It  should  be  transparent  to  natural  persons  that personal  data  concerning  them  are  collected,  used,  consulted  or  otherwise  processed  and  to  what  extent  the personal data are or will be processed. The principle of transparency requires that any information and communi­ cation relating to the processing of  those personal data be easily accessible and easy to understand, and that clear and  plain  language  be  used.  That  principle  concerns,  in  particular,  information  to  the  data  subjects  on  the identity  of  the  controller  and  the  purposes  of  the  processing  and  further  information  to  ensure  fair  and transparent  processing  in  respect  of  the  natural  persons  concerned  and  their  right  to  obtain  confirmation  and communication  of  personal  data  concerning  them  which  are  being  processed.  Natural  persons  should  be  made aware of risks, rules, safeguards and rights in relation to the processing of personal data and how to exercise their rights  in  relation  to  such  processing.  In  particular,  the  specific  purposes  for  which  personal  data  are  processed should  be  explicit  and  legitimate  and  determined  at  the  time  of  the  collection  of  the  personal  data.  The  personal data should be adequate, relevant and limited to what is necessary for  the purposes for  which they are processed. This  requires,  in  particular,  ensuring  that  the  period  for  which  the  personal  data  are  stored  is  limited  to  a  strict minimum.  Personal  data  should  be  processed  only  if  the  purpose  of  the  processing  could  not  reasonably  be fulfilled  by other  means.  In  order  to  ensure  that  the  personal  data  are  not  kept  longer  than  necessary,  time  limits should be established by the controller for erasure or for a periodic review. Every reasonable step should be taken to  ensure  that  personal  data  which  are  inaccurate  are  rectified  or  deleted.  Personal  data  should  be  processed  in  a manner  that  ensures  appropriate  security  and  confidentiality  of  the  personal  data,  including  for  preventing unauthorised access to or use of personal data and the equipment used for the processing.\n(40) In  order  for  processing  to  be  lawful,  personal  data  should  be  processed  on  the  basis  of  the  consent  of  the  data subject concerned or some other legitimate basis, laid down by law, either in this Regulation or in other Union or\nEN\nMember  State  law  as  referred  to  in  this  Regulation,  including  the  necessity  for  compliance  with  the  legal obligation  to which the  controller  is  subject  or  the  necessity  for  the  performance  of  a  contract  to which  the  data subject is party or in order  to take steps at the request of  the data subject prior  to entering into a contract.\n(41) Where this Regulation refers to a legal basis or a legislative measure, this does not necessarily require a legislative act  adopted  by  a  parliament,  without  prejudice  to  requirements  pursuant  to  the  constitutional  order  of  the Member  State  concerned.  However,  such  a  legal  basis  or  legislative  measure  should  be  clear  and  precise  and  its application should be foreseeable to persons subject to it, in  accordance with  the case-law of  the  Court of  Justice of  the  European Union (the 'Court of Justice') and the European Court of Human Rights.\n(42) Where  processing  is  based  on  the  data  subject's  consent,  the  controller  should  be  able  to  demonstrate  that  the data  subject  has  given  consent  to  the  processing  operation.  In  particular  in  the  context  of  a  written  declaration on  another  matter,  safeguards  should  ensure  that  the  data  subject  is  aware  of  the  fact  that  and  the  extent  to which  consent  is  given.  In  accordance  with  Council  Directive  93/13/EEC  ( 1 ) a  declaration  of  consent  preformulated by the controller should be provided in an intelligible and easily accessible form, using clear and plain language and it should not contain unfair  terms. For consent to be informed, the data subject should be aware at least  of  the  identity  of  the  controller  and  the  purposes  of  the  processing  for  which  the  personal  data  are intended.  Consent  should  not  be  regarded  as  freely  given  if  the  data  subject  has  no  genuine  or  free  choice  or  is unable to refuse or withdraw consent without detriment.\n(43) In order  to ensure that consent is freely given, consent should not provide a valid legal ground for  the processing of  personal data in a specific case where there is a clear  imbalance between the data subject and the controller, in particular  where  the  controller  is  a  public  authority  and  it  is  therefore  unlikely  that  consent  was  freely  given  in all  the  circumstances  of  that  specific  situation.  Consent  is  presumed  not  to  be  freely  given  if  it  does  not  allow separate  consent  to  be  given  to  different  personal  data  processing  operations  despite  it  being  appropriate  in  the individual  case,  or  if  the  performance  of  a  contract,  including  the  provision  of  a  service,  is  dependent  on  the consent despite such consent not being necessary for such performance.\n(44) Processing  should  be  lawful  where  it  is  necessary  in  the  context  of  a  contract  or  the  intention  to  enter  into  a contract.\n(45) Where processing is carried out in accordance with a legal obligation to which the controller  is  subject or  where processing  is  necessary  for  the  performance  of  a  task  carried  out  in  the  public  interest  or  in  the  exercise  of official  authority,  the  processing  should  have  a  basis  in  Union  or  Member  State  law.  This  Regulation  does  not require a specific law for each individual processing. A law as a basis for several processing operations based on a legal  obligation  to which  the  controller  is  subject  or  where  processing  is  necessary  for  the  performance  of  a  task carried  out  in  the  public  interest or  in  the  exercise  of  an  official  authority  may  be  sufficient.  It  should  also  be  for Union  or  Member  State  law  to  determine  the  purpose  of  processing.  Furthermore,  that  law  could  specify  the general conditions of this Regulation governing the lawfulness of personal data processing, establish specifications for  determining  the  controller,  the  type  of  personal  data  which  are  subject  to  the  processing,  the  data  subjects concerned,  the  entities  to  which  the  personal  data  may  be  disclosed,  the  purpose  limitations,  the  storage  period and  other  measures  to  ensure  lawful  and  fair  processing.  It  should  also  be  for  Union  or  Member  State  law  to determine whether  the controller  performing a task carried out in the public interest or  in the exercise of official authority  should  be  a  public  authority  or  another  natural  or  legal  person  governed  by  public  law,  or,  where  it  is in  the  public  interest  to  do  so,  including  for  health  purposes  such  as  public  health  and  social  protection  and  the management of health care services, by private law, such as a professional association.\n(46) The  processing  of  personal  data  should  also  be  regarded  to  be  lawful  where  it  is  necessary  to  protect  an  interest which  is  essential  for  the  life  of  the  data  subject  or  that  of  another  natural  person.  Processing  of  personal  data\nEN\nbased  on  the  vital  interest  of  another  natural  person  should  in  principle  take  place  only  where  the  processing cannot  be  manifestly  based  on  another  legal  basis.  Some  types  of  processing  may  serve  both  important  grounds of  public  interest  and  the  vital  interests  of  the  data  subject  as  for  instance  when  processing  is  necessary  for humanitarian  purposes,  including  for  monitoring  epidemics  and  their  spread  or  in  situations  of  humanitarian emergencies, in particular in situations of natural and man-made disasters.\n(47) The  legitimate  interests  of  a  controller,  including  those  of  a  controller  to  which  the  personal  data  may  be disclosed,  or  of  a  third  party,  may  provide  a  legal  basis  for  processing,  provided  that  the  interests  or  the fundamental  rights  and  freedoms  of  the  data  subject  are  not  overriding,  taking  into  consideration  the  reasonable expectations  of  data  subjects  based  on  their  relationship  with  the  controller.  Such  legitimate  interest  could  exist for  example where there is a relevant  and appropriate relationship  between the  data subject  and the controller  in situations such as where the data subject is a client or  in the service of  the controller. At any rate the existence of a  legitimate  interest  would  need  careful  assessment  including  whether  a  data  subject  can  reasonably expect  at  the time  and  in  the  context  of  the  collection  of  the  personal  data  that  processing  for  that  purpose  may  take  place. The  interests  and  fundamental  rights  of  the  data  subject  could  in  particular  override  the  interest  of  the  data controller  where  personal  data  are  processed  in  circumstances  where  data  subjects  do  not  reasonably  expect further  processing.  Given  that  it  is  for  the  legislator  to  provide  by  law  for  the  legal  basis  for  public  authorities  to process  personal  data,  that  legal  basis  should  not  apply  to  the  processing  by  public  authorities  in  the performance  of  their  tasks.  The  processing  of  personal  data  strictly  necessary  for  the  purposes  of  preventing fraud  also  constitutes  a  legitimate  interest  of  the  data  controller  concerned.  The  processing  of  personal  data  for direct marketing purposes may be regarded as carried out for a legitimate interest.\n(48) Controllers  that  are  part  of  a  group  of  undertakings  or  institutions  affiliated  to  a  central  body  may  have  a legitimate  interest  in  transmitting  personal  data  within  the  group  of  undertakings  for  internal  administrative purposes,  including  the  processing  of  clients'  or  employees'  personal  data.  The  general  principles  for  the  transfer of personal data, within a group of undertakings, to an undertaking located in a third country remain unaffected.\n(49) The  processing  of  personal  data  to  the  extent  strictly  necessary  and  proportionate  for  the  purposes  of  ensuring network and information security, i.e. the ability of a network or an  information system  to resist, at  a  given level of  confidence,  accidental  events  or  unlawful  or  malicious  actions  that  compromise  the  availability,  authenticity, integrity  and confidentiality of stored or  transmitted personal data, and the security of  the related services offered by,  or  accessible  via,  those  networks  and  systems,  by  public  authorities,  by  computer  emergency  response  teams (CERTs),  computer  security  incident  response  teams  (CSIRTs),  by  providers  of  electronic  communications networks  and  services  and  by  providers  of  security  technologies  and  services,  constitutes  a  legitimate  interest  of the  data  controller  concerned.  This  could,  for  example,  include  preventing  unauthorised  access  to  electronic communications networks and malicious code distribution and stopping 'denial of service' attacks and damage to computer and electronic communication systems.\n(50) The processing of personal data for purposes other  than those for  which the personal data were initially collected should  be  allowed  only  where  the  processing  is  compatible  with  the  purposes  for  which  the  personal  data  were initially  collected.  In  such  a  case,  no  legal  basis  separate  from  that  which  allowed  the  collection  of  the  personal data  is  required.  If  the  processing  is  necessary  for  the  performance  of  a  task  carried  out  in  the  public  interest  or in  the  exercise  of  official  authority  vested  in  the  controller,  Union  or  Member  State  law  may  determine  and specify  the  tasks  and  purposes  for  which  the  further  processing  should  be  regarded  as  compatible  and  lawful. Further  processing  for  archiving  purposes  in  the  public  interest,  scientific  or  historical  research  purposes  or statistical  purposes  should  be  considered  to  be  compatible  lawful  processing  operations.  The  legal  basis  provided by  Union  or  Member  State  law  for  the  processing  of  personal  data  may  also  provide  a  legal  basis  for  further processing.  In  order  to  ascertain  whether  a  purpose  of  further  processing  is  compatible  with  the  purpose  for which  the  personal  data  are  initially  collected,  the  controller,  after  having  met  all  the  requirements  for  the lawfulness  of  the  original  processing,  should  take  into  account,  inter  alia:  any  link  between  those  purposes  and the  purposes  of  the  intended  further  processing;  the  context  in  which  the  personal  data  have  been  collected,  in particular  the  reasonable  expectations  of  data  subjects  based  on  their  relationship  with  the  controller  as  to  their\nEN\nfurther  use;  the  nature  of  the  personal  data;  the  consequences  of  the  intended  further  processing  for  data subjects;  and  the  existence  of  appropriate  safeguards  in  both  the  original  and  intended  further  processing operations.\nWhere  the  data  subject  has  given  consent  or  the  processing  is  based  on  Union  or  Member  State  law  which constitutes  a  necessary  and  proportionate  measure  in  a  democratic  society  to  safeguard,  in  particular,  important objectives  of  general  public  interest,  the  controller  should  be  allowed  to  further  process  the  personal  data irrespective  of  the  compatibility  of  the  purposes.  In  any  case,  the  application  of  the  principles  set  out  in  this Regulation and in particular  the information of  the data subject on those other  purposes and on his or her  rights including  the  right  to  object,  should  be  ensured.  Indicating  possible  criminal  acts  or  threats  to  public  security  by the  controller  and  transmitting  the  relevant  personal  data  in  individual  cases  or  in  several  cases  relating  to  the same  criminal  act  or  threats  to  public  security  to  a  competent  authority  should  be  regarded  as  being  in  the legitimate  interest  pursued  by  the  controller.  However,  such  transmission  in  the  legitimate  interest  of  the controller  or  further  processing  of  personal  data  should  be  prohibited  if  the  processing  is  not  compatible  with  a legal, professional or other binding obligation of secrecy.\n(51) Personal  data  which  are,  by  their  nature,  particularly  sensitive  in  relation  to  fundamental  rights  and  freedoms merit specific protection as the context of  their  processing could create significant risks to the fundamental rights and freedoms. Those personal data should include personal data revealing racial or ethnic origin, whereby the use of  the  term  'racial  origin'  in  this  Regulation  does  not  imply  an  acceptance  by  the  Union  of  theories  which attempt to determine the existence of separate human races. The processing of photographs should not systemati­ cally  be  considered to be processing of special categories of personal data as they are covered by the definition of biometric  data  only  when  processed  through  a  specific  technical  means  allowing  the  unique  identification  or authentication  of  a  natural  person.  Such  personal  data  should  not  be  processed,  unless  processing  is  allowed  in specific  cases  set  out  in  this  Regulation,  taking  into  account  that  Member  States  law  may  lay  down  specific provisions  on  data  protection  in  order  to  adapt  the  application  of  the  rules  of  this  Regulation  for  compliance with  a  legal  obligation  or  for  the  performance  of  a  task  carried  out  in  the  public  interest  or  in  the  exercise  of official  authority  vested in  the  controller.  In  addition  to the  specific  requirements  for  such processing,  the  general principles  and  other  rules  of  this  Regulation  should  apply,  in  particular  as  regards  the  conditions  for  lawful processing.  Derogations  from  the  general  prohibition  for  processing  such  special  categories  of  personal  data should  be  explicitly  provided,  inter  alia,  where  the  data  subject  gives  his  or  her  explicit  consent  or  in  respect  of specific  needs  in  particular  where  the  processing  is  carried  out  in  the  course  of  legitimate  activities  by  certain associations or foundations the purpose of which is to permit the exercise of fundamental freedoms.\n(52) Derogating  from  the  prohibition  on  processing  special  categories  of  personal  data  should  also  be  allowed  when provided for  in  Union or  Member State law and subject to suitable safeguards, so as to protect personal data and other  fundamental  rights,  where  it  is  in  the  public  interest  to  do  so,  in  particular  processing  personal  data  in  the field  of  employment  law,  social  protection  law  including  pensions  and  for  health  security,  monitoring  and  alert purposes,  the  prevention  or  control  of  communicable  diseases  and  other  serious  threats  to  health.  Such  a derogation  may  be  made  for  health  purposes,  including  public  health  and  the  management  of  health-care services,  especially  in  order  to  ensure  the  quality  and  cost-effectiveness  of  the  procedures  used  for  settling  claims for  benefits  and  services  in  the  health  insurance  system,  or  for  archiving  purposes  in  the  public  interest,  scientific or  historical  research  purposes  or  statistical  purposes.  A  derogation  should  also  allow  the  processing  of  such personal  data  where  necessary  for  the  establishment,  exercise  or  defence  of  legal  claims,  whether  in  court proceedings or in an administrative or out-of-court procedure.\n(53) Special categories of personal data which merit higher  protection should be processed for health-related purposes only  where  necessary  to  achieve  those  purposes  for  the  benefit  of  natural  persons  and  society  as  a  whole,  in particular  in  the  context  of  the  management  of  health  or  social  care  services  and  systems,  including  processing by  the  management  and  central  national  health  authorities  of  such  data  for  the  purpose  of  quality  control, management information and the  general national  and  local  supervision  of  the  health  or  social  care  system,  and ensuring  continuity  of  health  or  social  care  and  cross-border  healthcare  or  health  security,  monitoring  and  alert purposes,  or  for  archiving  purposes  in  the  public  interest,  scientific  or  historical  research  purposes  or  statistical purposes,  based  on  Union  or  Member  State  law  which  has  to  meet  an  objective  of  public  interest,  as  well  as  for studies  conducted in the public interest in the area of public health. Therefore, this Regulation should provide for harmonised  conditions  for  the  processing  of  special  categories  of  personal  data  concerning  health,  in  respect  of specific  needs,  in  particular  where  the  processing  of  such  data  is  carried  out  for  certain  health-related  purposes\nEN\nby  persons  subject  to  a  legal  obligation  of  professional  secrecy.  Union  or  Member  State  law  should  provide  for specific  and  suitable  measures  so  as  to  protect  the  fundamental  rights  and  the  personal  data  of  natural  persons. Member States  should  be  allowed  to  maintain  or  introduce  further  conditions,  including  limitations,  with  regard to the processing of genetic data, biometric data or data concerning health. However, this should not hamper  the free flow of personal data within the Union when those conditions apply to cross-border processing of such data."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_3",
    "chunk_content": "REGULATIONS\n(54) The processing of  special  categories  of  personal  data  may  be  necessary  for  reasons  of  public  interest  in  the  areas of  public  health  without  consent  of  the  data  subject.  Such  processing  should  be  subject  to  suitable  and  specific measures  so  as  to  protect  the  rights  and  freedoms  of  natural  persons.  In  that  context,  'public  health'  should  be interpreted  as  defined  in  Regulation  (EC)  No  1338/2008  of  the  European  Parliament  and  of  the  Council  ( 1 ), namely  all  elements  related  to  health,  namely  health  status,  including  morbidity  and  disability,  the  determinants having  an  effect  on  that  health  status,  health  care  needs,  resources  allocated  to  health  care,  the  provision  of,  and universal access to, health care as well as health care expenditure and financing, and the causes of mortality. Such processing  of  data  concerning  health  for  reasons  of  public  interest  should  not  result  in  personal  data  being processed for other purposes by third parties such as employers or insurance and banking companies.\n(55) Moreover, the processing of personal data by official authorities for  the purpose of achieving the aims, laid down by  constitutional  law  or  by  international  public  law,  of  officially  recognised  religious  associations,  is  carried  out on grounds of public interest.\n(56) Where  in  the  course  of  electoral  activities,  the  operation  of  the  democratic  system  in  a  Member  State  requires that  political  parties  compile  personal  data  on  people's  political  opinions,  the  processing  of  such  data  may  be permitted for reasons of public interest, provided that appropriate safeguards are established.\n(57) If  the  personal  data  processed  by  a  controller  do  not  permit  the  controller  to  identify  a  natural  person,  the  data controller  should  not  be  obliged  to  acquire  additional  information  in  order  to  identify  the  data  subject  for  the sole  purpose  of  complying  with  any  provision  of  this  Regulation.  However,  the  controller  should  not  refuse  to take  additional  information  provided  by  the  data  subject  in  order  to  support  the  exercise  of  his  or  her  rights. Identification  should  include  the  digital  identification  of  a  data  subject,  for  example  through  authentication mechanism  such  as  the  same  credentials,  used  by  the  data  subject  to  log-in  to  the  on-line  service  offered  by  the data controller.\n(58) The  principle  of  transparency  requires  that  any  information  addressed  to  the  public  or  to  the  data  subject  be concise,  easily  accessible  and  easy  to  understand,  and  that  clear  and  plain  language  and,  additionally,  where appropriate,  visualisation  be  used.  Such  information  could  be  provided  in  electronic  form,  for  example,  when addressed  to  the  public,  through  a  website.  This  is  of  particular  relevance  in  situations  where  the  proliferation  of actors and the  technological  complexity of  practice  make it  difficult  for  the  data  subject  to  know  and  understand whether,  by  whom and  for  what  purpose  personal  data  relating  to  him  or  her  are  being  collected,  such  as  in  the case  of  online  advertising.  Given  that  children  merit  specific  protection,  any  information  and  communication, where  processing  is  addressed  to  a  child,  should  be  in  such  a  clear  and  plain  language  that  the  child  can  easily understand.\n(59) Modalities  should  be  provided  for  facilitating  the  exercise  of  the  data  subject's  rights  under  this  Regulation, including mechanisms to request and, if applicable, obtain, free of charge, in particular, access to and rectification or  erasure  of  personal  data  and  the  exercise  of  the  right  to  object.  The  controller  should  also  provide  means  for requests  to  be  made  electronically,  especially  where  personal  data  are  processed  by  electronic  means.  The controller  should  be  obliged  to  respond  to  requests  from  the  data  subject  without  undue  delay  and  at  the  latest within one month and to give reasons where the controller does not intend to comply with any such requests.\nEN\n(60) The principles of fair and transparent processing require that the data subject be informed of  the existence of  the processing  operation  and  its  purposes.  The  controller  should  provide  the  data  subject  with  any  further information  necessary  to  ensure  fair  and  transparent  processing  taking  into  account  the  specific  circumstances and  context  in  which  the  personal  data  are  processed.  Furthermore,  the  data  subject  should  be  informed  of  the existence  of  profiling  and  the  consequences  of  such  profiling.  Where  the  personal  data  are  collected  from  the data  subject,  the  data  subject  should  also  be  informed  whether  he  or  she  is  obliged  to  provide  the  personal  data and  of  the  consequences,  where  he  or  she  does  not  provide  such  data.  That  information  may  be  provided  in combination with standardised icons in order  to give in an easily visible,  intelligible and  clearly  legible  manner,  a meaningful  overview  of  the  intended  processing.  Where  the  icons  are  presented  electronically,  they  should  be machine-readable.\n(61) The information in relation to the processing of personal data relating to the data subject should be given to him or  her  at  the  time  of  collection  from  the  data  subject,  or,  where  the  personal  data  are  obtained  from  another source,  within  a  reasonable  period,  depending  on  the  circumstances  of  the  case.  Where  personal  data  can  be legitimately  disclosed  to  another  recipient,  the  data  subject  should  be  informed  when  the  personal  data  are  first disclosed to the recipient. Where the controller intends to process the personal data for a purpose other  than that for  which they were collected, the controller should provide the data subject prior  to that further processing with information  on  that  other  purpose  and  other  necessary  information.  Where  the  origin  of  the  personal  data cannot  be  provided  to  the  data  subject  because  various  sources  have  been  used,  general  information  should  be provided.\n(62) However,  it  is  not  necessary  to  impose  the  obligation  to  provide  information  where  the  data  subject  already possesses  the  information,  where  the  recording  or  disclosure  of  the  personal  data  is  expressly  laid  down  by  law or  where  the  provision  of  information  to  the  data  subject  proves  to be  impossible  or  would  involve  a  dispropor­ tionate  effort.  The  latter  could  in  particular  be  the  case  where  processing  is  carried  out  for  archiving  purposes  in the  public  interest,  scientific  or  historical  research  purposes  or  statistical  purposes.  In  that  regard,  the  number  of data subjects, the age of  the data and any appropriate safeguards adopted should be taken into consideration.\n(63) A data subject should have the right of access to personal data which have been collected concerning him or her, and to exercise that  right  easily  and  at  reasonable  intervals,  in  order  to  be  aware  of,  and  verify,  the  lawfulness  of the  processing.  This  includes  the  right  for  data  subjects  to  have  access  to  data  concerning  their  health,  for example  the  data  in  their  medical  records  containing  information  such  as  diagnoses,  examination  results, assessments  by  treating  physicians  and  any  treatment  or  interventions  provided.  Every  data  subject  should therefore  have  the  right  to  know  and  obtain  communication  in  particular  with  regard  to  the  purposes  for  which the  personal  data  are  processed,  where  possible  the  period  for  which  the  personal  data  are  processed,  the recipients  of  the  personal  data,  the  logic  involved  in  any  automatic  personal  data  processing  and,  at  least  when based on profiling, the consequences of such processing. Where possible, the controller should be able to provide remote  access  to  a  secure  system  which  would  provide  the  data  subject  with  direct  access  to  his  or  her  personal data. That right should not adversely affect the rights or freedoms of others, including trade secrets or  intellectual property  and  in  particular  the  copyright  protecting  the  software.  However,  the  result  of  those  considerations should  not  be  a  refusal  to  provide  all  information  to  the  data  subject.  Where  the  controller  processes  a  large quantity  of  information  concerning  the  data  subject,  the  controller  should  be  able  to  request  that,  before  the information  is  delivered,  the  data  subject  specify  the  information  or  processing  activities  to  which  the  request relates.\n(64) The  controller  should  use  all  reasonable  measures  to verify  the  identity  of  a  data  subject  who  requests  access,  in particular  in  the  context  of online  services  and  online  identifiers.  A controller  should  not  retain  personal  data  for the sole purpose of being able to react to potential requests.\n(65) A  data  subject  should  have  the  right  to  have  personal  data  concerning  him  or  her  rectified  and  a  'right  to  be forgotten'  where  the  retention  of  such  data  infringes  this  Regulation  or  Union  or  Member  State  law  to which  the controller  is  subject.  In  particular,  a  data  subject  should  have  the  right  to  have  his  or  her  personal  data  erased and  no  longer  processed  where  the  personal  data  are  no  longer  necessary  in  relation  to  the  purposes  for  which they  are  collected  or  otherwise  processed,  where  a  data  subject  has  withdrawn  his  or  her  consent  or  objects  to the  processing  of  personal  data  concerning  him  or  her,  or  where  the  processing  of  his  or  her  personal  data  does not  otherwise  comply  with  this  Regulation.  That  right  is  relevant  in  particular  where  the  data  subject  has  given\nEN\nhis  or  her  consent  as  a  child  and  is  not  fully  aware  of  the  risks  involved  by  the  processing,  and  later  wants  to remove  such  personal  data,  especially  on  the  internet.  The  data  subject  should  be  able  to  exercise  that  right notwithstanding  the  fact  that  he  or  she  is  no  longer  a  child.  However,  the  further  retention  of  the  personal  data should  be  lawful  where  it  is  necessary,  for  exercising  the  right  of  freedom  of  expression  and  information,  for compliance  with  a  legal  obligation,  for  the  performance  of  a  task  carried  out  in  the  public  interest  or  in  the exercise  of  official  authority  vested  in  the  controller,  on  the  grounds  of  public  interest  in  the  area  of  public health,  for  archiving  purposes  in  the  public  interest,  scientific  or  historical  research  purposes  or  statistical purposes, or for  the establishment, exercise or defence of  legal claims.\n(66) To strengthen the right to be forgotten in the online environment, the right to erasure should also be extended in such a  way  that  a  controller  who  has  made  the  personal  data  public  should  be  obliged  to  inform  the  controllers which are processing such personal data to erase any links to, or copies or  replications of  those personal data. In doing  so,  that  controller  should  take  reasonable  steps,  taking  into  account  available  technology  and  the  means available  to  the  controller,  including  technical  measures,  to  inform  the  controllers  which  are  processing  the personal data of the data subject's request.\n(67) Methods  by  which  to  restrict  the  processing  of  personal  data  could  include,  inter  alia,  temporarily  moving  the selected data to another  processing system, making the selected personal data unavailable to users, or  temporarily removing  published  data  from  a  website.  In  automated  filing  systems,  the  restriction  of  processing  should  in principle  be  ensured  by  technical  means  in  such  a  manner  that  the  personal  data  are  not  subject  to  further processing  operations  and  cannot  be  changed.  The  fact  that  the  processing  of  personal  data  is  restricted  should be clearly indicated in the system.\n(68) To  further  strengthen  the  control  over  his  or  her  own  data,  where  the  processing  of  personal  data  is  carried  out by  automated  means,  the  data  subject  should  also  be  allowed  to  receive  personal  data  concerning  him  or  her which he or she has provided to a controller in a structured, commonly used, machine-readable and interoperable format,  and  to  transmit  it  to  another  controller.  Data  controllers  should  be  encouraged  to  develop  interoperable formats that enable data portability. That right should apply where the data subject provided the personal data on the  basis  of  his  or  her  consent  or  the  processing  is  necessary  for  the  performance  of  a  contract.  It  should  not apply  where  processing  is  based  on  a  legal  ground  other  than  consent  or  contract.  By  its  very  nature,  that  right should  not  be  exercised  against  controllers  processing  personal  data  in  the  exercise  of  their  public  duties.  It should  therefore  not  apply  where  the  processing  of  the  personal  data  is  necessary  for  compliance  with  a  legal obligation  to which the controller  is  subject or  for  the  performance  of a  task  carried  out  in  the  public  interest  or in  the  exercise  of  an  official  authority  vested  in  the  controller.  The  data  subject's  right  to  transmit  or  receive personal  data  concerning  him  or  her  should  not  create  an  obligation  for  the  controllers  to  adopt  or  maintain processing  systems  which  are  technically  compatible.  Where,  in  a  certain  set  of  personal  data,  more  than  one data  subject  is  concerned,  the  right  to  receive  the  personal  data  should  be  without  prejudice  to  the  rights  and freedoms of other  data  subjects  in  accordance  with  this  Regulation.  Furthermore,  that  right  should  not  prejudice the  right  of  the  data  subject  to  obtain  the  erasure  of  personal  data  and  the  limitations  of  that  right  as  set  out  in this  Regulation  and  should,  in  particular,  not  imply  the  erasure  of  personal  data  concerning  the  data  subject which  have  been  provided  by  him  or  her  for  the  performance  of  a  contract  to  the  extent  that  and  for  as  long  as the  personal  data  are  necessary  for  the  performance  of  that  contract.  Where  technically  feasible,  the  data  subject should have the right to have the personal data transmitted directly from one controller  to another.\n(69) Where  personal  data  might  lawfully  be  processed  because  processing  is  necessary  for  the  performance  of  a  task carried  out  in  the  public  interest  or  in  the  exercise  of official  authority  vested  in  the  controller,  or  on  grounds  of the legitimate interests of a controller or a third party, a data subject should, nevertheless, be entitled to object to the  processing  of  any  personal  data  relating  to  his  or  her  particular  situation.  It  should  be  for  the  controller  to demonstrate that its compelling legitimate interest overrides the interests or  the fundamental rights and freedoms of  the  data subject.\n(70) Where personal data are processed for  the purposes of direct marketing, the data subject should have the right to object  to  such  processing,  including  profiling  to  the  extent  that  it  is  related  to  such  direct  marketing,  whether with regard to initial or further  processing, at any time and free of charge. That right should be explicitly brought to the attention of the data subject and presented clearly and separately from any other information.\nEN\n(71) The  data  subject  should  have  the  right  not  to  be  subject  to  a  decision,  which  may  include  a  measure,  evaluating personal  aspects  relating  to  him  or  her  which  is  based  solely  on  automated  processing  and  which  produces  legal effects  concerning  him  or  her  or  similarly  significantly  affects  him  or  her,  such  as  automatic  refusal  of  an  online credit  application  or  e-recruiting  practices  without  any  human  intervention.  Such  processing  includes  'profiling' that  consists  of  any  form  of  automated  processing  of  personal  data  evaluating  the  personal  aspects  relating  to  a natural  person,  in  particular  to  analyse  or  predict  aspects  concerning  the  data  subject's  performance  at  work, economic  situation,  health,  personal  preferences  or  interests,  reliability  or  behaviour,  location  or  movements, where  it  produces  legal  effects  concerning  him  or  her  or  similarly  significantly  affects  him  or  her.  However, decision-making  based  on  such  processing,  including  profiling,  should  be  allowed  where  expressly  authorised  by Union  or  Member  State  law  to  which  the  controller  is  subject,  including  for  fraud  and  tax-evasion  monitoring and  prevention  purposes  conducted  in  accordance  with  the  regulations,  standards  and  recommendations  of Union institutions  or  national  oversight  bodies  and  to  ensure  the  security  and  reliability  of  a  service  provided  by the  controller,  or  necessary  for  the  entering  or  performance  of  a  contract  between  the  data  subject  and  a controller,  or  when  the  data  subject  has  given  his  or  her  explicit  consent.  In  any case,  such  processing  should  be subject  to  suitable  safeguards,  which  should  include  specific  information  to  the  data  subject  and  the  right  to obtain  human intervention, to express  his  or  her  point  of  view,  to  obtain  an  explanation  of  the  decision  reached after such assessment and to challenge the decision. Such measure should not concern a child.\nIn  order  to  ensure  fair  and  transparent  processing  in  respect  of  the  data  subject,  taking  into  account  the  specific circumstances  and  context  in  which  the  personal  data  are  processed,  the  controller  should  use  appropriate mathematical  or  statistical  procedures  for  the  profiling,  implement  technical  and  organisational  measures appropriate  to  ensure,  in  particular,  that  factors  which  result  in  inaccuracies  in  personal  data  are  corrected  and the  risk  of  errors  is  minimised,  secure  personal  data  in  a  manner  that  takes  account  of  the  potential  risks involved  for  the  interests  and  rights  of  the  data  subject  and  that  prevents,  inter  alia,  discriminatory  effects  on natural  persons  on  the  basis  of  racial  or  ethnic  origin,  political  opinion,  religion  or  beliefs,  trade  union membership,  genetic  or  health  status  or  sexual  orientation,  or  that  result  in  measures  having  such  an  effect. Automated  decision-making  and  profiling  based  on  special  categories  of  personal  data  should  be  allowed  only under specific conditions.\n(72) Profiling  is  subject  to  the  rules  of  this  Regulation  governing  the  processing  of  personal  data,  such  as  the  legal grounds  for  processing  or  data  protection  principles.  The  European  Data  Protection  Board  established  by  this Regulation (the 'Board') should be able to issue guidance in that context.\n(73) Restrictions  concerning  specific  principles  and  the  rights  of  information,  access  to  and  rectification  or  erasure  of personal  data,  the  right  to  data  portability,  the  right  to  object,  decisions  based  on  profiling,  as  well  as  the communication of a personal data breach to a data subject and certain related obligations  of  the controllers  may be  imposed  by  Union  or  Member  State  law,  as  far  as  necessary  and  proportionate  in  a  democratic  society  to safeguard  public  security,  including  the  protection  of  human  life  especially  in  response  to  natural  or  manmade disasters,  the  prevention,  investigation  and  prosecution  of  criminal  offences  or  the  execution  of  criminal penalties,  including  the  safeguarding  against  and  the  prevention  of  threats  to  public  security,  or  of  breaches  of ethics  for  regulated  professions,  other  important  objectives  of  general  public  interest  of  the  Union  or  of  a Member State,  in  particular  an  important  economic  or  financial  interest  of  the  Union  or  of  a  Member  State,  the keeping of public registers kept for  reasons of general public interest, further  processing of archived personal data to  provide  specific  information  related  to  the  political  behaviour  under  former  totalitarian  state  regimes  or  the protection of  the  data  subject or  the  rights  and  freedoms  of others,  including  social  protection, public health  and humanitarian  purposes.  Those  restrictions  should  be  in  accordance  with  the  requirements  set  out  in  the  Charter and in the European Convention for the Protection of Human Rights and Fundamental Freedoms.\n(74) The responsibility  and  liability  of  the  controller  for  any  processing  of  personal  data  carried  out  by  the  controller or  on  the  controller's  behalf  should  be  established.  In  particular,  the  controller  should  be  obliged  to  implement appropriate  and  effective  measures  and  be  able  to  demonstrate  the  compliance  of  processing  activities  with  this Regulation,  including  the  effectiveness  of  the  measures.  Those  measures  should  take  into  account  the  nature, scope, context and purposes of the processing and the risk to the rights and freedoms of natural persons.\nEN\n(75) The  risk  to  the  rights  and  freedoms  of  natural  persons,  of  varying  likelihood  and  severity,  may  result  from personal  data  processing  which  could  lead  to  physical,  material  or  non-material  damage,  in  particular:  where  the processing may give rise to discrimination, identity theft or fraud, financial loss, damage to the reputation, loss of confidentiality  of  personal  data  protected  by  professional  secrecy,  unauthorised  reversal  of  pseudonymisation,  or any other  significant  economic  or  social  disadvantage;  where  data  subjects  might  be  deprived  of  their  rights  and freedoms or prevented from exercising control over  their  personal data; where personal data are processed which reveal  racial  or  ethnic  origin,  political  opinions,  religion  or  philosophical  beliefs,  trade  union  membership,  and the  processing  of  genetic  data,  data  concerning  health  or  data  concerning  sex  life  or  criminal  convictions  and offences  or  related  security  measures;  where  personal  aspects  are  evaluated,  in  particular  analysing  or  predicting aspects  concerning  performance  at  work,  economic  situation,  health,  personal  preferences  or  interests,  reliability or  behaviour,  location  or  movements,  in  order  to  create  or  use  personal  profiles;  where  personal  data  of vulnerable  natural  persons,  in  particular  of  children,  are  processed;  or  where  processing  involves  a  large  amount of personal data and affects a large number of data subjects.\n(76) The  likelihood  and  severity  of  the  risk  to  the  rights  and  freedoms  of  the  data  subject  should  be  determined  by reference  to  the  nature,  scope,  context  and  purposes  of  the  processing.  Risk  should  be  evaluated  on  the  basis  of an  objective  assessment,  by  which  it  is  established  whether  data  processing  operations  involve  a  risk  or  a  high risk.\n(77) Guidance  on  the  implementation  of  appropriate  measures  and  on  the  demonstration  of  compliance  by  the controller  or  the  processor,  especially  as  regards  the  identification  of  the  risk  related  to  the  processing,  their assessment  in  terms  of  origin,  nature,  likelihood  and  severity,  and  the  identification  of  best  practices  to  mitigate the  risk,  could  be  provided  in  particular  by  means  of  approved  codes  of  conduct,  approved  certifications, guidelines  provided  by  the  Board  or  indications  provided  by  a  data  protection  officer.  The  Board  may  also  issue guidelines  on  processing  operations  that  are  considered  to  be  unlikely  to  result  in  a  high  risk  to  the  rights  and freedoms of natural persons and indicate what measures may be sufficient in such cases to address such risk.\n(78) The  protection  of  the  rights  and  freedoms  of  natural  persons  with  regard  to  the  processing  of  personal  data require  that  appropriate  technical  and  organisational  measures  be  taken  to  ensure  that  the  requirements  of  this Regulation  are  met.  In  order  to  be  able  to  demonstrate  compliance  with  this  Regulation,  the  controller  should adopt  internal  policies  and  implement  measures  which  meet  in  particular  the  principles  of  data  protection  by design  and  data  protection  by  default.  Such  measures  could  consist,  inter  alia,  of  minimising  the  processing  of personal  data,  pseudonymising  personal  data  as  soon  as  possible,  transparency  with  regard  to  the  functions  and processing  of  personal  data,  enabling  the  data  subject  to  monitor  the  data  processing,  enabling  the  controller  to create  and  improve  security  features.  When  developing,  designing,  selecting  and  using  applications,  services  and products that are based on the processing of personal data or  process personal data to fulfil  their  task,  producers of  the  products,  services  and  applications  should  be  encouraged  to take  into  account  the  right  to  data  protection when developing and designing  such products,  services  and  applications  and,  with  due  regard  to  the  state  of  the art,  to  make sure that controllers and processors are able to fulfil  their data protection obligations. The principles of  data  protection  by  design  and  by  default  should  also  be  taken  into  consideration  in  the  context  of  public tenders.\n(79) The protection of  the  rights  and  freedoms of  data  subjects  as  well  as  the  responsibility  and  liability of  controllers and  processors,  also  in  relation  to  the  monitoring  by  and  measures  of  supervisory  authorities,  requires  a  clear allocation of  the  responsibilities  under  this  Regulation,  including  where  a  controller  determines  the  purposes  and means of the processing jointly with other controllers or  where a processing operation is carried out on behalf of a controller.\n(80) Where a controller  or  a  processor  not  established  in  the  Union  is  processing  personal  data  of  data  subjects  who are  in  the  Union  whose  processing  activities  are  related  to  the  offering  of  goods  or  services,  irrespective  of whether  a  payment  of  the  data  subject  is  required,  to  such  data  subjects  in  the  Union,  or  to  the  monitoring  of their  behaviour  as  far  as  their  behaviour  takes  place  within  the  Union,  the  controller  or  the  processor  should designate  a  representative,  unless  the  processing  is  occasional,  does  not  include  processing,  on  a  large  scale,  of special  categories  of  personal  data  or  the  processing  of  personal  data  relating  to  criminal  convictions  and offences,  and  is  unlikely  to  result  in  a  risk  to  the  rights  and  freedoms  of  natural  persons,  taking  into  account  the\nEN"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_4",
    "chunk_content": "REGULATIONS\nnature,  context,  scope  and  purposes  of  the  processing  or  if  the  controller  is  a  public  authority  or  body.  The  rep­ resentative  should  act  on  behalf  of  the  controller  or  the  processor  and  may  be  addressed  by  any  supervisory authority.  The  representative  should  be  explicitly  designated  by  a  written  mandate  of  the  controller  or  of  the processor  to act on its  behalf  with  regard  to  its  obligations  under  this  Regulation.  The  designation  of  such  a  rep­ resentative  does  not  affect  the  responsibility  or  liability  of  the  controller  or  of  the  processor  under  this Regulation. Such a representative should perform  its  tasks  according  to the  mandate received from  the controller or  processor,  including  cooperating  with  the  competent  supervisory  authorities  with  regard  to  any  action  taken to  ensure  compliance  with  this  Regulation.  The  designated  representative  should  be  subject  to  enforcement proceedings in the event of non-compliance by the controller or processor.\n(81) To  ensure  compliance  with  the  requirements  of  this  Regulation  in  respect  of  the  processing  to  be  carried  out  by the  processor  on  behalf  of  the  controller,  when  entrusting  a  processor  with  processing  activities,  the  controller should  use  only  processors  providing  sufficient  guarantees,  in  particular  in  terms  of  expert  knowledge,  reliability and  resources,  to  implement  technical  and  organisational  measures  which  will  meet  the  requirements  of  this Regulation,  including  for  the  security  of  processing.  The  adherence  of  the  processor  to  an  approved  code  of conduct or an approved certification mechanism may be used as an element to demonstrate compliance with the obligations  of  the  controller.  The  carrying-out  of  processing  by  a  processor  should  be  governed  by  a  contract  or other legal  act  under  Union  or  Member State law, binding the processor  to the controller, setting  out the subjectmatter  and  duration  of  the  processing,  the  nature  and  purposes  of  the  processing,  the  type  of  personal  data  and categories  of  data  subjects,  taking  into  account  the  specific  tasks  and  responsibilities  of  the  processor  in  the context  of  the  processing  to  be  carried  out  and  the  risk  to  the  rights  and  freedoms  of  the  data  subject.  The controller  and  processor  may  choose  to  use  an  individual  contract  or  standard  contractual  clauses  which  are adopted  either  directly  by  the  Commission  or  by  a  supervisory  authority  in  accordance  with  the  consistency mechanism  and  then  adopted  by  the  Commission.  After  the  completion  of  the  processing  on  behalf  of  the controller,  the  processor  should,  at  the  choice  of  the  controller,  return  or  delete  the  personal  data,  unless  there  is a requirement to store the personal data under Union or Member State law to which the processor is subject.\n(82) In  order  to  demonstrate  compliance  with  this  Regulation,  the  controller  or  processor  should  maintain  records  of processing  activities  under  its  responsibility.  Each  controller  and  processor  should  be  obliged  to  cooperate  with the  supervisory  authority  and  make  those  records,  on  request,  available  to  it,  so  that  it  might  serve  for monitoring those processing operations.\n(83) In  order  to  maintain  security  and  to  prevent  processing  in  infringement  of  this  Regulation,  the  controller  or processor  should  evaluate  the  risks  inherent  in  the  processing  and  implement  measures  to  mitigate  those  risks, such  as  encryption.  Those  measures  should  ensure  an  appropriate  level  of  security,  including  confidentiality, taking into account the state of  the art and  the costs of  implementation in relation to the risks  and  the nature of the  personal  data  to  be  protected.  In  assessing  data  security  risk,  consideration  should  be  given  to  the  risks  that are  presented  by  personal  data  processing,  such  as  accidental  or  unlawful  destruction,  loss,  alteration, unauthorised  disclosure  of,  or  access  to,  personal  data  transmitted,  stored  or  otherwise  processed  which  may  in particular lead to physical, material or non-material damage.\n(84) In  order  to  enhance  compliance  with  this  Regulation  where  processing  operations  are  likely  to  result  in  a  high risk  to  the  rights  and  freedoms  of  natural  persons,  the  controller  should  be  responsible  for  the  carrying-out  of  a data  protection  impact  assessment  to  evaluate,  in  particular,  the  origin,  nature,  particularity  and  severity  of  that risk.  The outcome of the assessment should be taken into account when determining the appropriate measures to be  taken  in  order  to  demonstrate  that  the  processing  of  personal  data  complies  with  this  Regulation.  Where  a data-protection  impact  assessment  indicates  that  processing  operations  involve  a  high  risk  which  the  controller cannot  mitigate  by  appropriate  measures  in  terms  of  available  technology  and  costs  of  implementation,  a consultation of the supervisory authority should take place prior  to the processing.\n(85) A personal data breach may, if not addressed in an appropriate and timely manner, result in physical, material or non-material  damage  to  natural  persons  such  as  loss  of  control  over  their  personal  data  or  limitation  of  their rights,  discrimination,  identity  theft  or  fraud,  financial  loss,  unauthorised  reversal  of  pseudonymisation,  damage to  reputation,  loss  of  confidentiality  of  personal  data  protected  by  professional  secrecy  or  any  other  significant economic  or  social  disadvantage  to  the  natural  person  concerned.  Therefore,  as  soon  as  the  controller  becomes\nEN\naware  that  a  personal  data  breach  has  occurred,  the  controller  should  notify  the  personal  data  breach  to  the supervisory  authority  without  undue  delay  and,  where  feasible,  not  later  than  72  hours  after  having  become aware  of  it,  unless  the  controller  is  able  to  demonstrate,  in  accordance  with  the  accountability  principle,  that  the personal  data  breach  is  unlikely  to  result  in  a  risk  to  the  rights  and  freedoms  of  natural  persons.  Where  such notification  cannot  be  achieved  within  72  hours,  the  reasons  for  the  delay  should  accompany  the  notification and information may be provided in phases without undue further delay.\n(86) The  controller  should  communicate  to  the  data  subject  a  personal  data  breach,  without  undue  delay,  where  that personal data breach is likely to result in  a  high  risk  to the  rights  and  freedoms  of  the  natural  person  in  order  to allow  him  or  her  to  take  the  necessary  precautions.  The  communication  should  describe  the  nature  of  the personal  data  breach  as  well  as  recommendations  for  the  natural  person  concerned  to  mitigate  potential  adverse effects.  Such  communications  to  data  subjects  should  be  made  as  soon  as  reasonably  feasible  and  in  close cooperation  with  the  supervisory  authority,  respecting  guidance  provided  by  it  or  by  other  relevant  authorities such  as  law-enforcement  authorities.  For  example,  the  need  to  mitigate  an  immediate  risk  of  damage  would  call for  prompt  communication  with  data  subjects  whereas  the  need  to  implement  appropriate  measures  against continuing or similar personal data breaches may justify more time for communication.\n(87) It  should  be  ascertained  whether  all  appropriate  technological  protection  and  organisational  measures  have  been implemented  to  establish  immediately  whether  a  personal  data  breach  has  taken  place  and  to  inform  promptly the  supervisory  authority  and  the  data  subject.  The  fact  that  the  notification  was  made  without  undue  delay should be established taking  into account  in particular  the  nature  and  gravity of  the  personal  data  breach  and  its consequences  and  adverse  effects  for  the  data  subject.  Such  notification  may  result  in  an  intervention  of  the supervisory authority in accordance with its tasks and powers laid down in this Regulation.\n(88) In  setting  detailed  rules  concerning  the  format  and  procedures  applicable  to  the  notification  of  personal  data breaches,  due  consideration  should  be  given  to  the  circumstances  of  that  breach,  including  whether  or  not personal  data  had  been  protected  by appropriate  technical  protection  measures,  effectively  limiting  the  likelihood of  identity  fraud  or  other  forms  of  misuse.  Moreover,  such  rules  and  procedures  should  take  into  account  the legitimate interests  of  law-enforcement  authorities  where  early  disclosure  could  unnecessarily  hamper  the  investi­ gation of the circumstances of a personal data breach.\n(89) Directive  95/46/EC provided for  a  general  obligation  to notify  the  processing  of  personal  data  to  the  supervisory authorities.  While  that  obligation  produces  administrative  and  financial  burdens,  it  did  not  in  all  cases  contribute to  improving  the  protection  of  personal  data.  Such  indiscriminate  general  notification  obligations  should therefore  be  abolished,  and  replaced  by effective  procedures  and  mechanisms  which  focus  instead  on  those  types of  processing operations which are likely to result in a high risk to the rights and freedoms of natural persons by virtue  of  their  nature,  scope,  context  and  purposes.  Such  types  of  processing  operations  may  be  those  which  in, particular,  involve  using  new  technologies,  or are  of a  new  kind  and  where  no data  protection  impact assessment has  been  carried  out  before  by  the  controller,  or  where  they  become  necessary  in  the  light  of  the  time  that  has elapsed since the initial processing.\n(90) In such cases, a data protection impact assessment should be carried out by the controller  prior  to the processing in  order  to  assess  the  particular  likelihood  and  severity  of  the  high  risk,  taking  into  account  the  nature,  scope, context  and  purposes  of  the  processing  and  the  sources  of  the  risk.  That  impact  assessment  should  include,  in particular, the measures, safeguards and mechanisms envisaged for mitigating that risk, ensuring the protection of personal data and demonstrating compliance with this Regulation.\n(91) This  should  in  particular  apply  to  large-scale  processing  operations  which  aim  to  process  a  considerable  amount of  personal  data  at  regional,  national  or  supranational  level  and  which  could  affect  a  large  number  of  data subjects  and  which  are  likely  to  result  in  a  high  risk,  for  example,  on  account  of  their  sensitivity,  where  in accordance  with  the  achieved  state  of  technological  knowledge  a  new  technology  is  used  on  a  large  scale  as  well as  to  other  processing  operations  which  result  in  a  high  risk  to  the  rights  and  freedoms  of  data  subjects,  in particular  where  those  operations  render  it  more  difficult  for  data  subjects  to  exercise  their  rights.  A  data\nEN\nprotection  impact  assessment  should  also  be  made  where  personal  data  are  processed  for  taking  decisions regarding  specific  natural  persons  following  any  systematic  and  extensive  evaluation  of  personal  aspects  relating to  natural  persons  based  on  profiling  those  data  or  following  the  processing  of  special  categories  of  personal data,  biometric  data, or  data  on  criminal  convictions and  offences  or  related  security  measures. A data protection impact  assessment  is  equally  required  for  monitoring  publicly  accessible  areas  on  a  large  scale,  especially  when using  optic-electronic  devices  or  for  any  other  operations  where  the  competent  supervisory  authority  considers that  the  processing  is  likely  to  result  in  a  high  risk  to  the  rights  and  freedoms  of  data  subjects,  in  particular because  they  prevent  data  subjects  from  exercising  a  right  or  using  a  service  or  a  contract,  or  because  they  are carried  out  systematically  on  a  large  scale.  The  processing  of  personal  data  should  not  be  considered  to  be  on  a large  scale  if  the  processing  concerns  personal  data  from  patients  or  clients  by  an  individual  physician,  other health care professional or lawyer. In such cases, a data protection impact assessment should not be mandatory.\n(92) There  are  circumstances  under  which  it  may  be  reasonable  and  economical  for  the  subject  of  a  data  protection impact  assessment  to  be  broader  than  a  single  project,  for  example  where  public  authorities  or  bodies  intend  to establish a common application or processing platform or  where several controllers plan to introduce a common application  or  processing  environment  across  an  industry  sector  or  segment  or  for  a  widely  used  horizontal activity.\n(93) In  the  context  of  the  adoption  of  the  Member  State  law  on  which  the  performance  of  the  tasks  of  the  public authority  or  public  body  is  based  and  which  regulates  the  specific  processing  operation  or  set  of  operations  in question, Member States may deem it necessary to carry out such assessment prior  to the processing activities.\n(94) Where  a  data  protection  impact  assessment  indicates  that  the  processing  would,  in  the  absence  of  safeguards, security measures and mechanisms to mitigate the risk, result in a high risk to the rights and freedoms of natural persons  and  the  controller  is  of  the  opinion  that  the  risk  cannot  be  mitigated  by  reasonable  means  in  terms  of available  technologies  and  costs  of  implementation,  the  supervisory  authority  should  be  consulted  prior  to  the start  of  processing activities.  Such high  risk  is  likely  to result  from  certain  types  of  processing  and  the  extent  and frequency  of  processing,  which  may  result  also  in  a  realisation  of  damage  or  interference  with  the  rights  and freedoms of  the  natural  person.  The  supervisory  authority  should  respond  to  the  request  for  consultation  within a  specified  period.  However,  the  absence  of  a  reaction  of  the  supervisory  authority  within  that  period  should  be without  prejudice  to  any  intervention  of  the  supervisory  authority  in  accordance  with  its  tasks  and  powers  laid down  in  this  Regulation,  including  the  power  to  prohibit  processing  operations.  As  part  of  that  consultation process,  the  outcome  of  a  data  protection  impact  assessment  carried  out  with  regard  to  the  processing  at  issue may  be  submitted  to  the  supervisory  authority,  in  particular  the  measures  envisaged  to  mitigate  the  risk  to  the rights and freedoms of natural persons.\n(95) The  processor  should  assist  the  controller,  where  necessary  and  upon  request,  in  ensuring  compliance  with  the obligations  deriving  from  the  carrying  out  of  data  protection  impact  assessments  and  from  prior  consultation  of the supervisory authority.\n(96) A consultation of the supervisory authority should also take place in the course of the preparation of a legislative or  regulatory  measure  which  provides  for  the  processing  of  personal  data,  in  order  to  ensure  compliance  of  the intended processing with this Regulation and in particular  to mitigate the risk involved for  the data subject.\n(97) Where  the  processing  is  carried  out  by  a  public  authority,  except  for  courts  or  independent  judicial  authorities when acting in their judicial capacity, where, in the private sector, processing is carried out by a controller  whose core activities consist of processing operations that require regular and systematic monitoring of the data subjects on  a  large  scale,  or  where  the  core  activities  of  the  controller  or  the  processor  consist  of  processing  on  a  large scale  of  special  categories  of  personal  data  and  data  relating  to  criminal  convictions  and  offences,  a  person  with expert  knowledge  of  data  protection  law  and  practices  should  assist  the  controller  or  processor  to  monitor internal  compliance  with  this  Regulation.  In  the  private  sector,  the  core  activities  of  a  controller  relate  to  its primary  activities  and  do  not  relate  to  the  processing  of  personal  data  as  ancillary  activities.  The  necessary  level of  expert  knowledge  should  be  determined  in  particular  according  to  the  data  processing  operations  carried  out\nEN\nand  the  protection  required  for  the  personal  data  processed  by  the  controller  or  the  processor.  Such  data protection  officers,  whether  or  not  they  are  an  employee  of  the  controller,  should  be  in  a  position  to  perform their duties and tasks in an independent manner.\n(98) Associations  or  other  bodies  representing  categories  of  controllers  or  processors  should  be  encouraged  to  draw up  codes  of  conduct,  within  the  limits  of  this  Regulation,  so  as  to  facilitate  the  effective  application  of  this Regulation,  taking  account  of  the  specific  characteristics  of  the  processing  carried  out  in  certain  sectors  and  the specific  needs  of  micro,  small  and  medium  enterprises.  In  particular,  such  codes  of  conduct  could  calibrate  the obligations  of  controllers  and  processors,  taking  into  account  the  risk  likely  to  result  from  the  processing  for  the rights and freedoms of natural persons.\n(99) When drawing up a code of conduct, or  when amending or extending such a code, associations and other bodies representing  categories  of  controllers  or  processors  should  consult  relevant  stakeholders,  including  data  subjects where feasible, and have regard to submissions received and views expressed in response to such consultations.\n(100)   In  order  to  enhance  transparency  and  compliance  with  this  Regulation,  the  establishment  of  certification mechanisms  and  data  protection  seals  and  marks  should  be  encouraged,  allowing  data  subjects  to  quickly  assess the level of data protection of relevant products and services.\n(101)   Flows  of  personal  data  to and  from  countries  outside  the  Union  and  international  organisations  are  necessary  for the  expansion  of  international  trade  and  international  cooperation.  The  increase  in  such  flows  has  raised  new challenges  and  concerns  with  regard  to  the  protection  of  personal  data.  However,  when  personal  data  are transferred  from  the  Union  to  controllers,  processors  or  other  recipients  in  third  countries  or  to  international organisations,  the  level  of  protection  of  natural  persons  ensured  in  the  Union  by  this  Regulation  should  not  be undermined,  including  in  cases  of  onward  transfers  of  personal  data  from  the  third  country  or  international organisation  to controllers,  processors  in  the  same  or  another  third  country or  international  organisation.  In  any event, transfers to third countries and international organisations may only be carried out in full compliance with this  Regulation.  A  transfer  could  take  place  only  if,  subject  to  the  other  provisions  of  this  Regulation,  the conditions  laid  down  in  the  provisions  of  this  Regulation  relating  to  the  transfer  of  personal  data  to  third countries or international organisations are complied with by the controller or processor.\n(102)   This  Regulation  is  without  prejudice  to  international  agreements  concluded  between  the  Union  and  third countries  regulating  the  transfer  of  personal  data  including  appropriate  safeguards  for  the  data  subjects.  Member States may conclude international agreements which involve the transfer of personal data to third countries or in­ ternational  organisations,  as  far  as  such  agreements  do  not  affect  this  Regulation  or  any  other  provisions  of Union law and include an appropriate level of protection for  the fundamental rights of the data subjects.\n(103)   The  Commission  may  decide  with  effect  for  the  entire  Union  that  a  third  country,  a  territory  or  specified  sector within  a  third  country,  or  an  international  organisation,  offers  an  adequate  level  of  data  protection,  thus providing  legal  certainty  and  uniformity  throughout  the  Union  as  regards  the  third  country  or  international organisation  which  is  considered  to  provide  such  level  of  protection.  In  such  cases,  transfers  of  personal  data  to that  third  country  or  international  organisation  may  take  place  without  the  need  to  obtain  any  further  authoris­ ation.  The  Commission  may  also  decide,  having  given  notice  and  a  full  statement  setting  out  the  reasons  to  the third country or international organisation, to revoke such a decision.\n(104)   In  line  with  the  fundamental values on which the Union is founded, in particular  the protection of human rights, the  Commission should, in its  assessment of  the  third  country,  or  of a  territory  or  specified  sector  within  a  third country,  take  into  account  how  a  particular  third  country  respects  the  rule  of  law,  access  to  justice  as  well  as  in­ ternational  human  rights  norms  and  standards  and  its  general  and  sectoral  law,  including  legislation  concerning public  security,  defence  and  national  security  as  well  as  public  order  and  criminal  law.  The  adoption  of  an adequacy decision with regard to a territory or a specified sector in a third country should take into account clear and  objective  criteria,  such  as  specific  processing  activities  and  the  scope  of  applicable  legal  standards  and legislation  in  force  in  the  third  country.  The  third  country  should  offer  guarantees  ensuring  an  adequate  level  of\nEN\nprotection  essentially  equivalent  to  that  ensured  within  the  Union,  in  particular  where  personal  data  are processed  in  one  or  several  specific  sectors.  In  particular,  the  third  country  should  ensure  effective  independent data  protection  supervision  and  should  provide  for  cooperation  mechanisms  with  the  Member  States'  data protection authorities, and the data subjects should be provided with effective and enforceable rights and effective administrative and judicial redress.\n(105)   Apart  from  the  international  commitments  the  third  country  or  international  organisation  has  entered  into,  the Commission  should  take  account  of  obligations  arising  from  the  third  country's  or  international  organisation's participation  in  multilateral  or  regional  systems  in  particular  in  relation  to  the  protection  of  personal  data,  as well  as  the  implementation  of  such  obligations.  In  particular,  the  third  country's  accession  to  the  Council  of Europe Convention of 28 January 1981 for the Protection of Individuals with regard to the Automatic Processing of  Personal  Data  and  its  Additional  Protocol  should  be  taken  into  account.  The  Commission  should  consult  the Board when assessing the level of protection in third countries or international organisations.\n(106)   The  Commission  should  monitor  the  functioning  of  decisions  on  the  level  of  protection  in  a  third  country,  a territory or  specified  sector  within  a  third  country,  or  an  international  organisation,  and  monitor  the  functioning of  decisions  adopted  on  the  basis  of  Article  25(6)  or  Article  26(4)  of  Directive  95/46/EC.  In  its  adequacy decisions,  the  Commission  should  provide  for  a  periodic  review  mechanism  of  their  functioning.  That  periodic review  should  be  conducted  in  consultation  with  the  third  country  or  international  organisation  in  question  and take  into  account  all  relevant  developments  in  the  third  country  or  international  organisation.  For  the  purposes of monitoring and of carrying out the periodic reviews, the Commission should take into consideration the views and  findings  of  the  European  Parliament  and  of  the  Council  as  well  as  of  other  relevant  bodies  and  sources.  The Commission  should  evaluate,  within  a  reasonable  time,  the  functioning  of  the  latter  decisions  and  report  any relevant  findings  to  the  Committee  within  the  meaning  of  Regulation  (EU)  No  182/2011  of  the  European Parliament  and  of  the  Council  ( 1 )  as  established  under  this  Regulation,  to  the  European  Parliament  and  to  the Council.\n(107)   The Commission may recognise that a third country, a territory or a specified sector within a third country, or an international  organisation  no  longer  ensures  an  adequate  level  of  data  protection.  Consequently  the  transfer  of personal data to that third country or  international organisation should be prohibited, unless the requirements in this  Regulation  relating  to  transfers  subject  to  appropriate  safeguards,  including  binding  corporate  rules,  and derogations  for  specific  situations  are  fulfilled.  In  that  case,  provision  should  be  made  for  consultations  between the  Commission  and  such  third  countries  or  international  organisations.  The  Commission  should,  in  a  timely manner, inform the third country or international organisation of the reasons and enter into consultations with it in order  to remedy the situation.\n(108)   In  the  absence  of  an  adequacy  decision,  the  controller  or  processor  should  take  measures  to  compensate  for  the lack of data protection in a third country by way of appropriate safeguards for  the data subject. Such appropriate safeguards may consist of making use of binding corporate rules, standard data protection clauses adopted by the Commission,  standard  data  protection  clauses  adopted  by  a  supervisory  authority  or  contractual  clauses authorised  by  a  supervisory  authority.  Those  safeguards  should  ensure  compliance  with  data  protection requirements  and  the  rights  of  the  data  subjects  appropriate  to  processing  within  the  Union,  including  the availability of enforceable data subject rights and of effective legal remedies, including to obtain effective adminis­ trative  or  judicial  redress  and  to  claim  compensation,  in  the  Union  or  in  a  third  country.  They  should  relate  in particular  to  compliance  with  the  general  principles  relating  to  personal  data  processing,  the  principles  of  data protection by design and by default. Transfers may also be carried out by public authorities or bodies with public authorities  or  bodies  in  third  countries  or  with  international  organisations  with  corresponding  duties  or functions,  including  on  the  basis  of  provisions  to  be  inserted  into  administrative  arrangements,  such  as  a memorandum of understanding, providing for enforceable and effective rights for data subjects. Authorisation by the  competent  supervisory  authority  should  be  obtained  when  the  safeguards  are  provided  for  in  administrative arrangements that are not legally binding.\n(109)   The  possibility  for  the  controller  or  processor  to  use  standard  data-protection  clauses  adopted  by  the Commission  or  by  a  supervisory  authority  should  prevent  controllers  or  processors  neither  from  including  the\nEN\nstandard  data-protection  clauses  in  a  wider  contract,  such  as  a  contract  between  the  processor  and  another processor,  nor  from  adding  other  clauses  or  additional  safeguards  provided  that  they  do  not  contradict,  directly or  indirectly,  the  standard  contractual  clauses  adopted  by  the  Commission  or  by  a  supervisory  authority  or prejudice  the  fundamental  rights  or  freedoms  of  the  data  subjects.  Controllers  and  processors  should  be encouraged  to  provide  additional  safeguards  via  contractual  commitments  that  supplement  standard  protection clauses."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_5",
    "chunk_content": "REGULATIONS\n(110)   A  group  of  undertakings,  or  a  group  of  enterprises  engaged  in  a  joint  economic  activity,  should  be  able  to  make use of approved binding corporate rules for  its international transfers from the Union to organisations within the same  group  of  undertakings,  or  group  of  enterprises  engaged  in  a  joint  economic  activity,  provided  that  such corporate  rules  include  all  essential  principles  and  enforceable  rights  to  ensure  appropriate  safeguards  for transfers or categories of transfers of personal data.\n(111)   Provisions  should  be  made  for  the  possibility  for  transfers  in  certain  circumstances  where  the  data  subject  has given his or her explicit consent, where the transfer  is occasional and necessary in relation to a contract or a legal claim,  regardless  of  whether  in  a  judicial  procedure  or  whether  in  an  administrative  or  any  out-of-court procedure,  including  procedures  before  regulatory  bodies.  Provision  should  also  be  made  for  the  possibility  for transfers  where  important  grounds  of  public  interest  laid  down  by  Union  or  Member  State  law  so  require  or where  the  transfer  is  made  from  a  register  established  by  law  and  intended  for  consultation  by  the  public  or persons  having  a  legitimate  interest.  In  the  latter  case,  such  a  transfer  should  not  involve  the  entirety  of  the personal  data  or  entire  categories  of  the  data  contained  in  the  register  and,  when  the  register  is  intended  for consultation  by  persons  having  a  legitimate  interest,  the  transfer  should  be  made  only  at  the  request  of  those persons  or,  if  they  are  to  be  the  recipients,  taking  into  full  account  the  interests  and  fundamental  rights  of  the data subject.\n(112)   Those  derogations  should  in  particular  apply  to  data  transfers  required  and  necessary  for  important  reasons  of public  interest,  for  example  in  cases  of  international  data  exchange  between  competition  authorities,  tax  or customs administrations, between financial supervisory authorities, between services competent for social security matters,  or  for  public  health,  for  example  in  the  case  of  contact  tracing  for  contagious  diseases  or  in  order  to reduce and/or eliminate doping in sport. A transfer of personal data should also be regarded as lawful where it is necessary  to  protect  an  interest  which  is  essential  for  the  data  subject's  or  another  person's  vital  interests, including  physical  integrity  or  life,  if  the  data  subject  is  incapable  of  giving  consent.  In  the  absence  of  an adequacy decision,  Union  or  Member  State law  may,  for  important  reasons  of  public  interest,  expressly  set  limits to  the  transfer  of  specific  categories  of  data  to  a  third  country  or  an  international  organisation.  Member  States should  notify  such  provisions  to  the  Commission.  Any  transfer  to  an  international  humanitarian  organisation  of personal  data  of  a  data  subject  who  is  physically  or  legally  incapable  of  giving  consent,  with  a  view  to accomplishing a task incumbent under  the Geneva Conventions or  to complying with international humanitarian law  applicable  in  armed  conflicts,  could  be  considered  to  be  necessary  for  an  important  reason  of  public  interest or because it is in the vital interest of the data subject.\n(113)   Transfers  which can  be  qualified  as  not  repetitive  and  that  only concern  a  limited  number  of  data  subjects,  could also  be  possible  for  the  purposes  of  the  compelling  legitimate  interests  pursued  by  the  controller,  when  those interests  are  not  overridden  by  the  interests  or  rights  and  freedoms  of  the  data  subject  and  when  the  controller has  assessed  all  the  circumstances  surrounding  the  data  transfer.  The  controller  should  give  particular  considera­ tion  to  the  nature  of  the  personal  data,  the  purpose  and  duration  of  the  proposed  processing  operation  or operations,  as  well  as  the  situation  in  the  country  of  origin,  the  third  country  and  the  country  of  final destination,  and  should  provide  suitable  safeguards  to  protect  fundamental  rights  and  freedoms  of  natural persons  with  regard  to  the  processing  of  their  personal  data.  Such  transfers  should  be  possible  only  in  residual cases where none of the other grounds for  transfer are applicable. For scientific or historical research purposes or statistical  purposes,  the  legitimate  expectations  of  society  for  an  increase  of  knowledge  should  be  taken  into  con­ sideration. The controller should inform the supervisory authority and the data subject about the transfer.\n(114)   In  any  case,  where  the  Commission  has  taken  no  decision  on  the  adequate  level  of  data  protection  in  a  third country, the controller or  processor should make use of solutions that provide data subjects with enforceable and effective  rights  as  regards  the  processing  of  their  data  in  the  Union  once  those  data  have  been  transferred  so  that that they will continue to benefit from fundamental rights and safeguards.\nEN\n(115)   Some  third  countries  adopt  laws,  regulations  and  other  legal  acts  which  purport  to  directly  regulate  the processing  activities  of  natural  and  legal  persons  under  the  jurisdiction  of  the  Member  States.  This  may  include judgments  of  courts  or  tribunals  or  decisions  of  administrative  authorities  in  third  countries  requiring  a controller  or  processor  to  transfer  or  disclose  personal  data,  and  which  are  not  based  on  an  international agreement,  such  as  a  mutual  legal  assistance  treaty,  in  force  between  the  requesting  third  country  and  the  Union or  a  Member  State.  The  extraterritorial  application  of  those  laws,  regulations  and  other  legal  acts  may  be  in breach  of  international  law  and  may  impede  the  attainment  of  the  protection  of  natural  persons  ensured  in  the Union by this Regulation. Transfers should only be allowed where the conditions of  this Regulation for a transfer to third countries are met. This may be the case, inter alia, where disclosure is necessary for an important ground of public interest recognised in Union or Member State law to which the controller is subject.\n(116)   When  personal  data  moves  across  borders  outside  the  Union  it  may  put  at  increased  risk  the  ability  of  natural persons  to  exercise  data  protection  rights  in  particular  to  protect  themselves  from  the  unlawful  use  or  disclosure of  that  information.  At  the  same  time,  supervisory  authorities  may  find  that  they  are  unable  to  pursue complaints or conduct investigations relating to the activities outside their borders. Their efforts to work together in  the  cross-border  context  may  also  be  hampered  by  insufficient  preventative  or  remedial  powers,  inconsistent legal  regimes,  and  practical  obstacles  like  resource  constraints.  Therefore,  there  is  a  need  to  promote  closer cooperation  among  data  protection  supervisory  authorities  to  help  them  exchange  information  and  carry  out investigations  with  their  international  counterparts.  For  the  purposes  of  developing  international  cooperation mechanisms  to  facilitate  and  provide  international  mutual  assistance  for  the  enforcement  of  legislation  for  the protection  of  personal  data,  the  Commission  and  the  supervisory  authorities  should  exchange  information  and cooperate in activities  related  to  the  exercise  of  their  powers  with  competent  authorities  in  third  countries,  based on reciprocity and in accordance with this Regulation.\n(117)   The  establishment  of  supervisory  authorities  in  Member  States,  empowered  to  perform  their  tasks  and  exercise their  powers  with  complete  independence,  is  an  essential  component  of  the  protection  of  natural  persons  with regard  to  the  processing  of  their  personal  data.  Member  States  should  be  able  to  establish  more  than  one supervisory authority, to reflect their constitutional, organisational and administrative structure.\n(118)   The  independence  of  supervisory  authorities  should  not  mean  that  the  supervisory  authorities  cannot  be  subject to control or monitoring mechanisms regarding their financial expenditure or to judicial review.\n(119)   Where  a  Member  State  establishes  several  supervisory  authorities,  it  should  establish  by  law  mechanisms  for ensuring  the  effective  participation  of  those  supervisory  authorities  in  the  consistency  mechanism.  That  Member State  should  in  particular  designate  the  supervisory  authority  which  functions  as  a  single  contact  point  for  the effective  participation  of  those  authorities  in  the  mechanism,  to  ensure  swift  and  smooth  cooperation with  other supervisory authorities, the Board and the Commission.\n(120)   Each  supervisory  authority  should  be  provided  with  the  financial  and  human  resources,  premises  and infrastructure  necessary  for  the  effective  performance  of  their  tasks,  including  those  related  to  mutual  assistance and  cooperation  with  other  supervisory  authorities  throughout  the  Union.  Each  supervisory  authority  should have a separate, public annual budget, which may be part of the overall state or national budget.\n(121)   The  general  conditions  for  the  member  or  members  of  the  supervisory  authority  should  be  laid  down  by  law  in each  Member  State  and  should  in  particular  provide  that  those  members  are  to  be  appointed,  by  means  of  a transparent  procedure,  either  by  the  parliament,  government  or  the  head  of  State  of  the  Member  State  on  the basis  of  a  proposal  from  the  government,  a  member  of  the  government,  the  parliament  or  a  chamber  of  the parliament,  or  by  an  independent  body  entrusted  under  Member  State  law.  In  order  to  ensure  the  independence of  the  supervisory  authority,  the  member  or  members  should  act  with  integrity,  refrain  from  any  action  that  is incompatible  with  their  duties  and  should  not,  during  their  term  of  office,  engage  in  any  incompatible occupation,  whether  gainful  or  not.  The  supervisory  authority  should  have  its  own  staff,  chosen  by  the supervisory  authority  or  an  independent  body  established  by  Member  State  law,  which  should  be  subject  to  the exclusive direction of the member or members of the supervisory authority.\n(122)   Each supervisory authority should be competent on the territory of  its own Member State to exercise the powers and  to  perform  the  tasks  conferred  on  it  in  accordance  with  this  Regulation.  This  should  cover  in  particular  the\nEN\nprocessing in the context of  the activities of an establishment of  the controller or  processor on the territory of its own  Member  State,  the  processing  of  personal  data  carried  out  by  public  authorities  or  private  bodies  acting  in the  public  interest,  processing  affecting  data  subjects  on  its  territory  or  processing  carried  out  by  a  controller  or processor  not  established  in  the  Union  when  targeting  data  subjects  residing  on  its  territory.  This  should  include handling complaints lodged by a data subject, conducting investigations on the application of this Regulation and promoting  public  awareness  of  the  risks,  rules,  safeguards  and  rights  in  relation  to  the  processing  of  personal data.\n(123)   The  supervisory  authorities  should  monitor  the  application  of  the  provisions  pursuant  to  this  Regulation  and contribute  to  its  consistent  application  throughout  the  Union,  in  order  to  protect  natural  persons  in  relation  to the  processing  of  their  personal  data  and  to  facilitate  the  free  flow  of  personal  data  within  the  internal  market. For  that  purpose,  the  supervisory  authorities  should  cooperate  with  each  other  and  with  the  Commission, without  the  need  for  any  agreement  between  Member  States  on  the  provision  of  mutual  assistance  or  on  such cooperation.\n(124)   Where  the  processing  of  personal  data  takes  place  in  the  context  of  the  activities  of  an  establishment  of  a controller  or  a  processor  in  the  Union  and  the  controller  or  processor  is  established  in  more  than  one Member  State,  or  where  processing  taking  place  in  the  context  of  the  activities  of  a  single  establishment  of  a controller  or  processor  in  the  Union  substantially  affects  or  is  likely  to  substantially  affect  data  subjects  in  more than  one  Member  State,  the  supervisory  authority  for  the  main  establishment  of  the  controller  or  processor  or for  the  single  establishment  of  the  controller  or  processor  should  act  as  lead  authority.  It  should  cooperate  with the other authorities concerned, because the controller or processor has an establishment on the territory of their Member State,  because  data  subjects  residing  on  their  territory  are  substantially  affected,  or  because  a  complaint has been lodged with them. Also where a data subject not residing in that Member State has lodged a complaint, the  supervisory  authority  with  which  such  complaint  has  been  lodged  should  also  be  a  supervisory  authority concerned.  Within  its  tasks  to  issue  guidelines  on  any  question  covering  the  application  of  this  Regulation,  the Board  should  be  able  to  issue  guidelines  in  particular  on  the  criteria  to  be  taken  into  account  in  order  to ascertain  whether  the  processing  in  question  substantially  affects  data  subjects  in  more  than  one  Member  State and on what constitutes a relevant and reasoned objection.\n(125)   The  lead  authority  should  be  competent  to  adopt  binding  decisions  regarding  measures  applying  the  powers conferred  on  it  in  accordance  with  this  Regulation.  In  its  capacity  as  lead  authority,  the  supervisory  authority should  closely  involve  and  coordinate  the  supervisory  authorities  concerned  in  the  decision-making  process. Where  the  decision  is  to  reject  the  complaint  by  the  data  subject  in  whole  or  in  part,  that  decision  should  be adopted by the supervisory authority with which the complaint has been lodged.\n(126)   The decision should be agreed jointly by the lead supervisory authority and the supervisory authorities concerned and should be directed towards the main or single establishment of the controller or processor and be binding on the  controller  and  processor.  The  controller  or  processor  should  take  the  necessary  measures  to  ensure compliance  with  this  Regulation  and  the  implementation  of  the  decision  notified  by  the  lead  supervisory authority  to  the  main  establishment  of  the  controller  or  processor  as  regards  the  processing  activities  in  the Union.\n(127)   Each  supervisory  authority  not  acting  as  the  lead  supervisory  authority  should  be  competent  to  handle  local cases  where  the  controller  or  processor  is  established  in  more  than  one  Member  State,  but  the  subject  matter  of the  specific  processing  concerns  only  processing  carried  out  in  a  single  Member  State  and  involves  only  data subjects in that single Member State, for example, where the subject matter concerns the processing of employees' personal  data  in  the  specific  employment  context  of  a  Member  State.  In  such  cases,  the  supervisory  authority should  inform  the  lead  supervisory  authority  without  delay  about  the  matter.  After  being  informed,  the  lead supervisory  authority  should  decide,  whether  it  will  handle  the  case  pursuant  to  the  provision  on  cooperation between the lead supervisory authority and other supervisory authorities concerned ('one-stop-shop mechanism'), or  whether  the  supervisory  authority  which  informed  it  should  handle  the  case  at  local  level.  When  deciding whether  it  will  handle  the  case,  the  lead  supervisory  authority  should  take  into  account  whether  there  is  an establishment of  the  controller  or  processor  in  the  Member  State  of  the  supervisory  authority  which  informed  it in  order  to  ensure  effective  enforcement  of  a  decision vis-à-vis the  controller  or  processor.  Where  the  lead supervisory  authority  decides  to  handle  the  case,  the  supervisory  authority  which  informed  it  should  have  the\nEN\npossibility  to  submit  a  draft  for  a  decision,  of  which  the  lead  supervisory  authority  should  take  utmost  account when preparing its draft decision in that one-stop-shop mechanism.\n(128)   The  rules  on  the  lead  supervisory  authority  and  the  one-stop-shop  mechanism  should  not  apply  where  the processing  is  carried  out  by  public  authorities  or  private  bodies  in  the  public  interest.  In  such  cases  the  only supervisory authority competent to exercise the powers conferred to it in accordance with this Regulation should be the supervisory authority of the Member State where the public authority or private body is established.\n(129)   In  order  to  ensure  consistent  monitoring  and  enforcement  of  this  Regulation  throughout  the  Union,  the supervisory  authorities  should  have  in  each  Member  State  the  same  tasks  and  effective  powers,  including  powers of  investigation, corrective powers and sanctions, and authorisation and advisory powers, in particular  in cases of complaints  from  natural  persons,  and  without  prejudice  to  the  powers  of  prosecutorial  authorities  under Member  State  law,  to  bring  infringements  of  this  Regulation  to  the  attention  of  the  judicial  authorities  and engage  in  legal  proceedings.  Such  powers  should  also  include  the  power  to  impose  a  temporary  or  definitive limitation,  including  a  ban,  on  processing.  Member  States  may  specify  other  tasks  related  to  the  protection  of personal  data  under  this  Regulation.  The  powers  of  supervisory  authorities  should  be  exercised  in  accordance with  appropriate  procedural  safeguards  set  out  in  Union  and  Member  State  law,  impartially,  fairly  and  within  a reasonable  time.  In  particular  each  measure  should  be  appropriate,  necessary  and  proportionate  in  view  of ensuring  compliance  with  this  Regulation,  taking  into  account  the  circumstances  of  each  individual  case,  respect the  right  of  every  person  to  be  heard  before  any  individual  measure  which  would  affect  him  or  her  adversely  is taken  and  avoid  superfluous  costs  and  excessive  inconveniences  for  the  persons  concerned.  Investigatory  powers as  regards  access  to  premises  should  be  exercised  in  accordance  with  specific  requirements  in  Member  State procedural  law,  such  as  the  requirement  to  obtain  a  prior  judicial  authorisation.  Each  legally  binding  measure  of the  supervisory  authority  should  be  in  writing,  be  clear  and  unambiguous,  indicate  the  supervisory  authority which  has  issued  the  measure,  the  date  of  issue  of  the  measure,  bear  the  signature  of  the  head,  or  a  member  of the supervisory authority authorised by him or her, give the reasons for  the measure, and refer  to the right of an effective remedy. This should not preclude additional requirements pursuant to Member State procedural law. The adoption  of  a  legally  binding  decision  implies  that  it  may  give  rise  to  judicial  review  in  the  Member  State  of  the supervisory authority that adopted the decision.\n(130)   Where the supervisory authority with which the complaint has been lodged is not the lead supervisory authority, the  lead  supervisory  authority  should  closely cooperate  with  the  supervisory  authority  with  which the  complaint has  been  lodged  in  accordance  with  the  provisions  on  cooperation  and  consistency  laid  down  in  this  Regulation. In  such  cases,  the  lead  supervisory  authority  should,  when  taking  measures  intended  to  produce  legal  effects, including  the  imposition  of  administrative  fines,  take  utmost  account  of  the  view  of  the  supervisory  authority with which the complaint has been lodged and which should remain competent to carry out any investigation on the territory of its own Member State in liaison with the competent supervisory authority.\n(131)   Where  another  supervisory  authority  should  act  as  a  lead  supervisory  authority  for  the  processing  activities  of the  controller  or  processor  but  the  concrete  subject  matter  of  a  complaint  or  the  possible  infringement  concerns only  processing  activities  of  the  controller  or  processor  in  the  Member  State  where  the  complaint  has  been lodged  or  the  possible  infringement  detected  and  the  matter  does  not  substantially  affect  or  is  not  likely  to substantially  affect  data  subjects  in  other  Member  States,  the  supervisory  authority  receiving  a  complaint  or detecting  or  being  informed  otherwise  of  situations  that  entail  possible  infringements  of  this  Regulation  should seek  an  amicable  settlement  with  the  controller  and,  if  this  proves  unsuccessful,  exercise  its  full  range  of  powers. This  should  include:  specific  processing  carried  out  in  the  territory  of  the  Member  State  of  the  supervisory authority  or  with  regard  to  data  subjects  on  the  territory  of  that  Member  State;  processing  that  is  carried  out  in the  context  of  an  offer  of  goods  or  services  specifically  aimed  at  data  subjects  in  the  territory  of  the  Member State  of  the  supervisory  authority;  or  processing  that  has  to  be  assessed  taking  into  account  relevant  legal obligations under Member State law.\n(132)   Awareness-raising  activities  by  supervisory  authorities  addressed  to  the  public  should  include  specific  measures directed  at  controllers  and  processors,  including  micro,  small  and  medium-sized  enterprises,  as  well  as  natural persons in particular in the educational context.\nEN\n(133)   The  supervisory  authorities  should  assist  each  other  in  performing  their  tasks  and  provide  mutual  assistance,  so as  to  ensure  the  consistent  application  and  enforcement  of  this  Regulation  in  the  internal  market.  A  supervisory authority requesting mutual assistance may adopt a provisional measure if it receives no response to a request for mutual assistance within one month of the receipt of that request by the other supervisory authority.\n(134)   Each  supervisory  authority  should,  where  appropriate,  participate  in  joint  operations  with  other  supervisory authorities.  The  requested  supervisory  authority  should  be  obliged  to  respond  to  the  request  within  a  specified time period.\n(135)   In  order  to  ensure  the  consistent  application  of  this  Regulation  throughout  the  Union,  a  consistency  mechanism for  cooperation  between  the  supervisory  authorities  should  be  established.  That  mechanism  should  in  particular apply  where  a  supervisory  authority  intends  to  adopt  a  measure  intended  to  produce  legal  effects  as  regards processing operations which substantially affect a significant number of data subjects in several Member States. It should  also  apply  where  any  supervisory  authority  concerned  or  the  Commission  requests  that  such  matter should  be  handled  in  the  consistency  mechanism.  That  mechanism  should  be  without  prejudice  to  any  measures that the Commission may take in the exercise of its powers under  the Treaties.\n(136)   In  applying  the  consistency  mechanism,  the  Board  should,  within  a  determined  period  of  time,  issue  an  opinion, if  a  majority  of  its  members  so  decides  or  if  so  requested  by  any  supervisory  authority  concerned  or  the Commission.  The  Board  should  also  be  empowered  to  adopt  legally  binding  decisions  where  there  are  disputes between  supervisory  authorities.  For  that  purpose,  it  should  issue,  in  principle  by  a  two-thirds  majority  of  its members, legally binding decisions in clearly specified cases where there are conflicting views among supervisory authorities,  in  particular  in  the  cooperation  mechanism  between  the  lead  supervisory  authority  and  supervisory authorities concerned on the merits of the case, in particular  whether  there is an infringement of this Regulation.\n(137)   There  may  be  an  urgent  need  to  act  in  order  to  protect  the  rights  and  freedoms  of  data  subjects,  in  particular when  the  danger  exists  that  the  enforcement  of  a  right  of  a  data  subject  could  be  considerably  impeded.  A supervisory authority should therefore be able to adopt duly justified  provisional measures on its territory  with a specified period of validity which should not exceed three months.\n(138)   The  application  of  such  mechanism  should  be  a  condition  for  the  lawfulness  of  a  measure  intended  to  produce legal  effects  by  a  supervisory  authority  in  those  cases  where  its  application  is  mandatory.  In  other  cases  of  crossborder  relevance,  the  cooperation  mechanism  between the lead supervisory  authority  and supervisory authorities concerned  should  be  applied  and  mutual  assistance  and  joint  operations  might  be  carried  out  between  the supervisory  authorities  concerned  on  a  bilateral  or  multilateral  basis  without  triggering  the  consistency mechanism.\n(139)   In  order  to  promote  the  consistent  application  of  this  Regulation,  the  Board  should  be  set  up  as  an  independent body  of  the  Union.  To  fulfil  its  objectives,  the  Board  should  have  legal  personality.  The  Board  should  be represented  by  its  Chair.  It  should  replace  the  Working  Party  on  the  Protection  of  Individuals  with  Regard  to  the Processing  of  Personal  Data  established  by  Directive  95/46/EC.  It  should  consist  of  the  head  of  a  supervisory authority  of  each  Member  State  and  the  European  Data  Protection  Supervisor  or  their  respective  representatives. The  Commission  should  participate  in  the  Board's  activities  without  voting  rights  and  the  European  Data Protection  Supervisor  should  have  specific  voting  rights.  The  Board  should  contribute  to  the  consistent application  of  this  Regulation  throughout  the  Union,  including  by  advising  the  Commission,  in  particular  on  the level  of  protection  in  third  countries  or  international  organisations,  and  promoting  cooperation  of  the supervisory authorities throughout the Union. The Board should act independently when performing its tasks.\n(140)   The  Board  should  be  assisted  by  a  secretariat  provided  by  the  European  Data  Protection  Supervisor.  The  staff  of the  European  Data  Protection  Supervisor  involved  in  carrying  out  the  tasks  conferred  on  the  Board  by  this Regulation should perform its tasks exclusively under  the instructions of, and report to, the Chair of the Board.\n(141)   Every data subject should have the right to lodge a complaint with a single supervisory authority, in particular  in the  Member  State  of  his  or  her  habitual  residence,  and  the  right  to  an  effective  judicial  remedy  in  accordance\nEN\nwith  Article  47  of  the  Charter  if  the  data  subject  considers  that  his  or  her  rights  under  this  Regulation  are infringed or  where the supervisory authority does not act on a complaint, partially or  wholly rejects or dismisses a  complaint  or  does  not  act  where  such  action  is  necessary  to  protect  the  rights  of  the  data  subject.  The  investi­ gation  following a  complaint  should  be  carried  out,  subject  to judicial  review,  to  the  extent  that  is  appropriate  in the  specific  case.  The  supervisory  authority  should  inform  the  data  subject  of  the  progress  and  the  outcome  of the  complaint  within  a  reasonable  period.  If  the  case  requires  further  investigation  or  coordination  with  another supervisory  authority,  intermediate  information  should  be  given  to  the  data  subject.  In  order  to  facilitate  the submission  of  complaints,  each  supervisory  authority  should  take  measures  such  as  providing  a  complaint submission form which can also be completed electronically, without excluding other means of communication."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_6",
    "chunk_content": "REGULATIONS\n(142)   Where  a  data  subject  considers  that  his  or  her  rights  under  this  Regulation  are  infringed,  he  or  she  should  have the  right  to  mandate  a  not-for-profit  body,  organisation  or  association  which  is  constituted  in  accordance  with the  law  of  a  Member  State,  has  statutory  objectives  which  are  in  the  public  interest  and  is  active  in  the  field  of the  protection  of  personal  data  to  lodge  a  complaint  on  his  or  her  behalf  with  a  supervisory  authority,  exercise the right to a judicial remedy on behalf of data subjects or, if provided for  in Member State law, exercise the right to receive compensation on behalf of data subjects. A Member State may provide for such a body, organisation or association  to  have  the  right  to  lodge  a  complaint  in  that  Member  State,  independently  of  a  data  subject's mandate,  and  the  right  to  an  effective  judicial  remedy  where  it  has  reasons  to  consider  that  the  rights  of  a  data subject  have  been  infringed  as  a  result  of  the  processing  of  personal  data  which  infringes  this  Regulation.  That body,  organisation  or  association  may  not  be  allowed  to  claim  compensation  on  a  data  subject's  behalf  indepen­ dently of  the data subject's mandate.\n(143)   Any  natural  or  legal  person  has  the  right  to  bring  an  action  for  annulment  of  decisions  of  the  Board  before  the Court  of  Justice  under  the  conditions  provided  for  in  Article  263  TFEU.  As  addressees  of  such  decisions,  the supervisory  authorities  concerned  which  wish  to  challenge  them  have  to  bring  action  within  two  months  of being  notified  of  them,  in  accordance  with  Article  263  TFEU.  Where  decisions  of  the  Board  are  of  direct  and individual  concern  to  a  controller,  processor  or  complainant,  the  latter  may  bring  an  action  for  annulment against  those  decisions  within  two  months  of  their  publication  on  the  website  of  the  Board,  in  accordance  with Article  263  TFEU.  Without  prejudice  to  this  right  under  Article  263  TFEU,  each  natural  or  legal  person  should have  an  effective  judicial  remedy  before  the  competent  national  court  against  a  decision  of  a  supervisory authority which produces legal effects concerning that person. Such a decision concerns in particular  the exercise of  investigative,  corrective  and  authorisation  powers  by  the  supervisory  authority or  the  dismissal  or  rejection  of complaints. However, the right to an effective judicial remedy does not encompass measures taken by supervisory authorities  which  are  not  legally  binding,  such  as  opinions  issued  by  or  advice  provided  by  the  supervisory authority.  Proceedings  against  a  supervisory  authority  should  be  brought  before  the  courts  of  the  Member  State where  the  supervisory  authority  is  established  and  should  be  conducted  in  accordance  with  that  Member  State's procedural  law.  Those  courts  should  exercise  full  jurisdiction,  which  should  include  jurisdiction  to  examine  all questions of fact and law relevant to the dispute before them.\nWhere  a  complaint  has  been  rejected  or  dismissed  by  a  supervisory  authority,  the  complainant  may  bring proceedings  before  the  courts  in  the  same  Member  State.  In  the  context  of  judicial  remedies  relating  to  the application  of  this  Regulation,  national  courts  which  consider  a  decision  on  the  question  necessary  to  enable them to give  judgment,  may,  or  in  the  case  provided  for  in  Article  267  TFEU,  must,  request  the  Court  of  Justice to  give  a  preliminary  ruling  on  the  interpretation  of  Union  law,  including  this  Regulation.  Furthermore,  where  a decision  of  a  supervisory  authority  implementing  a  decision  of  the  Board  is  challenged  before  a  national  court and  the  validity  of  the  decision  of  the  Board  is  at  issue,  that  national  court  does  not  have  the  power  to  declare the  Board's  decision  invalid  but  must  refer  the  question  of  validity  to  the  Court  of  Justice  in  accordance  with Article  267  TFEU  as  interpreted  by  the  Court  of  Justice,  where  it  considers  the  decision  invalid.  However,  a national  court  may  not  refer  a  question  on  the  validity of  the  decision  of  the  Board  at  the  request  of  a  natural  or legal  person  which  had  the  opportunity  to  bring  an  action  for  annulment  of  that  decision,  in  particular  if  it  was directly  and  individually  concerned  by  that  decision,  but  had  not  done  so  within  the  period  laid  down  in Article 263 TFEU.\n(144)   Where  a  court  seized  of  proceedings  against  a  decision  by  a  supervisory  authority  has  reason  to  believe  that proceedings  concerning  the  same  processing,  such  as  the  same  subject  matter  as  regards  processing  by  the  same controller  or  processor,  or  the  same  cause  of  action,  are  brought  before  a  competent  court  in  another Member  State,  it  should  contact  that  court  in  order  to  confirm  the  existence  of  such  related  proceedings.  If related  proceedings  are  pending  before  a  court  in  another  Member  State,  any  court  other  than  the  court  first\nEN\nseized  may  stay  its  proceedings  or  may,  on  request  of  one  of  the  parties,  decline  jurisdiction  in  favour  of  the court  first  seized  if  that  court  has  jurisdiction  over  the  proceedings  in  question  and  its  law  permits  the  consoli­ dation of such related proceedings. Proceedings are deemed to be related where they are so closely connected that it  is  expedient  to  hear  and  determine  them  together  in  order  to  avoid  the  risk  of  irreconcilable  judgments resulting from separate proceedings.\n(145)   For  proceedings  against  a  controller  or  processor,  the  plaintiff  should  have  the  choice  to  bring  the  action  before the courts of the Member States where the controller or processor has an establishment or where the data subject resides, unless the controller is a public authority of a Member State acting in the exercise of its public powers.\n(146)   The  controller  or  processor  should  compensate  any  damage  which  a  person  may  suffer  as  a  result  of  processing that  infringes  this  Regulation.  The  controller  or  processor  should  be  exempt  from  liability  if  it  proves  that  it  is not  in  any  way  responsible  for  the  damage.  The  concept  of  damage  should  be  broadly  interpreted  in  the  light  of the  case-law  of  the  Court  of  Justice  in  a  manner  which  fully  reflects  the  objectives  of  this  Regulation.  This  is without prejudice  to any claims  for  damage deriving  from  the  violation  of other  rules  in  Union  or  Member  State law.  Processing  that  infringes  this  Regulation  also  includes  processing  that  infringes  delegated  and  implementing acts  adopted  in  accordance  with  this  Regulation  and  Member  State  law  specifying  rules  of  this  Regulation.  Data subjects  should  receive  full  and  effective  compensation  for  the  damage  they  have  suffered.  Where  controllers  or processors  are  involved  in  the  same  processing,  each  controller  or  processor  should  be  held  liable  for  the  entire damage. However, where they are joined  to the  same  judicial  proceedings,  in  accordance  with  Member  State  law, compensation may be apportioned according to the responsibility of each controller or  processor for  the damage caused  by  the  processing,  provided  that  full  and  effective  compensation  of  the  data  subject  who  suffered  the damage  is  ensured.  Any  controller  or  processor  which  has  paid  full  compensation  may  subsequently  institute recourse proceedings against other controllers or processors involved in the same processing.\n(147)   Where specific  rules  on  jurisdiction  are  contained  in  this  Regulation,  in  particular  as  regards  proceedings  seeking a  judicial  remedy  including  compensation,  against  a  controller  or  processor,  general  jurisdiction  rules  such  as those  of  Regulation  (EU)  No  1215/2012  of  the  European  Parliament  and  of  the  Council  ( 1 )  should  not  prejudice the application of such specific rules.\n(148)   In  order  to  strengthen  the  enforcement  of  the  rules  of  this  Regulation,  penalties  including  administrative  fines should  be  imposed  for  any  infringement  of  this  Regulation,  in  addition  to,  or  instead  of  appropriate  measures imposed by the supervisory authority pursuant to this Regulation. In a case of a minor infringement or if the fine likely  to  be  imposed  would  constitute  a  disproportionate  burden  to  a  natural  person,  a  reprimand  may  be  issued instead of a fine. Due regard should however be given to the nature, gravity and duration of the infringement, the intentional  character  of  the  infringement,  actions  taken  to  mitigate  the  damage  suffered,  degree  of  responsibility or  any  relevant  previous  infringements,  the  manner  in which the  infringement became  known  to the supervisory authority,  compliance  with  measures  ordered  against the  controller  or  processor,  adherence  to a  code  of  conduct and  any  other  aggravating  or  mitigating  factor.  The  imposition  of  penalties  including  administrative  fines  should be  subject  to  appropriate  procedural  safeguards  in  accordance  with  the  general  principles  of  Union  law  and  the Charter, including effective judicial protection and due process.\n(149)   Member  States  should  be  able  to  lay  down  the  rules  on  criminal  penalties  for  infringements  of  this  Regulation, including  for  infringements  of  national  rules  adopted  pursuant  to  and  within  the  limits  of  this  Regulation.  Those criminal  penalties  may  also  allow  for  the  deprivation  of  the  profits  obtained  through  infringements  of  this Regulation.  However,  the  imposition  of  criminal  penalties  for  infringements  of  such  national  rules  and  of administrative  penalties  should  not  lead  to a  breach  of  the  principle  of ne  bis  in  idem ,  as  interpreted  by  the  Court of Justice.\n(150)   In  order  to  strengthen  and  harmonise  administrative  penalties  for  infringements  of  this  Regulation,  each supervisory  authority  should  have  the  power  to  impose  administrative  fines.  This  Regulation  should  indicate\nEN\ninfringements  and  the  upper  limit  and  criteria  for  setting  the  related  administrative  fines,  which  should  be determined  by  the  competent  supervisory  authority  in  each  individual  case,  taking  into  account  all  relevant circumstances  of  the  specific  situation,  with  due  regard  in  particular  to  the  nature,  gravity  and  duration  of  the infringement  and  of  its  consequences  and  the  measures  taken  to  ensure  compliance  with  the  obligations  under this  Regulation  and  to  prevent  or  mitigate  the  consequences  of  the  infringement.  Where  administrative  fines  are imposed  on  an  undertaking,  an  undertaking  should  be  understood  to  be  an  undertaking  in  accordance  with Articles  101  and  102  TFEU  for  those  purposes.  Where  administrative  fines  are  imposed  on  persons  that  are  not an undertaking, the supervisory authority should take account of the general level of income in the Member State as  well  as  the  economic  situation  of  the  person  in  considering  the  appropriate  amount  of  the  fine.  The consistency mechanism may also be used to promote a consistent application of administrative fines. It should be for  the  Member States to determine whether and to which extent public authorities should be subject to adminis­ trative  fines.  Imposing  an  administrative  fine  or  giving  a  warning  does  not  affect  the  application  of other  powers of  the  supervisory authorities or of other penalties under  this Regulation.\n(151)   The legal systems of Denmark and Estonia do not allow for administrative fines as set out in this Regulation. The rules on administrative fines may be applied in such a manner  that in Denmark the fine is imposed by competent national  courts  as  a  criminal  penalty  and  in  Estonia  the  fine  is  imposed  by  the  supervisory  authority  in  the framework of a misdemeanour  procedure, provided that such an application of  the  rules  in  those  Member  States has  an  equivalent  effect  to  administrative  fines  imposed  by  supervisory  authorities.  Therefore  the  competent national  courts  should  take  into  account  the  recommendation  by  the  supervisory  authority  initiating  the  fine.  In any event, the fines imposed should be effective, proportionate and dissuasive.\n(152)   Where  this  Regulation  does  not  harmonise  administrative  penalties  or  where  necessary  in  other  cases,  for example  in  cases  of  serious  infringements  of  this  Regulation,  Member  States  should  implement  a  system  which provides  for  effective,  proportionate  and  dissuasive  penalties.  The  nature  of  such  penalties,  criminal  or  adminis­ trative, should be determined by Member State law.\n(153)   Member  States  law  should  reconcile  the  rules  governing  freedom  of  expression  and  information,  including journalistic,  academic,  artistic  and  or  literary  expression  with  the  right  to  the  protection  of  personal  data pursuant  to  this  Regulation.  The  processing  of  personal  data  solely  for  journalistic  purposes,  or  for  the  purposes of  academic,  artistic  or  literary  expression  should  be  subject  to  derogations  or  exemptions  from  certain provisions  of  this  Regulation  if  necessary  to  reconcile  the  right  to  the  protection  of  personal  data  with  the  right to  freedom  of  expression  and  information,  as  enshrined  in  Article  11  of  the  Charter.  This  should  apply  in particular  to  the  processing  of  personal  data  in  the  audiovisual  field  and  in  news  archives  and  press  libraries. Therefore,  Member  States  should  adopt  legislative  measures  which  lay  down  the  exemptions  and  derogations necessary  for  the  purpose  of  balancing  those  fundamental  rights.  Member  States  should  adopt  such  exemptions and derogations on general principles, the rights of  the data subject, the controller and the processor, the transfer of  personal  data  to  third  countries  or  international  organisations,  the  independent  supervisory  authorities, cooperation  and  consistency,  and  specific  data-processing  situations.  Where  such  exemptions  or  derogations differ  from  one  Member  State  to  another,  the  law  of  the  Member  State  to  which  the  controller  is  subject  should apply.  In  order  to  take  account  of  the  importance  of  the  right  to  freedom  of  expression  in  every  democratic society, it is necessary to interpret notions relating to that freedom, such as journalism, broadly.\n(154)   This  Regulation  allows  the  principle  of  public  access  to  official  documents  to  be  taken  into  account  when applying  this  Regulation.  Public  access  to  official  documents  may  be  considered  to  be  in  the  public  interest. Personal  data  in  documents  held  by  a  public  authority  or  a  public  body  should  be  able  to  be  publicly  disclosed by  that  authority  or  body  if  the  disclosure  is  provided  for  by  Union  or  Member  State  law  to  which  the  public authority or  public  body  is  subject.  Such  laws  should  reconcile  public  access  to  official  documents  and  the  reuse of  public  sector  information  with  the  right  to  the  protection  of  personal  data  and  may  therefore  provide  for  the necessary  reconciliation  with  the  right  to  the  protection  of  personal  data  pursuant  to  this  Regulation.  The reference  to  public  authorities  and  bodies  should  in  that  context  include  all  authorities  or  other  bodies  covered by  Member  State  law  on  public  access  to  documents.  Directive  2003/98/EC  of  the  European  Parliament  and  of the  Council  ( 1 )  leaves  intact  and  in  no  way  affects  the  level  of  protection  of  natural  persons  with  regard  to  the\nEN\nprocessing of personal data under  the provisions of Union and Member State law, and in particular does not alter the  obligations  and  rights  set  out  in  this  Regulation.  In  particular,  that  Directive  should  not  apply  to  documents to which access is excluded or  restricted by virtue of  the access regimes on the grounds of protection of personal data,  and  parts  of  documents  accessible  by  virtue  of  those  regimes  which  contain  personal  data  the  re-use  of which  has  been  provided  for  by  law  as  being  incompatible  with  the  law  concerning  the  protection  of  natural persons with regard to the processing of personal data.\n(155)   Member  State  law  or  collective  agreements,  including  'works  agreements',  may  provide  for  specific  rules  on  the processing  of  employees'  personal  data  in  the  employment  context,  in  particular  for  the  conditions  under  which personal  data  in  the  employment  context  may  be  processed  on  the  basis  of  the  consent  of  the  employee,  the purposes  of  the  recruitment,  the  performance  of  the  contract  of  employment,  including  discharge  of  obligations laid  down  by  law  or  by  collective  agreements,  management,  planning  and  organisation  of  work,  equality  and diversity  in  the  workplace,  health  and  safety  at  work,  and  for  the  purposes  of  the  exercise  and  enjoyment,  on  an individual  or  collective  basis,  of  rights  and  benefits  related  to  employment,  and  for  the  purpose  of  the termination of the employment relationship.\n(156)   The  processing  of  personal  data  for  archiving  purposes  in  the  public  interest,  scientific  or  historical  research purposes  or  statistical  purposes  should  be  subject  to  appropriate  safeguards  for  the  rights  and  freedoms  of  the data  subject  pursuant  to  this  Regulation.  Those  safeguards  should  ensure  that  technical  and  organisational measures are in place in order  to ensure, in particular, the principle  of data  minimisation. The  further  processing of  personal  data  for  archiving  purposes  in  the  public  interest,  scientific  or  historical  research  purposes  or statistical  purposes  is  to  be  carried  out  when  the  controller  has  assessed  the  feasibility  to  fulfil  those  purposes  by processing  data  which  do  not  permit  or  no  longer  permit  the  identification  of  data  subjects,  provided  that appropriate  safeguards  exist  (such  as,  for  instance,  pseudonymisation  of  the  data).  Member  States  should  provide for  appropriate  safeguards  for  the  processing  of  personal  data  for  archiving  purposes  in  the  public  interest, scientific  or  historical  research  purposes  or  statistical  purposes.  Member  States  should  be  authorised  to  provide, under  specific  conditions  and  subject  to  appropriate  safeguards  for  data  subjects,  specifications  and  derogations with  regard  to  the  information  requirements  and  rights  to  rectification,  to  erasure,  to  be  forgotten,  to  restriction of  processing,  to  data  portability,  and  to  object  when  processing  personal  data  for  archiving  purposes  in  the public  interest,  scientific  or  historical  research  purposes  or  statistical  purposes.  The  conditions  and  safeguards  in question may entail specific  procedures  for  data  subjects  to  exercise  those  rights  if  this  is  appropriate  in  the  light of  the  purposes  sought  by  the  specific  processing  along  with  technical  and  organisational  measures  aimed  at minimising  the  processing  of  personal  data  in  pursuance  of  the  proportionality  and  necessity  principles.  The processing  of  personal  data  for  scientific  purposes  should  also  comply  with  other  relevant  legislation  such  as  on clinical trials.\n(157)   By  coupling  information  from  registries,  researchers  can  obtain  new  knowledge  of  great  value  with  regard  to widespread  medical  conditions  such  as  cardiovascular  disease,  cancer  and  depression.  On  the  basis  of  registries, research  results  can  be  enhanced,  as  they  draw  on  a  larger  population.  Within  social  science,  research  on  the basis  of  registries  enables  researchers  to  obtain  essential  knowledge  about  the  long-term  correlation  of  a  number of  social  conditions  such  as  unemployment  and  education  with  other  life  conditions.  Research  results  obtained through  registries  provide  solid,  high-quality  knowledge  which  can  provide  the  basis  for  the  formulation  and implementation  of  knowledge-based  policy,  improve  the  quality  of  life  for  a  number  of  people  and  improve  the efficiency  of  social  services.  In  order  to  facilitate  scientific  research,  personal  data  can  be  processed  for  scientific research purposes, subject to appropriate conditions and safeguards set out in Union or Member State law.\n(158)   Where  personal  data  are  processed  for  archiving  purposes,  this  Regulation  should  also  apply  to  that  processing, bearing in mind that this Regulation should not apply to deceased persons. Public authorities or public or private bodies  that  hold  records  of  public  interest  should  be  services  which,  pursuant  to  Union  or  Member  State  law, have  a  legal  obligation  to  acquire,  preserve,  appraise,  arrange,  describe,  communicate,  promote,  disseminate  and provide  access  to  records  of  enduring  value  for  general  public  interest.  Member  States  should  also  be  authorised to  provide  for  the  further  processing  of  personal  data  for  archiving  purposes,  for  example  with  a  view  to providing specific information related to the political behaviour under  former  totalitarian state regimes, genocide, crimes against humanity, in particular  the Holocaust, or war crimes.\nEN\n(159)   Where  personal  data  are  processed  for  scientific  research  purposes,  this  Regulation  should  also  apply  to  that processing.  For  the  purposes  of  this  Regulation,  the  processing  of  personal  data  for  scientific  research  purposes should  be  interpreted  in  a  broad  manner  including  for  example  technological  development  and  demonstration, fundamental research, applied research and privately funded research. In addition, it should take into account the Union's objective  under  Article  179(1)  TFEU  of achieving a  European  Research Area.  Scientific  research purposes should  also  include  studies  conducted  in  the  public  interest  in  the  area  of  public  health.  To  meet  the  specificities of  processing  personal  data  for  scientific  research  purposes,  specific  conditions  should  apply  in  particular  as regards  the  publication  or  otherwise  disclosure  of  personal  data  in  the  context  of  scientific  research  purposes.  If the result of scientific  research in particular  in the  health context gives reason for  further  measures in the interest of  the  data subject, the general rules of this Regulation should apply in view of those measures.\n(160)   Where  personal  data  are  processed  for  historical  research  purposes,  this  Regulation  should  also  apply  to  that processing.  This  should  also  include  historical  research  and  research  for  genealogical  purposes,  bearing  in  mind that this Regulation should not apply to deceased persons.\n(161)   For  the  purpose  of  consenting  to  the  participation  in  scientific  research  activities  in  clinical  trials,  the  relevant provisions of Regulation (EU) No 536/2014 of the European Parliament and of the Council ( 1 )  should apply.\n(162)   Where personal data are processed for statistical purposes, this Regulation should apply to that processing. Union or  Member  State  law  should,  within  the  limits  of  this  Regulation,  determine  statistical  content,  control  of  access, specifications  for  the  processing  of  personal  data  for  statistical  purposes  and  appropriate  measures  to  safeguard the  rights  and  freedoms  of  the  data  subject  and  for  ensuring  statistical  confidentiality.  Statistical  purposes  mean any  operation  of  collection  and  the  processing  of  personal  data  necessary  for  statistical  surveys  or  for  the production  of  statistical  results.  Those  statistical  results  may  further  be  used  for  different  purposes,  including  a scientific  research  purpose.  The  statistical  purpose  implies  that  the  result  of  processing  for  statistical  purposes  is not  personal  data,  but  aggregate  data,  and  that  this  result  or  the  personal  data  are  not  used  in  support  of measures or decisions regarding any particular natural person.\n(163)   The  confidential  information  which  the  Union  and  national  statistical  authorities  collect  for  the  production  of official  European  and  official  national  statistics  should  be  protected.  European  statistics  should  be  developed, produced  and  disseminated  in  accordance  with  the  statistical  principles  as  set  out  in  Article  338(2)  TFEU,  while national  statistics  should  also  comply  with  Member  State  law.  Regulation  (EC)  No  223/2009  of  the  European Parliament  and  of  the  Council  ( 2 ) provides  further  specifications  on  statistical  confidentiality  for  European statistics.\n(164)   As  regards  the  powers  of  the  supervisory  authorities  to  obtain  from  the  controller  or  processor  access  to personal data and access to their  premises, Member States may adopt by law, within the limits of  this Regulation, specific  rules  in  order  to  safeguard  the  professional  or  other  equivalent  secrecy obligations,  in  so  far  as  necessary to reconcile the right to the protection of personal data with an obligation of professional secrecy. This is without prejudice  to  existing  Member  State  obligations  to  adopt  rules  on  professional  secrecy  where  required  by  Union law.\n(165)   This  Regulation  respects  and  does  not  prejudice  the  status  under  existing  constitutional  law  of  churches  and religious associations or communities in the Member States, as recognised in Article 17 TFEU.\n(166)   In  order  to  fulfil  the  objectives  of  this  Regulation,  namely  to  protect  the  fundamental  rights  and  freedoms  of natural  persons  and  in  particular  their  right  to  the  protection  of  personal  data  and  to  ensure  the  free  movement\n( 1 ) Regulation (EU) No 536/2014 of the European Parliament and of the Council of 16 April 2014 on clinical trials on medicinal products for human use, and repealing Directive 2001/20/EC (OJ L 158, 27.5.2014, p. 1).\n( 2 ) Regulation (EC) No 223/2009 of the European Parliament and of the Council of 11 March 2009 on European statistics and repealing Regulation (EC, Euratom) No 1101/2008 of the European Parliament and of the Council on the transmission of data subject to statistical confidentiality to the Statistical Office of the European Communities, Council Regulation (EC) No 322/97 on Community Statistics, and Council Decision 89/382/EEC, Euratom establishing a Committee on the Statistical Programmes of the European Communities (OJ L 87, 31.3.2009, p. 164).\nEN"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_7",
    "chunk_content": "REGULATIONS\nof  personal  data  within  the  Union,  the  power  to  adopt  acts  in  accordance  with  Article  290  TFEU  should  be delegated  to  the  Commission.  In  particular,  delegated  acts  should  be  adopted  in  respect  of  criteria  and requirements for certification  mechanisms, information  to be presented  by standardised  icons  and  procedures  for providing  such  icons.  It  is  of  particular  importance  that  the  Commission  carry  out  appropriate  consultations during  its  preparatory  work,  including  at  expert  level.  The  Commission,  when  preparing  and  drawing-up delegated  acts,  should  ensure  a  simultaneous,  timely  and  appropriate  transmission  of  relevant  documents  to  the European Parliament and to the Council.\n(167)   In  order  to  ensure  uniform  conditions  for  the  implementation  of  this  Regulation,  implementing  powers  should be  conferred  on  the  Commission  when  provided  for  by  this  Regulation.  Those  powers  should  be  exercised  in accordance  with  Regulation  (EU)  No  182/2011.  In  that  context,  the  Commission  should  consider  specific measures for micro, small and medium-sized enterprises.\n(168)   The  examination  procedure  should  be  used  for  the  adoption  of  implementing  acts  on  standard  contractual clauses  between  controllers  and  processors  and  between  processors;  codes  of  conduct;  technical  standards  and mechanisms  for  certification;  the  adequate  level  of  protection  afforded  by  a  third  country,  a  territory  or  a specified  sector  within  that  third  country,  or  an  international  organisation;  standard  protection  clauses;  formats and  procedures  for  the  exchange  of  information  by  electronic  means  between  controllers,  processors  and supervisory  authorities  for  binding  corporate  rules;  mutual  assistance;  and  arrangements  for  the  exchange  of information  by  electronic  means  between  supervisory  authorities,  and  between  supervisory  authorities  and  the Board.\n(169)   The  Commission  should  adopt  immediately  applicable  implementing  acts  where  available  evidence  reveals  that  a third  country, a territory or a specified sector  within that third country, or an international organisation does not ensure an adequate level of protection, and imperative grounds of urgency so require.\n(170)   Since  the  objective  of  this  Regulation,  namely  to  ensure  an  equivalent  level  of  protection  of  natural  persons  and the  free  flow  of  personal  data  throughout  the  Union,  cannot  be  sufficiently  achieved  by  the  Member  States  and can rather,  by reason of  the scale  or effects of  the  action,  be  better  achieved at  Union  level,  the  Union  may  adopt measures, in accordance with the principle of subsidiarity as set out in Article 5 of the Treaty on European Union (TEU).  In  accordance  with  the  principle  of  proportionality  as  set  out  in  that  Article,  this  Regulation  does  not  go beyond what is necessary in order  to achieve that objective.\n(171)   Directive  95/46/EC  should  be  repealed  by  this  Regulation.  Processing  already  under  way  on  the  date  of application  of  this  Regulation  should  be  brought  into  conformity  with  this  Regulation  within  the  period  of  two years  after  which  this  Regulation  enters  into  force.  Where  processing  is  based  on  consent  pursuant  to  Directive 95/46/EC,  it  is  not  necessary  for  the  data  subject  to  give  his  or  her  consent  again  if  the  manner  in  which  the consent has been given is in line with the conditions of  this Regulation, so as to allow the controller  to continue such processing after the date of application of this Regulation. Commission decisions adopted and authorisations by supervisory authorities based on Directive 95/46/EC remain in force until amended, replaced or repealed.\n(172)   The  European  Data  Protection  Supervisor  was  consulted  in  accordance  with  Article  28(2)  of  Regulation  (EC) No 45/2001 and delivered an opinion on 7 March 2012 ( 1 ).\n(173)   This  Regulation  should  apply  to  all  matters  concerning  the  protection  of  fundamental  rights  and  freedoms vis-àvis the processing of personal data which are not subject to specific obligations with the same objective set out in Directive  2002/58/EC  of  the  European  Parliament  and  of  the  Council  ( 2 ),  including  the  obligations  on  the controller  and  the  rights  of  natural  persons.  In  order  to  clarify  the  relationship  between  this  Regulation  and Directive  2002/58/EC,  that  Directive  should  be  amended  accordingly.  Once  this  Regulation  is  adopted, Directive 2002/58/EC should be reviewed in particular in order  to ensure consistency with this Regulation,\nEN\nHAVE ADOPTED THIS REGULATION:\nCHAPTER I"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_8",
    "chunk_content": "General provisions\nArticle 1"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_9",
    "chunk_content": "Subject-matter and objectives\n[<Paragraph children=[<RawText children=('This  Regulation  lays  down  rules  relating  to  the  protection  of  '\n 'natural  persons  with  regard  to  the  processing  of personal data and '\n 'rules relating to the free movement of personal data.')>]>]\n[<Paragraph children=[<RawText children=('This  Regulation  protects  fundamental  rights  and  freedoms  of  natural  '\n 'persons  and  in  particular  their  right  to  the protection of personal '\n 'data.')>]>]\n[<Paragraph children=[<RawText children=('The  free  movement  of  personal  data  within  the  Union  shall  be  '\n 'neither  restricted  nor  prohibited  for  reasons connected with the '\n 'protection of natural persons with regard to the processing of personal '\n 'data.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_10",
    "chunk_content": "Material scope\n[<Paragraph children=[<RawText children=('This  Regulation  applies  to  the  processing  of  personal  data  wholly  '\n 'or  partly  by  automated  means  and  to  the processing  other  than  by  '\n 'automated  means  of  personal  data  which  form  part  of a  filing  '\n 'system  or  are  intended  to  form part of a filing system.')>]>]\n[<Paragraph children=[<RawText children='This Regulation does not apply to the processing of personal data:'>]>]\n(a)   in  the  course of an activity which falls outside the scope of Union law;\n(b)   by the Member States when carrying out activities which fall within the scope of Chapter 2 of Title V of the TEU;\n(c)   by a natural person in the course of a purely personal or household activity;\n(d)   by  competent  authorities  for  the  purposes  of  the  prevention,  investigation,  detection  or  prosecution  of  criminal offences  or  the  execution  of  criminal  penalties,  including  the  safeguarding  against  and  the  prevention  of  threats  to public security.\n[<Paragraph children=[<RawText children=('For  the  processing  of  personal  data  by  the  Union  institutions,  '\n 'bodies,  offices  and  agencies,  Regulation  (EC) No 45/2001 applies. '\n 'Regulation  (EC)  No  45/2001  and  other  Union  legal  acts  applicable  '\n 'to  such  processing  of  personal data shall be adapted to the principles '\n 'and rules of this Regulation in accordance with Article 98.')>]>]\n[<Paragraph children=[<RawText children=('This  Regulation  shall  be  without  prejudice  to  the  application  of  '\n 'Directive  2000/31/EC,  in  particular  of  the  liability rules of '\n 'intermediary service providers in Articles 12 to 15 of that Directive.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_11",
    "chunk_content": "Territorial scope\n[<Paragraph children=[<RawText children=('This  Regulation  applies  to  the  processing  of  personal  data  in  the  '\n 'context  of  the  activities  of  an  establishment  of  a controller or a '\n 'processor in the Union, regardless of whether the processing takes place in '\n 'the Union or not.')>]>]\nEN\n[<Paragraph children=[<RawText children=('This Regulation applies to the processing of personal data of data subjects '\n 'who are in the Union by a controller or processor not established in the '\n 'Union, where the processing activities are related to:')>]>]\n(a)   the  offering  of  goods  or  services,  irrespective  of  whether  a  payment  of  the  data  subject  is  required,  to  such  data subjects in the Union; or\n(b)   the  monitoring of  their behaviour as far as their behaviour takes place within the Union.\n[<Paragraph children=[<RawText children=('This  Regulation  applies  to  the  processing  of  personal  data  by  a  '\n 'controller  not  established  in  the  Union,  but  in  a place where Member '\n 'State law applies by virtue of public international law.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_12",
    "chunk_content": "Definitions\nFor  the purposes of this Regulation:\n(1)  'personal  data'  means  any  information  relating  to  an  identified  or  identifiable  natural  person  ('data  subject');  an identifiable  natural  person  is  one  who  can  be  identified,  directly  or  indirectly,  in  particular  by  reference  to  an identifier  such  as  a  name,  an  identification  number,  location  data,  an  online  identifier  or  to  one  or  more  factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person;\n(2)  'processing'  means  any  operation  or  set  of  operations  which  is  performed  on  personal  data  or  on  sets  of  personal data,  whether  or  not  by  automated  means,  such  as  collection,  recording,  organisation,  structuring,  storage, adaptation or alteration,  retrieval,  consultation,  use,  disclosure  by  transmission,  dissemination  or  otherwise  making available, alignment or combination, restriction, erasure or destruction;\n(3)  'restriction  of  processing'  means  the  marking  of  stored  personal  data  with  the  aim  of  limiting  their  processing  in the future;\n(4)  'profiling'  means  any  form  of  automated  processing  of  personal  data  consisting  of  the  use  of  personal  data  to evaluate certain personal aspects relating to a natural person, in particular  to analyse or  predict aspects concerning that  natural  person's  performance  at  work,  economic  situation,  health,  personal  preferences,  interests,  reliability, behaviour, location or movements;\n(5)  'pseudonymisation'  means  the  processing  of  personal  data  in  such  a  manner  that  the  personal  data  can  no  longer be  attributed  to  a  specific  data  subject  without  the  use  of  additional  information,  provided  that  such  additional information  is  kept  separately  and  is  subject  to  technical  and  organisational  measures  to  ensure  that  the  personal data are not attributed to an identified or identifiable natural person;\n(6)  'filing  system'  means  any structured  set of  personal  data which are accessible  according  to specific criteria,  whether centralised, decentralised or dispersed on a functional or geographical basis;\n(7)  'controller'  means  the  natural  or  legal  person,  public  authority,  agency  or  other  body  which,  alone  or  jointly  with others,  determines  the  purposes  and  means  of  the  processing  of  personal  data;  where  the  purposes  and  means  of such  processing  are  determined  by  Union  or  Member  State  law,  the  controller  or  the  specific  criteria  for  its nomination may be provided for by Union or Member State law;\n(8)  'processor'  means  a  natural  or  legal  person,  public  authority,  agency  or  other  body  which  processes  personal  data on behalf of the controller;\n(9)  'recipient'  means a natural or legal person, public authority, agency or another body, to which the personal data are disclosed,  whether  a  third  party  or  not.  However,  public  authorities  which  may  receive  personal  data  in  the\nEN\nframework  of  a  particular  inquiry  in  accordance  with  Union  or  Member  State  law  shall  not  be  regarded  as recipients;  the  processing  of  those  data  by  those  public  authorities  shall  be  in  compliance  with  the  applicable  data protection rules according to the purposes of the processing;\n(10)  'third  party'  means  a  natural  or  legal  person,  public  authority,  agency  or  body  other  than  the  data  subject, controller,  processor  and  persons  who,  under  the  direct  authority  of  the  controller  or  processor,  are  authorised  to process personal data;\n(11)  'consent'  of  the  data  subject  means  any  freely  given,  specific,  informed  and  unambiguous  indication  of  the  data subject's  wishes  by  which  he  or  she,  by  a  statement  or  by  a  clear  affirmative  action,  signifies  agreement  to  the processing of personal data relating to him or her;\n(12)  'personal  data  breach'  means  a  breach  of  security  leading  to  the  accidental  or  unlawful  destruction,  loss,  alteration, unauthorised disclosure of, or access to, personal data transmitted, stored or otherwise processed;\n(13)  'genetic  data'  means  personal  data  relating  to  the  inherited  or  acquired  genetic  characteristics  of  a  natural  person which  give  unique  information  about  the  physiology  or  the  health  of  that  natural  person  and  which  result,  in particular, from an analysis of a biological sample from the natural person in question;\n(14) 'biometric  data'  means  personal  data  resulting  from  specific  technical  processing  relating  to  the  physical,  physio­ logical  or  behavioural  characteristics  of  a  natural  person,  which  allow  or  confirm  the  unique  identification  of  that natural person, such as facial images or dactyloscopic data;\n(15)  'data concerning health' means personal data related to the physical or  mental health of a natural person, including the provision of health care services, which reveal information about his or her health status;\n(16)  'main establishment' means:\n(a) as  regards  a  controller  with  establishments  in  more  than  one  Member  State,  the  place  of  its  central  adminis­ tration  in  the  Union,  unless  the  decisions  on  the  purposes  and  means  of  the  processing  of  personal  data  are taken  in  another  establishment  of  the  controller  in  the  Union  and  the  latter  establishment  has  the  power  to have  such  decisions  implemented,  in  which  case  the  establishment  having  taken  such  decisions  is  to  be considered to be the main establishment;\n(b) as  regards  a  processor  with  establishments  in  more  than  one  Member  State,  the  place  of  its  central  adminis­ tration  in  the  Union,  or,  if  the  processor  has  no  central  administration  in  the  Union,  the  establishment  of  the processor  in  the  Union where  the  main processing activities  in  the  context of  the  activities  of  an  establishment of  the  processor  take  place  to  the  extent  that  the  processor  is  subject  to  specific  obligations  under  this Regulation;\n(17)  'representative'  means  a  natural  or  legal  person  established  in  the  Union  who,  designated  by  the  controller  or processor  in  writing  pursuant  to  Article  27,  represents  the  controller  or  processor  with  regard  to  their  respective obligations under  this Regulation;\n(18)  'enterprise'  means a natural or legal person engaged in an economic activity, irrespective of its legal form, including partnerships or associations regularly engaged in an economic activity;\n(19)  'group of undertakings' means a controlling undertaking and its controlled undertakings;\n(20)  'binding corporate rules' means personal data protection policies which are adhered to by a controller or  processor established  on  the  territory  of  a  Member  State  for  transfers  or  a  set  of  transfers  of  personal  data  to  a  controller  or processor  in  one  or  more  third  countries  within  a  group  of  undertakings,  or  group  of  enterprises  engaged  in  a joint economic activity;\n(21)  'supervisory  authority'  means  an  independent  public  authority  which  is  established  by  a  Member  State  pursuant  to Article 51;\nImage\n(22)  'supervisory  authority concerned'  means  a  supervisory  authority  which  is  concerned  by  the  processing  of  personal data because:\n(a)   the  controller or  processor  is established on the territory of  the Member State of that supervisory authority;\n(b)   data  subjects  residing  in the Member State of  that supervisory authority are substantially affected or likely to be substantially affected by the processing; or\n(c)   a  complaint has been lodged with that supervisory authority;\n(23)  'cross-border  processing' means either:\n(a)   processing  of  personal  data  which  takes  place  in  the  context  of  the  activities  of  establishments  in  more  than one Member State of a controller or  processor  in the Union where the controller or  processor  is  established  in more than one Member State; or\n(b)   processing  of  personal  data  which  takes  place  in  the  context  of  the  activities  of  a  single  establishment  of  a controller  or  processor  in  the  Union  but  which  substantially  affects  or  is  likely  to  substantially  affect  data subjects in more than one Member State.\n(24)  'relevant  and  reasoned  objection'  means  an  objection  to  a  draft  decision  as  to  whether  there  is  an  infringement  of this  Regulation,  or  whether  envisaged  action  in  relation  to  the  controller  or  processor  complies  with  this Regulation,  which  clearly  demonstrates  the  significance  of  the  risks  posed  by  the  draft  decision  as  regards  the fundamental  rights  and  freedoms  of  data  subjects  and,  where  applicable,  the  free  flow  of  personal  data  within  the Union;\n(25)  'information  society  service'  means  a  service  as  defined  in  point  (b)  of  Article  1(1)  of  Directive  (EU)  2015/1535  of the European Parliament and of the Council ( 1 );\n(26)  'international  organisation'  means  an  organisation  and  its  subordinate  bodies  governed  by  public  international  law, or any other body which is set up by, or on the basis of, an agreement between two or more countries."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_13",
    "chunk_content": "Principles\nArticle 5"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_14",
    "chunk_content": "Principles relating to processing of personal data\n[<Paragraph children=[<RawText children='Personal data shall be:'>]>]\n(a)   processed  lawfully,  fairly  and  in  a  transparent  manner  in  relation  to  the  data  subject  ('lawfulness,  fairness  and transparency');\n(b)   collected  for  specified,  explicit  and  legitimate  purposes  and  not  further  processed  in  a  manner  that  is  incompatible with  those  purposes;  further  processing  for  archiving  purposes  in  the  public  interest,  scientific  or  historical  research purposes  or  statistical  purposes  shall,  in  accordance  with  Article  89(1),  not  be  considered  to  be  incompatible  with the initial purposes ('purpose limitation');\n(c)   adequate,  relevant  and  limited  to  what  is  necessary  in  relation  to  the  purposes  for  which  they  are  processed  ('data minimisation');\n(d)   accurate and, where necessary, kept up to date; every reasonable step must be taken to ensure that personal data that are  inaccurate,  having  regard  to  the  purposes  for  which  they  are  processed,  are  erased  or  rectified  without  delay ('accuracy');\n( 1 ) Directive  (EU)  2015/1535  of  the  European  Parliament  and  of  the  Council  of  9  September  2015  laying  down  a  procedure  for  the provision of information in the field of technical regulations and of rules on Information Society services (OJ L 241, 17.9.2015, p. 1).\nEN\n(e)   kept  in  a  form  which  permits  identification  of  data  subjects  for  no  longer  than  is  necessary  for  the  purposes  for which  the  personal  data  are  processed;  personal  data  may  be  stored  for  longer  periods  insofar  as  the  personal  data will  be  processed  solely  for  archiving  purposes  in  the  public  interest,  scientific  or  historical  research  purposes  or statistical  purposes  in  accordance  with  Article  89(1)  subject  to  implementation  of  the  appropriate  technical  and organisational measures required by this Regulation in order  to safeguard the rights and freedoms of the data subject ('storage limitation');\n(f)   processed  in  a  manner  that  ensures  appropriate  security  of  the  personal  data,  including  protection  against unauthorised  or  unlawful  processing  and  against  accidental  loss,  destruction  or  damage,  using  appropriate  technical or organisational measures ('integrity and confidentiality').\n[<Paragraph children=[<RawText children=('The controller shall be responsible for, and be able to demonstrate '\n \"compliance with, paragraph 1 ('accountability').\")>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_15",
    "chunk_content": "Lawfulness of processing\n[<Paragraph children=[<RawText children=('Processing shall be lawful only if and to the extent that at least one of '\n 'the following applies:')>]>]\n(a)   the  data subject has given consent to the processing of his or her  personal data for one or  more specific purposes;\n(b)   processing  is  necessary  for  the  performance of a contract  to which the data subject  is party or  in  order  to take steps at  the request of  the data subject prior  to entering into a contract;\n(c)   processing is necessary for compliance with a legal obligation to which the controller is subject;\n(d)   processing is necessary in order  to protect the vital interests of the data subject or of another  natural person;\n(e)   processing  is  necessary  for  the  performance  of  a  task  carried  out  in  the  public  interest  or  in  the  exercise  of  official authority vested in the controller;\n(f)   processing  is  necessary  for  the  purposes  of  the  legitimate  interests  pursued  by  the  controller  or  by  a  third  party, except  where  such  interests  are  overridden  by  the  interests  or  fundamental  rights  and  freedoms  of  the  data  subject which require protection of personal data, in particular  where the data subject is a child.\nPoint  (f)  of  the  first  subparagraph  shall  not  apply  to  processing  carried  out  by  public  authorities  in  the  performance  of their  tasks.\n[<Paragraph children=[<RawText children=('Member  States  may  maintain  or  introduce  more  specific  provisions  '\n 'to  adapt  the  application  of  the  rules  of  this Regulation  with  '\n 'regard  to  processing  for  compliance  with  points  (c)  and  (e)  of  '\n 'paragraph  1  by  determining  more precisely  specific  requirements  for  '\n 'the  processing  and  other  measures  to  ensure  lawful  and  fair  '\n 'processing  including  for other specific processing situations as provided '\n 'for in Chapter IX.')>]>]\n[<Paragraph children=[<RawText children=('The basis for  the processing referred to in point (c) and (e) of paragraph '\n '1 shall be laid down by:')>]>]\n(a)   Union law; or\n(b)   Member State law to which the controller is subject.\nThe purpose of the processing shall be determined in that legal basis or, as regards the processing referred to in point (e) of  paragraph  1,  shall  be  necessary  for  the  performance  of  a  task  carried  out  in  the  public  interest  or  in  the  exercise  of official  authority  vested  in  the  controller.  That  legal  basis  may  contain  specific  provisions  to  adapt  the  application  of rules  of  this  Regulation,  inter  alia:  the  general  conditions  governing  the  lawfulness  of  processing  by  the  controller;  the types  of  data  which  are  subject  to  the  processing;  the  data  subjects  concerned;  the  entities  to,  and  the  purposes  for which,  the  personal  data  may  be  disclosed;  the  purpose  limitation;  storage  periods;  and  processing  operations  and processing  procedures,  including  measures  to  ensure  lawful  and  fair  processing  such  as  those  for  other  specific\nEN\nprocessing  situations  as  provided  for  in  Chapter  IX.  The  Union  or  the  Member  State  law  shall  meet  an  objective  of public interest and be proportionate to the legitimate aim pursued.\n[<Paragraph children=[<RawText children=('Where the  processing  for  a  purpose  other  than  that  for  which  the  '\n 'personal  data  have  been  collected  is  not  based on  the  data  '\n \"subject's  consent  or  on  a  Union  or  Member  State  law  which  \"\n 'constitutes  a  necessary  and  proportionate measure  in  a  democratic  '\n 'society  to  safeguard  the  objectives  referred  to  in  Article  23(1),  '\n 'the  controller  shall,  in  order  to ascertain  whether  processing  for  '\n 'another  purpose  is  compatible  with  the  purpose  for  which  the  '\n 'personal  data  are initially collected, take into account, inter alia:')>]>]\n(a)   any  link  between  the  purposes  for  which  the  personal  data  have  been  collected  and  the  purposes  of  the  intended further processing;\n(b)   the  context  in  which  the  personal  data  have  been  collected,  in  particular  regarding  the  relationship  between  data subjects and the controller;\n(c)   the  nature  of  the  personal  data,  in  particular  whether  special  categories  of  personal  data  are  processed,  pursuant  to Article  9,  or  whether  personal  data  related  to  criminal  convictions  and  offences  are  processed,  pursuant  to  Article 10;\n(d)   the  possible consequences of  the intended further processing for data subjects;\n(e)   the  existence of appropriate safeguards, which may include encryption or pseudonymisation."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_16",
    "chunk_content": "Conditions for consent\n[<Paragraph children=[<RawText children=('Where  processing  is  based  on  consent,  the  controller  shall  be  '\n 'able  to  demonstrate  that  the  data  subject  has consented to processing '\n 'of his or her personal data.')>]>]\n[<Paragraph children=[<RawText children=(\"If  the  data  subject's  consent  is  given  in  the  context  of  a  \"\n 'written  declaration  which  also  concerns  other  matters,  the request  '\n 'for  consent  shall  be  presented  in  a  manner  which  is  clearly  '\n 'distinguishable  from  the  other  matters,  in  an intelligible  and  '\n 'easily  accessible  form,  using  clear  and  plain  language.  Any  part  '\n 'of  such  a  declaration  which  constitutes an infringement of this '\n 'Regulation shall not be binding.')>]>]\n[<Paragraph children=[<RawText children=('The  data  subject  shall  have  the  right  to  withdraw  his  or  her  '\n 'consent  at  any  time.  The  withdrawal  of  consent  shall not  affect  '\n 'the  lawfulness  of  processing  based  on  consent  before  its  '\n 'withdrawal.  Prior  to  giving  consent,  the  data  subject shall be '\n 'informed thereof. It shall be as easy to withdraw as to give consent.')>]>]\n[<Paragraph children=[<RawText children=('When  assessing  whether  consent  is  freely  given,  utmost  account  '\n 'shall  be  taken  of  whether, inter  alia , the performance  of  a  '\n 'contract,  including  the  provision  of  a  service,  is  conditional  on  '\n 'consent  to  the  processing  of  personal data that is not necessary for  '\n 'the performance of that contract.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_17",
    "chunk_content": "Conditions applicable to child's consent in relation to information society services\n[<Paragraph children=[<RawText children=('Where  point  (a)  of  Article  6(1)  applies,  in  relation  to  the  '\n 'offer  of  information  society  services  directly  to  a  child, the  '\n 'processing  of  the  personal  data  of  a  child  shall  be  lawful  where  '\n 'the  child  is  at  least  16  years  old.  Where  the  child  is below  '\n 'the  age  of  16  years,  such  processing  shall  be  lawful  only  if  '\n 'and  to  the  extent  that  consent  is  given  or  authorised by the holder '\n 'of parental responsibility over  the child.')>]>]\nMember  States  may  provide  by  law  for  a  lower  age  for  those  purposes  provided  that  such  lower  age  is  not  below  13 years.\nEN\n[<Paragraph children=[<RawText children=('The  controller  shall  make  reasonable  efforts  to  verify  in  such  '\n 'cases  that  consent  is  given  or  authorised  by  the holder of parental '\n 'responsibility over  the child, taking into consideration available '\n 'technology.')>]>]\n[<Paragraph children=[<RawText children=('Paragraph 1 shall  not  affect  the  general  contract  law of  Member  '\n 'States  such  as  the  rules  on  the  validity,  formation or effect of a '\n 'contract in relation to a child.')>]>]\nArticle 9"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_18",
    "chunk_content": "Processing of special categories of personal data\n[<Paragraph children=[<RawText children=('Processing of personal data revealing racial or ethnic origin, political '\n 'opinions, religious or  philosophical beliefs, or trade  union  membership,  '\n 'and  the  processing  of  genetic  data,  biometric  data  for  the  '\n 'purpose  of  uniquely  identifying  a natural  person,  data  concerning  '\n \"health  or  data  concerning  a  natural  person's  sex  life  or  sexual  \"\n 'orientation  shall  be prohibited.')>]>]\n[<Paragraph children=[<RawText children='Paragraph 1 shall not apply if one of the following applies:'>]>]\n(a)   the  data  subject  has  given  explicit  consent  to  the  processing  of  those  personal  data  for  one  or  more  specified purposes, except where Union or Member State law provide that the prohibition referred to in paragraph 1 may not be lifted by the data subject;\n(b)   processing  is  necessary  for  the  purposes  of  carrying  out  the  obligations  and  exercising  specific  rights  of  the controller  or  of  the  data  subject  in  the  field  of  employment  and  social  security  and  social  protection  law  in  so  far as it  is  authorised by Union or Member State law or a collective agreement pursuant to Member State law providing for appropriate safeguards for  the fundamental rights and the interests of the data subject;\n(c)   processing  is  necessary  to  protect  the  vital  interests  of  the  data  subject  or  of  another  natural  person  where  the  data subject is physically or legally incapable of giving consent;\n(d)   processing  is  carried  out  in  the  course  of  its  legitimate  activities  with  appropriate  safeguards  by  a  foundation, association  or  any  other  not-for-profit  body  with  a  political,  philosophical,  religious  or  trade  union  aim  and  on condition  that  the  processing  relates  solely  to  the  members  or  to  former  members  of  the  body  or  to  persons  who have regular contact with it in connection with its purposes and that the personal data are not disclosed outside that body without the consent of the data subjects;\n(e)   processing relates to personal data which are manifestly made public by the data subject;\n(f)   processing  is  necessary  for  the  establishment,  exercise  or  defence  of  legal  claims  or  whenever  courts  are  acting  in their  judicial capacity;\n(g)   processing  is  necessary  for  reasons  of  substantial  public  interest,  on  the  basis  of  Union  or  Member  State  law  which shall  be  proportionate  to  the  aim  pursued,  respect  the  essence  of  the  right  to  data  protection  and  provide  for suitable and specific measures to safeguard the fundamental rights and the interests of the data subject;\n(h)   processing  is  necessary  for  the  purposes  of  preventive  or  occupational  medicine,  for  the  assessment  of  the  working capacity of  the  employee,  medical  diagnosis,  the  provision  of  health  or  social  care  or  treatment  or  the  management of  health  or  social  care  systems  and  services  on  the  basis  of  Union  or  Member  State  law  or  pursuant  to  contract with a health professional and subject to the conditions and safeguards referred to in paragraph 3;\n(i) processing  is  necessary  for  reasons  of  public  interest  in  the  area  of  public  health,  such  as  protecting  against  serious cross-border  threats  to  health  or  ensuring  high  standards  of  quality  and  safety  of  health  care  and  of  medicinal products  or  medical  devices,  on  the  basis  of  Union  or  Member  State  law  which  provides  for  suitable  and  specific measures to safeguard the rights and freedoms of the data subject, in particular professional secrecy;\nEN\n(j) processing  is  necessary  for  archiving  purposes  in  the  public  interest,  scientific  or  historical  research  purposes  or statistical  purposes  in  accordance  with  Article  89(1)  based  on  Union  or  Member  State  law  which  shall  be  propor­ tionate  to  the  aim  pursued,  respect  the  essence  of  the  right  to  data  protection  and  provide  for  suitable  and  specific measures to safeguard the fundamental rights and the interests of the data subject.\n[<Paragraph children=[<RawText children=('Personal data referred to in paragraph 1 may be processed for  the purposes '\n 'referred to in point (h) of paragraph 2 when those  data  are  processed  by '\n 'or  under  the  responsibility  of  a  professional  subject  to  the  '\n 'obligation  of  professional secrecy  under  Union  or  Member  State  law  '\n 'or  rules  established  by  national  competent  bodies  or  by  another  '\n 'person  also subject to an obligation of secrecy under Union or Member State '\n 'law or rules established by national competent bodies.')>]>]\n[<Paragraph children=[<RawText children=('Member States  may  maintain  or  introduce  further  conditions,  '\n 'including  limitations,  with  regard  to  the  processing of genetic data, '\n 'biometric data or data concerning health.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_19",
    "chunk_content": "Processing of personal data relating to criminal convictions and offences\nProcessing  of  personal  data  relating  to  criminal  convictions  and  offences  or  related  security  measures  based  on Article  6(1)  shall  be  carried  out  only  under  the  control  of  official  authority  or  when  the  processing  is  authorised  by Union  or  Member  State  law  providing  for  appropriate  safeguards  for  the  rights  and  freedoms  of  data  subjects.  Any comprehensive register of criminal convictions shall be kept only under  the control of official authority."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_20",
    "chunk_content": "Processing which does not require identification\n[<Paragraph children=[<RawText children=('If  the  purposes  for  which  a  controller  processes  personal  data  do  '\n 'not  or  do  no  longer  require  the  identification  of a  data  subject  '\n 'by  the  controller,  the  controller  shall  not  be  obliged  to  '\n 'maintain,  acquire  or  process  additional information in order  to '\n 'identify the data subject for  the sole purpose of complying with this '\n 'Regulation.')>]>]\n[<Paragraph children=[<RawText children=('Where,  in  cases  referred  to  in  paragraph  1  of  this  Article,  the  '\n 'controller  is  able  to  demonstrate  that  it  is  not  in  a position  '\n 'to  identify  the  data  subject,  the  controller  shall  inform  the  '\n 'data  subject  accordingly,  if  possible.  In  such  cases, Articles  15  '\n 'to  20  shall  not  apply  except  where  the  data  subject,  for  the  '\n 'purpose  of  exercising  his  or  her  rights  under those articles, '\n 'provides additional information enabling his or her identification.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_21",
    "chunk_content": "Rights of the data subject\nSection 1"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_22",
    "chunk_content": "Transparent  information,  communication  and  modalities  for  the  exercise  of  the  rights  of  the  data subject\n[<Paragraph children=[<RawText children=('The  controller  shall  take  appropriate  measures  to  provide  any  '\n 'information  referred  to  in  Articles  13  and  14  and any communication '\n 'under Articles 15 to 22 and 34 relating  to processing  to the  data  '\n 'subject  in  a  concise,  transparent, intelligible  and  easily  '\n 'accessible  form,  using  clear  and  plain  language,  in  particular  for  '\n 'any  information  addressed specifically to a child. The information shall '\n 'be provided in writing, or by other  means, including, where appropriate, by '\n 'electronic  means.  When  requested  by  the  data  subject,  the  '\n 'information  may  be  provided  orally,  provided  that  the identity of  '\n 'the data subject is proven by other means.')>]>]\nEN\n[<Paragraph children=[<RawText children=('The controller  shall  facilitate  the  exercise  of  data  subject  rights  '\n 'under  Articles  15  to  22.  In  the  cases  referred  to  in Article  '\n '11(2),  the  controller  shall  not  refuse  to  act  on  the  request  of  '\n 'the  data  subject  for  exercising  his  or  her  rights under Articles 15 '\n 'to 22, unless the controller demonstrates that it is not in a position to '\n 'identify the data subject.')>]>]\n[<Paragraph children=[<RawText children=('The  controller  shall  provide  information  on  action  taken  on  a  '\n 'request  under  Articles  15  to  22  to  the  data  subject without undue '\n 'delay and in any event within one month of receipt of  the request. That '\n 'period may be extended by two further  months  where  necessary,  taking  '\n 'into  account  the  complexity  and  number  of  the  requests.  The  '\n 'controller  shall inform the  data  subject  of any  such  extension  '\n 'within  one  month  of  receipt of  the  request,  together  with  the  '\n 'reasons  for the  delay.  Where  the  data  subject  makes  the  request  '\n 'by  electronic  form  means,  the  information  shall  be  provided  by '\n 'electronic means where possible, unless otherwise requested by the data '\n 'subject.')>]>]\n[<Paragraph children=[<RawText children=('If  the  controller  does not take action on the request of  the data '\n 'subject, the controller shall inform the data subject without  delay  and  '\n 'at  the  latest  within  one  month  of  receipt  of  the  request  of  the  '\n 'reasons  for  not  taking  action  and  on the possibility of  lodging a '\n 'complaint with a supervisory authority and seeking a judicial remedy.')>]>]\n[<Paragraph children=[<RawText children=('Information  provided  under  Articles  13  and  14  and  any communication  '\n 'and  any  actions  taken  under  Articles  15 to  22  and  34  shall  be  '\n 'provided  free  of  charge.  Where  requests  from  a  data  subject  are  '\n 'manifestly  unfounded  or excessive, in particular because of their '\n 'repetitive character, the controller may either:')>]>]\n(a)   charge  a  reasonable  fee  taking  into  account  the  administrative  costs  of  providing  the  information  or  communication or  taking the action requested; or\n(b)   refuse to act on the request.\nThe controller shall bear  the burden of demonstrating the manifestly unfounded or excessive character of the request.\n[<Paragraph children=[<RawText children=('Without prejudice to Article 11, where the controller has reasonable doubts '\n 'concerning the identity of  the natural person  making  the  request  '\n 'referred  to  in  Articles  15  to  21,  the  controller  may  request  the  '\n 'provision  of  additional information necessary to confirm the identity of '\n 'the data subject.')>]>]\n[<Paragraph children=[<RawText children=('The  information  to  be  provided  to  data  subjects  pursuant  to  '\n 'Articles  13  and  14  may  be  provided  in  combination with standardised '\n 'icons in order  to give in an easily visible, intelligible and clearly '\n 'legible manner a meaningful overview of  the intended processing. Where the '\n 'icons are presented electronically they shall be machine-readable.')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  shall  be  empowered  to  adopt  delegated  acts  in  '\n 'accordance  with  Article  92  for  the  purpose  of determining the '\n 'information to be presented by the icons and the procedures for providing '\n 'standardised icons.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_23",
    "chunk_content": "Information to be provided where personal data are collected from the data subject\n[<Paragraph children=[<RawText children=('Where personal  data  relating  to  a  data  subject  are  collected  from  '\n 'the  data  subject,  the  controller  shall,  at  the  time when personal '\n 'data are obtained, provide the data subject with all of the following '\n 'information:')>]>]\n(a)   the  identity  and the contact details of  the controller and, where applicable, of  the controller's representative;\n(b)   the  contact details of  the data protection officer, where applicable;\n(c)   the  purposes of  the processing for  which the personal data are intended as well as the legal basis for  the processing;\nEN\n(d)   where  the  processing  is  based  on  point  (f)  of  Article  6(1),  the  legitimate  interests  pursued  by  the  controller  or  by  a third party;\n(e)   the  recipients or categories of recipients of  the personal data, if any;\n(f)   where  applicable,  the  fact  that  the  controller  intends  to  transfer  personal  data  to  a  third  country  or  international organisation  and  the  existence  or  absence  of  an  adequacy  decision  by  the  Commission,  or  in  the  case  of  transfers referred  to in  Article  46  or  47,  or  the  second  subparagraph  of  Article  49(1),  reference  to the  appropriate  or  suitable safeguards and the means by which to obtain a copy of them or where they have been made available.\n[<Paragraph children=[<RawText children=('In  addition  to  the  information  referred  to  in  paragraph  1,  the  '\n 'controller  shall,  at  the  time  when  personal  data  are obtained,  '\n 'provide  the  data  subject  with  the  following  further  information  '\n 'necessary  to  ensure  fair  and  transparent processing:')>]>]\n(a)   the  period  for  which  the  personal  data  will  be  stored,  or  if  that  is  not  possible,  the  criteria  used  to  determine  that period;\n(b)   the  existence  of  the  right  to  request  from  the  controller  access  to  and  rectification  or  erasure  of  personal  data  or restriction  of  processing  concerning  the  data  subject  or  to  object  to  processing  as  well  as  the  right  to  data portability;\n(c)   where  the  processing  is  based  on  point  (a)  of  Article  6(1)  or  point  (a)  of  Article  9(2),  the  existence  of  the  right  to withdraw consent at any time, without affecting the lawfulness of processing based on consent before its withdrawal;\n(d)   the  right  to lodge a complaint with a supervisory authority;\n(e)   whether  the provision of personal data is a statutory or contractual requirement, or a requirement necessary to enter into  a  contract,  as  well  as  whether  the  data  subject  is  obliged  to  provide  the  personal  data  and  of  the  possible consequences of failure to provide such data;\n(f)   the  existence  of  automated  decision-making,  including  profiling,  referred  to  in  Article  22(1)  and  (4)  and,  at  least  in those  cases,  meaningful  information  about  the  logic  involved,  as  well  as  the  significance  and  the  envisaged consequences of such processing for the data subject.\n[<Paragraph children=[<RawText children=('Where  the  controller  intends  to  further  process  the  personal  data  '\n 'for  a  purpose  other  than  that  for  which  the personal  data  were  '\n 'collected,  the  controller  shall  provide  the  data  subject  prior  to  '\n 'that  further  processing  with information on that other purpose and with '\n 'any relevant further information as referred to in paragraph 2.')>]>]\n[<Paragraph children=[<RawText children=('Paragraphs 1, 2 and 3 shall not apply where and insofar as the data subject '\n 'already has the information.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_24",
    "chunk_content": "Information to be provided where personal data have not been obtained from the data subject\n[<Paragraph children=[<RawText children=('Where  personal  data  have  not  been  obtained  from  the  data  subject,  '\n 'the  controller  shall  provide  the  data  subject with the following '\n 'information:')>]>]\n(a)   the  identity  and the contact details of  the controller and, where applicable, of  the controller's representative;\n(b)   the  contact details of  the data protection officer, where applicable;\n(c)   the  purposes of  the processing for  which the personal data are intended as well as the legal basis for  the processing;\n(d)   the  categories of personal data concerned;\n(e)   the  recipients or categories of recipients of  the personal data, if any;\nEN\n(f) where  applicable,  that  the  controller  intends  to  transfer  personal  data  to  a  recipient  in  a  third  country  or  internat­ ional  organisation  and  the  existence  or  absence  of  an  adequacy  decision  by  the  Commission,  or  in  the  case  of transfers referred to in Article 46 or 47, or  the second subparagraph of Article 49(1), reference to the appropriate or suitable safeguards and the means to obtain a copy of them or where they have been made available.\n[<Paragraph children=[<RawText children=('In  addition  to  the  information  referred  to  in  paragraph  1,  the  '\n 'controller  shall  provide  the  data  subject  with  the following '\n 'information necessary to ensure fair and transparent processing in respect '\n 'of the data subject:')>]>]\n(a)   the  period  for  which  the  personal  data  will  be  stored,  or  if  that  is  not  possible,  the  criteria  used  to  determine  that period;\n(b)   where  the  processing  is  based  on  point  (f)  of  Article  6(1),  the  legitimate  interests  pursued  by  the  controller  or  by  a third party;\n(c)   the  existence  of  the  right  to  request  from  the  controller  access  to  and  rectification  or  erasure  of  personal  data  or restriction  of  processing  concerning  the  data  subject  and  to  object  to  processing  as  well  as  the  right  to  data portability;\n(d)   where  processing  is  based  on  point  (a)  of  Article  6(1)  or  point  (a)  of  Article  9(2),  the  existence  of  the  right  to withdraw consent at any time, without affecting the lawfulness of processing based on consent before its withdrawal;\n(e)   the  right  to lodge a complaint with a supervisory authority;\n(f)   from which source the personal data originate, and if applicable, whether it came from publicly accessible sources;\n(g)   the  existence  of  automated  decision-making,  including  profiling,  referred  to  in  Article  22(1)  and  (4)  and,  at  least  in those  cases,  meaningful  information  about  the  logic  involved,  as  well  as  the  significance  and  the  envisaged consequences of such processing for the data subject.\n[<Paragraph children=[<RawText children=('The controller shall provide the information referred to in paragraphs 1 and '\n '2:')>]>]\n(a)   within  a  reasonable  period  after  obtaining  the  personal  data,  but  at  the  latest  within  one  month,  having  regard  to the specific circumstances in which the personal data are processed;\n(b)   if  the  personal  data  are  to  be  used  for  communication  with  the  data  subject,  at  the  latest  at  the  time  of  the  first communication to that data subject; or\n(c)   if  a  disclosure  to another  recipient is envisaged, at the latest when the personal data are first disclosed.\n[<Paragraph children=[<RawText children=('Where  the  controller  intends  to  further  process  the  personal  data  '\n 'for  a  purpose  other  than  that  for  which  the personal  data  were  '\n 'obtained,  the  controller  shall  provide  the  data  subject  prior  to  '\n 'that  further  processing  with information on that other purpose and with '\n 'any relevant further information as referred to in paragraph 2.')>]>]\n[<Paragraph children=[<RawText children='Paragraphs 1 to 4 shall not apply where and insofar as:'>]>]\n(a)   the  data subject already has the information;\n(b)   the  provision  of  such  information  proves  impossible  or  would  involve  a  disproportionate  effort,  in  particular  for processing  for  archiving  purposes  in  the  public  interest,  scientific  or  historical  research  purposes  or  statistical purposes,  subject  to  the  conditions  and  safeguards  referred  to  in  Article  89(1)  or  in  so  far  as  the  obligation  referred to  in  paragraph  1  of  this  Article  is  likely  to  render  impossible  or  seriously  impair  the  achievement  of  the  objectives of  that  processing.  In  such  cases  the  controller  shall  take  appropriate  measures  to  protect  the  data  subject's  rights and freedoms and legitimate interests, including making the information publicly available;\n(c)   obtaining  or  disclosure  is  expressly  laid  down  by  Union  or  Member  State  law  to which  the  controller  is  subject  and which provides appropriate measures to protect the data subject's legitimate interests; or\n(d)   where the personal data must remain confidential subject to an obligation of professional secrecy regulated by Union or Member State law, including a statutory obligation of secrecy.\nEN"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_25",
    "chunk_content": "Right of access by the data subject\n[<Paragraph children=[<RawText children=('The data subject shall have the right to obtain from the controller '\n 'confirmation as to whether or not personal data concerning  him  or  her  '\n 'are  being  processed,  and,  where  that  is  the  case,  access  to  the  '\n 'personal  data  and  the  following information:')>]>]\n(a)   the  purposes of  the processing;\n(b)   the  categories of personal data concerned;\n(c)   the  recipients  or  categories  of  recipient  to  whom  the  personal  data  have  been  or  will  be  disclosed,  in  particular recipients in third countries or international organisations;\n(d)   where  possible,  the  envisaged  period  for  which  the  personal  data  will  be  stored,  or,  if  not  possible,  the  criteria  used to determine that period;\n(e)   the  existence  of  the  right  to  request  from  the  controller  rectification  or  erasure  of  personal  data  or  restriction  of processing of personal data concerning the data subject or  to object to such processing;\n(f)   the  right to lodge a complaint with a supervisory authority;\n(g)   where the personal data are not collected from the data subject, any available information as to their source;\n(h)   the  existence  of  automated  decision-making,  including  profiling,  referred  to  in  Article  22(1)  and  (4)  and,  at  least  in those  cases,  meaningful  information  about  the  logic  involved,  as  well  as  the  significance  and  the  envisaged consequences of such processing for the data subject.\n[<Paragraph children=[<RawText children=('Where  personal  data  are  transferred  to  a  third  country  or  to  an  '\n 'international  organisation,  the  data  subject  shall have the right to be '\n 'informed of the appropriate safeguards pursuant to Article 46 relating to '\n 'the transfer.')>]>]\n[<Paragraph children=[<RawText children=('The  controller  shall  provide  a  copy  of  the  personal  data  '\n 'undergoing  processing.  For  any  further  copies  requested by  the  data  '\n 'subject,  the  controller  may  charge  a  reasonable  fee  based  on  '\n 'administrative  costs.  Where  the  data  subject makes  the  request  by  '\n 'electronic  means,  and  unless  otherwise  requested  by  the  data  '\n 'subject,  the  information  shall  be provided in a commonly used electronic '\n 'form.')>]>]\n[<Paragraph children=[<RawText children=('The right to obtain a copy referred to in paragraph 3 shall not adversely '\n 'affect the rights and freedoms of others.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_26",
    "chunk_content": "Right to rectification\nThe  data  subject  shall  have  the  right  to  obtain  from  the  controller  without  undue  delay  the  rectification  of  inaccurate personal data concerning him or her. Taking into account the purposes of  the processing, the data subject shall have the right to have incomplete personal data completed, including by means of providing a supplementary statement."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_27",
    "chunk_content": "Right to erasure ('right to be forgotten')\n[<Paragraph children=[<RawText children=('The data  subject  shall  have  the  right  to  obtain  from  the  '\n 'controller  the  erasure  of  personal  data  concerning  him  or her  '\n 'without  undue  delay  and  the  controller  shall  have  the  obligation  '\n 'to  erase  personal  data  without  undue  delay  where one of the following '\n 'grounds applies:')>]>]\n(a)   the  personal  data  are  no  longer  necessary  in  relation  to  the  purposes  for  which  they  were  collected  or  otherwise processed;\nEN\n(b)   the  data  subject  withdraws  consent  on  which  the  processing  is  based  according  to  point  (a)  of  Article  6(1),  or point (a) of Article 9(2), and where there is no other legal ground for  the processing;\n(c)   the  data  subject  objects  to  the  processing  pursuant  to  Article  21(1)  and  there  are  no  overriding  legitimate  grounds for  the processing, or  the data subject objects to the processing pursuant to Article 21(2);\n(d)   the  personal data have been unlawfully processed;\n(e)   the  personal  data  have  to  be  erased  for  compliance  with  a  legal  obligation  in  Union  or  Member  State  law  to  which the controller is subject;\n(f)   the  personal  data  have  been  collected  in  relation  to  the  offer  of  information  society  services  referred  to  in Article 8(1).\n[<Paragraph children=[<RawText children=('Where  the  controller  has  made  the  personal  data  public  and  is  '\n 'obliged  pursuant  to  paragraph  1  to  erase  the personal  data,  the  '\n 'controller,  taking  account  of  available  technology  and  the  cost  of  '\n 'implementation,  shall  take reasonable  steps,  including  technical  '\n 'measures,  to  inform  controllers  which  are  processing  the  personal  '\n 'data  that  the data subject has requested the erasure by such controllers '\n 'of any links to, or copy or replication of, those personal data.')>]>]\n[<Paragraph children=[<RawText children='Paragraphs 1 and 2 shall not apply to the extent that processing is necessary:'>]>]\n(a)   for  exercising the right of freedom of expression and information;\n(b)   for  compliance  with  a  legal  obligation  which  requires  processing  by  Union  or  Member  State  law  to  which  the controller  is  subject  or  for  the  performance  of  a  task  carried  out  in  the  public  interest  or  in  the  exercise  of  official authority vested in the controller;\n(c)   for  reasons  of  public  interest  in  the  area  of  public  health  in  accordance  with  points  (h)  and  (i)  of  Article  9(2)  as  well as Article 9(3);\n(d)   for  archiving  purposes  in  the  public  interest,  scientific  or  historical  research  purposes  or  statistical  purposes  in accordance  with  Article  89(1)  in  so  far  as  the  right  referred  to  in  paragraph  1  is  likely  to  render  impossible  or seriously impair the achievement of the objectives of that processing; or\n(e)   for  the  establishment, exercise or defence of  legal claims."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_28",
    "chunk_content": "Right to restriction of processing\n[<Paragraph children=[<RawText children=('The  data  subject  shall  have  the  right  to  obtain  from  the  '\n 'controller  restriction  of  processing  where  one  of  the following '\n 'applies:')>]>]\n(a)   the  accuracy  of  the  personal  data  is  contested  by  the  data  subject,  for  a  period  enabling  the  controller  to  verify  the accuracy of the personal data;\n(b)   the  processing  is  unlawful  and  the  data  subject  opposes  the  erasure  of  the  personal  data  and  requests  the  restriction of  their  use  instead;\n(c)   the  controller  no  longer  needs  the  personal  data  for  the  purposes  of  the  processing,  but  they  are  required  by  the data subject for  the establishment, exercise or defence of  legal claims;\n(d)   the  data  subject  has  objected  to  processing  pursuant  to  Article  21(1)  pending  the  verification  whether  the  legitimate grounds of the controller override those of the data subject.\n[<Paragraph children=[<RawText children=('Where  processing  has  been  restricted  under  paragraph  1,  such  '\n 'personal  data  shall,  with  the  exception  of  storage, only be  '\n \"processed  with  the  data  subject's  consent  or  for  the  \"\n 'establishment,  exercise  or  defence  of  legal  claims  or  for  the '\n 'protection of  the rights of another  natural or legal person or  for  '\n 'reasons of  important public interest of  the Union or of a Member State.')>]>]\nImage\n[<Paragraph children=[<RawText children=('A  data  subject  who  has  obtained  restriction  of  processing  pursuant  '\n 'to  paragraph  1  shall  be  informed  by  the controller before the '\n 'restriction of processing is lifted.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_29",
    "chunk_content": "Notification  obligation  regarding  rectification  or  erasure  of  personal  data  or  restriction  of processing\nThe controller shall communicate any rectification or erasure of personal data or  restriction of processing carried out in accordance  with  Article  16,  Article  17(1)  and  Article  18  to  each  recipient  to  whom  the  personal  data  have  been disclosed,  unless  this  proves  impossible  or  involves  disproportionate  effort.  The  controller  shall  inform  the  data  subject about those recipients if the data subject requests it."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_30",
    "chunk_content": "Right to data portability\n[<Paragraph children=[<RawText children=('The  data  subject  shall  have  the  right  to  receive  the  personal  '\n 'data  concerning  him  or  her,  which  he  or  she  has provided  to  a  '\n 'controller,  in  a  structured,  commonly  used  and  machine-readable  '\n 'format  and  have  the  right  to  transmit those  data  to  another  '\n 'controller  without  hindrance  from  the  controller  to which  the  '\n 'personal  data  have  been  provided, where:')>]>]\n(a)   the  processing  is  based  on  consent  pursuant  to  point  (a)  of  Article  6(1)  or  point  (a)  of  Article  9(2)  or  on  a  contract pursuant to point (b) of Article 6(1); and\n(b)   the  processing is carried out by automated means.\n[<Paragraph children=[<RawText children=('In  exercising  his  or  her  right  to  data  portability  pursuant  to  '\n 'paragraph  1,  the  data  subject  shall  have  the  right  to have the '\n 'personal data transmitted directly from one controller to another, where '\n 'technically feasible.')>]>]\n[<Paragraph children=[<RawText children=('The  exercise  of  the  right  referred  to  in  paragraph  1  of  this  '\n 'Article  shall  be  without  prejudice  to  Article  17.  That right  shall  '\n 'not  apply  to  processing  necessary  for  the  performance  of  a  task  '\n 'carried  out  in  the  public  interest  or  in  the exercise of official '\n 'authority vested in the controller.')>]>]\n[<Paragraph children=[<RawText children=('The right referred to in paragraph 1 shall not adversely affect the rights '\n 'and freedoms of others.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_31",
    "chunk_content": "Right to object and automated individual decision-making\nArticle 21"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_32",
    "chunk_content": "Right to object\n[<Paragraph children=[<RawText children=('The data subject shall have the right to object, on grounds relating to his '\n 'or her  particular situation, at any time to processing  of  personal  data  '\n 'concerning  him  or  her  which  is  based  on  point  (e)  or  (f)  of  '\n 'Article  6(1),  including  profiling based  on  those  provisions.  The  '\n 'controller  shall  no  longer  process  the  personal  data  unless  the  '\n 'controller  demonstrates compelling legitimate grounds for  the processing '\n 'which override the interests, rights and freedoms of  the data subject or '\n 'for  the establishment, exercise or defence of  legal claims.')>]>]\n[<Paragraph children=[<RawText children=('Where personal data are processed for direct marketing purposes, the data '\n 'subject  shall have the right to object  at any  time  to  processing  of  '\n 'personal  data  concerning  him  or  her  for  such  marketing,  which  '\n 'includes  profiling  to  the extent that it is related to such direct '\n 'marketing.')>]>]\n[<Paragraph children=[<RawText children=('Where  the  data  subject  objects  to  processing  for  direct  marketing  '\n 'purposes,  the  personal  data  shall  no  longer  be processed for such '\n 'purposes.')>]>]\nEN\n[<Paragraph children=[<RawText children=('At the latest at the time of  the first communication with the data subject, '\n 'the right referred to in paragraphs 1 and 2  shall  be  explicitly  brought  '\n 'to  the  attention  of  the  data  subject  and  shall  be  presented  '\n 'clearly  and  separately  from  any other information.')>]>]\n[<Paragraph children=[<RawText children=('In  the  context  of  the  use  of  information  society  services,  and  '\n 'notwithstanding  Directive  2002/58/EC,  the  data subject may exercise his '\n 'or her right to object by automated means using technical specifications.')>]>]\n[<Paragraph children=[<RawText children=('Where personal data  are  processed  for  scientific  or  historical  '\n 'research  purposes  or  statistical  purposes  pursuant  to Article  89(1),  '\n 'the  data  subject,  on  grounds  relating  to  his  or  her  particular  '\n 'situation,  shall  have  the  right  to  object  to processing  of  '\n 'personal  data  concerning  him  or  her,  unless  the  processing  is  '\n 'necessary  for  the  performance  of  a  task carried out for reasons of '\n 'public interest.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_33",
    "chunk_content": "Automated individual decision-making, including profiling\n[<Paragraph children=[<RawText children=('The  data  subject  shall  have  the  right  not  to  be  subject  to  a  '\n 'decision  based  solely  on  automated  processing, including profiling, '\n 'which produces legal effects concerning him or her or similarly '\n 'significantly affects him or her.')>]>]\n[<Paragraph children=[<RawText children='Paragraph 1 shall not apply if the decision:'>]>]\n(a)   is  necessary for entering into, or  performance of, a contract between the data subject and a data controller;\n(b)   is  authorised  by  Union  or  Member  State  law  to  which  the  controller  is  subject  and  which  also  lays  down  suitable measures to safeguard the data subject's rights and freedoms and legitimate interests; or\n(c)   is  based  on the data subject's explicit consent.\n[<Paragraph children=[<RawText children=('In  the  cases  referred  to  in  points  (a)  and  (c)  of  paragraph  2,  '\n 'the  data  controller  shall  implement  suitable  measures to  safeguard  '\n \"the  data  subject's  rights  and  freedoms  and  legitimate  interests,  \"\n 'at  least  the  right  to  obtain  human intervention on the part of the '\n 'controller, to express his or her point of view and to contest the decision.')>]>]\n[<Paragraph children=[<RawText children=('Decisions  referred  to  in  paragraph  2  shall  not  be  based  on  '\n 'special  categories  of  personal  data  referred  to  in Article 9(1), '\n 'unless point (a) or (g) of Article 9(2) applies and suitable measures to '\n \"safeguard the data subject's rights and freedoms and legitimate interests \"\n 'are in place.')>]>]\nSection 5"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_34",
    "chunk_content": "Restrictions\nArticle 23\n[<Paragraph children=[<RawText children=('Union or Member State law to which the data controller or processor is '\n 'subject may restrict by way of a legislative measure the scope of  the '\n 'obligations and rights provided for  in Articles 12  to 22  and Article 34, '\n 'as  well as  Article 5  in so  far  as  its  provisions  correspond  to  '\n 'the  rights  and  obligations  provided  for  in  Articles  12  to  22,  '\n 'when  such  a restriction  respects  the  essence of  the fundamental  '\n 'rights  and freedoms and is a necessary and proportionate measure in a '\n 'democratic society to safeguard:')>]>]\n(a)   national security;\n(b)   defence;\n(c)   public security;\nImage\n(d)   the  prevention,  investigation,  detection  or  prosecution  of  criminal  offences  or  the  execution  of  criminal  penalties, including the safeguarding against and the prevention of threats to public security;\n(e)   other  important  objectives  of  general  public  interest  of  the  Union  or  of  a  Member  State,  in  particular  an  important economic  or  financial  interest  of  the  Union  or  of  a  Member  State,  including  monetary,  budgetary  and  taxation  a matters, public health and social security;\n(f)   the  protection of judicial independence and judicial proceedings;\n(g)   the  prevention, investigation, detection and prosecution of breaches of ethics for regulated professions;\n(h)   a  monitoring,  inspection  or  regulatory  function  connected,  even  occasionally,  to  the  exercise  of  official  authority  in the cases referred to in points (a) to (e) and (g);\n(i) the protection of the data subject or  the rights and freedoms of others;\n(j) the enforcement of civil law claims.\n[<Paragraph children=[<RawText children=('In  particular,  any  legislative  measure  referred  to  in  paragraph  1  '\n 'shall  contain  specific  provisions  at  least,  where relevant, as to:')>]>]\n(a)   the  purposes of  the processing or categories of processing;\n(b)   the  categories of personal data;\n(c)   the  scope of  the restrictions introduced;\n(d)   the  safeguards to prevent abuse or  unlawful access or  transfer;\n(e)   the  specification of  the controller or categories of controllers;\n(f)   the  storage  periods  and  the  applicable  safeguards  taking  into  account  the  nature,  scope  and  purposes  of  the processing or categories of processing;\n(g)   the  risks  to the rights and freedoms of data subjects; and\n(h)   the  right  of  data  subjects  to  be  informed  about  the  restriction,  unless  that  may  be  prejudicial  to  the  purpose  of  the restriction."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_35",
    "chunk_content": "Controller and processor\nSection 1"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_36",
    "chunk_content": "General obligations\nArticle 24"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_37",
    "chunk_content": "Responsibility of the controller\n[<Paragraph children=[<RawText children=('Taking into account the nature, scope, context and purposes of processing as '\n 'well as the risks of varying likelihood and  severity  for  the  rights  '\n 'and  freedoms  of  natural  persons,  the  controller  shall  implement  '\n 'appropriate  technical  and organisational  measures  to  ensure  and  to  '\n 'be  able  to  demonstrate  that  processing  is  performed  in  accordance  '\n 'with  this Regulation. Those measures shall be reviewed and updated where '\n 'necessary.')>]>]\n[<Paragraph children=[<RawText children=('Where proportionate in  relation  to  processing  activities,  the  '\n 'measures  referred  to  in  paragraph  1  shall  include  the implementation '\n 'of appropriate data protection policies by the controller.')>]>]\n[<Paragraph children=[<RawText children=('Adherence  to  approved  codes  of  conduct  as  referred  to  in  Article  '\n '40  or  approved  certification  mechanisms  as referred  to  in  Article  '\n '42  may  be  used  as  an  element  by  which  to  demonstrate  compliance  '\n 'with  the  obligations  of  the controller.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_38",
    "chunk_content": "Data protection by design and by default\n[<Paragraph children=[<RawText children=('Taking into account the state of the art, the cost of implementation and the '\n 'nature, scope, context and purposes of processing as well as the risks of '\n 'varying likelihood and severity for  rights and freedoms of natural persons '\n 'posed by the processing, the controller shall, both at the time of the '\n 'determination of  the means for processing and at the time of  the '\n 'processing  itself,  implement  appropriate  technical  and  organisational  '\n 'measures,  such  as  pseudonymisation,  which  are designed to implement '\n 'data-protection principles, such as data minimisation, in an effective '\n 'manner and to integrate the necessary  safeguards  into  the  processing  '\n 'in  order  to  meet  the  requirements  of  this  Regulation  and  protect  '\n 'the  rights  of data subjects.')>]>]\n[<Paragraph children=[<RawText children=('The  controller  shall  implement  appropriate  technical  and  '\n 'organisational  measures  for  ensuring  that,  by  default, only personal '\n 'data which are necessary for each specific purpose of the processing are '\n 'processed. That obligation applies to the amount of personal data collected, '\n 'the extent of their processing, the period of their storage and their '\n 'accessibility. In  particular,  such  measures  shall  ensure  that  by  '\n 'default  personal  data  are  not  made  accessible  without  the  '\n \"individual's intervention to an indefinite number of natural persons.\")>]>]\n[<Paragraph children=[<RawText children=('An  approved  certification  mechanism  pursuant  to  Article  42  may  be  '\n 'used  as  an  element  to  demonstrate compliance with the requirements set '\n 'out in paragraphs 1 and 2 of this Article.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_39",
    "chunk_content": "Joint controllers\n[<Paragraph children=[<RawText children=('Where  two  or  more  controllers  jointly  determine  the  purposes  and  '\n 'means  of  processing,  they  shall  be  joint controllers.  They  shall  '\n 'in  a  transparent  manner  determine  their  respective  responsibilities  '\n 'for  compliance  with  the obligations  under  this  Regulation,  in  '\n 'particular  as  regards  the  exercising  of  the  rights  of  the  data  '\n 'subject  and  their respective  duties  to  provide  the  information  '\n 'referred  to  in  Articles  13  and  14,  by  means  of  an  arrangement  '\n 'between them unless, and in so far as, the respective responsibilities of  '\n 'the  controllers  are determined by Union or Member State law to which the '\n 'controllers are subject. The arrangement may designate a contact point for '\n 'data subjects.')>]>]\n[<Paragraph children=[<RawText children=('The  arrangement  referred  to  in  paragraph  1  shall  duly  reflect  the  '\n 'respective  roles  and  relationships  of  the  joint controllers vis-à-vis '\n 'the data subjects. The essence of the arrangement shall be made available to '\n 'the data subject.')>]>]\n[<Paragraph children=[<RawText children=('Irrespective  of  the  terms  of  the  arrangement  referred  to  in  '\n 'paragraph  1,  the  data  subject  may  exercise  his  or  her rights under  '\n 'this Regulation in respect of and against each of the controllers.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_40",
    "chunk_content": "Representatives of controllers or processors not established in the Union\n[<Paragraph children=[<RawText children=('Where Article 3(2) applies, the controller or  the processor shall designate '\n 'in writing a representative in the Union.')>]>]\n[<Paragraph children=[<RawText children='The obligation laid down in paragraph 1 of this Article shall not apply to:'>]>]\n(a)   processing  which is  occasional, does not  include, on a large  scale, processing of  special categories of data as  referred to  in  Article  9(1)  or  processing  of  personal  data  relating  to  criminal  convictions  and  offences  referred  to  in  Article 10,  and  is  unlikely  to  result  in  a  risk  to  the  rights  and  freedoms  of  natural  persons,  taking  into  account  the  nature, context, scope and purposes of the processing; or\n(b)   a  public authority or body.\nEN\nEN\n[<Paragraph children=[<RawText children=('The  representative  shall  be  established  in  one  of  the  Member  '\n 'States  where  the  data  subjects,  whose  personal  data are processed in '\n 'relation to the offering of goods or services to them, or whose behaviour is '\n 'monitored, are.')>]>]\n[<Paragraph children=[<RawText children=('The  representative  shall  be  mandated  by  the  controller  or  '\n 'processor  to  be  addressed  in  addition  to  or  instead  of the  '\n 'controller  or  the  processor  by,  in  particular,  supervisory  '\n 'authorities  and  data  subjects,  on  all  issues  related  to processing, '\n 'for  the purposes of ensuring compliance with this Regulation.')>]>]\n[<Paragraph children=[<RawText children=('The designation of a representative by the controller or  processor shall be '\n 'without prejudice to legal actions which could be initiated against the '\n 'controller or  the processor  themselves.')>]>]\nArticle 28"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_41",
    "chunk_content": "Processor\n[<Paragraph children=[<RawText children=('Where processing  is  to  be  carried  out  on  behalf  of  a  controller,  '\n 'the  controller  shall  use  only  processors  providing sufficient  '\n 'guarantees  to  implement  appropriate  technical  and  organisational  '\n 'measures  in  such  a  manner  that  processing will meet the requirements '\n 'of this Regulation and ensure the protection of the rights of the data '\n 'subject.')>]>]\n[<Paragraph children=[<RawText children=('The  processor  shall  not  engage  another  processor  without  prior  '\n 'specific  or  general  written  authorisation  of  the controller. In the '\n 'case of general written authorisation, the processor shall inform the '\n 'controller of any intended changes concerning  the  addition  or  '\n 'replacement  of  other  processors,  thereby  giving  the  controller  the  '\n 'opportunity  to  object  to such changes.')>]>]\n[<Paragraph children=[<RawText children=('Processing  by  a  processor  shall  be  governed  by  a  contract  or  '\n 'other  legal  act  under  Union  or  Member  State  law, that  is  binding  '\n 'on  the  processor  with  regard  to  the  controller  and  that  sets  out  '\n 'the  subject-matter  and  duration  of  the processing,  the  nature  and  '\n 'purpose  of  the  processing,  the  type  of  personal  data  and  '\n 'categories  of  data  subjects  and  the obligations and rights of the '\n 'controller. That contract or other legal act shall stipulate, in particular, '\n 'that the processor:')>]>]\n(a)   processes  the  personal  data  only  on  documented  instructions  from  the  controller,  including  with  regard  to  transfers of  personal  data  to  a  third  country  or  an  international  organisation,  unless  required  to  do  so  by  Union  or Member State law to which the processor  is subject; in such a case, the processor shall inform the controller of  that legal  requirement  before  processing,  unless  that  law  prohibits  such  information  on  important  grounds  of  public interest;\n(b)   ensures  that  persons  authorised  to  process  the  personal  data  have  committed  themselves  to  confidentiality  or  are under an appropriate statutory obligation of confidentiality;\n(c)   takes  all  measures required pursuant to Article 32;\n(d)   respects the conditions referred to in paragraphs 2 and 4 for engaging another processor;\n(e)   taking  into  account  the  nature  of  the  processing,  assists  the  controller  by  appropriate  technical  and  organisational measures,  insofar  as  this  is  possible,  for  the  fulfilment  of  the  controller's  obligation  to  respond  to  requests  for exercising the data subject's rights laid down in Chapter III;\n(f)   assists  the  controller  in  ensuring  compliance  with  the  obligations  pursuant  to  Articles  32  to  36  taking  into  account the nature of processing and the information available to the processor;\n(g)   at  the  choice of  the  controller,  deletes or  returns all  the personal data  to the controller after  the end of  the provision of  services  relating  to  processing,  and  deletes  existing  copies  unless  Union  or  Member  State  law  requires  storage  of the personal data;\n(h)   makes  available  to  the  controller  all  information  necessary  to  demonstrate  compliance  with  the  obligations  laid down  in  this  Article  and  allow  for  and  contribute  to  audits,  including  inspections,  conducted  by  the  controller  or another auditor mandated by the controller.\nEN\nWith  regard  to  point  (h)  of  the  first  subparagraph,  the  processor  shall  immediately  inform  the  controller  if,  in  its opinion, an instruction infringes this Regulation or other Union or Member State data protection provisions.\n[<Paragraph children=[<RawText children=('Where  a  processor  engages  another  processor  for  carrying  out  '\n 'specific  processing  activities  on  behalf  of  the controller,  the  '\n 'same  data  protection  obligations  as  set  out  in  the  contract  or  '\n 'other  legal  act  between  the  controller  and the processor as referred '\n 'to in paragraph 3 shall be imposed on that other  processor by way of a '\n 'contract or other legal act  under  Union  or  Member  State  law,  in  '\n 'particular  providing  sufficient  guarantees  to  implement  appropriate  '\n 'technical and organisational measures in such a manner  that the processing '\n 'will meet the requirements of  this Regulation. Where that  other  '\n 'processor  fails  to  fulfil  its  data  protection  obligations,  the  '\n 'initial  processor  shall  remain  fully  liable  to  the controller for  '\n \"the performance of that other processor's obligations.\")>]>]\n[<Paragraph children=[<RawText children=('Adherence of a processor  to an approved code of conduct as referred to in '\n 'Article 40 or an approved certification mechanism  as  referred  to  in  '\n 'Article  42  may  be  used  as  an  element  by  which  to  demonstrate  '\n 'sufficient  guarantees  as referred to in paragraphs 1 and 4 of this '\n 'Article.')>]>]\n[<Paragraph children=[<RawText children=('Without  prejudice  to  an  individual  contract  between  the  controller  '\n 'and  the  processor,  the  contract  or  the  other legal  act  referred  '\n 'to  in  paragraphs  3  and  4  of  this  Article  may  be  based,  in  '\n 'whole  or  in  part,  on  standard  contractual clauses  referred  to  in  '\n 'paragraphs  7  and  8  of  this  Article,  including  when  they  are  part  '\n 'of  a  certification  granted  to  the controller or processor pursuant to '\n 'Articles 42 and 43.')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  may  lay  down  standard  contractual  clauses  for  the  '\n 'matters  referred  to  in  paragraph  3  and  4  of this Article and in '\n 'accordance with the examination procedure referred to in Article 93(2).')>]>]\n[<Paragraph children=[<RawText children=('A  supervisory  authority  may  adopt  standard  contractual  clauses  for  '\n 'the  matters  referred  to  in  paragraph  3  and  4 of  this Article and in '\n 'accordance with the consistency mechanism referred to in Article 63.')>]>]\n[<Paragraph children=[<RawText children=('The  contract  or  the  other  legal  act  referred  to  in  paragraphs  3  '\n 'and  4  shall  be  in  writing,  including  in  electronic form.')>]>]\n[<Paragraph children=[<RawText children=('Without prejudice to Articles 82, 83 and 84, if a processor infringes this '\n 'Regulation by determining the purposes and means of processing, the '\n 'processor shall be considered to be a controller in respect of that '\n 'processing.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_42",
    "chunk_content": "Processing under the authority of the controller or processor\nThe  processor  and  any  person  acting  under  the  authority  of  the  controller  or  of  the  processor,  who  has  access  to personal data, shall not process those data except on instructions from the controller, unless required to do so by Union or Member State law."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_43",
    "chunk_content": "Records of processing activities\n[<Paragraph children=[<RawText children=(\"Each  controller  and,  where  applicable,  the  controller's  \"\n 'representative,  shall  maintain  a  record  of  processing activities under '\n 'its responsibility. That record shall contain all of  the following '\n 'information:')>]>]\n(a) the  name and contact details  of  the  controller  and,  where  applicable,  the  joint  controller,  the  controller's  representa­ tive and the data protection officer;\n(b)   the  purposes of  the processing;\n(c)   a  description of  the categories of data subjects and of the categories of personal data;\nImage\n(d)   the  categories  of  recipients  to  whom  the  personal  data  have  been  or  will  be  disclosed  including  recipients  in  third countries or  international organisations;\n(e) where applicable, transfers of personal data to a third country or an international organisation, including the identifi­ cation  of  that  third  country  or  international  organisation  and,  in  the  case  of  transfers  referred  to  in  the  second subparagraph of Article 49(1), the documentation of suitable safeguards;\n(f)   where possible, the envisaged time limits for erasure of the different categories of data;\n(g)   where  possible,  a  general  description  of  the  technical  and  organisational  security  measures  referred  to  in Article 32(1).\n[<Paragraph children=[<RawText children=(\"Each  processor  and,  where  applicable,  the  processor's  representative  \"\n 'shall  maintain  a  record  of  all  categories  of processing activities '\n 'carried out on behalf of a controller, containing:')>]>]\n(a)   the  name  and  contact  details  of  the  processor  or  processors  and  of each controller  on  behalf of  which the  processor is  acting,  and, where applicable, of the controller's or  the processor's representative, and the data protection officer;\n(b)   the  categories of processing carried out on behalf of each controller;\n(c) where applicable, transfers of personal data to a third country or an international organisation, including the identifi­ cation  of  that  third  country  or  international  organisation  and,  in  the  case  of  transfers  referred  to  in  the  second subparagraph of Article 49(1), the documentation of suitable safeguards;\n(d)   where  possible,  a  general  description  of  the  technical  and  organisational  security  measures  referred  to  in Article 32(1).\n[<Paragraph children=[<RawText children=('The records referred to in paragraphs 1 and 2 shall be in writing, including '\n 'in electronic form.')>]>]\n[<Paragraph children=[<RawText children=(\"The controller or  the processor and, where applicable, the controller's or  \"\n \"the processor's representative, shall make the record available to the \"\n 'supervisory authority on request.')>]>]\n[<Paragraph children=[<RawText children=('The  obligations  referred  to  in  paragraphs  1  and  2  shall  not  '\n 'apply  to  an  enterprise  or  an  organisation  employing fewer  than  250  '\n 'persons  unless  the  processing  it  carries  out  is  likely  to  result  '\n 'in  a  risk  to  the  rights  and  freedoms  of data  subjects,  the  '\n 'processing  is  not  occasional,  or  the  processing  includes  special  '\n 'categories  of  data  as  referred  to  in Article 9(1) or personal data '\n 'relating to criminal convictions and offences referred to in Article 10.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_44",
    "chunk_content": "Cooperation with the supervisory authority\nThe  controller  and  the  processor  and,  where  applicable,  their  representatives,  shall  cooperate,  on  request,  with  the supervisory authority in the performance of its tasks."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_45",
    "chunk_content": "Security of personal data\nArticle 32"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_46",
    "chunk_content": "Security of processing\n[<Paragraph children=[<RawText children=('Taking  into  account  the  state  of  the  art,  the  costs  of  '\n 'implementation  and  the  nature,  scope,  context  and  purposes of  '\n 'processing  as  well  as  the  risk  of  varying  likelihood  and  severity  '\n 'for  the  rights  and  freedoms  of  natural  persons,  the controller  and  '\n 'the  processor  shall  implement  appropriate  technical  and  '\n 'organisational  measures  to  ensure  a  level  of security appropriate to '\n 'the risk, including inter alia as appropriate:')>]>]\n(a)   the  pseudonymisation and encryption of personal data;\nImage\n(b)   the  ability  to  ensure  the  ongoing  confidentiality,  integrity,  availability  and  resilience  of  processing  systems  and services;\n(c)   the  ability  to  restore  the  availability  and  access  to  personal  data  in  a  timely  manner  in  the  event  of  a  physical  or technical incident;\n(d)   a  process  for  regularly  testing,  assessing  and  evaluating  the  effectiveness  of  technical  and  organisational  measures  for ensuring the security of the processing.\n[<Paragraph children=[<RawText children=('In  assessing  the  appropriate  level  of  security  account  shall  be  '\n 'taken  in  particular  of  the  risks  that  are  presented  by processing, '\n 'in particular from accidental or unlawful destruction, loss, alteration, '\n 'unauthorised disclosure of, or access to personal data transmitted, stored '\n 'or otherwise processed.')>]>]\n[<Paragraph children=[<RawText children=('Adherence to an approved code of conduct as referred to in Article 40 or an '\n 'approved certification mechanism as referred  to  in  Article  42  may  be  '\n 'used  as  an  element  by  which  to  demonstrate  compliance  with  the  '\n 'requirements  set  out in paragraph 1 of this Article.')>]>]\n[<Paragraph children=[<RawText children=('The  controller  and  processor  shall  take  steps  to  ensure  that  any  '\n 'natural  person  acting  under  the  authority  of  the controller  or  the  '\n 'processor  who  has  access  to  personal  data  does  not  process  them  '\n 'except  on  instructions  from  the controller, unless he or she is required '\n 'to do so by Union or Member State law.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_47",
    "chunk_content": "Notification of a personal data breach to the supervisory authority\n[<Paragraph children=[<RawText children=('In  the  case  of  a  personal  data  breach,  the  controller  shall  '\n 'without  undue  delay  and,  where  feasible,  not  later  than 72  hours  '\n 'after  having  become  aware  of  it,  notify  the  personal  data  breach  '\n 'to  the  supervisory  authority  competent  in accordance  with  Article  '\n '55,  unless  the  personal  data  breach  is  unlikely  to  result  in  a  '\n 'risk  to  the  rights  and  freedoms  of natural  persons.  Where  the  '\n 'notification  to  the  supervisory  authority  is  not  made  within  72  '\n 'hours,  it  shall  be accompanied by reasons for the delay.')>]>]\n[<Paragraph children=[<RawText children=('The processor shall notify the controller  without undue delay after '\n 'becoming aware of a personal data breach.')>]>]\n[<Paragraph children=[<RawText children='The notification referred to in paragraph 1 shall at least:'>]>]\n(a)   describe  the  nature  of  the  personal  data  breach  including  where  possible,  the  categories  and  approximate  number  of data subjects concerned and the categories and approximate number of personal data records concerned;\n(b)   communicate  the  name  and  contact  details  of  the  data  protection  officer  or  other  contact  point  where  more information can be obtained;\n(c)   describe the likely consequences of  the personal data breach;\n(d)   describe  the  measures  taken  or  proposed  to  be  taken  by  the  controller  to  address  the  personal  data  breach, including, where appropriate, measures to mitigate its possible adverse effects.\n[<Paragraph children=[<RawText children=('Where,  and  in  so  far  as,  it  is  not  possible  to  provide  the  '\n 'information  at  the  same  time,  the  information  may  be provided in '\n 'phases without undue further delay.')>]>]\n[<Paragraph children=[<RawText children=('The  controller  shall  document  any  personal  data  breaches,  '\n 'comprising  the  facts  relating  to  the  personal  data breach,  its  '\n 'effects  and  the  remedial  action  taken.  That  documentation  shall  '\n 'enable  the  supervisory  authority  to  verify compliance with this '\n 'Article.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_48",
    "chunk_content": "Communication of a personal data breach to the data subject\n[<Paragraph children=[<RawText children=('When the personal  data  breach  is  likely  to  result  in  a  high  risk  '\n 'to  the  rights  and  freedoms  of  natural  persons,  the controller shall '\n 'communicate the personal data breach to the data subject without undue '\n 'delay.')>]>]\nEN\n[<Paragraph children=[<RawText children=('The  communication  to  the  data  subject  referred  to  in  paragraph  1  '\n 'of  this  Article  shall  describe  in  clear  and  plain language  the  '\n 'nature  of  the  personal  data  breach  and  contain  at  least  the  '\n 'information  and  measures  referred  to  in points (b), (c) and (d) of '\n 'Article 33(3).')>]>]\n[<Paragraph children=[<RawText children=('The  communication  to  the  data  subject  referred  to  in  paragraph  1  '\n 'shall  not  be  required  if  any  of  the  following conditions are met:')>]>]\n(a)   the  controller  has  implemented  appropriate  technical  and  organisational  protection  measures,  and  those  measures were  applied  to  the  personal  data  affected  by  the  personal  data  breach,  in  particular  those  that  render  the  personal data unintelligible to any person who is not authorised to access it, such as encryption;\n(b)   the  controller  has  taken  subsequent  measures  which  ensure  that  the  high  risk  to  the  rights  and  freedoms  of  data subjects referred to in paragraph 1 is no longer likely to materialise;\n(c)   it  would  involve  disproportionate  effort.  In  such  a  case,  there  shall  instead  be  a  public  communication  or  similar measure whereby the data subjects are informed in an equally effective manner.\n[<Paragraph children=[<RawText children=('If  the  controller  has  not  already  communicated  the  personal  data  '\n 'breach  to  the  data  subject,  the  supervisory authority,  having  '\n 'considered  the  likelihood  of  the  personal  data  breach  resulting  in  '\n 'a  high  risk,  may  require  it  to  do  so or  may decide that any of the '\n 'conditions referred to in paragraph 3 are met.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_49",
    "chunk_content": "Data protection impact assessment\n[<Paragraph children=[<RawText children=('Where  a  type  of  processing  in  particular  using  new  technologies,  '\n 'and  taking  into  account  the  nature,  scope, context  and  purposes  of  '\n 'the  processing,  is  likely  to  result  in  a  high  risk  to  the  '\n 'rights  and  freedoms  of  natural  persons, the  controller  shall,  prior  '\n 'to  the  processing,  carry  out  an  assessment  of  the  impact  of  the  '\n 'envisaged  processing operations  on  the  protection  of  personal  data.  '\n 'A  single  assessment  may  address  a  set  of  similar  processing  '\n 'operations that present similar high risks.')>]>]\n[<Paragraph children=[<RawText children=('The  controller  shall  seek  the  advice  of  the  data  protection  '\n 'officer,  where  designated,  when  carrying  out  a  data protection impact '\n 'assessment.')>]>]\n[<Paragraph children=[<RawText children=('A data protection impact assessment referred to in paragraph 1 shall in '\n 'particular be required in the case of:')>]>]\n(a)   a  systematic  and  extensive  evaluation  of  personal  aspects  relating  to  natural  persons  which  is  based  on  automated processing,  including  profiling,  and  on  which  decisions  are  based  that  produce  legal  effects  concerning  the  natural person or similarly significantly affect the natural person;\n(b)   processing  on  a  large  scale  of  special  categories  of  data  referred  to  in  Article  9(1),  or  of  personal  data  relating  to criminal convictions and offences referred to in Article 10; or\n(c)   a  systematic monitoring of a publicly accessible area on a large scale.\n[<Paragraph children=[<RawText children=('The  supervisory  authority  shall  establish  and  make  public  a  list  '\n 'of  the  kind  of  processing  operations  which  are subject  to  the  '\n 'requirement  for  a  data  protection  impact  assessment  pursuant  to  '\n 'paragraph  1.  The  supervisory  authority shall communicate those lists to '\n 'the Board referred to in Article 68.')>]>]\n[<Paragraph children=[<RawText children=('The supervisory authority may also establish and make public a list of  the '\n 'kind of processing operations for  which no data protection impact '\n 'assessment is required. The supervisory authority shall communicate those '\n 'lists to the Board.')>]>]\n[<Paragraph children=[<RawText children=('Prior  to  the  adoption  of  the  lists  referred  to  in  paragraphs  4  '\n 'and  5,  the  competent  supervisory  authority  shall apply  the  '\n 'consistency  mechanism  referred  to  in  Article  63  where  such  lists  '\n 'involve  processing  activities  which  are related  to  the  offering  of  '\n 'goods  or  services  to  data  subjects  or  to  the  monitoring  of  their  '\n 'behaviour  in  several Member States, or may substantially affect the free '\n 'movement of personal data within the Union.')>]>]\nEN\n[<Paragraph children=[<RawText children='The assessment shall contain at least:'>]>]\n(a)   a  systematic  description of  the envisaged processing operations and the purposes of  the processing, including, where applicable, the legitimate interest pursued by the controller;\n(b)   an  assessment of  the necessity and proportionality of  the processing operations in relation to the purposes;\n(c)   an  assessment of  the risks to the rights and freedoms of data subjects referred to in paragraph 1; and\n(d)   the  measures  envisaged  to  address  the  risks,  including  safeguards,  security  measures  and  mechanisms  to  ensure  the protection  of  personal  data  and  to  demonstrate  compliance  with  this  Regulation  taking  into  account  the  rights  and legitimate interests of data subjects and other persons concerned.\n[<Paragraph children=[<RawText children=('Compliance  with  approved  codes  of  conduct  referred  to  in  Article  '\n '40  by  the  relevant  controllers  or  processors shall  be  taken  into  '\n 'due  account  in  assessing  the  impact  of  the  processing  operations  '\n 'performed  by  such  controllers  or processors, in particular for  the '\n 'purposes of a data protection impact assessment.')>]>]\n[<Paragraph children=[<RawText children=('Where  appropriate,  the  controller  shall  seek  the  views  of  data  '\n 'subjects  or  their  representatives  on  the  intended processing,  '\n 'without  prejudice  to  the  protection  of  commercial  or  public  '\n 'interests  or  the  security  of  processing operations.')>]>]\n[<Paragraph children=[<RawText children=('Where processing  pursuant  to  point  (c)  or  (e)  of  Article  6(1)  has  '\n 'a  legal  basis  in  Union  law  or  in  the  law  of  the Member State to '\n 'which the controller  is subject, that  law regulates  the specific  '\n 'processing operation or  set of operations in question, and a data '\n 'protection impact assessment has already been carried out as part of a '\n 'general impact assessment in  the  context  of  the  adoption  of  that  '\n 'legal  basis,  paragraphs  1  to  7  shall  not  apply  unless  Member  '\n 'States  deem  it  to  be necessary to carry out such an assessment prior to '\n 'processing activities.')>]>]\n[<Paragraph children=[<RawText children=('Where  necessary,  the  controller  shall  carry  out  a  review  to  '\n 'assess  if  processing  is  performed  in  accordance  with the data '\n 'protection impact assessment at least when there is a change of the risk '\n 'represented by processing operations.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_50",
    "chunk_content": "Prior consultation\n[<Paragraph children=[<RawText children=('The  controller  shall  consult  the  supervisory  authority  prior  to  '\n 'processing  where  a  data  protection  impact assessment  under  Article  '\n '35  indicates  that  the  processing  would  result  in  a  high  risk  in  '\n 'the  absence  of  measures  taken by the controller  to mitigate the risk.')>]>]\n[<Paragraph children=[<RawText children=('Where  the  supervisory  authority  is  of  the  opinion  that  the  '\n 'intended  processing  referred  to  in  paragraph  1  would infringe  this  '\n 'Regulation,  in  particular  where  the  controller  has  insufficiently  '\n 'identified  or  mitigated  the  risk,  the supervisory authority shall, '\n 'within period of up to eight weeks of receipt of  the request for '\n 'consultation, provide written advice  to  the  controller  and,  where  '\n 'applicable  to  the  processor,  and  may  use  any of  its  powers  '\n 'referred  to  in  Article  58. That  period  may  be  extended  by  six  '\n 'weeks,  taking  into  account  the  complexity  of  the  intended  '\n 'processing.  The supervisory authority shall inform the controller and, '\n 'where applicable, the processor, of any such extension within one month  of  '\n 'receipt  of  the  request  for  consultation  together  with  the  reasons  '\n 'for  the  delay.  Those  periods  may  be suspended  until  the  '\n 'supervisory  authority  has  obtained  information  it  has  requested  for  '\n 'the  purposes  of  the consultation.')>]>]\n[<Paragraph children=[<RawText children=('When  consulting  the  supervisory  authority  pursuant  to  paragraph  1,  '\n 'the  controller  shall  provide  the  supervisory authority with:')>]>]\n(a)   where  applicable,  the  respective  responsibilities  of  the  controller,  joint  controllers  and  processors  involved  in  the processing, in particular for processing within a group of undertakings;\n(b)   the  purposes and means of the intended processing;\n(c)   the  measures  and  safeguards  provided  to  protect  the  rights  and  freedoms  of  data  subjects  pursuant  to  this Regulation;\n(d)   where applicable, the contact details of  the data protection officer;\nImage\n(e)   the  data protection impact assessment provided for in Article 35; and\n(f)   any other  information requested by the supervisory authority.\n[<Paragraph children=[<RawText children=('Member  States  shall  consult  the  supervisory  authority  during  the  '\n 'preparation  of  a  proposal  for  a  legislative measure to be  adopted  '\n 'by  a  national  parliament,  or  of  a  regulatory  measure  based  on  '\n 'such  a  legislative  measure,  which relates to processing.')>]>]\n[<Paragraph children=[<RawText children=('Notwithstanding paragraph 1, Member State law may require controllers to '\n 'consult with, and obtain prior author\\xad isation from, the supervisory '\n 'authority in relation to processing by a controller for  the performance of '\n 'a task carried out by the controller in the public interest, including '\n 'processing in relation to social protection and public health.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_51",
    "chunk_content": "Data protection officer\nArticle 37"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_52",
    "chunk_content": "Designation of the data protection officer\n[<Paragraph children=[<RawText children=('The controller and the processor shall designate a data protection officer '\n 'in any case where:')>]>]\n(a)   the  processing is carried out by a public authority or body, except for courts acting in their  judicial capacity;\n(b)   the  core  activities  of  the  controller  or  the  processor  consist  of  processing  operations  which,  by  virtue  of  their nature, their scope and/or  their  purposes, require regular and systematic monitoring of data subjects on a large scale; or\n(c)   the  core  activities  of  the  controller  or  the  processor  consist  of  processing  on  a  large  scale  of  special  categories  of data pursuant to Article 9 and personal data relating to criminal convictions and offences referred to in Article 10.\n[<Paragraph children=[<RawText children=('A  group  of  undertakings  may  appoint  a  single  data  protection  '\n 'officer  provided  that  a  data  protection  officer  is easily accessible '\n 'from each establishment.')>]>]\n[<Paragraph children=[<RawText children=('Where  the  controller  or  the  processor  is  a  public  authority  or  '\n 'body,  a  single  data  protection  officer  may  be designated for several '\n 'such authorities or bodies, taking account of their organisational structure '\n 'and size.')>]>]\n[<Paragraph children=[<RawText children=('In  cases  other  than  those  referred  to  in  paragraph  1,  the  '\n 'controller  or  processor  or  associations  and  other  bodies '\n 'representing  categories  of  controllers  or  processors  may  or,  where  '\n 'required  by  Union  or  Member  State  law  shall, designate  a  data  '\n 'protection  officer.  The  data  protection  officer  may  act  for  such  '\n 'associations  and  other  bodies representing controllers or processors.')>]>]\n[<Paragraph children=[<RawText children=('The  data  protection  officer  shall  be  designated  on  the  basis  of  '\n 'professional  qualities  and,  in  particular,  expert knowledge of data '\n 'protection law and practices and the ability to fulfil the tasks referred to '\n 'in Article 39.')>]>]\n[<Paragraph children=[<RawText children=('The data protection officer  may be a staff member of  the controller or  '\n 'processor, or fulfil  the tasks on the basis of a service contract.')>]>]\n[<Paragraph children=[<RawText children=('The  controller  or  the  processor  shall  publish  the  contact  details  '\n 'of  the  data  protection  officer  and  communicate them to the supervisory '\n 'authority.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_53",
    "chunk_content": "Position of the data protection officer\n[<Paragraph children=[<RawText children=('The controller  and  the  processor  shall  ensure  that  the  data  '\n 'protection  officer  is  involved,  properly  and  in  a  timely manner, in '\n 'all issues which relate to the protection of personal data.')>]>]\nEN\n[<Paragraph children=[<RawText children=('The  controller  and  processor  shall  support  the  data  protection  '\n 'officer  in  performing  the  tasks  referred  to  in Article  39  by  '\n 'providing  resources  necessary  to  carry  out  those  tasks  and  access  '\n 'to  personal  data  and  processing operations, and to maintain his or her '\n 'expert knowledge.')>]>]\n[<Paragraph children=[<RawText children=('The  controller  and  processor  shall  ensure  that  the  data  protection  '\n 'officer  does  not  receive  any  instructions regarding the exercise of '\n 'those tasks. He or she shall not be dismissed or penalised by the controller '\n 'or  the processor for performing  his  tasks.  The  data  protection  '\n 'officer  shall  directly  report  to  the  highest  management  level  of  '\n 'the  controller or  the processor.')>]>]\n[<Paragraph children=[<RawText children=('Data  subjects  may  contact  the  data  protection  officer  with  regard  '\n 'to  all  issues  related  to  processing  of  their personal data and to the '\n 'exercise of their rights under  this Regulation.')>]>]\n[<Paragraph children=[<RawText children=('The  data  protection  officer  shall  be  bound  by  secrecy  or  '\n 'confidentiality  concerning  the  performance  of  his  or  her tasks, in '\n 'accordance with Union or Member State law.')>]>]\n[<Paragraph children=[<RawText children=('The data protection officer may fulfil other  tasks and duties. The '\n 'controller or  processor shall ensure that any such tasks and duties do not '\n 'result in a conflict of interests.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_54",
    "chunk_content": "Tasks of the data protection officer\n[<Paragraph children=[<RawText children='The data protection officer shall have at least the following tasks:'>]>]\n(a)   to  inform  and  advise  the  controller  or  the  processor  and  the  employees  who  carry  out  processing  of  their obligations pursuant to this Regulation and to other Union or Member State data protection provisions;\n(b)   to  monitor  compliance with  this  Regulation,  with  other  Union  or  Member  State  data  protection provisions  and with the  policies  of  the  controller  or  processor  in  relation  to  the  protection  of  personal  data,  including  the  assignment  of responsibilities, awareness-raising and training of staff involved in processing operations, and the related audits;\n(c)   to  provide  advice  where  requested  as  regards  the  data  protection  impact  assessment  and  monitor  its  performance pursuant to Article 35;\n(d)   to cooperate with the supervisory authority;\n(e)   to  act  as  the  contact  point  for  the  supervisory  authority  on  issues  relating  to  processing,  including  the  prior consultation referred to in Article 36, and to consult, where appropriate, with regard to any other matter.\n[<Paragraph children=[<RawText children=('The data protection officer shall in  the performance of his or her  tasks  '\n 'have  due regard to the risk  associated with processing operations, taking '\n 'into account the nature, scope, context and purposes of processing.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_55",
    "chunk_content": "Codes of conduct\n[<Paragraph children=[<RawText children=('The Member States, the supervisory authorities, the Board and the Commission '\n 'shall encourage the drawing up of codes  of  conduct  intended  to  '\n 'contribute  to  the  proper  application  of  this  Regulation,  taking  '\n 'account  of  the  specific features of  the various processing sectors and '\n 'the specific needs of micro, small and medium-sized enterprises.')>]>]\n[<Paragraph children=[<RawText children=('Associations  and  other  bodies  representing  categories  of  controllers  '\n 'or  processors  may  prepare  codes  of  conduct, or amend or extend such '\n 'codes, for the purpose of specifying the application of this Regulation, '\n 'such as with regard to:')>]>]\n(a)   fair  and  transparent processing;\n(b)   the  legitimate interests pursued by controllers in specific contexts;\n(c)   the  collection of personal data;\n(d)   the  pseudonymisation of personal data;\n(e)   the  information provided to the public and to data subjects;\n(f)   the  exercise of  the rights of data subjects;\n(g)   the  information provided  to, and  the protection of, children,  and the  manner  in which the  consent of  the  holders of parental responsibility over children is to be obtained;\n(h)   the  measures  and  procedures  referred  to  in  Articles  24  and  25  and  the  measures  to  ensure  security  of  processing referred to in Article 32;\n(i) the  notification  of  personal  data  breaches  to  supervisory  authorities  and  the  communication  of  such  personal  data breaches to data subjects;\n(j) the transfer of personal data to third countries or international organisations; or\n(k)   out-of-court proceedings and other dispute resolution procedures for resolving disputes between controllers and data subjects with regard to processing, without prejudice to the rights of data subjects pursuant to Articles 77 and 79.\n[<Paragraph children=[<RawText children=('In  addition  to  adherence  by  controllers  or  processors  subject  to  '\n 'this  Regulation,  codes  of  conduct  approved pursuant  to  paragraph  5  '\n 'of  this  Article  and  having  general  validity  pursuant  to  paragraph  '\n '9  of  this  Article  may  also  be adhered to by controllers  or  '\n 'processors  that  are  not  subject  to  this  Regulation  pursuant  to  '\n 'Article  3  in  order  to  provide appropriate  safeguards  within  the  '\n 'framework of  personal  data  transfers  to  third  countries  or  '\n 'international  organisations under  the  terms  referred  to  in  point  '\n '(e)  of  Article  46(2).  Such  controllers  or  processors  shall  make  '\n 'binding  and enforceable  commitments,  via  contractual  or  other  '\n 'legally  binding  instruments,  to  apply  those  appropriate  safeguards '\n 'including with regard to the rights of data subjects.')>]>]\n[<Paragraph children=[<RawText children=('A  code  of  conduct  referred  to  in  paragraph  2  of  this  Article  '\n 'shall  contain  mechanisms  which  enable  the  body referred  to  in  '\n 'Article  41(1)  to  carry  out  the  mandatory  monitoring  of  compliance  '\n 'with  its  provisions  by  the  controllers or  processors  which  '\n 'undertake  to  apply  it,  without  prejudice  to  the  tasks  and  powers  '\n 'of  supervisory  authorities competent pursuant to Article 55 or 56.')>]>]\n[<Paragraph children=[<RawText children=('Associations and other bodies referred to in paragraph 2 of this Article '\n 'which intend to prepare a code of conduct or  to  amend  or  extend  an  '\n 'existing  code  shall  submit  the  draft  code,  amendment  or  extension  '\n 'to  the  supervisory authority which is competent pursuant to Article 55. '\n 'The supervisory authority shall provide an opinion on whether  the draft  '\n 'code,  amendment  or  extension  complies  with  this  Regulation  and  '\n 'shall  approve  that  draft  code,  amendment  or extension if it finds that '\n 'it provides sufficient appropriate safeguards.')>]>]\n[<Paragraph children=[<RawText children=('Where  the  draft  code,  or  amendment  or  extension  is  approved  in  '\n 'accordance  with  paragraph  5,  and  where  the code  of  conduct  '\n 'concerned  does  not  relate  to  processing  activities  in  several  '\n 'Member  States,  the  supervisory  authority shall register and publish the '\n 'code.')>]>]\n[<Paragraph children=[<RawText children=('Where  a  draft  code  of  conduct  relates  to  processing  activities  in  '\n 'several  Member  States,  the  supervisory  authority which is competent '\n 'pursuant to Article 55 shall, before approving the draft code, amendment or '\n 'extension, submit it in the  procedure  referred  to  in  Article  63  to  '\n 'the  Board  which  shall  provide  an  opinion  on  whether  the  draft  '\n 'code, amendment  or  extension  complies  with  this  Regulation  or,  in  '\n 'the  situation  referred  to  in  paragraph  3  of  this  Article, provides '\n 'appropriate safeguards.')>]>]\n[<Paragraph children=[<RawText children=('Where  the  opinion  referred  to  in  paragraph  7  confirms  that  the  '\n 'draft  code,  amendment  or  extension  complies with  this  Regulation,  '\n 'or,  in  the  situation  referred  to  in  paragraph  3,  provides  '\n 'appropriate  safeguards,  the  Board  shall submit its opinion to the '\n 'Commission.')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  may,  by  way  of  implementing  acts,  decide  that  the  '\n 'approved  code  of  conduct,  amendment  or extension  submitted  to  it  '\n 'pursuant  to  paragraph  8  of  this  Article  have  general  validity  '\n 'within  the  Union.  Those implementing acts shall be adopted in accordance '\n 'with the examination procedure set out in Article 93(2).')>]>]\nEN\n[<Paragraph children=[<RawText children=('The  Commission  shall  ensure  appropriate  publicity  for  the  approved  '\n 'codes  which  have  been  decided  as  having general validity in accordance '\n 'with paragraph 9.')>]>]\n[<Paragraph children=[<RawText children=('The  Board  shall  collate  all  approved  codes  of  conduct,  amendments  '\n 'and  extensions  in  a  register  and  shall  make them publicly available '\n 'by way of appropriate means.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_56",
    "chunk_content": "Monitoring of approved codes of conduct\n[<Paragraph children=[<RawText children=('Without  prejudice  to  the  tasks  and  powers  of  the  competent  '\n 'supervisory  authority  under  Articles  57  and  58,  the monitoring  of  '\n 'compliance  with  a  code  of  conduct  pursuant  to  Article  40  may  be  '\n 'carried  out  by  a  body  which  has  an appropriate  level  of  expertise  '\n 'in  relation  to  the  subject-matter  of  the  code  and  is  accredited  '\n 'for  that  purpose  by  the competent supervisory authority.')>]>]\n[<Paragraph children=[<RawText children=('A body as referred to in paragraph 1 may be accredited to monitor compliance '\n 'with a code of conduct where that body has:')>]>]\n(a)   demonstrated  its  independence  and  expertise  in  relation  to  the  subject-matter  of  the  code  to  the  satisfaction  of  the competent supervisory authority;\n(b)   established  procedures  which  allow  it  to  assess  the  eligibility  of  controllers  and  processors  concerned  to  apply  the code, to monitor their compliance with its provisions and to periodically review its operation;\n(c)   established  procedures and structures to handle complaints about infringements of  the code or  the manner  in which the  code  has  been,  or  is  being,  implemented  by  a  controller  or  processor,  and  to  make  those  procedures  and structures transparent to data subjects and the public; and\n(d)   demonstrated  to  the  satisfaction  of  the  competent  supervisory  authority  that  its  tasks  and  duties  do  not  result  in  a conflict of interests.\n[<Paragraph children=[<RawText children=('The  competent  supervisory  authority  shall  submit  the  draft  criteria  '\n 'for  accreditation  of  a  body  as  referred  to  in paragraph 1 of this '\n 'Article to the Board pursuant to the consistency mechanism referred to in '\n 'Article 63.')>]>]\n[<Paragraph children=[<RawText children=('Without  prejudice  to  the  tasks  and  powers  of  the  competent  '\n 'supervisory  authority  and  the  provisions  of Chapter  VIII,  a  body  '\n 'as  referred  to  in  paragraph  1  of  this  Article  shall,  subject  to  '\n 'appropriate  safeguards,  take appropriate  action  in  cases  of  '\n 'infringement  of  the  code  by  a  controller  or  processor,  including  '\n 'suspension  or  exclusion of  the  controller  or  processor  concerned  '\n 'from  the  code.  It  shall  inform  the  competent  supervisory  authority  '\n 'of  such actions and the reasons for  taking them.')>]>]\n[<Paragraph children=[<RawText children=('The  competent  supervisory  authority  shall  revoke  the  accreditation  '\n 'of  a  body  as  referred  to  in  paragraph  1  if  the conditions for '\n 'accreditation are not, or are no longer, met or  where actions taken by the '\n 'body infringe this Regulation.')>]>]\n[<Paragraph children=[<RawText children=('This Article shall not apply to processing carried out by public authorities '\n 'and bodies.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_57",
    "chunk_content": "Certification\n[<Paragraph children=[<RawText children=('The  Member  States,  the  supervisory  authorities,  the  Board  and  the  '\n 'Commission  shall  encourage,  in  particular  at Union  level,  the  '\n 'establishment  of  data  protection  certification  mechanisms  and  of  '\n 'data  protection  seals  and  marks,  for the  purpose  of  demonstrating  '\n 'compliance  with  this  Regulation  of  processing  operations  by  '\n 'controllers  and  processors. The specific needs of micro, small and '\n 'medium-sized enterprises shall be taken into account.')>]>]\nEN\n[<Paragraph children=[<RawText children=('In  addition  to  adherence  by  controllers  or  processors  subject  to  '\n 'this  Regulation,  data  protection  certification mechanisms,  seals  or  '\n 'marks  approved  pursuant  to  paragraph  5  of  this  Article  may  be  '\n 'established  for  the  purpose  of demonstrating  the  existence  of  '\n 'appropriate  safeguards  provided  by controllers  or  processors  that  '\n 'are  not  subject  to  this Regulation  pursuant  to  Article  3  within  '\n 'the  framework  of  personal  data  transfers  to  third  countries  or  '\n 'international organisations under  the terms referred to in point (f) of '\n 'Article 46(2). Such controllers or  processors shall make binding and  '\n 'enforceable  commitments,  via  contractual  or  other  legally  binding  '\n 'instruments,  to  apply  those  appropriate safeguards, including with '\n 'regard to the rights of data subjects.')>]>]\n[<Paragraph children=[<RawText children=('The certification shall be voluntary and available via a process that is '\n 'transparent.')>]>]\n[<Paragraph children=[<RawText children=('A  certification  pursuant  to  this  Article  does  not  reduce  the  '\n 'responsibility  of  the  controller  or  the  processor  for compliance  '\n 'with  this  Regulation  and  is  without  prejudice  to  the  tasks  and  '\n 'powers  of  the  supervisory  authorities  which are competent pursuant to '\n 'Article 55 or 56.')>]>]\n[<Paragraph children=[<RawText children=('A certification pursuant to this Article shall be issued by the '\n 'certification bodies referred to in Article 43 or by the competent '\n 'supervisory authority, on the  basis  of  criteria  approved  by  that  '\n 'competent  supervisory  authority  pursuant  to Article  58(3)  or  by  the  '\n 'Board  pursuant  to Article  63.  Where  the  criteria  are  approved  by '\n 'the  Board,  this  may  result  in  a common certification, the European '\n 'Data Protection Seal.')>]>]\n[<Paragraph children=[<RawText children=('The  controller  or  processor  which  submits  its  processing  to  the  '\n 'certification  mechanism  shall  provide  the  certifi\\xad cation  body  '\n 'referred  to  in  Article  43,  or  where  applicable,  the  competent  '\n 'supervisory  authority,  with  all  information and access to its processing '\n 'activities which are necessary to conduct the certification procedure.')>]>]\n[<Paragraph children=[<RawText children=('Certification  shall  be  issued  to  a  controller  or  processor  for  a  '\n 'maximum  period  of  three  years  and  may  be renewed,  under  the  same  '\n 'conditions,  provided  that  the  relevant  requirements  continue  to  be  '\n 'met.  Certification  shall  be withdrawn, as applicable, by the '\n 'certification bodies referred to in Article 43  or by the competent '\n 'supervisory authority where the requirements for the certification are not '\n 'or are no longer met.')>]>]\n[<Paragraph children=[<RawText children=('The  Board  shall  collate  all  certification  mechanisms  and  data  '\n 'protection  seals  and  marks  in  a  register  and  shall make them '\n 'publicly available by any appropriate means.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_58",
    "chunk_content": "Certification bodies\n[<Paragraph children=[<RawText children=('Without  prejudice  to  the  tasks  and  powers  of  the  competent  '\n 'supervisory  authority  under  Articles  57  and  58, certification  bodies  '\n 'which  have  an  appropriate  level  of  expertise  in  relation  to  data  '\n 'protection  shall,  after  informing  the supervisory  authority  in  order  '\n 'to  allow  it  to  exercise  its  powers  pursuant  to  point  (h)  of  '\n 'Article  58(2)  where  necessary, issue  and  renew certification. Member '\n 'States shall ensure that those certification bodies are accredited by one or '\n 'both of the following:')>]>]\n(a)   the  supervisory authority which is competent pursuant to Article 55 or 56;\n(b)   the  national accreditation body named in accordance with Regulation (EC) No 765/2008 of the European Parliament and of  the  Council  ( 1 )  in  accordance  with  EN-ISO/IEC  17065/2012 and with the additional requirements established by the supervisory authority which is competent pursuant to Article 55 or 56.\n[<Paragraph children=[<RawText children=('Certification  bodies  referred  to  in  paragraph  1  shall  be  '\n 'accredited  in  accordance  with  that  paragraph  only  where they have:')>]>]\n(a)   demonstrated  their  independence  and  expertise  in  relation  to  the  subject-matter  of  the  certification  to  the satisfaction of  the competent supervisory authority;\n( 1 ) Regulation (EC) No 765/2008 of the European Parliament and of the Council of 9 July 2008 setting out the requirements for accredi­ tation and market surveillance relating to the marketing of products and repealing Regulation (EEC) No 339/93 (OJ L 218, 13.8.2008, p. 30).\nImage\n(b)   undertaken  to  respect  the  criteria  referred  to  in  Article  42(5)  and  approved  by  the  supervisory  authority  which  is competent pursuant to Article 55 or 56 or by the Board pursuant to Article 63;\n(c)   established  procedures  for  the  issuing,  periodic  review  and  withdrawal  of  data  protection  certification,  seals  and marks;\n(d)   established procedures and structures to handle complaints about infringements of the certification or  the manner in which  the  certification  has  been,  or  is  being,  implemented  by  the  controller  or  processor,  and  to  make  those procedures and structures transparent to data subjects and the public; and\n(e)   demonstrated,  to  the  satisfaction  of  the  competent  supervisory  authority,  that  their  tasks  and  duties  do  not  result  in a conflict of interests.\n[<Paragraph children=[<RawText children=('The accreditation of certification bodies as  referred  to in paragraphs 1 '\n 'and 2 of  this  Article  shall take place on the basis of criteria approved '\n 'by the supervisory authority which is competent pursuant to Article 55 or 56 '\n 'or by the Board pursuant  to  Article  63.  In  the  case  of  '\n 'accreditation  pursuant  to  point  (b)  of  paragraph  1  of  this  '\n 'Article,  those requirements  shall  complement  those  envisaged  in  '\n 'Regulation  (EC)  No  765/2008  and  the  technical  rules  that  describe '\n 'the methods and procedures of the certification bodies.')>]>]\n[<Paragraph children=[<RawText children=('The  certification  bodies  referred  to  in  paragraph  1  shall  be  '\n 'responsible  for  the  proper  assessment  leading  to  the certification  '\n 'or  the  withdrawal of such certification  without prejudice to the '\n 'responsibility of  the controller  or  processor for  compliance  with  '\n 'this  Regulation.  The  accreditation  shall  be  issued  for  a  maximum  '\n 'period  of  five  years  and  may  be renewed on the same conditions '\n 'provided that the certification body meets the requirements set out in this '\n 'Article.')>]>]\n[<Paragraph children=[<RawText children=('The  certification  bodies  referred  to  in  paragraph  1  shall  provide  '\n 'the  competent  supervisory  authorities  with  the reasons for granting or '\n 'withdrawing the requested certification.')>]>]\n[<Paragraph children=[<RawText children=('The  requirements  referred  to  in  paragraph  3  of  this  Article  and  '\n 'the  criteria  referred  to  in  Article  42(5)  shall  be made  public  by  '\n 'the  supervisory  authority  in  an  easily  accessible  form.  The  '\n 'supervisory  authorities  shall  also  transmit those  requirements  and  '\n 'criteria  to  the  Board.  The  Board  shall  collate  all  certification  '\n 'mechanisms  and  data  protection seals in a register and shall make them '\n 'publicly available by any appropriate means.')>]>]\n[<Paragraph children=[<RawText children=('Without  prejudice  to  Chapter  VIII,  the  competent  supervisory  '\n 'authority  or  the  national  accreditation  body  shall revoke  an  '\n 'accreditation  of  a  certification  body  pursuant  to  paragraph  1  of  '\n 'this  Article  where  the  conditions  for  the accreditation are not, or '\n 'are no longer, met or  where actions taken by a certification body infringe '\n 'this Regulation.')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  shall  be  empowered  to  adopt  delegated  acts  in  '\n 'accordance  with  Article  92  for  the  purpose  of specifying  the  '\n 'requirements  to  be  taken  into  account  for  the  data  protection  '\n 'certification  mechanisms  referred  to  in Article 42(1).')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  may  adopt  implementing  acts  laying  down  technical  '\n 'standards  for  certification  mechanisms  and data  protection  seals  and  '\n 'marks,  and  mechanisms  to  promote  and  recognise  those  certification  '\n 'mechanisms,  seals  and marks.  Those  implementing  acts  shall  be  '\n 'adopted  in  accordance  with  the  examination  procedure  referred  to  in '\n 'Article 93(2).')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_59",
    "chunk_content": "General principle for transfers\nAny  transfer  of  personal  data  which  are  undergoing  processing  or  are  intended  for  processing  after  transfer  to  a  third country or  to an international organisation shall take place only if, subject to the other  provisions of this Regulation, the conditions  laid  down  in  this  Chapter  are  complied  with  by  the  controller  and  processor,  including  for  onward  transfers of personal data from the third country or an international organisation to another  third country or  to another internat­ ional  organisation.  All  provisions  in  this  Chapter  shall  be  applied  in  order  to  ensure  that  the  level  of  protection  of natural persons guaranteed by this Regulation is not undermined.\nEN"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_60",
    "chunk_content": "Transfers on the basis of an adequacy decision\n[<Paragraph children=[<RawText children=('A  transfer  of  personal  data  to  a  third  country  or  an  '\n 'international  organisation  may  take  place  where  the Commission has '\n 'decided that the third country, a territory or one or more specified sectors '\n 'within that third country, or the  international  organisation  in  '\n 'question  ensures  an  adequate  level  of  protection.  Such  a  transfer  '\n 'shall  not  require  any specific authorisation.')>]>]\n[<Paragraph children=[<RawText children=('When  assessing  the  adequacy  of  the  level  of  protection,  the  '\n 'Commission  shall,  in  particular,  take  account  of  the following '\n 'elements:')>]>]\n(a)   the  rule  of  law,  respect  for  human  rights  and  fundamental  freedoms,  relevant  legislation,  both  general  and  sectoral, including concerning public security, defence, national security and criminal law and the access of public authorities to  personal  data,  as  well  as  the  implementation  of  such  legislation,  data  protection  rules,  professional  rules  and security  measures,  including  rules  for  the  onward  transfer  of  personal  data  to another  third  country or  international organisation which are complied with in that country or  international organisation, case-law, as well as effective and enforceable  data  subject  rights  and  effective  administrative  and  judicial  redress  for  the  data  subjects  whose  personal data are being transferred;\n(b)   the  existence and effective functioning of one or more independent supervisory authorities in the third country or  to which  an  international  organisation  is  subject,  with  responsibility  for  ensuring  and  enforcing  compliance  with  the data  protection  rules,  including  adequate  enforcement  powers,  for  assisting  and  advising  the  data  subjects  in exercising their  rights and for cooperation with the supervisory authorities of the Member States; and\n(c)   the  international  commitments  the  third  country  or  international  organisation  concerned  has  entered  into,  or  other obligations  arising  from  legally  binding  conventions  or  instruments  as  well  as  from  its  participation  in  multilateral or  regional systems, in particular  in relation to the protection of personal data.\n[<Paragraph children=[<RawText children=('The  Commission,  after  assessing  the  adequacy  of  the  level  of  '\n 'protection,  may  decide,  by  means  of  implementing act,  that  a  third  '\n 'country,  a  territory  or  one  or  more  specified  sectors  within  a  '\n 'third  country,  or  an  international organisation  ensures  an  adequate  '\n 'level  of  protection  within  the  meaning  of  paragraph  2  of  this  '\n 'Article.  The implementing  act  shall  provide  for  a  mechanism  for  a  '\n 'periodic  review,  at  least  every  four  years,  which  shall  take  into '\n 'account all  relevant  developments  in  the  third  country or  '\n 'international  organisation.  The  implementing  act  shall  specify its  '\n 'territorial  and  sectoral  application  and,  where  applicable,  identify  '\n 'the  supervisory  authority  or  authorities  referred  to in  point  (b)  '\n 'of  paragraph  2  of  this  Article.  The  implementing  act  shall  be  '\n 'adopted  in  accordance  with  the  examination procedure referred to in '\n 'Article 93(2).')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  shall,  on  an  ongoing  basis,  monitor  developments  in  '\n 'third  countries  and  international  organ\\xad isations  that  could  '\n 'affect  the  functioning  of  decisions  adopted  pursuant  to  paragraph  '\n '3  of  this  Article  and  decisions adopted on the basis of Article 25(6) '\n 'of Directive 95/46/EC.')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  shall,  where  available  information  reveals,  in  '\n 'particular  following  the  review  referred  to  in paragraph  3  of  this  '\n 'Article,  that  a  third  country,  a  territory  or  one  or  more  '\n 'specified  sectors  within  a  third  country,  or an  international  '\n 'organisation  no  longer  ensures  an  adequate  level  of  protection  '\n 'within  the  meaning  of  paragraph  2  of this  Article,  to  the  extent  '\n 'necessary,  repeal,  amend  or  suspend  the  decision  referred  to  in  '\n 'paragraph  3  of  this  Article  by means  of  implementing  acts  without  '\n 'retro-active  effect.  Those  implementing  acts  shall  be  adopted  in  '\n 'accordance  with the examination procedure referred to in Article 93(2).')>]>]\nOn duly justified  imperative  grounds  of  urgency,  the  Commission  shall  adopt immediately  applicable  implementing  acts in accordance with the procedure referred to in Article 93(3).\n[<Paragraph children=[<RawText children=('The Commission shall enter  into consultations  with  the  third  country '\n 'or  international  organisation with  a  view  to remedying the situation '\n 'giving rise to the decision made pursuant to paragraph 5.')>]>]\n[<Paragraph children=[<RawText children=('A  decision  pursuant  to  paragraph  5  of  this  Article  is  without  '\n 'prejudice  to  transfers  of  personal  data  to  the  third country,  a  '\n 'territory  or  one  or  more  specified  sectors  within  that  third  '\n 'country,  or  the  international  organisation  in question pursuant to '\n 'Articles 46 to 49.')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  shall  publish  in  the Official  Journal  of  the  '\n 'European  Union and  on  its  website  a  list  of  the  third countries, '\n 'territories and specified sectors within a third country and international '\n 'organisations for  which it has decided that an adequate level of protection '\n 'is or is no longer ensured.')>]>]\nEN\n[<Paragraph children=[<RawText children=('Decisions  adopted  by  the  Commission  on  the  basis  of  Article  25(6)  '\n 'of  Directive  95/46/EC  shall  remain  in  force until  amended,  replaced  '\n 'or  repealed  by  a  Commission  Decision  adopted  in  accordance  with  '\n 'paragraph  3  or  5  of  this Article.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_61",
    "chunk_content": "Transfers subject to appropriate safeguards\n[<Paragraph children=[<RawText children=('In  the  absence  of  a  decision  pursuant  to  Article  45(3),  a  '\n 'controller  or  processor  may  transfer  personal  data  to  a third  '\n 'country  or  an  international  organisation  only  if  the  controller  or  '\n 'processor  has  provided  appropriate  safeguards, and on condition that '\n 'enforceable data subject rights and effective legal remedies for data '\n 'subjects are available.')>]>]\n[<Paragraph children=[<RawText children=('The appropriate safeguards referred to in paragraph 1 may be provided for, '\n 'without requiring any specific authoris\\xad ation from a supervisory '\n 'authority, by:')>]>]\n(a)   a  legally  binding and enforceable instrument between public authorities or bodies;\n(b)   binding corporate rules in accordance with Article 47;\n(c)   standard  data  protection  clauses  adopted by the Commission in accordance with the examination procedure referred to in Article 93(2);\n(d)   standard  data  protection  clauses  adopted  by  a  supervisory  authority  and  approved  by  the  Commission  pursuant  to the examination procedure referred to in Article 93(2);\n(e)   an  approved  code  of  conduct  pursuant  to  Article  40  together  with  binding  and  enforceable  commitments  of  the controller  or  processor  in  the  third  country  to  apply  the  appropriate  safeguards,  including  as  regards  data  subjects' rights; or\n(f)   an  approved  certification  mechanism pursuant  to Article  42  together  with  binding and  enforceable  commitments  of the  controller  or  processor  in  the  third  country  to  apply  the  appropriate  safeguards,  including  as  regards  data subjects' rights.\n[<Paragraph children=[<RawText children=('Subject  to  the  authorisation  from  the  competent  supervisory  '\n 'authority,  the  appropriate  safeguards  referred  to  in paragraph 1 may '\n 'also be provided for, in particular, by:')>]>]\n(a)   contractual  clauses  between  the controller or  processor and the controller, processor or  the recipient of  the personal data in the third country or international organisation; or\n(b)   provisions  to  be  inserted  into  administrative  arrangements  between  public  authorities  or  bodies  which  include enforceable and effective data subject rights.\n[<Paragraph children=[<RawText children=('The supervisory  authority  shall  apply  the  consistency  mechanism  '\n 'referred  to  in  Article  63  in  the  cases  referred  to in paragraph 3 '\n 'of this Article.')>]>]\n[<Paragraph children=[<RawText children=('Authorisations  by  a  Member  State  or  supervisory  authority  on  the  '\n 'basis  of  Article  26(2)  of  Directive  95/46/EC shall  remain  valid  '\n 'until  amended,  replaced  or  repealed,  if  necessary,  by  that  '\n 'supervisory  authority.  Decisions  adopted  by the  Commission  on  the  '\n 'basis  of  Article  26(4)  of  Directive  95/46/EC  shall  remain  in  '\n 'force  until  amended,  replaced  or repealed, if necessary, by a Commission '\n 'Decision adopted in accordance with paragraph 2 of this Article.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_62",
    "chunk_content": "Binding corporate rules\n[<Paragraph children=[<RawText children=('The  competent  supervisory  authority  shall  approve  binding  corporate  '\n 'rules  in  accordance  with  the  consistency mechanism set out in Article '\n '63, provided that they:')>]>]\n(a)   are  legally  binding  and  apply  to  and  are  enforced  by  every  member  concerned  of  the  group  of  undertakings,  or group of enterprises engaged in a joint economic activity, including their employees;\nEN\n(b)   expressly confer enforceable rights on data subjects with regard to the processing of their personal data; and\n(c)   fulfil  the  requirements laid down in paragraph 2.\n[<Paragraph children=[<RawText children='The binding corporate rules referred to in paragraph 1 shall specify at least:'>]>]\n(a) the  structure  and  contact  details  of  the  group  of  undertakings,  or  group  of  enterprises  engaged  in  a  joint  economic activity and of each of its members;\n(b)   the  data  transfers  or  set  of  transfers,  including  the  categories  of  personal  data,  the  type  of  processing  and  its purposes, the type of data subjects affected and the identification of the third country or countries in question;\n(c) their legally binding nature, both internally and externally;\n(d)   the  application  of  the  general  data  protection principles,  in particular  purpose limitation, data  minimisation, limited storage  periods,  data  quality,  data  protection  by  design  and  by  default,  legal  basis  for  processing,  processing  of special  categories  of  personal  data,  measures  to  ensure  data  security,  and  the  requirements  in  respect  of  onward transfers to bodies not bound by the binding corporate rules;\n(e) the  rights  of  data  subjects  in  regard  to  processing  and  the  means  to  exercise  those  rights,  including  the  right  not  to be subject to decisions based solely on automated processing, including profiling  in accordance with Article 22, the right  to  lodge  a  complaint  with  the  competent  supervisory  authority  and  before  the  competent  courts  of  the Member  States  in  accordance  with  Article  79,  and  to  obtain  redress  and,  where  appropriate,  compensation  for  a breach of the binding corporate rules;\n(f) the  acceptance  by  the  controller  or  processor  established  on  the  territory  of  a  Member  State  of  liability  for  any breaches  of  the  binding  corporate  rules  by  any  member  concerned  not  established  in  the  Union;  the  controller  or the  processor  shall  be  exempt  from  that  liability,  in  whole  or  in  part,  only  if  it  proves  that  that  member  is  not responsible for  the event giving rise to the damage;\n(g) how  the  information  on  the  binding  corporate  rules,  in  particular  on  the  provisions  referred  to  in  points  (d),  (e) and (f) of  this paragraph is provided to the data subjects in addition to Articles 13 and 14;\n(h)   the  tasks  of  any  data  protection  officer  designated  in  accordance  with  Article  37  or  any  other  person  or  entity  in charge  of  the  monitoring  compliance  with  the  binding  corporate  rules  within  the  group  of  undertakings,  or  group of enterprises engaged in a joint economic activity, as well as monitoring training and complaint-handling;\n(i) the complaint procedures;\n(j) the  mechanisms  within  the  group  of  undertakings,  or  group  of  enterprises  engaged  in  a  joint  economic  activity  for ensuring  the  verification  of  compliance  with  the  binding  corporate  rules.  Such  mechanisms  shall  include  data protection  audits  and  methods  for  ensuring  corrective  actions  to  protect  the  rights  of  the  data  subject.  Results  of such  verification  should  be  communicated  to  the  person  or  entity  referred  to  in  point  (h)  and  to  the  board  of  the controlling  undertaking  of  a  group  of  undertakings,  or  of  the  group  of  enterprises  engaged  in  a  joint  economic activity, and should be available upon request to the competent supervisory authority;\n(k) the  mechanisms  for  reporting  and  recording  changes  to  the  rules  and  reporting  those  changes  to  the  supervisory authority;\n(l) the  cooperation  mechanism  with  the  supervisory  authority  to  ensure  compliance  by  any  member  of  the  group  of undertakings,  or  group  of  enterprises  engaged  in  a  joint  economic  activity,  in  particular  by  making  available  to  the supervisory authority the results of verifications of the measures referred to in point (j);\n(m)   the  mechanisms for  reporting to the competent supervisory authority any legal requirements to which a member of the group of undertakings, or group of enterprises engaged in a joint economic activity is subject in a third country which are likely to have a substantial adverse effect on the guarantees provided by the binding corporate rules; and\n(n)   the appropriate data protection training to personnel having permanent or regular access to personal data.\nEN\n[<Paragraph children=[<RawText children=('The  Commission  may  specify  the  format  and  procedures  for  the  '\n 'exchange  of  information  between  controllers, processors  and  '\n 'supervisory  authorities  for  binding  corporate  rules  within  the  '\n 'meaning  of  this  Article.  Those implementing acts shall be adopted in '\n 'accordance with the examination procedure set out in Article 93(2).')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_63",
    "chunk_content": "Transfers or disclosures not authorised by Union law\nAny  judgment  of  a  court  or  tribunal  and  any  decision  of  an  administrative  authority  of  a  third  country  requiring  a controller  or  processor  to  transfer  or  disclose  personal  data  may  only  be  recognised  or  enforceable  in  any  manner  if based  on  an  international  agreement,  such  as  a  mutual  legal  assistance  treaty,  in  force  between  the  requesting  third country and the Union or a Member State, without prejudice to other grounds for transfer pursuant to this Chapter."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_64",
    "chunk_content": "Derogations for specific situations\n[<Paragraph children=[<RawText children=('In  the  absence  of  an  adequacy  decision  pursuant  to  Article  45(3),  '\n 'or  of  appropriate  safeguards  pursuant  to Article 46, including binding '\n 'corporate rules, a transfer or a set of  transfers of personal data to a '\n 'third country or an in\\xad ternational organisation shall take place only on '\n 'one of the following conditions:')>]>]\n(a)   the  data  subject  has  explicitly consented to the proposed transfer, after having been informed of  the possible risks  of such transfers for  the data subject due to the absence of an adequacy decision and appropriate safeguards;\n(b)   the  transfer  is  necessary  for  the  performance  of  a  contract  between  the  data  subject  and  the  controller  or  the implementation of pre-contractual measures taken at the data subject's request;\n(c)   the  transfer  is  necessary for  the conclusion or  performance of a contract concluded in the interest of  the data subject between the controller and another natural or legal person;\n(d)   the  transfer  is  necessary for  important reasons of public interest;\n(e)   the  transfer  is  necessary for  the establishment, exercise or defence of  legal claims;\n(f)   the  transfer  is  necessary  in  order  to  protect  the  vital  interests  of  the  data  subject  or  of other  persons,  where  the  data subject is physically or legally incapable of giving consent;\n(g)   the  transfer  is  made  from  a  register  which  according  to  Union  or  Member  State  law  is  intended  to  provide information  to  the  public  and  which  is  open  to  consultation  either  by  the  public  in  general  or  by  any  person  who can  demonstrate  a  legitimate  interest,  but  only  to  the  extent  that  the  conditions  laid  down  by  Union  or Member State law for consultation are fulfilled in the particular case.\nWhere a transfer  could  not  be  based  on  a  provision  in  Article  45  or  46,  including  the  provisions  on  binding  corporate rules,  and  none  of  the  derogations  for  a  specific  situation  referred  to  in  the  first  subparagraph  of  this  paragraph  is applicable,  a  transfer  to  a  third  country  or  an  international  organisation  may  take  place  only  if  the  transfer  is  not repetitive,  concerns  only  a  limited  number  of  data  subjects,  is  necessary  for  the  purposes  of  compelling  legitimate interests  pursued  by  the  controller  which  are  not  overridden  by  the  interests  or  rights  and  freedoms  of  the  data  subject, and  the  controller  has  assessed  all  the  circumstances  surrounding  the  data  transfer  and  has  on  the  basis  of  that assessment  provided  suitable  safeguards  with  regard  to  the  protection  of  personal  data.  The  controller  shall  inform  the supervisory  authority  of  the  transfer.  The  controller  shall,  in  addition  to  providing  the  information  referred  to  in Articles 13 and 14, inform the data subject of the transfer and on the compelling legitimate interests pursued.\n[<Paragraph children=[<RawText children=('A  transfer  pursuant  to  point  (g)  of  the  first  subparagraph  of  '\n 'paragraph  1  shall  not  involve  the  entirety  of  the personal  data  '\n 'or  entire  categories  of  the  personal  data  contained  in  the  '\n 'register.  Where  the  register  is  intended  for consultation by persons '\n 'having a legitimate interest, the transfer shall be made only at the request '\n 'of  those persons or  if they are to be the recipients.')>]>]\nEN\n[<Paragraph children=[<RawText children=('Points (a), (b) and (c) of  the first  subparagraph of paragraph 1 and the '\n 'second subparagraph thereof shall not apply to activities carried out by '\n 'public authorities in the exercise of  their public powers.')>]>]\n[<Paragraph children=[<RawText children=('The  public  interest  referred  to  in  point  (d)  of  the  first  '\n 'subparagraph  of  paragraph  1  shall  be  recognised  in  Union law or in '\n 'the law of the Member State to which the controller is subject.')>]>]\n[<Paragraph children=[<RawText children=('In  the  absence  of  an  adequacy  decision,  Union  or  Member  State  '\n 'law  may,  for  important  reasons  of  public  interest, expressly  set  '\n 'limits  to  the  transfer  of  specific  categories  of  personal  data  to  '\n 'a  third  country  or  an  international organisation. Member States shall '\n 'notify such provisions to the Commission.')>]>]\n[<Paragraph children=[<RawText children=('The  controller  or  processor  shall  document  the  assessment  as  well  '\n 'as  the  suitable  safeguards  referred  to  in  the second subparagraph of '\n 'paragraph 1 of this Article in the records referred to in Article 30.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_65",
    "chunk_content": "International cooperation for the protection of personal data\nIn  relation  to  third  countries  and  international  organisations,  the  Commission  and  supervisory  authorities  shall  take appropriate steps to:\n(a)   develop  international  cooperation  mechanisms  to facilitate the  effective  enforcement of  legislation  for  the  protection of personal data;\n(b)   provide  international  mutual  assistance  in  the  enforcement  of  legislation  for  the  protection  of  personal  data, including  through  notification,  complaint  referral,  investigative  assistance  and  information  exchange,  subject  to appropriate safeguards for  the protection of personal data and other fundamental rights and freedoms;\n(c)   engage  relevant  stakeholders  in  discussion  and  activities  aimed  at  furthering  international  cooperation  in  the enforcement of  legislation for  the protection of personal data;\n(d) promote the exchange and documentation of personal data protection legislation and practice, including on jurisdic­ tional conflicts with third countries."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_66",
    "chunk_content": "Independent supervisory authorities\nSection 1"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_67",
    "chunk_content": "Independent status\nArticle 51"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_68",
    "chunk_content": "Supervisory authority\n[<Paragraph children=[<RawText children=('Each Member State shall provide for one or  more independent  public '\n 'authorities  to be  responsible  for  monitoring the application of this '\n 'Regulation, in order  to protect the fundamental rights and freedoms of '\n 'natural persons in relation to processing and to facilitate the free flow of '\n \"personal data within the Union ('supervisory authority').\")>]>]\n[<Paragraph children=[<RawText children=('Each supervisory  authority  shall  contribute  to  the  consistent  '\n 'application  of  this  Regulation  throughout  the  Union. For  that  '\n 'purpose,  the  supervisory  authorities  shall  cooperate  with  each  '\n 'other  and  the  Commission  in  accordance  with Chapter VII.')>]>]\n[<Paragraph children=[<RawText children=('Where  more  than  one  supervisory  authority  is  established  in  a  '\n 'Member  State,  that  Member  State  shall  designate the supervisory '\n 'authority which is to represent those authorities in the Board and shall set '\n 'out the mechanism to ensure compliance by the other authorities with the '\n 'rules relating to the consistency mechanism referred to in Article 63.')>]>]\n[<Paragraph children=[<RawText children=('Each  Member  State  shall  notify  to  the  Commission  the  provisions  '\n 'of  its  law  which  it  adopts  pursuant  to  this Chapter, by 25 May 2018 '\n 'and, without delay, any subsequent amendment affecting them.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_69",
    "chunk_content": "Independence\n[<Paragraph children=[<RawText children=('Each supervisory  authority  shall  act  with  complete  independence  in  '\n 'performing  its  tasks  and  exercising  its  powers in accordance with this '\n 'Regulation.')>]>]\n[<Paragraph children=[<RawText children=('The  member  or  members  of  each  supervisory  authority  shall,  in  the  '\n 'performance  of  their  tasks  and  exercise  of their  powers  in  '\n 'accordance  with  this  Regulation,  remain  free  from  external  '\n 'influence,  whether  direct  or  indirect,  and shall neither seek nor  take '\n 'instructions from anybody.')>]>]\n[<Paragraph children=[<RawText children=('Member  or  members  of  each  supervisory  authority  shall  refrain  from  '\n 'any  action  incompatible  with  their  duties and shall not, during their  '\n 'term of office, engage in any incompatible occupation, whether gainful or '\n 'not.')>]>]\n[<Paragraph children=[<RawText children=('Each  Member  State  shall  ensure  that  each  supervisory  authority  is  '\n 'provided  with  the  human,  technical  and financial  resources,  premises  '\n 'and  infrastructure  necessary  for  the  effective  performance  of  its  '\n 'tasks  and  exercise  of  its powers,  including  those  to  be  carried  '\n 'out  in  the  context  of  mutual  assistance,  cooperation  and  '\n 'participation  in  the Board.')>]>]\n[<Paragraph children=[<RawText children=('Each  Member  State  shall  ensure  that  each  supervisory  authority  '\n 'chooses  and  has  its  own  staff  which  shall  be subject to the '\n 'exclusive direction of the member or members of the supervisory authority '\n 'concerned.')>]>]\n[<Paragraph children=[<RawText children=('Each  Member  State  shall  ensure  that  each  supervisory  authority  is  '\n 'subject  to  financial  control  which  does  not affect its independence '\n 'and that it has separate, public annual budgets, which may be part of the '\n 'overall state or national budget.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_70",
    "chunk_content": "General conditions for the members of the supervisory authority\n[<Paragraph children=[<RawText children=('Member  States  shall  provide  for  each  member  of  their  supervisory  '\n 'authorities  to  be  appointed  by  means  of  a transparent procedure by:')>]>]\n[<Paragraph children=[<RawText children='their parliament;'>]>]\n[<Paragraph children=[<RawText children='their government;'>]>]\n[<Paragraph children=[<RawText children='their head of State; or'>]>]\n[<Paragraph children=[<RawText children='an independent body entrusted with the appointment under Member State law.'>]>]\n[<Paragraph children=[<RawText children=('Each  member  shall  have  the  qualifications,  experience  and  skills,  '\n 'in  particular  in  the  area  of  the  protection  of personal data, '\n 'required to perform its duties and exercise its powers.')>]>]\n[<Paragraph children=[<RawText children=('The  duties  of  a  member  shall  end  in  the  event  of  the  expiry  of  '\n 'the  term  of  office,  resignation  or  compulsory retirement, in '\n 'accordance with the law of the Member State concerned.')>]>]\n[<Paragraph children=[<RawText children=('A member shall be dismissed only in cases of serious misconduct or if the '\n 'member no longer fulfils the conditions required for  the performance of the '\n 'duties.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_71",
    "chunk_content": "Rules on the establishment of the supervisory authority\n[<Paragraph children=[<RawText children='Each Member State shall provide by law for all of the following:'>]>]\n(a)   the  establishment of each supervisory authority;\nEN\nEN\n(b)   the  qualifications and eligibility conditions required to be appointed as member of each supervisory authority;\n(c)   the  rules  and procedures for  the appointment of the member or members of each supervisory authority;\n(d)   the  duration of  the term  of  the  member or  members of each supervisory authority of no less than four  years, except for  the  first  appointment  after  24  May  2016,  part  of  which  may  take  place  for  a  shorter  period  where  that  is necessary to protect the independence of the supervisory authority by means of a staggered appointment procedure;\n(e)   whether  and,  if  so,  for  how  many  terms  the  member  or  members  of  each  supervisory  authority  is  eligible  for reappointment;\n(f)   the  conditions  governing  the  obligations  of  the  member  or  members  and  staff  of  each  supervisory  authority, prohibitions  on  actions,  occupations  and  benefits  incompatible  therewith  during  and  after  the  term  of  office  and rules governing the cessation of employment.\n[<Paragraph children=[<RawText children=('The  member  or  members  and  the  staff  of  each  supervisory  authority  '\n 'shall,  in  accordance  with  Union  or  Member State  law,  be  subject  '\n 'to  a  duty  of  professional  secrecy  both  during  and  after  their  '\n 'term  of  office,  with  regard  to  any confidential  information which  '\n 'has  come  to their  knowledge in  the  course  of  the  performance  of  '\n 'their  tasks  or  exercise of  their  powers.  During  their  term  of  '\n 'office,  that  duty  of  professional  secrecy  shall  in  particular  '\n 'apply  to  reporting  by natural persons of infringements of this '\n 'Regulation.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_72",
    "chunk_content": "Competence\n[<Paragraph children=[<RawText children=('Each supervisory authority shall be competent for  the performance of  the '\n 'tasks  assigned to and the exercise of  the powers conferred on it in '\n 'accordance with this Regulation on the territory of its own Member State.')>]>]\n[<Paragraph children=[<RawText children=('Where  processing  is  carried  out  by  public  authorities  or  private  '\n 'bodies  acting  on  the  basis  of  point  (c)  or  (e)  of Article  6(1),  '\n 'the  supervisory  authority of  the  Member  State  concerned  shall  be  '\n 'competent.  In  such cases  Article  56  does not apply.')>]>]\n[<Paragraph children=[<RawText children=('Supervisory authorities  shall  not  be  competent  to supervise  '\n 'processing  operations  of  courts  acting  in  their  judicial capacity.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_73",
    "chunk_content": "Competence of the lead supervisory authority\n[<Paragraph children=[<RawText children=('Without prejudice to Article 55, the supervisory authority of the main '\n 'establishment or of the single establishment of  the  controller  or  '\n 'processor  shall  be  competent  to  act  as  lead  supervisory  authority  '\n 'for  the  cross-border  processing carried out by that controller or '\n 'processor in accordance with the procedure provided in Article 60.')>]>]\n[<Paragraph children=[<RawText children=('By derogation from paragraph 1, each supervisory authority shall be '\n 'competent to handle a complaint lodged with it  or  a  possible  '\n 'infringement of  this Regulation, if  the subject matter  relates only to an '\n 'establishment in its Member State or substantially affects data subjects '\n 'only in its Member State.')>]>]\n[<Paragraph children=[<RawText children=('In  the  cases  referred  to  in  paragraph  2  of  this  Article,  the  '\n 'supervisory  authority  shall  inform  the  lead  supervisory authority  '\n 'without  delay  on  that  matter.  Within  a  period  of  three  weeks  '\n 'after  being  informed  the  lead  supervisory authority  shall  decide  '\n 'whether  or  not  it  will  handle  the  case  in  accordance  with  the  '\n 'procedure  provided  in  Article  60, taking  into  account  whether  or  '\n 'not  there  is  an  establishment  of  the  controller  or  processor  in  '\n 'the  Member  State  of which the supervisory authority informed it.')>]>]\nEN\n[<Paragraph children=[<RawText children=('Where the lead supervisory authority decides  to handle  the case,  the  '\n 'procedure  provided  in  Article  60  shall  apply. The supervisory '\n 'authority which informed the lead supervisory authority may submit to the '\n 'lead supervisory authority a draft  for  a  decision.  The  lead  '\n 'supervisory  authority  shall  take  utmost  account  of  that  draft  when  '\n 'preparing  the  draft decision referred to in Article 60(3).')>]>]\n[<Paragraph children=[<RawText children=('Where the lead supervisory authority decides not to handle the case, the '\n 'supervisory authority which informed the lead supervisory authority shall '\n 'handle it according to Articles 61 and 62.')>]>]\n[<Paragraph children=[<RawText children=('The  lead  supervisory  authority  shall  be  the  sole  interlocutor  of  '\n 'the  controller  or  processor  for  the  cross-border processing carried '\n 'out by that controller or processor.')>]>]\nArticle 57"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_74",
    "chunk_content": "Tasks\n[<Paragraph children=[<RawText children=('Without prejudice to other tasks set out under  this Regulation, each '\n 'supervisory authority shall on its territory:')>]>]\n(a) monitor and enforce the application of this Regulation;\n(b)   promote  public  awareness  and  understanding  of  the  risks,  rules,  safeguards  and  rights  in  relation  to  processing. Activities addressed specifically to children shall receive specific attention;\n(c) advise,  in  accordance  with  Member  State  law,  the  national  parliament,  the  government,  and  other  institutions  and bodies  on  legislative  and  administrative  measures  relating  to  the  protection  of  natural  persons'  rights  and  freedoms with regard to processing;\n(d)   promote the awareness of controllers and processors of their obligations under this Regulation;\n(e) upon request,  provide  information  to  any  data  subject  concerning  the  exercise  of  their  rights  under  this  Regulation and, if appropriate, cooperate with the supervisory authorities in other Member States to that end;\n(f) handle complaints lodged by a data subject, or by a body, organisation or association in accordance with Article 80, and  investigate,  to  the  extent  appropriate,  the  subject  matter  of  the  complaint  and  inform  the  complainant  of  the progress  and  the  outcome  of  the  investigation  within  a  reasonable  period,  in  particular  if  further  investigation  or coordination with another supervisory authority is necessary;\n(g) cooperate  with,  including  sharing  information  and  provide  mutual  assistance  to,  other  supervisory  authorities  with a view to ensuring the consistency of application and enforcement of this Regulation;\n(h)   conduct  investigations  on  the  application  of  this  Regulation,  including  on  the  basis  of  information  received  from another supervisory authority or other public authority;\n(i) monitor relevant developments, insofar as they have an impact on the protection of personal data, in particular  the development of information and communication technologies and commercial practices;\n(j) adopt standard contractual clauses referred to in Article 28(8) and in point (d) of Article 46(2);\n(k) establish  and  maintain  a  list  in  relation  to  the  requirement  for  data  protection  impact  assessment  pursuant  to Article 35(4);\n(l) give advice on the processing operations referred to in Article 36(2);\n(m)   encourage the  drawing  up  of  codes  of  conduct  pursuant  to Article  40(1)  and  provide  an  opinion  and  approve  such codes of conduct which provide sufficient safeguards, pursuant to Article 40(5);\n(n)   encourage  the  establishment  of  data  protection  certification  mechanisms  and  of  data  protection  seals  and  marks pursuant to Article 42(1), and approve the criteria of certification pursuant to Article 42(5);\n(o)   where applicable, carry out a periodic review of certifications issued in accordance with Article 42(7);\nImage\n(p)   draft  and  publish  the  criteria  for  accreditation  of  a  body  for  monitoring  codes  of  conduct  pursuant  to  Article  41 and of a certification body pursuant to Article 43;\n(q)   conduct  the  accreditation  of  a  body  for  monitoring  codes  of  conduct  pursuant  to  Article  41  and  of  a  certification body pursuant to Article 43;\n(r) authorise contractual clauses and provisions referred to in Article 46(3);\n(s) approve binding corporate rules pursuant to Article 47;\n(t) contribute to the activities of  the Board;\n(u)   keep  internal  records  of  infringements  of  this  Regulation  and  of  measures  taken  in  accordance  with  Article  58(2); and\n(v) fulfil  any other  tasks  related to the protection of personal data.\n[<Paragraph children=[<RawText children=('Each  supervisory  authority  shall  facilitate  the  submission  of  '\n 'complaints  referred  to  in  point  (f)  of  paragraph  1  by measures  '\n 'such  as  a  complaint  submission  form  which  can  also  be  completed  '\n 'electronically,  without  excluding  other means of communication.')>]>]\n[<Paragraph children=[<RawText children=('The performance of  the tasks  of each supervisory authority  shall be  '\n 'free  of  charge for  the  data  subject  and,  where applicable, for  the '\n 'data protection officer.')>]>]\n[<Paragraph children=[<RawText children=('Where  requests  are  manifestly  unfounded  or  excessive,  in  particular  '\n 'because  of  their  repetitive  character,  the supervisory  authority  may  '\n 'charge  a  reasonable  fee  based  on  administrative  costs,  or  refuse  '\n 'to  act  on  the  request.  The supervisory  authority  shall  bear  the  '\n 'burden  of  demonstrating  the  manifestly  unfounded  or  excessive  '\n 'character  of  the request.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_75",
    "chunk_content": "Powers\n[<Paragraph children=[<RawText children=('Each supervisory authority shall have all of the following investigative '\n 'powers:')>]>]\n(a)   to  order  the  controller  and  the  processor,  and,  where  applicable,  the  controller's  or  the  processor's  representative  to provide any information it requires for  the performance of its tasks;\n(b)   to carry out investigations in the form of data protection audits;\n(c)   to carry out a review on certifications issued pursuant to Article 42(7);\n(d)   to notify the controller or  the processor of an alleged infringement of this Regulation;\n(e)   to  obtain,  from  the  controller  and  the  processor,  access  to  all  personal  data  and  to  all  information  necessary  for  the performance of its tasks;\n(f)   to  obtain  access  to  any  premises  of  the  controller  and  the  processor,  including  to  any  data  processing  equipment and means, in accordance with Union or Member State procedural law.\n[<Paragraph children=[<RawText children='Each supervisory authority shall have all of the following corrective powers:'>]>]\n(a)   to  issue  warnings  to a controller or  processor  that intended processing operations are likely to infringe provisions of this Regulation;\n(b)   to  issue  reprimands  to  a  controller  or  a  processor  where  processing  operations  have  infringed  provisions  of  this Regulation;\n(c)   to  order  the  controller  or  the  processor  to  comply  with  the  data  subject's  requests  to  exercise  his  or  her  rights pursuant to this Regulation;\nEN\n(d)   to  order  the  controller  or  processor  to  bring  processing  operations  into  compliance  with  the  provisions  of  this Regulation, where appropriate, in a specified manner and within a specified period;\n(e)   to order  the controller  to communicate a personal data breach to the data subject;\n(f)   to impose a temporary or definitive limitation including a ban on processing;\n(g)   to  order  the  rectification  or  erasure  of  personal  data  or  restriction  of  processing  pursuant  to  Articles  16,  17  and  18 and  the  notification  of  such  actions  to  recipients  to  whom  the  personal  data  have  been  disclosed  pursuant  to Article 17(2) and Article 19;\n(h)   to  withdraw  a  certification  or  to  order  the  certification  body  to  withdraw  a  certification  issued  pursuant  to Articles  42  and  43,  or  to  order  the  certification  body  not  to  issue  certification  if  the  requirements  for  the  certifi­ cation are not or are no longer met;\n(i) to  impose  an  administrative  fine  pursuant  to  Article  83,  in  addition  to,  or  instead  of  measures  referred  to  in  this paragraph, depending on the circumstances of each individual case;\n(j) to order  the suspension of data flows to a recipient in a third country or  to an international organisation.\n[<Paragraph children=[<RawText children=('Each supervisory authority shall have all of the following authorisation and '\n 'advisory powers:')>]>]\n(a)   to advise the controller  in accordance with the prior consultation procedure referred to in Article 36;\n(b)   to  issue,  on  its  own  initiative  or  on  request,  opinions  to  the  national  parliament,  the  Member  State  government  or, in  accordance  with  Member  State  law,  to  other  institutions  and  bodies  as  well  as  to  the  public  on  any  issue  related to the protection of personal data;\n(c)   to authorise processing referred to in Article 36(5), if  the law of  the Member State requires such prior authorisation;\n(d)   to issue an opinion and approve draft codes of conduct pursuant to Article 40(5);\n(e)   to accredit certification bodies pursuant to Article 43;\n(f)   to issue certifications and approve criteria of certification in accordance with Article 42(5);\n(g)   to adopt standard data protection clauses referred to in Article 28(8) and in point (d) of Article 46(2);\n(h)   to authorise contractual clauses referred to in point (a) of Article 46(3);\n(i) to authorise administrative arrangements referred to in point (b) of Article 46(3);\n(j) to approve binding corporate rules pursuant to Article 47.\n[<Paragraph children=[<RawText children=('The  exercise  of  the  powers  conferred  on  the  supervisory  authority  '\n 'pursuant  to  this  Article  shall  be  subject  to appropriate  '\n 'safeguards,  including  effective  judicial  remedy  and  due  process,  '\n 'set  out  in  Union  and  Member  State  law  in accordance with the '\n 'Charter.')>]>]\n[<Paragraph children=[<RawText children=('Each Member State shall provide by law that its supervisory authority shall '\n 'have the power  to bring infringements of  this  Regulation  to  the  '\n 'attention  of  the  judicial  authorities  and  where  appropriate,  to  '\n 'commence  or  engage  otherwise in legal proceedings, in order  to enforce '\n 'the provisions of this Regulation.')>]>]\n[<Paragraph children=[<RawText children=('Each  Member  State  may  provide  by  law  that  its  supervisory  '\n 'authority  shall  have  additional  powers  to  those referred  to  in  '\n 'paragraphs  1,  2  and  3.  The  exercise  of  those  powers  shall  not  '\n 'impair  the  effective  operation  of Chapter VII.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_76",
    "chunk_content": "Activity reports\nEach  supervisory  authority  shall  draw  up  an  annual  report  on  its  activities,  which  may  include  a  list  of  types  of infringement  notified  and  types  of  measures  taken  in  accordance  with  Article  58(2).  Those  reports  shall  be  transmitted to the national parliament, the government and other authorities as designated by Member State law. They shall be made available to the public, to the Commission and to the Board.\nEN"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_77",
    "chunk_content": "Cooperation and consistency\nSection 1"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_78",
    "chunk_content": "Cooperation\nArticle 60"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_79",
    "chunk_content": "Cooperation  between  the  lead  supervisory  authority  and  the  other  supervisory  authorities concerned\n[<Paragraph children=[<RawText children=('The  lead  supervisory  authority  shall  cooperate  with  the  other  '\n 'supervisory  authorities  concerned  in  accordance with  this  Article  in  '\n 'an  endeavour  to  reach  consensus.  The  lead  supervisory  authority  '\n 'and  the  supervisory  authorities concerned shall exchange all relevant '\n 'information with each other.')>]>]\n[<Paragraph children=[<RawText children=('The lead supervisory authority may request at any time other supervisory '\n 'authorities concerned to provide mutual assistance pursuant to Article 61 '\n 'and may conduct joint operations pursuant to Article 62, in particular for '\n 'carrying out investigations  or  for  monitoring  the  implementation  of  '\n 'a  measure  concerning  a  controller  or  processor  established  in '\n 'another Member State.')>]>]\n[<Paragraph children=[<RawText children=('The  lead  supervisory  authority  shall,  without  delay,  communicate  '\n 'the  relevant  information  on  the  matter  to  the other  supervisory  '\n 'authorities  concerned.  It  shall  without  delay  submit  a  draft  '\n 'decision  to  the  other  supervisory authorities concerned for their '\n 'opinion and take due account of their views.')>]>]\n[<Paragraph children=[<RawText children=('Where  any  of  the  other  supervisory  authorities  concerned  within  a  '\n 'period  of  four  weeks  after  having  been consulted  in  accordance  '\n 'with  paragraph  3  of  this  Article,  expresses  a  relevant  and  '\n 'reasoned  objection  to  the  draft decision,  the  lead  supervisory  '\n 'authority  shall,  if  it  does  not  follow  the  relevant  and  reasoned  '\n 'objection  or  is  of  the opinion  that  the  objection  is  not  relevant  '\n 'or  reasoned,  submit  the  matter  to  the  consistency  mechanism  '\n 'referred  to  in Article 63.')>]>]\n[<Paragraph children=[<RawText children=('Where  the  lead  supervisory  authority  intends  to  follow  the  '\n 'relevant  and  reasoned  objection  made,  it  shall  submit to the other '\n 'supervisory authorities concerned a revised draft decision for  their '\n 'opinion. That revised draft decision shall be subject to the procedure '\n 'referred to in paragraph 4 within a period of two weeks.')>]>]\n[<Paragraph children=[<RawText children=('Where  none  of  the  other  supervisory  authorities  concerned  has  '\n 'objected  to  the  draft  decision  submitted  by  the lead  supervisory  '\n 'authority  within  the  period  referred  to  in  paragraphs  4  and  5,  '\n 'the  lead  supervisory  authority  and  the supervisory authorities '\n 'concerned shall be deemed to be in agreement with that draft decision and '\n 'shall be bound by it.')>]>]\n[<Paragraph children=[<RawText children=('The  lead  supervisory  authority  shall  adopt  and  notify  the  decision  '\n 'to  the  main  establishment  or  single establishment of  the controller '\n 'or  processor, as  the case  may  be  and inform the  other  supervisory  '\n 'authorities concerned and  the  Board  of  the  decision  in  question,  '\n 'including  a  summary  of  the  relevant  facts  and  grounds.  The  '\n 'supervisory authority with which a complaint has been lodged shall inform '\n 'the complainant on the decision.')>]>]\n[<Paragraph children=[<RawText children=('By derogation from paragraph 7, where a complaint is dismissed or  rejected, '\n 'the supervisory authority with which the  complaint  was  lodged  shall  '\n 'adopt  the  decision  and  notify  it  to  the  complainant  and  shall  '\n 'inform  the  controller thereof.')>]>]\n[<Paragraph children=[<RawText children=('Where the lead supervisory authority and the supervisory authorities '\n 'concerned agree to dismiss or  reject parts of a  complaint  and  to  act  '\n 'on  other  parts  of  that  complaint,  a  separate  decision  shall  be  '\n 'adopted  for  each  of  those  parts  of the  matter.  The  lead  '\n 'supervisory  authority  shall  adopt  the  decision  for  the  part  '\n 'concerning  actions  in  relation  to  the controller, shall notify it to '\n 'the main establishment or single establishment of the controller or '\n 'processor on the territory of  its  Member  State  and  shall  inform  the  '\n 'complainant  thereof,  while  the  supervisory  authority  of  the  '\n 'complainant  shall adopt  the  decision  for  the  part  concerning  '\n 'dismissal  or  rejection  of  that  complaint,  and  shall  notify  it  to  '\n 'that complainant and shall inform the controller or processor thereof.')>]>]\n[<Paragraph children=[<RawText children=('After  being  notified  of  the  decision  of  the  lead  supervisory  '\n 'authority  pursuant  to  paragraphs  7  and  9,  the controller  or  '\n 'processor  shall  take  the  necessary  measures  to  ensure  compliance  '\n 'with  the  decision  as  regards  processing activities  in  the  context  '\n 'of  all  its  establishments  in  the  Union.  The  controller  or  '\n 'processor  shall  notify  the  measures taken  for  complying  with  the  '\n 'decision  to  the  lead  supervisory  authority,  which  shall  inform  the  '\n 'other  supervisory authorities concerned.')>]>]\nEN\n[<Paragraph children=[<RawText children=('Where,  in  exceptional  circumstances,  a  supervisory  authority  '\n 'concerned  has  reasons  to  consider  that  there  is  an urgent need to '\n 'act in order  to protect the interests of data subjects, the urgency '\n 'procedure referred to in Article 66 shall apply.')>]>]\n[<Paragraph children=[<RawText children=('The  lead  supervisory  authority  and  the  other  supervisory  '\n 'authorities  concerned  shall  supply  the  information required under this '\n 'Article to each other by electronic means, using a standardised format.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_80",
    "chunk_content": "Mutual assistance\n[<Paragraph children=[<RawText children=('Supervisory  authorities  shall  provide  each  other  with  relevant  '\n 'information  and  mutual  assistance  in  order  to implement  and  apply  '\n 'this  Regulation  in  a  consistent  manner,  and  shall  put  in  place  '\n 'measures  for  effective  cooperation with  one  another.  Mutual  '\n 'assistance  shall  cover,  in  particular,  information  requests  and  '\n 'supervisory  measures,  such  as requests to carry out prior authorisations '\n 'and consultations, inspections and investigations.')>]>]\n[<Paragraph children=[<RawText children=('Each supervisory authority shall take all appropriate measures required to '\n 'reply to a request of another supervisory authority  without  undue  delay  '\n 'and  no  later  than  one  month  after  receiving  the  request.  Such  '\n 'measures  may  include,  in particular, the transmission of relevant '\n 'information on the conduct of an investigation.')>]>]\n[<Paragraph children=[<RawText children=('Requests  for  assistance  shall  contain  all  the  necessary  '\n 'information,  including  the  purpose  of  and  reasons  for  the request. '\n 'Information exchanged shall be used only for the purpose for  which it was '\n 'requested.')>]>]\n[<Paragraph children=[<RawText children=('The requested supervisory authority shall not refuse to comply with the '\n 'request unless:')>]>]\n(a)   it  is  not  competent for  the subject-matter of  the request or  for  the measures it is requested to execute; or\n(b)   compliance  with the  request  would infringe this Regulation or Union or Member State law to which the supervisory authority receiving the request is subject.\n[<Paragraph children=[<RawText children=('The requested supervisory authority  shall inform the requesting  '\n 'supervisory authority of  the  results  or,  as  the  case may  be,  of  '\n 'the  progress  of  the  measures  taken  in  order  to  respond  to  the  '\n 'request.  The  requested  supervisory  authority shall provide reasons for '\n 'any refusal to comply with a request pursuant to paragraph 4.')>]>]\n[<Paragraph children=[<RawText children=('Requested  supervisory  authorities  shall,  as  a  rule,  supply  the  '\n 'information  requested  by  other  supervisory authorities by electronic '\n 'means, using a standardised format.')>]>]\n[<Paragraph children=[<RawText children=('Requested  supervisory  authorities  shall  not  charge  a  fee  for  any  '\n 'action  taken  by  them  pursuant  to  a  request  for mutual  assistance.  '\n 'Supervisory  authorities  may  agree  on  rules  to  indemnify  each  other  '\n 'for  specific  expenditure  arising from the provision of mutual assistance '\n 'in exceptional circumstances.')>]>]\n[<Paragraph children=[<RawText children=('Where a  supervisory  authority  does  not  provide  the  information  '\n 'referred  to  in  paragraph  5  of  this  Article  within one  month  of  '\n 'receiving  the  request  of  another  supervisory  authority,  the  '\n 'requesting  supervisory  authority  may  adopt  a provisional  measure  on  '\n 'the  territory of  its  Member  State  in  accordance  with  Article  '\n '55(1).  In  that  case,  the  urgent  need to  act  under  Article  66(1)  '\n 'shall  be  presumed  to  be  met  and  require  an  urgent  binding  '\n 'decision  from  the  Board  pursuant to Article 66(2).')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  may,  by  means  of  implementing  acts,  specify  the  '\n 'format  and  procedures  for  mutual  assistance referred  to  in  this  '\n 'Article  and  the  arrangements  for  the  exchange  of  information  by  '\n 'electronic  means  between supervisory  authorities,  and  between  '\n 'supervisory  authorities  and  the  Board,  in  particular  the  '\n 'standardised  format referred to in paragraph 6 of  this Article. Those '\n 'implementing acts shall be adopted in accordance with the examination '\n 'procedure referred to in Article 93(2).')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_81",
    "chunk_content": "Joint operations of supervisory authorities\n[<Paragraph children=[<RawText children=('The  supervisory  authorities  shall,  where  appropriate,  conduct  joint  '\n 'operations  including  joint  investigations  and joint  enforcement  '\n 'measures  in  which  members  or  staff  of  the  supervisory  authorities  '\n 'of  other  Member  States  are involved.')>]>]\nEN\n[<Paragraph children=[<RawText children=('Where  the  controller  or  processor  has  establishments  in  several  '\n 'Member  States  or  where  a  significant  number  of data  subjects  in  '\n 'more  than  one  Member  State  are  likely  to  be  substantially  '\n 'affected  by  processing  operations,  a supervisory  authority  of  each  '\n 'of  those  Member  States  shall  have  the  right  to  participate  in  '\n 'joint  operations.  The supervisory  authority  which  is  competent  '\n 'pursuant  to  Article  56(1)  or  (4)  shall  invite  the  supervisory  '\n 'authority  of  each of  those  Member  States  to  take  part  in  the  '\n 'joint  operations  and  shall  respond  without  delay  to  the  request  '\n 'of  a supervisory authority to participate.')>]>]\n[<Paragraph children=[<RawText children=('A  supervisory  authority  may,  in  accordance  with  Member  State  law,  '\n \"and  with  the  seconding  supervisory authority's  authorisation,  confer  \"\n 'powers,  including  investigative  powers  on  the  seconding  supervisory  '\n \"authority's members  or  staff  involved  in  joint  operations  or,  in  \"\n 'so  far  as  the  law  of  the  Member  State  of  the  host  supervisory '\n \"authority  permits,  allow  the  seconding  supervisory  authority's  \"\n 'members  or  staff  to  exercise  their  investigative  powers  in '\n 'accordance with the law of  the  Member State  of  the  seconding  '\n 'supervisory  authority.  Such investigative  powers  may  be exercised  '\n 'only  under  the  guidance  and  in  the  presence  of  members  or  staff  '\n 'of  the  host  supervisory  authority.  The seconding  supervisory  '\n \"authority's  members  or  staff  shall  be  subject  to  the  Member  State  \"\n 'law  of  the  host  supervisory authority.')>]>]\n[<Paragraph children=[<RawText children=('Where,  in  accordance  with  paragraph  1,  staff  of  a  seconding  '\n 'supervisory  authority  operate  in  another  Member State,  the  Member '\n 'State of  the host supervisory authority shall assume responsibility for  '\n 'their actions, including liability, for  any  damage  caused  by  them  '\n 'during  their  operations,  in  accordance  with  the  law  of  the  Member  '\n 'State  in  whose territory they are operating.')>]>]\n[<Paragraph children=[<RawText children=('The  Member  State  in  whose  territory  the  damage  was  caused  shall  '\n 'make  good  such  damage  under  the  conditions applicable  to  damage '\n 'caused  by its  own  staff.  The  Member  State  of  the  seconding  '\n 'supervisory  authority  whose  staff  has caused  damage  to  any  person  '\n 'in  the  territory  of  another  Member  State  shall  reimburse  that  '\n 'other  Member  State  in  full any sums it has paid to the persons entitled '\n 'on their behalf.')>]>]\n[<Paragraph children=[<RawText children=('Without  prejudice  to  the  exercise  of  its  rights vis-à-vis third  '\n 'parties  and  with  the  exception  of  paragraph  5,  each Member  State  '\n 'shall  refrain,  in  the  case  provided  for  in  paragraph  1,  from  '\n 'requesting  reimbursement  from  another Member State in relation to damage '\n 'referred to in paragraph 4.')>]>]\n[<Paragraph children=[<RawText children=('Where  a  joint  operation  is  intended  and  a  supervisory  authority  '\n 'does  not,  within  one  month,  comply  with  the obligation  laid  down  '\n 'in  the  second  sentence  of  paragraph  2  of  this  Article,  the  other  '\n 'supervisory  authorities  may  adopt a  provisional  measure  on  the  '\n 'territory  of  its  Member  State  in  accordance  with  Article  55.  In  '\n 'that  case,  the  urgent  need to  act  under  Article  66(1)  shall  be  '\n 'presumed  to  be  met  and  require  an  opinion  or  an  urgent  binding  '\n 'decision  from  the Board pursuant to Article 66(2).')>]>]\nSection 2"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_82",
    "chunk_content": "Consistency mechanism\nIn  order  to contribute to the  consistent  application of  this Regulation throughout the Union, the supervisory authorities shall  cooperate  with  each  other  and,  where  relevant,  with  the  Commission,  through  the  consistency  mechanism  as  set out in this Section."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_83",
    "chunk_content": "Opinion of the Board\n[<Paragraph children=[<RawText children=('The  Board  shall  issue  an  opinion  where  a  competent  supervisory  '\n 'authority  intends  to  adopt  any  of  the  measures below. To that end, '\n 'the competent supervisory authority shall communicate the draft decision to '\n 'the Board, when it:')>]>]\n(a)   aims  to  adopt  a  list  of  the  processing  operations  subject  to  the  requirement  for  a  data  protection  impact  assessment pursuant to Article 35(4);\n(b)   concerns  a  matter  pursuant  to  Article  40(7)  whether  a  draft  code  of  conduct  or  an  amendment  or  extension  to  a code of conduct complies with this Regulation;\nImage\n(c)   aims  to  approve  the  criteria  for  accreditation  of  a  body  pursuant  to Article  41(3)  or  a  certification  body  pursuant  to Article 43(3);\n(d)   aims to determine standard data protection clauses referred to in point (d) of Article 46(2) and in Article 28(8);\n(e)   aims to authorise contractual clauses referred to in point (a) of Article 46(3); or\n(f)   aims to approve binding corporate rules within the meaning of Article 47.\n[<Paragraph children=[<RawText children=('Any  supervisory  authority,  the  Chair  of  the  Board  or  the  '\n 'Commission  may  request  that  any  matter  of  general application or  '\n 'producing effects in  more  than  one Member State be examined by the Board '\n 'with a view to obtaining an opinion,  in  particular  where  a  competent  '\n 'supervisory  authority  does  not  comply  with  the  obligations  for  '\n 'mutual assistance in accordance with Article 61 or for joint operations in '\n 'accordance with Article 62.')>]>]\n[<Paragraph children=[<RawText children=('In  the  cases  referred  to  in  paragraphs  1  and  2,  the  Board  shall  '\n 'issue  an  opinion  on  the  matter  submitted  to  it provided that it has '\n 'not already issued an opinion on the same matter. That opinion shall be '\n 'adopted within eight weeks by  simple  majority  of  the  members  of  the  '\n 'Board.  That  period  may  be  extended  by  a  further  six  weeks,  '\n 'taking  into account  the  complexity  of  the  subject  matter.  Regarding  '\n 'the  draft  decision  referred  to  in  paragraph  1  circulated  to  the '\n 'members  of  the  Board  in  accordance  with  paragraph  5,  a  member  '\n 'which  has  not  objected  within  a  reasonable  period indicated by the '\n 'Chair, shall be deemed to be in agreement with the draft decision.')>]>]\n[<Paragraph children=[<RawText children=('Supervisory  authorities  and  the  Commission  shall,  without  undue  '\n 'delay,  communicate  by  electronic  means  to  the Board,  using  a  '\n 'standardised  format  any  relevant  information,  including  as  the  case  '\n 'may  be  a  summary  of  the  facts,  the draft  decision,  the  grounds  '\n 'which  make  the  enactment  of  such  measure  necessary,  and  the  views  '\n 'of  other  supervisory authorities concerned.')>]>]\n[<Paragraph children=[<RawText children='The Chair of the Board shall, without undue, delay inform by electronic means:'>]>]\n(a)   the  members  of  the  Board  and  the  Commission  of  any  relevant  information  which  has  been  communicated  to  it using  a  standardised  format.  The  secretariat  of  the  Board  shall,  where  necessary,  provide  translations  of  relevant information; and\n(b)   the  supervisory authority referred to, as the case may be, in paragraphs 1 and 2, and the Commission of the opinion and make it public.\n[<Paragraph children=[<RawText children=('The competent supervisory authority shall not adopt its draft decision '\n 'referred to in paragraph 1 within the period referred to in paragraph 3.')>]>]\n[<Paragraph children=[<RawText children=('The  supervisory  authority  referred  to  in  paragraph  1  shall  take  '\n 'utmost  account  of  the  opinion  of  the  Board  and shall,  within two '\n 'weeks after receiving the opinion, communicate to the Chair of the Board by '\n 'electronic means whether it  will  maintain or amend its draft decision and, '\n 'if any, the amended draft decision, using a standardised format.')>]>]\n[<Paragraph children=[<RawText children=('Where  the  supervisory  authority  concerned  informs  the  Chair  of  the  '\n 'Board  within  the  period  referred  to  in paragraph 7 of this Article '\n 'that it does not intend to follow the opinion of  the Board, in whole or  in '\n 'part, providing the relevant grounds, Article 65(1) shall apply.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_84",
    "chunk_content": "Dispute resolution by the Board\n[<Paragraph children=[<RawText children=('In  order  to  ensure  the  correct  and  consistent  application  of  this  '\n 'Regulation  in  individual  cases,  the  Board  shall adopt a binding '\n 'decision in the following cases:')>]>]\n(a)   where,  in  a  case  referred  to  in  Article  60(4),  a  supervisory  authority  concerned  has  raised  a  relevant  and  reasoned objection  to  a  draft  decision  of  the  lead  authority  or  the  lead  authority  has  rejected  such  an  objection  as  being  not relevant  or  reasoned.  The  binding  decision  shall  concern  all  the  matters  which  are  the  subject  of  the  relevant  and reasoned objection, in particular  whether  there is an infringement of this Regulation;\nEN\n(b)   where  there  are  conflicting  views  on  which  of  the  supervisory  authorities  concerned  is  competent  for  the  main establishment;\n(c)   where  a  competent  supervisory  authority  does  not  request  the  opinion  of  the  Board  in  the  cases  referred  to  in Article  64(1),  or  does  not  follow  the  opinion  of  the  Board  issued  under  Article  64.  In  that  case,  any  supervisory authority concerned or the Commission may communicate the matter to the Board.\n[<Paragraph children=[<RawText children=('The decision referred  to in paragraph  1 shall  be  adopted  within  one  '\n 'month  from  the  referral  of  the  subject-matter by a  two-thirds  '\n 'majority of  the  members  of  the  Board.  That  period  may  be  extended  '\n 'by a  further  month  on  account of the complexity of the subject-matter. '\n 'The decision referred to in paragraph 1 shall be reasoned and addressed to '\n 'the lead supervisory authority and all the supervisory authorities concerned '\n 'and binding on them.')>]>]\n[<Paragraph children=[<RawText children=('Where the Board has been unable to adopt a decision within the periods  '\n 'referred  to in paragraph 2,  it shall  adopt its  decision  within  two  '\n 'weeks  following  the  expiration  of  the  second  month  referred  to  in  '\n 'paragraph  2  by  a  simple majority of  the  members  of  the  Board.  '\n 'Where  the  members  of  the  Board  are  split,  the  decision  shall  by  '\n 'adopted  by  the vote of its Chair.')>]>]\n[<Paragraph children=[<RawText children=('The  supervisory  authorities  concerned  shall  not  adopt  a  decision  '\n 'on  the  subject  matter  submitted  to  the  Board under paragraph 1 during '\n 'the periods referred to in paragraphs 2 and 3.')>]>]\n[<Paragraph children=[<RawText children=('The Chair of the Board shall notify, without undue delay, the decision '\n 'referred to in paragraph 1 to the supervisory authorities  concerned.  It  '\n 'shall  inform  the  Commission  thereof.  The  decision  shall  be  '\n 'published  on  the  website  of  the Board without delay after the '\n 'supervisory authority has notified the final decision referred to in '\n 'paragraph 6.')>]>]\n[<Paragraph children=[<RawText children=('The  lead  supervisory  authority  or,  as  the  case  may  be,  the  '\n 'supervisory  authority  with  which  the  complaint  has been lodged shall  '\n 'adopt its  final  decision  on  the  basis  of  the  decision  referred  to  '\n 'in  paragraph  1  of  this  Article,  without undue delay  and  at  the  '\n 'latest  by one  month  after  the  Board  has  notified  its  decision.  '\n 'The  lead  supervisory  authority  or, as  the  case  may  be,  the  '\n 'supervisory  authority  with  which  the  complaint  has  been  lodged,  '\n 'shall  inform  the  Board  of  the date  when  its  final  decision  is  '\n 'notified  respectively  to  the  controller  or  the  processor  and  to  '\n 'the  data  subject.  The  final decision  of  the  supervisory  authorities  '\n 'concerned  shall  be  adopted  under  the  terms  of  Article  60(7),  (8)  '\n 'and  (9).  The final  decision  shall  refer  to  the  decision  referred  '\n 'to  in  paragraph  1  of  this  Article  and  shall  specify  that  the  '\n 'decision referred  to  in  that  paragraph  will  be  published  on  the  '\n 'website  of  the  Board  in  accordance  with  paragraph  5  of  this '\n 'Article. The final decision shall attach the decision referred to in '\n 'paragraph 1 of this Article.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_85",
    "chunk_content": "Urgency procedure\n[<Paragraph children=[<RawText children=('In  exceptional  circumstances,  where  a  supervisory  authority  '\n 'concerned  considers  that  there  is  an  urgent  need  to act  in  order  '\n 'to  protect  the  rights  and  freedoms  of  data  subjects,  it  may,  by  '\n 'way  of  derogation  from  the  consistency mechanism  referred  to  in  '\n 'Articles  63,  64  and  65  or  the  procedure  referred  to  in  Article  '\n '60,  immediately  adopt provisional measures intended to produce legal '\n 'effects on its own territory with a specified period of validity which shall '\n 'not  exceed  three  months.  The  supervisory  authority  shall,  without  '\n 'delay,  communicate  those  measures  and  the  reasons for adopting them to '\n 'the other supervisory authorities concerned, to the Board and to the '\n 'Commission.')>]>]\n[<Paragraph children=[<RawText children=('Where  a  supervisory  authority  has  taken  a  measure  pursuant  to  '\n 'paragraph  1  and  considers  that  final  measures need  urgently  be  '\n 'adopted,  it  may  request  an  urgent  opinion  or  an  urgent  binding  '\n 'decision  from  the  Board,  giving reasons for requesting such opinion or '\n 'decision.')>]>]\n[<Paragraph children=[<RawText children=('Any supervisory authority may request an urgent opinion or an urgent binding '\n 'decision, as the case may be, from the  Board  where  a  competent  '\n 'supervisory  authority  has  not  taken  an  appropriate  measure  in  a  '\n 'situation  where  there  is an  urgent  need  to  act,  in  order  to  '\n 'protect  the  rights  and  freedoms  of  data  subjects,  giving  reasons  '\n 'for  requesting  such opinion or decision, including for  the urgent need to '\n 'act.')>]>]\n[<Paragraph children=[<RawText children=('By derogation from Article 64(3) and Article 65(2), an urgent opinion or an '\n 'urgent binding decision referred to in paragraphs 2 and 3 of this Article '\n 'shall be adopted within two weeks by simple majority of the members of the '\n 'Board.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_86",
    "chunk_content": "Exchange of information\nThe  Commission  may  adopt  implementing  acts  of  general  scope  in  order  to  specify  the  arrangements  for  the  exchange of  information by electronic means between supervisory authorities, and between supervisory authorities and the Board, in particular  the standardised format referred to in Article 64.\nThose implementing acts shall be adopted in accordance with the examination procedure referred to in Article 93(2)."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_87",
    "chunk_content": "European data protection board\nArticle 68"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_88",
    "chunk_content": "European Data Protection Board\n[<Paragraph children=[<RawText children=(\"The European Data Protection Board (the 'Board') is hereby established as a \"\n 'body of  the Union and shall have legal personality.')>]>]\n[<Paragraph children=[<RawText children='The Board shall be represented by its Chair.'>]>]\n[<Paragraph children=[<RawText children=('The Board shall be composed of  the head of one supervisory authority of '\n 'each Member State and of  the European Data Protection Supervisor, or  their '\n 'respective representatives.')>]>]\n[<Paragraph children=[<RawText children=('Where  in  a  Member  State  more  than  one  supervisory  authority  is  '\n 'responsible  for  monitoring  the  application  of the  provisions  '\n 'pursuant  to  this  Regulation,  a  joint  representative  shall  be  '\n \"appointed  in  accordance  with  that  Member State's law.\")>]>]\n[<Paragraph children=[<RawText children=('The  Commission  shall  have  the  right  to  participate  in  the  '\n 'activities  and  meetings  of  the  Board  without  voting right.  The  '\n 'Commission  shall  designate  a  representative.  The  Chair  of  the  '\n 'Board  shall  communicate  to  the  Commission the activities of  the Board.')>]>]\n[<Paragraph children=[<RawText children=('In  the  cases  referred  to  in  Article  65,  the  European  Data  '\n 'Protection  Supervisor  shall  have  voting  rights  only  on decisions  '\n 'which  concern  principles  and  rules  applicable  to  the  Union  '\n 'institutions,  bodies,  offices  and  agencies  which correspond in '\n 'substance to those of this Regulation.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_89",
    "chunk_content": "Independence\n[<Paragraph children=[<RawText children=('The  Board  shall  act  independently  when  performing  its  tasks  or  '\n 'exercising  its  powers  pursuant  to  Articles  70 and 71.')>]>]\n[<Paragraph children=[<RawText children=('Without prejudice to requests by the Commission referred to in point (b) of '\n 'Article 70(1) and in Article 70(2), the Board  shall,  in  the  performance  '\n 'of  its  tasks  or  the  exercise  of  its  powers,  neither  seek  nor  '\n 'take  instructions  from anybody.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_90",
    "chunk_content": "Tasks of the Board\n[<Paragraph children=[<RawText children=('The  Board  shall  ensure  the  consistent  application  of  this  '\n 'Regulation.  To  that  end,  the  Board  shall,  on  its  own initiative or, '\n 'where relevant, at the request of the Commission, in particular:')>]>]\n(a) monitor  and  ensure  the  correct  application  of  this  Regulation  in  the  cases  provided  for  in  Articles  64  and  65 without prejudice to the tasks of national supervisory authorities;\nEN\nImage\n(b)   advise  the  Commission  on  any  issue  related  to  the  protection  of  personal  data  in  the  Union,  including  on  any proposed amendment of this Regulation;\n(c) advise  the  Commission  on  the  format  and  procedures  for  the  exchange  of  information  between  controllers, processors and supervisory authorities for binding corporate rules;\n(d)   issue  guidelines,  recommendations,  and  best  practices  on  procedures  for  erasing  links,  copies  or  replications  of personal data from publicly available communication services as referred to in Article 17(2);\n(e) examine,  on  its  own  initiative,  on  request  of  one  of  its  members  or  on  request  of  the  Commission,  any  question covering  the  application  of  this  Regulation  and  issue  guidelines,  recommendations  and  best  practices  in  order  to encourage consistent application of this Regulation;\n(f) issue  guidelines,  recommendations  and  best  practices  in  accordance  with  point  (e)  of  this  paragraph  for  further specifying the criteria and conditions for decisions based on profiling pursuant to Article 22(2);\n(g) issue  guidelines,  recommendations and best practices in accordance with point (e) of  this paragraph for establishing the  personal  data  breaches  and  determining  the  undue  delay  referred  to  in  Article  33(1)  and  (2)  and  for  the particular circumstances in which a controller or a processor is required to notify the personal data breach;\n(h)   issue  guidelines,  recommendations  and  best  practices  in  accordance  with  point  (e)  of  this  paragraph  as  to  the circumstances  in  which  a  personal  data  breach  is  likely  to  result  in  a  high  risk  to  the  rights  and  freedoms  of  the natural persons referred to in Article 34(1).\n(i) issue guidelines, recommendations and best practices in accordance with point (e) of  this paragraph for  the purpose of  further  specifying  the  criteria  and  requirements  for  personal  data  transfers  based  on  binding  corporate  rules adhered  to  by  controllers  and  binding  corporate  rules  adhered  to  by  processors  and  on  further  necessary requirements to ensure the protection of personal data of the data subjects concerned referred to in Article 47;\n(j) issue guidelines, recommendations and best practices in accordance with point (e) of  this paragraph for  the purpose of further specifying the criteria and requirements for  the personal data transfers on the basis of Article 49(1);\n(k) draw  up  guidelines  for  supervisory  authorities  concerning  the  application  of  measures  referred  to  in  Article  58(1), (2) and (3) and the setting of administrative fines pursuant to Article 83;\n(l) review  the  practical  application  of  the  guidelines,  recommendations  and  best  practices  referred  to  in  points  (e) and (f);\n(m)   issue  guidelines,  recommendations  and best  practices  in  accordance  with point (e)  of  this  paragraph for  establishing common procedures for reporting by natural persons of infringements of this Regulation pursuant to Article 54(2);\n(n)   encourage  the  drawing-up  of  codes  of  conduct  and  the  establishment  of  data  protection  certification  mechanisms and data protection seals and marks pursuant to Articles 40 and 42;\n(o)   carry  out  the  accreditation  of  certification  bodies  and  its  periodic  review  pursuant  to  Article  43  and  maintain  a public  register  of  accredited  bodies  pursuant  to  Article  43(6)  and  of  the  accredited  controllers  or  processors established in third countries pursuant to Article 42(7);\n(p)   specify  the  requirements  referred  to  in  Article  43(3)  with  a  view  to  the  accreditation  of  certification  bodies  under Article 42;\n(q)   provide the Commission with an opinion on the certification requirements referred to in Article 43(8);\n(r) provide the Commission with an opinion on the icons referred to in Article 12(7);\n(s) provide  the  Commission  with  an  opinion  for  the  assessment  of  the  adequacy  of  the  level  of  protection  in  a  third country  or  international  organisation,  including  for  the  assessment  whether  a  third  country,  a  territory  or  one  or more  specified  sectors  within  that  third  country,  or  an  international  organisation  no  longer  ensures  an  adequate level  of  protection.  To  that  end,  the  Commission  shall  provide  the  Board  with  all  necessary  documentation, including  correspondence  with  the  government  of  the  third  country,  with  regard  to  that  third  country,  territory  or specified sector, or  with the international organisation.\nImage\n(t) issue  opinions  on  draft  decisions  of  supervisory  authorities  pursuant  to  the  consistency  mechanism  referred  to  in Article  64(1),  on  matters  submitted pursuant  to Article 64(2) and to issue binding decisions pursuant to Article 65, including in cases referred to in Article 66;\n(u)   promote  the  cooperation  and  the  effective  bilateral  and  multilateral  exchange  of  information  and  best  practices between the supervisory authorities;\n(v) promote common training programmes and facilitate personnel exchanges between the supervisory authorities and, where appropriate, with the supervisory authorities of third countries or  with international organisations;\n(w)   promote  the  exchange  of  knowledge  and  documentation  on  data  protection  legislation  and  practice  with  data protection supervisory authorities worldwide.\n(x) issue opinions on codes of conduct drawn up at Union level pursuant to Article 40(9); and\n(y) maintain  a  publicly  accessible  electronic  register  of  decisions  taken  by  supervisory  authorities  and  courts  on  issues handled in the consistency mechanism.\n[<Paragraph children=[<RawText children=('Where  the  Commission  requests  advice  from  the  Board,  it  may  '\n 'indicate  a  time  limit,  taking  into  account  the urgency of the matter.')>]>]\n[<Paragraph children=[<RawText children=('The  Board  shall  forward  its  opinions,  guidelines,  recommendations,  '\n 'and  best  practices  to  the  Commission  and  to the committee referred to '\n 'in Article 93 and make them public.')>]>]\n[<Paragraph children=[<RawText children=('The Board shall, where appropriate, consult interested parties and give them '\n 'the opportunity to comment within a reasonable  period.  The  Board  shall,  '\n 'without  prejudice  to  Article  76,  make  the  results  of  the  '\n 'consultation  procedure publicly available.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_91",
    "chunk_content": "Reports\n[<Paragraph children=[<RawText children=('The Board shall draw up an annual report regarding the protection of natural '\n 'persons with regard to processing in the  Union  and,  where  relevant,  in  '\n 'third  countries  and  international  organisations.  The  report  shall  '\n 'be  made  public  and be transmitted to the European Parliament, to the '\n 'Council and to the Commission.')>]>]\n[<Paragraph children=[<RawText children=('The  annual  report  shall  include  a  review  of  the  practical  '\n 'application  of  the  guidelines,  recommendations  and  best practices '\n 'referred to in point (l) of Article 70(1) as well as of the binding '\n 'decisions referred to in Article 65.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_92",
    "chunk_content": "Procedure\n[<Paragraph children=[<RawText children=('The  Board  shall  take  decisions  by  a  simple  majority  of  its  '\n 'members,  unless  otherwise  provided  for  in  this Regulation.')>]>]\n[<Paragraph children=[<RawText children=('The  Board  shall  adopt  its  own  rules  of  procedure  by  a  two-thirds  '\n 'majority  of  its  members  and  organise  its  own operational '\n 'arrangements.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_93",
    "chunk_content": "Chair\n[<Paragraph children=[<RawText children=('The Board shall elect a chair and two deputy chairs from amongst its members '\n 'by simple majority.')>]>]\n[<Paragraph children=[<RawText children=('The term of office of the Chair and of the deputy chairs shall be five years '\n 'and be renewable once.')>]>]\nEN"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_94",
    "chunk_content": "Tasks of the Chair\n[<Paragraph children=[<RawText children='The Chair shall have the following tasks:'>]>]\n(a)   to convene the meetings of the Board and prepare its agenda;\n(b)   to  notify  decisions  adopted  by  the  Board  pursuant  to  Article  65  to  the  lead  supervisory  authority  and  the supervisory authorities concerned;\n(c)   to  ensure  the  timely  performance  of  the  tasks  of  the  Board,  in  particular  in  relation  to  the  consistency  mechanism referred to in Article 63.\n[<Paragraph children=[<RawText children=('The Board shall lay down the allocation of tasks between the Chair and the '\n 'deputy chairs in its rules of procedure.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_95",
    "chunk_content": "Secretariat\n[<Paragraph children=[<RawText children=('The Board shall have a secretariat, which shall be provided by the European '\n 'Data Protection Supervisor.')>]>]\n[<Paragraph children=[<RawText children=('The secretariat shall perform its tasks exclusively under  the instructions '\n 'of the Chair of the Board.')>]>]\n[<Paragraph children=[<RawText children=('The staff of  the  European Data Protection Supervisor  involved in carrying '\n 'out the tasks  conferred on the Board by this  Regulation  shall  be  '\n 'subject  to  separate reporting lines  from  the  staff  involved  in  '\n 'carrying  out  tasks  conferred  on  the European Data Protection '\n 'Supervisor.')>]>]\n[<Paragraph children=[<RawText children=('Where  appropriate,  the  Board  and  the  European  Data  Protection  '\n 'Supervisor  shall  establish  and  publish  a Memorandum  of  Understanding  '\n 'implementing  this  Article,  determining  the  terms  of  their  '\n 'cooperation,  and  applicable to the staff of  the European Data Protection '\n 'Supervisor involved in carrying out the tasks conferred on the Board by this '\n 'Regulation.')>]>]\n[<Paragraph children=[<RawText children=('The secretariat shall provide analytical, administrative and logistical '\n 'support to the Board.')>]>]\n[<Paragraph children=[<RawText children='The secretariat shall be responsible in particular for:'>]>]\n(a)   the  day-to-day business of  the Board;\n(b)   communication between the members of the Board, its Chair and the Commission;\n(c)   communication with other institutions and the public;\n(d)   the  use  of electronic means for  the internal and external communication;\n(e)   the  translation of relevant information;\n(f)   the  preparation and follow-up of the meetings of the Board;\n(g)   the  preparation,  drafting  and  publication  of  opinions,  decisions  on  the  settlement  of  disputes  between  supervisory authorities and other  texts adopted by the Board."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_96",
    "chunk_content": "Confidentiality\n[<Paragraph children=[<RawText children=('The discussions  of  the  Board  shall  be  confidential  where  the  Board  '\n 'deems  it  necessary,  as  provided  for  in  its  rules of procedure.')>]>]\nEN\n[<Paragraph children=[<RawText children=('Access  to  documents  submitted  to  members  of  the  Board,  experts  '\n 'and  representatives  of  third  parties  shall  be governed by Regulation '\n '(EC) No 1049/2001 of the European Parliament and of the Council ( 1 ).')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_97",
    "chunk_content": "Right to lodge a complaint with a supervisory authority\n[<Paragraph children=[<RawText children=('Without prejudice to any other administrative or  judicial remedy, every '\n 'data subject shall have the right to lodge a complaint with a supervisory '\n 'authority, in particular  in the Member State of his or her habitual '\n 'residence, place of work or  place  of  the  alleged  infringement  if  the  '\n 'data  subject  considers  that  the  processing  of  personal  data  '\n 'relating  to  him  or her infringes this Regulation.')>]>]\n[<Paragraph children=[<RawText children=('The supervisory authority with which the complaint has been lodged shall '\n 'inform the complainant on the progress and the outcome of the complaint '\n 'including the possibility of a judicial remedy pursuant to Article 78.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_98",
    "chunk_content": "Right to an effective judicial remedy against a supervisory authority\n[<Paragraph children=[<RawText children=('Without  prejudice  to  any  other  administrative  or  non-judicial  '\n 'remedy,  each  natural  or  legal  person  shall  have  the right to an '\n 'effective judicial remedy against a legally binding decision of a '\n 'supervisory authority concerning them.')>]>]\n[<Paragraph children=[<RawText children=('Without prejudice to any other administrative or non-judicial remedy, each '\n 'data subject shall have the right to a an effective  judicial  remedy  '\n 'where  the  supervisory  authority  which  is  competent  pursuant  to  '\n 'Articles  55  and  56  does  not handle  a  complaint  or  does  not  '\n 'inform  the  data  subject  within  three  months  on  the  progress  or  '\n 'outcome  of  the complaint lodged pursuant to Article 77.')>]>]\n[<Paragraph children=[<RawText children=('Proceedings  against  a  supervisory  authority  shall  be  brought  before  '\n 'the  courts  of  the  Member  State  where  the supervisory authority is '\n 'established.')>]>]\n[<Paragraph children=[<RawText children=('Where proceedings are brought against a decision of a supervisory authority '\n 'which was preceded by an opinion or a  decision  of  the  Board  in  the  '\n 'consistency  mechanism,  the  supervisory  authority  shall  forward  that  '\n 'opinion  or  decision to the court.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_99",
    "chunk_content": "Right to an effective judicial remedy against a controller or processor\n[<Paragraph children=[<RawText children=('Without prejudice  to any available  administrative  or  non-judicial  '\n 'remedy,  including  the  right  to  lodge  a  complaint with a supervisory '\n 'authority pursuant to Article 77, each data subject shall have the right to '\n 'an effective judicial remedy where he or  she  considers  that  his  or  '\n 'her  rights  under  this  Regulation  have  been  infringed  as  a  result  '\n 'of  the  processing of his or her  personal data in non-compliance with this '\n 'Regulation.')>]>]\n[<Paragraph children=[<RawText children=('Proceedings  against  a  controller  or  a  processor  shall  be  brought  '\n 'before  the  courts  of  the  Member  State  where  the controller  or  '\n 'processor  has  an  establishment.  Alternatively,  such  proceedings  may  '\n 'be  brought  before  the  courts  of  the Member  State  where  the  data  '\n 'subject  has  his  or  her  habitual  residence,  unless  the  controller  '\n 'or  processor  is  a  public authority of a Member State acting in the '\n 'exercise of its public powers.')>]>]\nEN"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_100",
    "chunk_content": "Representation of data subjects\n[<Paragraph children=[<RawText children=('The data  subject  shall  have  the  right  to  mandate  a  not-for-profit  '\n 'body,  organisation  or  association  which  has  been properly  '\n 'constituted  in  accordance  with  the  law  of  a  Member  State,  has  '\n 'statutory  objectives  which  are  in  the  public interest,  and  is  '\n \"active  in  the  field  of  the  protection  of  data  subjects'  rights  \"\n 'and  freedoms  with  regard  to the  protection  of their  personal  data  '\n 'to  lodge  the  complaint  on  his  or  her  behalf,  to  exercise  the  '\n 'rights  referred  to  in  Articles  77,  78  and 79 on his or her behalf,  '\n 'and  to exercise  the  right  to  receive  compensation  referred  to  in  '\n 'Article  82  on  his  or  her  behalf where provided for by Member State '\n 'law.')>]>]\n[<Paragraph children=[<RawText children=('Member States may provide that any body, organisation or association '\n 'referred to in paragraph 1 of this Article, in\\xad dependently of a  data  '\n \"subject's  mandate,  has  the  right  to  lodge,  in  that  Member  State,  \"\n 'a  complaint  with  the  supervisory authority  which  is  competent  '\n 'pursuant  to  Article  77  and  to  exercise  the  rights  referred  to  in  '\n 'Articles  78  and  79  if  it considers that the rights of a data subject '\n 'under  this Regulation have been infringed as a result of the processing.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_101",
    "chunk_content": "Suspension of proceedings\n[<Paragraph children=[<RawText children=('Where a competent court of a Member State has information on proceedings, '\n 'concerning the same subject matter as  regards  processing  by  the  same  '\n 'controller  or  processor,  that  are  pending  in  a  court  in  another  '\n 'Member  State,  it  shall contact that court in the other Member State to '\n 'confirm the existence of such proceedings.')>]>]\n[<Paragraph children=[<RawText children=('Where proceedings  concerning  the  same  subject  matter  as  regards  '\n 'processing  of  the  same  controller  or  processor are  pending  in  a  '\n 'court  in  another  Member  State,  any  competent  court  other  than  the  '\n 'court  first  seized  may  suspend  its proceedings.')>]>]\n[<Paragraph children=[<RawText children=('Where those proceedings are pending at first instance, any court other  than '\n 'the court first  seized may also, on the application of one of  the parties, '\n 'decline jurisdiction if  the court first  seized has jurisdiction over  the '\n 'actions in question and its law permits the consolidation thereof.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_102",
    "chunk_content": "Right to compensation and liability\n[<Paragraph children=[<RawText children=('Any  person  who  has  suffered  material  or  non-material  damage  as  a  '\n 'result  of  an  infringement  of  this  Regulation shall have the right to '\n 'receive compensation from the controller or processor for  the damage '\n 'suffered.')>]>]\n[<Paragraph children=[<RawText children=('Any  controller  involved  in  processing  shall  be  liable  for  the  '\n 'damage  caused  by  processing  which  infringes  this Regulation.  A  '\n 'processor  shall  be  liable  for  the  damage  caused  by  processing  '\n 'only  where  it  has  not  complied  with obligations  of  this  Regulation  '\n 'specifically  directed  to  processors  or  where  it  has  acted  outside  '\n 'or  contrary  to  lawful instructions of  the controller.')>]>]\n[<Paragraph children=[<RawText children=('A  controller  or  processor  shall  be  exempt  from  liability  under  '\n 'paragraph  2  if  it  proves  that  it  is  not  in  any  way responsible '\n 'for  the event giving rise to the damage.')>]>]\n[<Paragraph children=[<RawText children=('Where  more  than  one  controller  or  processor,  or  both  a  controller  '\n 'and  a  processor,  are  involved  in  the  same processing  and  where  '\n 'they  are,  under  paragraphs  2  and  3,  responsible  for  any  damage  '\n 'caused  by  processing,  each controller  or  processor  shall  be  held  '\n 'liable  for  the  entire  damage  in  order  to  ensure  effective  '\n 'compensation  of  the  data subject.')>]>]\n[<Paragraph children=[<RawText children=('Where  a  controller  or  processor  has,  in  accordance  with  paragraph  '\n '4,  paid  full  compensation  for  the  damage suffered,  that  controller  '\n 'or  processor  shall  be  entitled  to claim  back from  the  other  '\n 'controllers  or  processors  involved  in the  same  processing  that  part  '\n 'of  the  compensation  corresponding  to  their  part  of  responsibility  '\n 'for  the  damage,  in accordance with the conditions set out in paragraph 2.')>]>]\nEN\n[<Paragraph children=[<RawText children=('Court  proceedings  for  exercising  the  right  to  receive  compensation  '\n 'shall  be  brought  before  the  courts  competent under the law of the '\n 'Member State referred to in Article 79(2).')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_103",
    "chunk_content": "General conditions for imposing administrative fines\n[<Paragraph children=[<RawText children=('Each  supervisory  authority  shall  ensure  that  the  imposition  of  '\n 'administrative  fines  pursuant  to  this  Article  in respect of '\n 'infringements of  this Regulation referred to in paragraphs 4, 5 and 6 shall '\n 'in each individual case be effective, proportionate and dissuasive.')>]>]\n[<Paragraph children=[<RawText children=('Administrative  fines  shall,  depending  on  the  circumstances  of  each  '\n 'individual  case,  be  imposed  in  addition  to,  or instead  of,  '\n 'measures  referred  to  in  points  (a)  to  (h)  and  (j)  of  Article  '\n '58(2).  When  deciding  whether  to  impose  an administrative  fine  and  '\n 'deciding  on  the  amount  of  the  administrative  fine  in  each  '\n 'individual  case  due  regard  shall  be given to the following:')>]>]\n(a)   the  nature,  gravity  and  duration  of  the  infringement  taking  into  account  the  nature  scope  or  purpose  of  the processing concerned as well as the number of data subjects affected and the level of damage suffered by them;\n(b)   the  intentional or  negligent character of  the infringement;\n(c)   any action taken by the controller or processor  to mitigate the damage suffered by data subjects;\n(d)   the  degree  of  responsibility of  the  controller  or  processor  taking  into  account  technical  and  organisational  measures implemented by them pursuant to Articles 25 and 32;\n(e)   any relevant previous infringements by the controller or processor;\n(f)   the  degree  of  cooperation  with  the  supervisory  authority,  in  order  to  remedy  the  infringement  and  mitigate  the possible adverse effects of the infringement;\n(g)   the  categories of personal data affected by the infringement;\n(h)   the  manner  in  which  the  infringement  became  known  to  the  supervisory  authority,  in  particular  whether,  and  if  so to what extent, the controller or processor notified the infringement;\n(i) where  measures  referred  to  in  Article  58(2)  have  previously  been  ordered  against  the  controller  or  processor concerned with regard to the same subject-matter, compliance with those measures;\n(j) adherence  to  approved  codes  of  conduct  pursuant  to  Article  40  or  approved  certification  mechanisms  pursuant  to Article 42; and\n(k)   any  other  aggravating  or  mitigating  factor  applicable  to  the  circumstances  of  the  case,  such  as  financial  benefits gained, or losses avoided, directly or indirectly, from the infringement.\n[<Paragraph children=[<RawText children=('If  a  controller  or  processor  intentionally  or  negligently,  for  the  '\n 'same  or  linked  processing  operations,  infringes several  provisions  '\n 'of  this  Regulation,  the  total  amount  of  the  administrative  fine  '\n 'shall  not  exceed  the  amount  specified for  the gravest infringement.')>]>]\n[<Paragraph children=[<RawText children=('Infringements  of  the  following  provisions  shall,  in  accordance  with  '\n 'paragraph  2,  be  subject  to  administrative  fines up  to  10  000  000  '\n 'EUR,  or  in  the  case  of  an  undertaking,  up  to  2  %  of  the  total  '\n 'worldwide  annual  turnover  of  the preceding financial year, whichever is '\n 'higher:')>]>]\n(a)   the  obligations of  the controller and the processor  pursuant to Articles 8, 11, 25 to 39 and 42 and 43;\n(b)   the  obligations of  the certification body pursuant to Articles 42 and 43;\n(c)   the  obligations of  the monitoring body pursuant to Article 41(4).\nEN\n[<Paragraph children=[<RawText children=('Infringements  of  the  following  provisions  shall,  in  accordance  with  '\n 'paragraph  2,  be  subject  to  administrative  fines up  to  20  000  000  '\n 'EUR,  or  in  the  case  of  an  undertaking,  up  to  4  %  of  the  total  '\n 'worldwide  annual  turnover  of  the preceding financial year, whichever is '\n 'higher:')>]>]\n(a)   the  basic  principles for  processing, including conditions for consent, pursuant to Articles 5, 6, 7 and 9;\n(b)   the  data subjects' rights pursuant to Articles 12 to 22;\n(c)   the  transfers  of  personal  data  to  a  recipient  in  a  third  country  or  an  international  organisation  pursuant  to Articles 44 to 49;\n(d)   any obligations pursuant to Member State law adopted under Chapter IX;\n(e)   non-compliance with an order or a temporary or definitive limitation on processing or  the suspension of data flows by the supervisory authority pursuant to Article 58(2) or failure to provide access in violation of Article 58(1).\n[<Paragraph children=[<RawText children=('Non-compliance  with  an  order  by  the  supervisory  authority  as  '\n 'referred  to  in  Article  58(2)  shall,  in  accordance with  paragraph  2  '\n 'of  this  Article,  be  subject  to  administrative  fines  up  to  20  000  '\n '000  EUR,  or  in  the  case  of  an undertaking, up to 4 % of the total '\n 'worldwide annual turnover of the preceding financial year, whichever is '\n 'higher.')>]>]\n[<Paragraph children=[<RawText children=('Without  prejudice  to  the  corrective  powers  of  supervisory  '\n 'authorities  pursuant  to  Article  58(2),  each Member  State  may  lay  '\n 'down  the  rules  on  whether  and  to  what  extent  administrative  fines  '\n 'may  be  imposed  on  public authorities and bodies established in that '\n 'Member State.')>]>]\n[<Paragraph children=[<RawText children=('The  exercise  by  the  supervisory  authority  of  its  powers  under  '\n 'this  Article  shall  be  subject  to  appropriate procedural  safeguards  '\n 'in  accordance  with  Union  and  Member  State  law,  including  effective  '\n 'judicial  remedy  and  due process.')>]>]\n[<Paragraph children=[<RawText children=('Where the legal system  of  the  Member  State does  not  provide  for  '\n 'administrative  fines,  this  Article  may  be  applied in  such  a  manner  '\n 'that  the  fine  is  initiated  by  the  competent  supervisory  authority  '\n 'and  imposed  by  competent  national courts,  while  ensuring  that  those  '\n 'legal  remedies  are  effective  and  have  an  equivalent  effect  to  the  '\n 'administrative  fines imposed  by  supervisory  authorities.  In  any  '\n 'event,  the  fines  imposed  shall  be  effective,  proportionate  and  '\n 'dissuasive. Those  Member  States  shall  notify  to  the  Commission  the  '\n 'provisions  of  their  laws  which  they  adopt  pursuant  to  this '\n 'paragraph by 25 May 2018 and, without delay, any subsequent amendment law or '\n 'amendment affecting them.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_104",
    "chunk_content": "Penalties\n[<Paragraph children=[<RawText children=('Member  States  shall  lay  down  the  rules  on  other  penalties  '\n 'applicable  to  infringements  of  this  Regulation  in particular  for  '\n 'infringements  which  are  not  subject  to  administrative  fines  '\n 'pursuant  to  Article  83,  and  shall  take  all measures necessary to '\n 'ensure that they are implemented. Such penalties shall be effective, '\n 'proportionate and dissuasive.')>]>]\n[<Paragraph children=[<RawText children=('Each  Member  State  shall  notify  to  the  Commission  the  provisions  '\n 'of  its  law  which  it  adopts  pursuant  to paragraph 1, by 25 May 2018 '\n 'and, without delay, any subsequent amendment affecting them.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_105",
    "chunk_content": "Processing and freedom of expression and information\n[<Paragraph children=[<RawText children=('Member States shall by law reconcile  the  right  to  the  protection  of  '\n 'personal  data  pursuant  to  this  Regulation  with the  right  to  '\n 'freedom  of  expression  and  information,  including  processing  for  '\n 'journalistic  purposes  and  the  purposes  of academic, artistic or '\n 'literary expression.')>]>]\nEN\n[<Paragraph children=[<RawText children=('For  processing  carried  out  for  journalistic  purposes  or  the  '\n 'purpose  of  academic  artistic  or  literary  expression, Member  States  '\n 'shall  provide  for  exemptions  or  derogations  from  Chapter  II  '\n '(principles),  Chapter  III  (rights  of  the  data subject),  Chapter  IV  '\n '(controller  and  processor),  Chapter  V  (transfer  of  personal  data  '\n 'to  third  countries  or  international organisations),  Chapter  VI  '\n '(independent  supervisory  authorities),  Chapter  VII  (cooperation  and  '\n 'consistency)  and Chapter  IX  (specific  data  processing  situations)  if  '\n 'they  are  necessary  to  reconcile  the  right  to  the  protection  of  '\n 'personal data with the freedom of expression and information.')>]>]\n[<Paragraph children=[<RawText children=('Each  Member  State  shall  notify  to  the  Commission  the  provisions  '\n 'of  its  law  which  it  has  adopted  pursuant  to paragraph 2 and, without '\n 'delay, any subsequent amendment law or amendment affecting them.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_106",
    "chunk_content": "Processing and public access to official documents\nPersonal data in official  documents held by a public authority or a public body or a private body for  the performance of a  task  carried  out  in  the  public  interest  may  be  disclosed  by the  authority or  body in  accordance with Union or Member State  law  to which the  public  authority or  body  is  subject  in  order  to  reconcile  public  access  to  official  documents  with the right to the protection of personal data pursuant to this Regulation."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_107",
    "chunk_content": "Processing of the national identification number\nMember  States  may  further  determine  the  specific  conditions  for  the  processing  of  a  national  identification  number  or any  other  identifier  of  general  application.  In  that  case  the  national  identification  number  or  any  other  identifier  of general  application  shall  be  used  only  under  appropriate  safeguards  for  the  rights  and  freedoms  of  the  data  subject pursuant to this Regulation."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_108",
    "chunk_content": "Processing in the context of employment\n[<Paragraph children=[<RawText children=('Member States may, by law or by collective agreements, provide for more '\n 'specific rules to ensure the protection of the  rights  and  freedoms  in  '\n \"respect  of  the  processing  of  employees'  personal  data  in  the  \"\n 'employment  context,  in particular  for  the  purposes  of  the  '\n 'recruitment,  the  performance  of  the  contract  of  employment,  '\n 'including  discharge  of obligations laid down by law or by collective '\n 'agreements, management, planning and organisation of work, equality and '\n 'diversity  in  the  workplace,  health  and  safety  at  work,  protection  '\n \"of  employer's  or  customer's  property  and  for  the purposes  of  the  \"\n 'exercise  and  enjoyment,  on  an  individual  or  collective  basis,  of  '\n 'rights  and  benefits  related  to employment, and for the purpose of the '\n 'termination of the employment relationship.')>]>]\n[<Paragraph children=[<RawText children=('Those  rules  shall  include  suitable  and  specific  measures  to  '\n \"safeguard  the  data  subject's  human  dignity,  legitimate interests  and  \"\n 'fundamental  rights,  with  particular  regard  to  the  transparency  of  '\n 'processing,  the  transfer  of  personal  data within  a  group  of  '\n 'undertakings,  or  a  group  of  enterprises  engaged  in  a  joint  '\n 'economic  activity  and  monitoring  systems at the work place.')>]>]\n[<Paragraph children=[<RawText children=('Each  Member  State  shall  notify  to  the  Commission  those  provisions  '\n 'of  its  law  which  it  adopts  pursuant  to paragraph 1, by 25 May 2018 '\n 'and, without delay, any subsequent amendment affecting them.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_109",
    "chunk_content": "Safeguards  and  derogations  relating  to  processing  for  archiving  purposes  in  the  public  interest, scientific or historical research purposes or statistical purposes\n[<Paragraph children=[<RawText children=('Processing  for  archiving  purposes  in  the  public  interest,  '\n 'scientific  or  historical  research  purposes  or  statistical purposes,  '\n 'shall  be  subject  to  appropriate  safeguards,  in  accordance  with  '\n 'this  Regulation,  for  the  rights  and  freedoms  of the  data  subject.  '\n 'Those  safeguards  shall  ensure  that  technical  and  organisational  '\n 'measures  are  in  place  in  particular  in')>]>]\nEN\norder  to  ensure  respect  for  the  principle  of  data  minimisation.  Those  measures  may  include  pseudonymisation  provided that  those  purposes  can  be  fulfilled  in  that  manner.  Where  those  purposes  can  be  fulfilled  by  further  processing  which does not permit or no longer permits the identification of data subjects, those purposes shall be fulfilled in that manner.\n[<Paragraph children=[<RawText children=('Where  personal  data  are  processed  for  scientific  or  historical  '\n 'research  purposes  or  statistical  purposes,  Union  or Member State law '\n 'may provide  for  derogations  from  the  rights  referred  to  in  '\n 'Articles  15,  16,  18  and  21  subject  to  the conditions  and  '\n 'safeguards  referred  to  in  paragraph  1  of  this  Article  in  so  far  '\n 'as  such  rights  are  likely  to  render impossible  or  seriously  impair  '\n 'the  achievement  of  the  specific  purposes,  and  such  derogations  are  '\n 'necessary  for  the fulfilment of those purposes.')>]>]\n[<Paragraph children=[<RawText children=('Where personal  data  are  processed  for  archiving  purposes  in  the  '\n 'public  interest,  Union  or  Member  State  law  may provide  for  '\n 'derogations  from  the  rights  referred  to  in  Articles  15,  16,  18,  '\n '19,  20  and  21  subject  to  the  conditions  and safeguards  referred  '\n 'to  in  paragraph  1  of  this  Article  in  so  far  as  such  rights  are  '\n 'likely  to  render  impossible  or  seriously impair  the  achievement  of  '\n 'the  specific  purposes,  and  such  derogations  are  necessary  for  the  '\n 'fulfilment  of  those purposes.')>]>]\n[<Paragraph children=[<RawText children=('Where processing referred to in paragraphs 2 and 3 serves at the same time '\n 'another purpose, the derogations shall apply only to processing for  the '\n 'purposes referred to in those paragraphs.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_110",
    "chunk_content": "Obligations of secrecy\n[<Paragraph children=[<RawText children=('Member States may adopt specific rules to set out the powers of the '\n 'supervisory authorities laid down in points (e) and  (f)  of  Article  '\n '58(1)  in  relation  to  controllers  or  processors  that  are  subject,  '\n 'under  Union  or  Member  State  law  or rules  established  by  national  '\n 'competent  bodies,  to  an  obligation  of  professional  secrecy  or  '\n 'other  equivalent  obligations of  secrecy  where  this  is  necessary  and  '\n 'proportionate  to  reconcile  the  right  of  the  protection  of  personal  '\n 'data  with  the obligation  of  secrecy.  Those  rules  shall  apply  only  '\n 'with  regard  to  personal  data  which  the  controller  or  processor  has '\n 'received as a result of or has obtained in an activity covered by that '\n 'obligation of secrecy.')>]>]\n[<Paragraph children=[<RawText children=('Each  Member  State  shall  notify  to  the  Commission  the  rules  '\n 'adopted  pursuant  to  paragraph  1,  by  25  May  2018 and, without delay, '\n 'any subsequent amendment affecting them.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_111",
    "chunk_content": "Existing data protection rules of churches and religious associations\n[<Paragraph children=[<RawText children=('Where  in  a  Member  State,  churches  and  religious  associations  or  '\n 'communities  apply,  at  the  time  of  entry  into force  of  this  '\n 'Regulation,  comprehensive  rules  relating  to  the  protection  of  '\n 'natural  persons  with  regard  to  processing, such rules may continue to '\n 'apply, provided that they are brought into line with this Regulation.')>]>]\n[<Paragraph children=[<RawText children=('Churches  and  religious  associations  which  apply  comprehensive  rules  '\n 'in  accordance  with  paragraph  1  of  this Article  shall  be  subject  '\n 'to  the  supervision  of  an  independent  supervisory  authority,  which '\n 'may be  specific,  provided that it  fulfils  the  conditions laid down in '\n 'Chapter VI of  this Regulation.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_112",
    "chunk_content": "Delegated acts and implementing acts\nArticle 92"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_113",
    "chunk_content": "Exercise of the delegation\n[<Paragraph children=[<RawText children=('The  power  to  adopt  delegated  acts  is  conferred  on  the  Commission  '\n 'subject  to  the  conditions  laid  down  in  this Article.')>]>]\nEN\n[<Paragraph children=[<RawText children=('The  delegation  of  power  referred  to  in  Article  12(8)  and  Article  '\n '43(8)  shall  be  conferred  on  the  Commission  for an indeterminate '\n 'period of time from 24 May 2016.')>]>]\n[<Paragraph children=[<RawText children=('The  delegation  of  power  referred  to  in  Article  12(8)  and  Article  '\n '43(8)  may  be  revoked  at  any  time  by  the European Parliament or by '\n 'the Council. A decision of revocation shall put an end to the delegation of '\n 'power specified in that decision. It shall take effect the day following '\n 'that of its publication in the Official  Journal  of  the  European  Union '\n 'or at a later date specified therein. It shall not affect the validity of '\n 'any delegated acts already in force.')>]>]\n[<Paragraph children=[<RawText children=('As soon as it adopts a delegated act, the Commission shall notify it '\n 'simultaneously to the European Parliament and to the Council.')>]>]\n[<Paragraph children=[<RawText children=('A delegated  act  adopted  pursuant  to  Article  12(8)  and  Article  '\n '43(8)  shall  enter  into  force  only  if  no  objection  has been '\n 'expressed by either  the European Parliament or  the Council within a period '\n 'of  three months of notification of  that act  to  the  European  '\n 'Parliament  and  the  Council  or  if,  before  the  expiry of  that  '\n 'period,  the  European  Parliament  and  the Council have both informed the '\n 'Commission that they will not object. That period shall be extended by three '\n 'months at the initiative of  the European Parliament or of the Council.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_114",
    "chunk_content": "Committee procedure\n[<Paragraph children=[<RawText children=('The  Commission  shall  be  assisted  by  a  committee.  That  committee  '\n 'shall  be  a  committee  within  the  meaning  of Regulation (EU) No '\n '182/2011.')>]>]\n[<Paragraph children=[<RawText children=('Where reference is made to this paragraph, Article 5 of Regulation (EU) No '\n '182/2011 shall apply.')>]>]\n[<Paragraph children=[<RawText children=('Where  reference  is  made  to  this  paragraph,  Article  8  of  '\n 'Regulation  (EU)  No  182/2011,  in  conjunction  with Article 5 thereof, '\n 'shall apply.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_115",
    "chunk_content": "Final provisions\nArticle 94"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_116",
    "chunk_content": "Repeal of Directive 95/46/EC\n[<Paragraph children=[<RawText children='Directive 95/46/EC is repealed with effect from 25 May 2018.'>]>]\n[<Paragraph children=[<RawText children=('References  to the  repealed  Directive  shall  be  construed  as  '\n 'references  to  this  Regulation.  References  to  the  Working Party  on  '\n 'the  Protection  of  Individuals  with  regard  to  the  Processing  of  '\n 'Personal  Data  established  by  Article  29  of Directive  95/46/EC  shall  '\n 'be  construed  as  references  to  the  European  Data  Protection  Board  '\n 'established  by  this Regulation.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_117",
    "chunk_content": "Relationship with Directive 2002/58/EC\nThis  Regulation  shall  not  impose  additional  obligations  on  natural  or  legal  persons  in  relation  to  processing  in connection  with  the  provision  of  publicly  available  electronic  communications  services  in  public  communication networks  in  the  Union  in  relation  to  matters  for  which  they  are  subject  to  specific  obligations  with  the  same  objective set out in Directive 2002/58/EC.\nEN"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_118",
    "chunk_content": "Relationship with previously concluded Agreements\nInternational  agreements  involving  the  transfer  of  personal  data  to  third  countries  or  international  organisations  which were concluded by Member States prior  to 24 May 2016, and which comply with Union law as applicable prior  to that date, shall remain in force until amended, replaced or revoked."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_119",
    "chunk_content": "Commission reports\n[<Paragraph children=[<RawText children=('By  25  May  2020  and  every  four  years  thereafter,  the  Commission  '\n 'shall  submit  a  report  on  the  evaluation  and review of this Regulation '\n 'to the European Parliament and to the Council. The reports shall be made '\n 'public.')>]>]\n[<Paragraph children=[<RawText children=('In  the  context  of  the  evaluations  and  reviews  referred  to  in  '\n 'paragraph  1,  the  Commission  shall  examine,  in particular, the '\n 'application and functioning of:')>]>]\n(a)   Chapter  V on  the  transfer  of  personal  data  to  third  countries  or  international  organisations  with  particular  regard  to decisions adopted pursuant to Article 45(3) of this Regulation and decisions adopted on the basis of Article 25(6) of Directive 95/46/EC;\n(b)   Chapter VII on cooperation and consistency.\n[<Paragraph children=[<RawText children=('For  the  purpose  of  paragraph  1,  the  Commission  may  request  '\n 'information  from  Member  States  and  supervisory authorities.')>]>]\n[<Paragraph children=[<RawText children=('In  carrying  out  the  evaluations  and  reviews  referred  to  in  '\n 'paragraphs  1  and  2,  the  Commission  shall  take  into account the '\n 'positions and findings of the European Parliament, of the Council, and of '\n 'other relevant bodies or sources.')>]>]\n[<Paragraph children=[<RawText children=('The  Commission  shall,  if  necessary,  submit  appropriate  proposals  to  '\n 'amend  this  Regulation,  in  particular  taking into  account  of  '\n 'developments  in  information  technology  and  in  the  light  of  the  '\n 'state  of  progress  in  the  information society.')>]>]"
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_120",
    "chunk_content": "Review of other Union legal acts on data protection\nThe  Commission  shall,  if  appropriate,  submit  legislative  proposals  with  a  view  to  amending  other  Union  legal  acts  on the  protection  of  personal  data,  in  order  to  ensure  uniform  and  consistent  protection  of  natural  persons  with  regard  to processing.  This  shall  in  particular  concern  the  rules  relating  to  the  protection  of  natural  persons  with  regard  to processing by Union institutions, bodies, offices and agencies and on the free movement of such data."
  },
  {
    "document_name": "GDPR-with-image-refs",
    "chunk_id": "GDPR-with-image-refs_chunk_121",
    "chunk_content": "Entry into force and application\n[<Paragraph children=[<RawText children=('This Regulation shall enter  into force on the twentieth day following that '\n 'of its publication in the Official  Journal  of the European Union .')>]>]\n[<Paragraph children=[<RawText children='It  shall  apply from 25 May 2018.'>]>]\nImage\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.\nDone at Brussels, 27 April 2016.\nFor  the European Parliament The President M. SCHULZ\nFor  the Council The President\nJ.A.  HENNIS-PLASSCHAERT"
  }
]