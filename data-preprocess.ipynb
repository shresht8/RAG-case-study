{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the environment variable if the user doesn't provide Project ID.\n",
    "import os\n",
    "\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import (\n",
    "    FunctionDeclaration,\n",
    "    GenerativeModel,\n",
    "    Tool,\n",
    "    ToolConfig,\n",
    "    Part,\n",
    "    GenerationConfig,\n",
    ")\n",
    "PROJECT_ID = \"104916006626\"  # @param {type: \"string\", placeholder: \"[your-project-id]\" isTemplate: true}\n",
    "if not PROJECT_ID or PROJECT_ID == \"xyz\":\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"australia-southeast1\")\n",
    "\n",
    "vertexai.init(project=\"104916006626\", location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0a50b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Path to your service account key file\n",
    "key_path = \"C:\\\\Users\\\\shres\\\\Projects\\\\RAG-case-study\\keys\\\\keyproject-401005-6e1cdcbb5996.json\"\n",
    "\n",
    "# Create credentials using the service account key file\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    key_path\n",
    ")\n",
    "\n",
    "# Set the credentials for the current environment\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = key_path\n",
    "# auth_request = transport.requests.Request()\n",
    "# credentials.refresh(auth_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddda4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controlled generation example test\n",
    "response_schema = {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"recipe_name\": {\n",
    "                \"type\": \"string\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"recipe_name\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "model = GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "\n",
    "response = model.generate_content(\n",
    "    \"List a few popular cookie recipes\",\n",
    "    generation_config=GenerationConfig(\n",
    "        response_mime_type=\"application/json\", response_schema=response_schema\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455743c5",
   "metadata": {},
   "source": [
    "## Document preprocessing:\n",
    "\n",
    "Each document is to pre-processed individually as the structure of each document is different from the other. The objective it to extract meaningful chunks out of each document while preserving the original structure of the document, long term and short term context so that the chunk is indexed better and retrieved accurately.\n",
    "The chunking strategy is as follows:\n",
    "- LLM to create an index for the document dividing the document into various sections based on heading and sub headings. This will be used as metadata for the chunk.\n",
    "- The document generates chunks by outputing the first and last sentence for the chunk. The chunk is then extracted from the md file which contains the document text. Generated chunk is restricted insize to a set number of tokens\n",
    "- Each chunk is appended with short term and long term context for the document to aid the embedding and retrieval process.\n",
    "- LLM must help remove unnecessary headers and footers  of the document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62443bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_case_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
