{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the environment variable if the user doesn't provide Project ID.\n",
    "import os\n",
    "\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import (\n",
    "    FunctionDeclaration,\n",
    "    GenerativeModel,\n",
    "    Tool,\n",
    "    ToolConfig,\n",
    "    Part,\n",
    "    GenerationConfig,\n",
    ")\n",
    "PROJECT_ID = \"104916006626\"  # @param {type: \"string\", placeholder: \"[your-project-id]\" isTemplate: true}\n",
    "if not PROJECT_ID or PROJECT_ID == \"xyz\":\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"australia-southeast1\")\n",
    "\n",
    "vertexai.init(project=\"104916006626\", location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Path to your service account key file\n",
    "key_path = \"C:\\\\Users\\\\shres\\\\Projects\\\\RAG-case-study\\keys\\\\keyproject-401005-6e1cdcbb5996.json\"\n",
    "\n",
    "# Create credentials using the service account key file\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    key_path\n",
    ")\n",
    "\n",
    "# Set the credentials for the current environment\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = key_path\n",
    "# auth_request = transport.requests.Request()\n",
    "# credentials.refresh(auth_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controlled generation example test\n",
    "response_schema = {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "            },\n",
    "            \"answer\": {\n",
    "                \"type\": \"string\",\n",
    "            },\n",
    "            \"difficulty\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"easy\", \"medium\", \"hard\"],\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"question\", \"answer\", \"difficulty\"],\n",
    "    },\n",
    "\n",
    "\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import system_prompt_QA_eval_bot\n",
    "def generate_questions(context, num_questions=10):\n",
    "    \"\"\"\n",
    "    Generate a set of questions and answers from a given context.\n",
    "\n",
    "    Args:\n",
    "    context: The context to generate questions from.\n",
    "    num_questions: The number of questions to generate.\n",
    "\n",
    "    Returns:\n",
    "    A list of questions and answers.\n",
    "    \"\"\"\n",
    "    model = GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "\n",
    "    response = model.generate_content(\n",
    "    system_prompt_QA_eval_bot.format(context=context, num_questions=num_questions),\n",
    "    generation_config=GenerationConfig(\n",
    "        response_mime_type=\"application/json\", response_schema=response_schema\n",
    "    ),\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a cross encode to get the similarity between the eval question and the document chunks\n",
    " The cross encoder will output a score between 0 and 1 for each question and document chunk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shres\\anaconda3\\envs\\rag_case_study\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\shres\\.cache\\huggingface\\hub\\models--cross-encoder--stsb-distilroberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "model = CrossEncoder(\"cross-encoder/stsb-distilroberta-base\")\n",
    "scores = model.predict([[\"My first\", \"sentence pair\"], [\"Second text\", \"pair\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11382268, 0.11522377], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shres\\anaconda3\\envs\\rag_case_study\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "from typing import Dict, List\n",
    "from transformers import AutoTokenizer\n",
    "from docling.chunking import HybridChunker\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "class DocumentChunker:\n",
    "    def __init__(self, base_dir: str = \"processed_docs\", model_id: str = \"answerdotai/ModernBERT-base\"):\n",
    "        \"\"\"\n",
    "        Initialize the DocumentChunker with necessary components.\n",
    "        \n",
    "        Args:\n",
    "            base_dir: Base directory containing markdown files\n",
    "            model_id: Model ID for the tokenizer\n",
    "        \"\"\"\n",
    "        # Setup logging\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.model_id = model_id\n",
    "        \n",
    "        # Initialize components\n",
    "        self._setup_components()\n",
    "        \n",
    "        # Store results\n",
    "        self.document_chunks: Dict[str, List[str]] = {}\n",
    "\n",
    "    def _setup_components(self) -> None:\n",
    "        \"\"\"Initialize tokenizer, chunker and document converter.\"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_id)\n",
    "        self.chunker = HybridChunker(\n",
    "            tokenizer=self.tokenizer,\n",
    "            merge_peers=True,\n",
    "        )\n",
    "        self.doc_converter = DocumentConverter()\n",
    "        \n",
    "    def process_single_document(self, file_path: Path) -> List[str]:\n",
    "        \"\"\"\n",
    "        Process a single markdown file and return its chunks.\n",
    "        \n",
    "        Args:\n",
    "            file_path: Path to the markdown file\n",
    "            \n",
    "        Returns:\n",
    "            List of chunks for the document\n",
    "        \"\"\"\n",
    "        chunks = []\n",
    "        \n",
    "        try:\n",
    "            # Convert markdown to docling document\n",
    "            doc = self.doc_converter.convert(source=str(file_path)).document\n",
    "            \n",
    "            # Generate and store chunks in order\n",
    "            for chunk in self.chunker.chunk(dl_doc=doc):\n",
    "                chunks.append(self.chunker.serialize(chunk=chunk))\n",
    "                \n",
    "            self.logger.info(f\"Successfully processed {file_path.name} - Generated {len(chunks)} chunks\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing {file_path.name}: {str(e)}\")\n",
    "        \n",
    "        return chunks\n",
    "\n",
    "    def process_directory(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Process all markdown files in the directory and its subdirectories.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary mapping document names to their ordered chunks\n",
    "        \"\"\"\n",
    "        # Find all markdown files\n",
    "        md_files = list(self.base_dir.glob(\"**/*-with-image-refs.md\"))\n",
    "        \n",
    "        if not md_files:\n",
    "            self.logger.warning(f\"No markdown files found in {self.base_dir}\")\n",
    "            return self.document_chunks\n",
    "        \n",
    "        self.logger.info(f\"Found {len(md_files)} markdown files to process\")\n",
    "        \n",
    "        # Process each file\n",
    "        for md_file in md_files:\n",
    "            self.logger.info(f\"Processing {md_file.relative_to(self.base_dir)}\")\n",
    "            \n",
    "            # Store chunks with document name as key\n",
    "            doc_key = md_file.stem\n",
    "            self.document_chunks[doc_key] = self.process_single_document(md_file)\n",
    "        \n",
    "        self.logger.info(f\"Completed processing all documents\")\n",
    "        return self.document_chunks\n",
    "    \n",
    "    def get_document_statistics(self) -> None:\n",
    "        \"\"\"Print statistics about processed documents and their chunks.\"\"\"\n",
    "        if not self.document_chunks:\n",
    "            print(\"No documents have been processed yet.\")\n",
    "            return\n",
    "            \n",
    "        print(\"\\nDocument Processing Statistics:\")\n",
    "        print(\"-\" * 30)\n",
    "        for doc_name, chunks in self.document_chunks.items():\n",
    "            print(f\"\\nDocument: {doc_name}\")\n",
    "            print(f\"Number of chunks: {len(chunks)}\")\n",
    "            if chunks:\n",
    "                avg_chunk_length = sum(len(self.tokenizer.tokenize(chunk)) \n",
    "                                     for chunk in chunks) / len(chunks)\n",
    "                print(f\"Average chunk length: {avg_chunk_length:.2f} tokens\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Found 3 markdown files to process\n",
      "INFO:__main__:Processing AI_ACT\\AI_ACT-with-image-refs.md\n",
      "INFO:docling.document_converter:Going to convert document batch...\n",
      "INFO:docling.pipeline.base_pipeline:Processing document AI_ACT-with-image-refs.md\n",
      "INFO:docling.document_converter:Finished converting document AI_ACT-with-image-refs.md in 293.09 sec.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8230 > 8192). Running this sequence through the model will result in indexing errors\n",
      "INFO:__main__:Successfully processed AI_ACT-with-image-refs.md - Generated 152 chunks\n",
      "INFO:__main__:Processing Cybersecurity_California_Privacy\\Cybersecurity_California_Privacy-with-image-refs.md\n",
      "INFO:docling.document_converter:Going to convert document batch...\n",
      "INFO:docling.pipeline.base_pipeline:Processing document Cybersecurity_California_Privacy-with-image-refs.md\n",
      "INFO:docling.document_converter:Finished converting document Cybersecurity_California_Privacy-with-image-refs.md in 17.14 sec.\n",
      "INFO:__main__:Successfully processed Cybersecurity_California_Privacy-with-image-refs.md - Generated 41 chunks\n",
      "INFO:__main__:Processing GDPR\\GDPR-with-image-refs.md\n",
      "INFO:docling.document_converter:Going to convert document batch...\n",
      "INFO:docling.pipeline.base_pipeline:Processing document GDPR-with-image-refs.md\n",
      "INFO:docling.document_converter:Finished converting document GDPR-with-image-refs.md in 188.16 sec.\n",
      "INFO:__main__:Successfully processed GDPR-with-image-refs.md - Generated 122 chunks\n",
      "INFO:__main__:Completed processing all documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document Processing Statistics:\n",
      "------------------------------\n",
      "\n",
      "Document: AI_ACT-with-image-refs\n",
      "Number of chunks: 152\n",
      "Average chunk length: 1133.82 tokens\n",
      "\n",
      "Document: Cybersecurity_California_Privacy-with-image-refs\n",
      "Number of chunks: 41\n",
      "Average chunk length: 266.54 tokens\n",
      "\n",
      "Document: GDPR-with-image-refs\n",
      "Number of chunks: 122\n",
      "Average chunk length: 938.01 tokens\n"
     ]
    }
   ],
   "source": [
    "doc_chunker = DocumentChunker()\n",
    "\n",
    "# Process all documents\n",
    "document_chunks = doc_chunker.process_directory()\n",
    "\n",
    "# Print statistics\n",
    "doc_chunker.get_document_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 315 chunks to document_chunks.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Prepare list to store all chunks with their metadata\n",
    "chunks_data = []\n",
    "\n",
    "# Loop through the document_chunks dictionary\n",
    "for doc_name, chunks in document_chunks.items():\n",
    "    # Process each chunk in the document\n",
    "    for i, chunk_content in enumerate(chunks):\n",
    "        chunk_data = {\n",
    "            \"document_name\": doc_name,\n",
    "            \"chunk_id\": f\"{doc_name}_chunk_{i}\",\n",
    "            \"chunk_content\": chunk_content\n",
    "        }\n",
    "        chunks_data.append(chunk_data)\n",
    "\n",
    "# Save to JSON file\n",
    "output_path = \"document_chunks.json\"\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(chunks_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved {len(chunks_data)} chunks to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded chunks for 3 documents\n"
     ]
    }
   ],
   "source": [
    "# Load and restructure the chunks data\n",
    "with open(\"document_chunks.json\", 'r', encoding='utf-8') as f:\n",
    "    chunks_list = json.load(f)\n",
    "\n",
    "# Convert the flat list structure back to document_chunks dictionary\n",
    "document_chunks = {}\n",
    "for chunk in chunks_list:\n",
    "    doc_name = chunk['document_name']\n",
    "    if doc_name not in document_chunks:\n",
    "        document_chunks[doc_name] = []\n",
    "    document_chunks[doc_name].append(chunk['chunk_content'])\n",
    "\n",
    "print(f\"Loaded chunks for {len(document_chunks)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To verify all chunks are loaded correctly\n",
    "# len(document_chunks['GDPR-with-image-refs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_document_chunks(document_chunks: Dict[str, List[str]]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Format chunks for each document into a single string with separators and chunk names.\n",
    "    \n",
    "    Args:\n",
    "        document_chunks: Dictionary mapping document names to their chunks\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping document names to their formatted content string\n",
    "    \"\"\"\n",
    "    formatted_docs = {}\n",
    "    \n",
    "    for doc_id, chunks in document_chunks.items():\n",
    "        formatted_content = f\"{doc_id}:\\n\\n\"\n",
    "        \n",
    "        for i, chunk in enumerate(chunks):\n",
    "            formatted_content += \"----x----\\n\"\n",
    "            formatted_content += f\"chunk_{i}\\n\\n\"\n",
    "            formatted_content += f\"{chunk}\\n\\n\"\n",
    "            \n",
    "        formatted_docs[doc_id] = formatted_content\n",
    "    \n",
    "    return formatted_docs\n",
    "\n",
    "# Generate eval sets for each document\n",
    "formatted_docs = format_document_chunks(document_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"question\": \"What is the aim of this regulation?\", \"answer\": \"The purpose of this Regulation is to improve the functioning of the internal market by laying down a uniform legal framework in particular for the development, the placing on the market, the putting into service and the use of artificial intelligence systems (AI systems) in the Union, in accordance with Union values, to promote the uptake of human centric and trustworthy artificial intelligence (AI) while ensuring a high level of protection of health, safety, fundamental rights as enshrined in the Charter of Fundamental Rights of the European Union (the \\'Charter\\'), including democracy, the rule of law and environmental protection, to protect against the harmful effects of AI systems in the Union, and to support innovation.\", \"difficulty\": \"medium\"}, {\"question\": \"When will this regulation be applied?\", \"answer\": \"This regulation will be applied from 2 August 2026.\", \"difficulty\": \"easy\"}, {\"question\": \"When were the opinions on this draft delivered?\", \"answer\": \"The European Data Protection Supervisor and the European Data Protection Board delivered their joint opinion on 18 June 2021.\", \"difficulty\": \"easy\"}, {\"question\": \"What does this regulation address?\", \"answer\": \"This regulation lays down harmonised rules for the placing on the market, the putting into service, and the use of AI systems in the Union prohibitions of certain AI practices specific requirements for high-risk AI systems and obligations for operators of such systems harmonised transparency rules for certain AI systems harmonised rules for the placing on the market of general-purpose AI models rules on market monitoring, market surveillance, governance and enforcement measures to support innovation, with a particular focus on SMEs, including start-ups.\", \"difficulty\": \"medium\"}, {\"question\": \"Does this regulation apply to AI systems for military use?\", \"answer\": \"This Regulation does not apply to AI systems where and in so far they are placed on the market, put into service, or used with or without modification exclusively for military, defence or national security purposes, regardless of the type of entity carrying out those activities. This Regulation does not apply to AI systems which are not placed on the market or put into service in the Union, where the output is used in the Union exclusively for military, defence or national security purposes, regardless of the type of entity carrying out those activities.\", \"difficulty\": \"medium\"}, {\"question\": \"What is an AI system?\", \"answer\": \"AI system means a machine-based system that is designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment, and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments.\", \"difficulty\": \"medium\"}, {\"question\": \"What does \\'putting into service\\' mean?\", \"answer\": \"\\'Putting into service\\' means the supply of an AI system for first use directly to the deployer or for own use in the Union for its intended purpose.\", \"difficulty\": \"medium\"}, {\"question\": \"What is \\'AI literacy\\'?\", \"answer\": \"\\'AI literacy\\' means skills, knowledge and understanding that allow providers, deployers and affected persons, taking into account their respective rights and obligations in the context of this Regulation, to make an informed deployment of AI systems, as well as to gain awareness about the opportunities and risks of AI and possible harm it can cause.\", \"difficulty\": \"medium\"}, {\"question\": \"What practices involving AI are prohibited?\", \"answer\": \"The use of AI systems that deploy subliminal techniques or manipulative techniques that cause harm, exploit vulnerabilities of specific groups, use social scoring leading to detrimental treatment, create facial recognition databases via untargeted scraping, infer emotions in workplaces and schools (except for medical reasons), categorize based on sensitive attributes, and use real-time remote biometric identification in public spaces (with exceptions).\", \"difficulty\": \"hard\"}, {\"question\": \"In what situations is the use of real-time remote biometric identification systems allowed?\", \"answer\": \"The targeted search for specific victims of abduction, trafficking, or sexual exploitation, prevention of an imminent threat to life or a terrorist attack, and the localization or identification of a suspect of serious criminal offences.\", \"difficulty\": \"medium\"},\\n{\"question\": \"What conditions need to be met for real-time remote biometric identification?\", \"answer\": \"The use must be strictly necessary and proportionate, considering the nature of the situation, consequences for rights and freedoms, and relevant safeguards.  It requires prior authorization by a judicial or independent administrative authority, except in urgent situations where authorization is requested within 24 hours.\", \"difficulty\": \"medium\"}, {\"question\": \"Who assumes responsibility for compliance with AI system requirements?\", \"answer\": \"The provider assumes the responsibility for compliance with requirements set out in Section 2.\", \"difficulty\": \"easy\"}, {\"question\": \"What should the authorized representative verify?\", \"answer\": \"The authorized representative shall verify that the EU declaration of conformity and technical documentation have been drawn up and an appropriate conformity assessment procedure has been carried out by the provider.\", \"difficulty\": \"medium\"}, {\"question\": \"What is the purpose of the EU database?\", \"answer\": \"The database contains information on high-risk AI systems registered under Articles 49 and 60, and systems classified as non-high-risk under Article 6(3) registered according to Article 6(4) and 49. It facilitates transparency and compliance monitoring.\", \"difficulty\": \"medium\"}, {\"question\": \"What happens if an authorized representative believes a provider is violating the regulation?\", \"answer\": \"The authorized representative shall terminate the mandate and immediately inform the market surveillance authority and relevant notified body.\", \"difficulty\": \"easy\"}, {\"question\": \"What is the duration of an authorised representatives\\' mandate?\", \"answer\": \"The mandate lasts until it is terminated by the representative or revoked by the provider.\", \"difficulty\": \"easy\"}, {\"question\": \"What obligations do importers of AI systems have?\", \"answer\": \"Importers must ensure the AI system conforms to the regulation before placing it on the market. This includes verifying conformity assessment, technical documentation, CE marking, and appointment of an authorized representative. They must also handle non-compliant or falsified systems and keep records.\", \"difficulty\": \"medium\"}, {\"question\": \"What should importers do with non-compliant AI systems?\", \"answer\": \"Importers must not place non-compliant systems on the market until they have been brought into conformity.  If the system presents a risk, they must inform the provider, authorized representative, and market surveillance authorities.\", \"difficulty\": \"easy\"}, {\"question\": \"What measures are Member States encouraged to take regarding SMEs involved with AI?\", \"answer\": \"Member States should prioritize SME access to AI regulatory sandboxes, organize awareness campaigns and training, establish communication channels for guidance, and facilitate SME participation in standardization.\", \"difficulty\": \"medium\"}, {\"question\": \"What are distributors of high-risk AI systems required to do before making a system available on the market?\", \"answer\": \"Verify the presence of the CE marking, that the system is accompanied by the EU declaration of conformity and instructions for use, and that the provider and importer (if applicable) have met their obligations as specified in Article 16(b), 16(c), and Article 23(3).\", \"difficulty\": \"medium\"}, {\"question\": \"What should a distributor do if they believe a high-risk AI system is non-compliant?\", \"answer\": \"They should not make it available until it conforms to the requirements and must inform the provider or importer.\", \"difficulty\": \"easy\"}, {\"question\": \"When can a distributor, importer, deployer, or other third party be considered a provider?\", \"answer\": \"If they put their name or trademark on an existing high-risk AI system, make substantial modifications to a high-risk system, or modify the intended purpose of a system so that it becomes high-risk.\", \"difficulty\": \"medium\"}, {\"question\": \"What is the role of a deployer in ensuring fundamental rights?\", \"answer\": \"Deployers play a critical role in protecting fundamental rights by understanding the context of use and identifying unforeseen risks, complementing the provider\\'s obligations.  They must also inform individuals subject to high-risk AI systems about the system\\'s use and their right to an explanation.\", \"difficulty\": \"medium\"},\\n{\"question\": \"What information must be included in the fundamental rights impact assessment?\", \"answer\": \"Description of the processes, timeframe, affected groups, specific risks, human oversight measures, and steps to be taken if risks materialize.\", \"difficulty\": \"medium\"}, {\"question\": \"What actions must a provider of high-risk AI system take?\", \"answer\": \"Ensure compliance with requirements, provide contact information, implement quality management system, keep documentation and logs, conduct conformity assessment, affix CE marking, register the system, take corrective actions, demonstrate conformity on request, and meet accessibility requirements.\", \"difficulty\": \"hard\"}, {\"question\": \"What are the aspects included in the documentation kept by providers?\", \"answer\": \"Technical documentation, documentation about quality management system, changes approved by notified bodies, decisions by notified bodies, and the EU declaration of conformity.\", \"difficulty\": \"medium\"}, {\"question\": \"What information must the technical documentation of a high-risk AI system contain?\", \"answer\": \"At minimum, the elements set out in Annex IV.\", \"difficulty\": \"easy\"}, {\"question\": \"What are the obligations of deployers regarding high-risk AI systems?\", \"answer\": \"Deployers must take measures to use the system according to instructions, assign human oversight, ensure data quality (if applicable), monitor the system\\'s operation, keep logs, inform workers\\' representatives about AI system use at work and comply with registration obligations for certain systems.  They must also carry out a fundamental rights impact assessment for certain systems and inform individuals subject to high-risk AI systems.\", \"difficulty\": \"hard\"}, {\"question\": \"What is the role of testing in real-world conditions?\", \"answer\": \"To gather robust data, assess, and verify the AI system\\'s conformity with the regulation before market release, without qualifying as placing it on the market or putting it into service.\", \"difficulty\": \"medium\"}, {\"question\": \"What is the maximum duration of real-world testing?\", \"answer\": \"Six months, extendable by another six months with prior notification and justification to the market surveillance authority.\", \"difficulty\": \"easy\"}, {\"question\": \"What information must providers include in the instructions for use?\", \"answer\": \"Provider/representative contact details, system characteristics/limitations, pre-determined changes and human oversight measures, resource requirements, maintenance details, log interpretation mechanisms.\", \"difficulty\": \"medium\"}, {\"question\": \"What is the human oversight requirement for certain biometric systems?\", \"answer\": \"No action can be taken based on the system\\'s identification unless verified by at least two natural persons, except in law enforcement, migration, border control, or asylum where deemed disproportionate.\", \"difficulty\": \"medium\"}, {\"question\": \"What is the purpose of human oversight for high-risk AI systems?\", \"answer\": \"To prevent or minimize risks to health, safety, or fundamental rights that may arise during use, even when other requirements are met.\", \"difficulty\": \"medium\"}, {\"question\": \"How can robustness in high-risk AI systems be achieved?\", \"answer\": \"Through technical redundancy solutions, such as backup or fail-safe plans.\", \"difficulty\": \"easy\"}, {\"question\": \"How should high-risk AI systems handle continuous learning?\", \"answer\": \"They should minimize bias in feedback loops and address them with mitigation measures.\", \"difficulty\": \"medium\"}, {\"question\": \"What are the objectives of AI regulatory sandboxes?\", \"answer\": \"Foster AI innovation, enhance legal certainty, facilitate regulatory learning, support cooperation and sharing of best practices, and accelerate market access.\", \"difficulty\": \"medium\"}, {\"question\": \"What are the key aspects of a quality management system for high-risk AI systems?\", \"answer\": \"Regulatory compliance strategy, design and development procedures, testing and validation, data management, risk management, post-market monitoring, serious incident reporting, communication handling, record-keeping, resource management, and accountability framework.\", \"difficulty\": \"hard\"}, {\"question\": \"How long must providers keep documentation for high-risk AI systems?\", \"answer\": \"10 years after the system is placed on the market or put into service.\", \"difficulty\": \"easy\"},\\n{\"question\": \"What are the quality criteria for data used in high-risk AI systems?\", \"answer\": \"Data sets must be relevant, representative, error-free, complete, and have appropriate statistical properties for the intended purpose, considering potential biases and how outputs might influence future inputs.\", \"difficulty\": \"medium\"}, {\"question\": \"What is the role of European common data spaces in AI development?\", \"answer\": \"To provide trustworthy and non-discriminatory access to high-quality data sets for training, validation, and testing of AI systems.\", \"difficulty\": \"medium\"}, {\"question\": \"When may providers process special categories of personal data?\", \"answer\": \"Exceptionally, when strictly necessary for bias detection and correction in high-risk systems, subject to safeguards and conditions outlined in data protection regulations.\", \"difficulty\": \"medium\"}, {\"question\": \"What are the transparency obligations for AI systems interacting with humans?\", \"answer\": \"Users must be informed they are interacting with an AI system unless obvious, with exceptions for law enforcement systems (unless used for public reporting).  AI systems generating synthetic content must mark outputs as artificially generated.  Deployers must disclose use of emotion recognition or biometric categorization systems (except in law enforcement).\", \"difficulty\": \"hard\"}, {\"question\": \"When are deployers required to conduct a fundamental rights impact assessment?\", \"answer\": \"Before putting into service certain high-risk AI systems, if they are public bodies, private entities providing public services or when using high-risk AI systems for certain specified purposes.\", \"difficulty\": \"medium\"}, {\"question\": \"What are the conditions for using personal data in AI regulatory sandboxes?\", \"answer\": \"Data must be lawfully collected, used for developing systems in the public interest (public safety, health, environment, etc.), necessary for compliance with Chapter III Section 2 requirements, processed in a separate environment with monitoring mechanisms, and not used for decisions affecting data subjects without their consent, among other conditions.\", \"difficulty\": \"hard\"}, {\"question\": \"What are some of the key elements to be considered when amending the list of high-risk AI systems?\", \"answer\": \"Intended purpose, extent of use, data processed, autonomy, evidence of harm, potential impact, user dependence, power imbalance, reversibility of outcomes, benefits, existing legal redress and risk mitigation measures.\", \"difficulty\": \"hard\"}, {\"question\": \"What measures are taken to support providers and notified bodies in complying with the Regulation?\", \"answer\": \"AI-on-demand platform, European Digital Innovation Hubs, and testing and experimentation facilities can offer support, including technical and scientific advice. Microenterprises have simplified quality management system requirements, and there are provisions for accessing testing facilities.\", \"difficulty\": \"medium\"}, {\"question\": \"What are the obligations of providers of general-purpose AI models?\", \"answer\": \"Maintain technical documentation, provide information to downstream providers, have a copyright compliance policy, and summarize training data content.\", \"difficulty\": \"medium\"}, {\"question\": \"What additional obligations apply to providers of general-purpose AI models with systemic risk?\", \"answer\": \"Model evaluation, systemic risk assessment and mitigation, reporting serious incidents, ensuring cybersecurity.\", \"difficulty\": \"medium\"}, {\"question\": \"What is the role of the scientific panel?\", \"answer\": \"To advise and support the AI Office, especially on general-purpose AI models and systems, including alerting on systemic risks, methodology development, classification advice, and supporting market surveillance authorities.\", \"difficulty\": \"medium\"}, {\"question\": \"What are the tasks of the European Artificial Intelligence Board?\", \"answer\": \"Advise and assist the Commission and Member States on consistent application of the regulation, including coordinating competent authorities, sharing expertise, providing advice on implementation, harmonizing administrative practices, issuing recommendations and opinions, promoting AI literacy, and contributing to guidance documents.\", \"difficulty\": \"hard\"}, {\"question\": \"What are the transparency obligations for AI systems generating deep fakes?\", \"answer\": \"Deployers must disclose that the content has been artificially generated or manipulated, except for artistic or creative works, where disclosure is limited to acknowledging the AI\\'s involvement without hindering the work\\'s presentation.\", \"difficulty\": \"medium\"}, {\"question\": \"What are the penalties for non-compliance with the AI Act?\", \"answer\": \"Penalties include administrative fines, with upper limits defined for different types of infringements. The amounts vary depending on factors such as the nature and severity of the infringement, the operator\\'s size and turnover, and cooperation with authorities.\", \"difficulty\": \"medium\"}, {\"question\": \"What is the right to explanation for individuals affected by high-risk AI system decisions?\", \"answer\": \"Individuals have the right to clear explanations about the AI system\\'s role in decisions that significantly affect them, unless exceptions or restrictions apply under other laws.\", \"difficulty\": \"medium\"}, {\"question\": \"What rules govern the application of penalties for violating this regulation?\", \"answer\": \"Member States define the rules and measures for penalties, ensuring they are effective, proportionate, and dissuasive, considering SME interests.  These must be notified to the Commission.  Specific administrative fine limits are set for various infringements.\", \"difficulty\": \"medium\"}]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate eval set for one doc to see results\n",
    "# generate_questions(formatted_docs['AI_ACT-with-image-refs'],50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_sets = {}\n",
    "\n",
    "for doc_id, formatted_content in formatted_docs.items():\n",
    "    print(f\"Generating questions for {doc_id}...\")\n",
    "    eval_sets[doc_id] = generate_questions(formatted_content, num_questions=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Parse the eval sets and add document information\n",
    "parsed_eval_sets = []\n",
    "\n",
    "for doc_id, eval_set in eval_sets.items():\n",
    "    # Convert string response to Python list of dictionaries\n",
    "    questions = json.loads(eval_set)\n",
    "    \n",
    "    # Add document information to each question\n",
    "    for question in questions:\n",
    "        question['document'] = doc_id\n",
    "        parsed_eval_sets.append(question)\n",
    "\n",
    "# Save to JSON file\n",
    "output_path = \"evaluation_sets.json\"\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(parsed_eval_sets, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved {len(parsed_eval_sets)} questions to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the eval sets when needed\n",
    "with open(\"evaluation_sets.json\", 'r', encoding='utf-8') as f:\n",
    "    eval_sets = json.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_case_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
