{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Evaluation Sets\n",
    "The idea behind creating these evaluation sets it to test the performance of the retriever in the RAG system. The issue lies in the fact that most of the times there is no ground truth to compare the performance of the retriever. This notebook explores the process of creating evaluation sets.\n",
    "These will be the steps followed to create the evaluation sets:\n",
    "1. The document chunker will be used to chunk the all the document into smaller chunks.\n",
    "2. The chunks are fed to the LLM to generate the evaluation sets which contain questions, answers, difficulty level and the chunk IDs that the question and answer are based on. The issue is that there is no ground truth to compare the performance of the LLM generating the evlaution set\n",
    "3. Since cross encoders capture deep relationships between the question and the chunk, we will use them to compare the performance of the LLM generating the evaluation set.\n",
    "4. The objective is to maximise the overlap between the synthetic evluation set generator and the cross encoder. The final ground truth will be the overlap between the evaluation set and the cross encoder. Another strategy is to use the combination of the synthetic LLM eval generator and the cross encoder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the environment variable if the user doesn't provide Project ID.\n",
    "import os\n",
    "\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import (\n",
    "    FunctionDeclaration,\n",
    "    GenerativeModel,\n",
    "    Tool,\n",
    "    ToolConfig,\n",
    "    Part,\n",
    "    GenerationConfig,\n",
    ")\n",
    "PROJECT_ID = \"104916006626\"  # @param {type: \"string\", placeholder: \"[your-project-id]\" isTemplate: true}\n",
    "if not PROJECT_ID or PROJECT_ID == \"xyz\":\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"australia-southeast1\")\n",
    "\n",
    "vertexai.init(project=\"104916006626\", location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Path to your service account key file\n",
    "key_path = \"C:\\\\Users\\\\shres\\\\Projects\\\\RAG-case-study\\keys\\\\keyproject-401005-6e1cdcbb5996.json\"\n",
    "\n",
    "# Create credentials using the service account key file\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    key_path\n",
    ")\n",
    "\n",
    "# Set the credentials for the current environment\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = key_path\n",
    "# auth_request = transport.requests.Request()\n",
    "# credentials.refresh(auth_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schema = {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "            },\n",
    "            \"answer\": {\n",
    "                \"type\": \"string\",\n",
    "            },\n",
    "            \"difficulty\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"easy\", \"medium\", \"hard\"],\n",
    "            },\n",
    "            \"chunk_ids\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"description\": \"List of chunk IDs that the question and answer are based on\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"question\", \"answer\", \"difficulty\", \"chunk_ids\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import system_prompt_QA_eval_bot\n",
    "def generate_questions(context, num_questions=10):\n",
    "    \"\"\"\n",
    "    Generate a set of questions and answers from a given context.\n",
    "\n",
    "    Args:\n",
    "    context: The context to generate questions from.\n",
    "    num_questions: The number of questions to generate.\n",
    "\n",
    "    Returns:\n",
    "    A list of questions and answers.\n",
    "    \"\"\"\n",
    "    model = GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "\n",
    "    response = model.generate_content(\n",
    "    system_prompt_QA_eval_bot.format(context=context, num_questions=num_questions),\n",
    "    generation_config=GenerationConfig(\n",
    "        response_mime_type=\"application/json\", response_schema=response_schema\n",
    "    ),\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a cross encode to get the similarity between the eval question and the document chunks\n",
    " The cross encoder will output a score between 0 and 1 for each question and document chunk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shres\\anaconda3\\envs\\rag_case_study\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\shres\\.cache\\huggingface\\hub\\models--cross-encoder--stsb-distilroberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "model = CrossEncoder(\"cross-encoder/stsb-distilroberta-base\")\n",
    "scores = model.predict([[\"My first\", \"sentence pair\"], [\"Second text\", \"pair\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11382268, 0.11522377], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shres\\anaconda3\\envs\\rag_case_study\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "from typing import Dict, List\n",
    "from transformers import AutoTokenizer\n",
    "from docling.chunking import HybridChunker\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "class DocumentChunker:\n",
    "    def __init__(self, base_dir: str = \"processed_docs\", model_id: str = \"answerdotai/ModernBERT-base\"):\n",
    "        \"\"\"\n",
    "        Initialize the DocumentChunker with necessary components.\n",
    "        \n",
    "        Args:\n",
    "            base_dir: Base directory containing markdown files\n",
    "            model_id: Model ID for the tokenizer\n",
    "        \"\"\"\n",
    "        # Setup logging\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.model_id = model_id\n",
    "        \n",
    "        # Initialize components\n",
    "        self._setup_components()\n",
    "        \n",
    "        # Store results\n",
    "        self.document_chunks: Dict[str, List[str]] = {}\n",
    "\n",
    "    def _setup_components(self) -> None:\n",
    "        \"\"\"Initialize tokenizer, chunker and document converter.\"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_id)\n",
    "        self.chunker = HybridChunker(\n",
    "            tokenizer=self.tokenizer,\n",
    "            merge_peers=True,\n",
    "        )\n",
    "        self.doc_converter = DocumentConverter()\n",
    "        \n",
    "    def process_single_document(self, file_path: Path) -> List[str]:\n",
    "        \"\"\"\n",
    "        Process a single markdown file and return its chunks.\n",
    "        \n",
    "        Args:\n",
    "            file_path: Path to the markdown file\n",
    "            \n",
    "        Returns:\n",
    "            List of chunks for the document\n",
    "        \"\"\"\n",
    "        chunks = []\n",
    "        \n",
    "        try:\n",
    "            # Convert markdown to docling document\n",
    "            doc = self.doc_converter.convert(source=str(file_path)).document\n",
    "            \n",
    "            # Generate and store chunks in order\n",
    "            for chunk in self.chunker.chunk(dl_doc=doc):\n",
    "                chunks.append(self.chunker.serialize(chunk=chunk))\n",
    "                \n",
    "            self.logger.info(f\"Successfully processed {file_path.name} - Generated {len(chunks)} chunks\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing {file_path.name}: {str(e)}\")\n",
    "        \n",
    "        return chunks\n",
    "\n",
    "    def process_directory(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Process all markdown files in the directory and its subdirectories.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary mapping document names to their ordered chunks\n",
    "        \"\"\"\n",
    "        # Find all markdown files\n",
    "        md_files = list(self.base_dir.glob(\"**/*-with-image-refs.md\"))\n",
    "        \n",
    "        if not md_files:\n",
    "            self.logger.warning(f\"No markdown files found in {self.base_dir}\")\n",
    "            return self.document_chunks\n",
    "        \n",
    "        self.logger.info(f\"Found {len(md_files)} markdown files to process\")\n",
    "        \n",
    "        # Process each file\n",
    "        for md_file in md_files:\n",
    "            self.logger.info(f\"Processing {md_file.relative_to(self.base_dir)}\")\n",
    "            \n",
    "            # Store chunks with document name as key\n",
    "            doc_key = md_file.stem\n",
    "            self.document_chunks[doc_key] = self.process_single_document(md_file)\n",
    "        \n",
    "        self.logger.info(f\"Completed processing all documents\")\n",
    "        return self.document_chunks\n",
    "    \n",
    "    def get_document_statistics(self) -> None:\n",
    "        \"\"\"Print statistics about processed documents and their chunks.\"\"\"\n",
    "        if not self.document_chunks:\n",
    "            print(\"No documents have been processed yet.\")\n",
    "            return\n",
    "            \n",
    "        print(\"\\nDocument Processing Statistics:\")\n",
    "        print(\"-\" * 30)\n",
    "        for doc_name, chunks in self.document_chunks.items():\n",
    "            print(f\"\\nDocument: {doc_name}\")\n",
    "            print(f\"Number of chunks: {len(chunks)}\")\n",
    "            if chunks:\n",
    "                avg_chunk_length = sum(len(self.tokenizer.tokenize(chunk)) \n",
    "                                     for chunk in chunks) / len(chunks)\n",
    "                print(f\"Average chunk length: {avg_chunk_length:.2f} tokens\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Found 3 markdown files to process\n",
      "INFO:__main__:Processing AI_ACT\\AI_ACT-with-image-refs.md\n",
      "INFO:docling.document_converter:Going to convert document batch...\n",
      "INFO:docling.pipeline.base_pipeline:Processing document AI_ACT-with-image-refs.md\n",
      "INFO:docling.document_converter:Finished converting document AI_ACT-with-image-refs.md in 293.09 sec.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8230 > 8192). Running this sequence through the model will result in indexing errors\n",
      "INFO:__main__:Successfully processed AI_ACT-with-image-refs.md - Generated 152 chunks\n",
      "INFO:__main__:Processing Cybersecurity_California_Privacy\\Cybersecurity_California_Privacy-with-image-refs.md\n",
      "INFO:docling.document_converter:Going to convert document batch...\n",
      "INFO:docling.pipeline.base_pipeline:Processing document Cybersecurity_California_Privacy-with-image-refs.md\n",
      "INFO:docling.document_converter:Finished converting document Cybersecurity_California_Privacy-with-image-refs.md in 17.14 sec.\n",
      "INFO:__main__:Successfully processed Cybersecurity_California_Privacy-with-image-refs.md - Generated 41 chunks\n",
      "INFO:__main__:Processing GDPR\\GDPR-with-image-refs.md\n",
      "INFO:docling.document_converter:Going to convert document batch...\n",
      "INFO:docling.pipeline.base_pipeline:Processing document GDPR-with-image-refs.md\n",
      "INFO:docling.document_converter:Finished converting document GDPR-with-image-refs.md in 188.16 sec.\n",
      "INFO:__main__:Successfully processed GDPR-with-image-refs.md - Generated 122 chunks\n",
      "INFO:__main__:Completed processing all documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document Processing Statistics:\n",
      "------------------------------\n",
      "\n",
      "Document: AI_ACT-with-image-refs\n",
      "Number of chunks: 152\n",
      "Average chunk length: 1133.82 tokens\n",
      "\n",
      "Document: Cybersecurity_California_Privacy-with-image-refs\n",
      "Number of chunks: 41\n",
      "Average chunk length: 266.54 tokens\n",
      "\n",
      "Document: GDPR-with-image-refs\n",
      "Number of chunks: 122\n",
      "Average chunk length: 938.01 tokens\n"
     ]
    }
   ],
   "source": [
    "doc_chunker = DocumentChunker()\n",
    "\n",
    "# Process all documents\n",
    "document_chunks = doc_chunker.process_directory()\n",
    "\n",
    "# Print statistics\n",
    "doc_chunker.get_document_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 315 chunks to document_chunks.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Prepare list to store all chunks with their metadata\n",
    "chunks_data = []\n",
    "\n",
    "# Loop through the document_chunks dictionary\n",
    "for doc_name, chunks in document_chunks.items():\n",
    "    # Process each chunk in the document\n",
    "    for i, chunk_content in enumerate(chunks):\n",
    "        chunk_data = {\n",
    "            \"document_name\": doc_name,\n",
    "            \"chunk_id\": f\"{doc_name}_chunk_{i}\",\n",
    "            \"chunk_content\": chunk_content\n",
    "        }\n",
    "        chunks_data.append(chunk_data)\n",
    "\n",
    "# Save to JSON file\n",
    "output_path = \"document_chunks.json\"\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(chunks_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved {len(chunks_data)} chunks to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded chunks for 3 documents\n"
     ]
    }
   ],
   "source": [
    "# If chunks are already generated, start here\n",
    "# Load and restructure the chunks data\n",
    "with open(\"document_chunks.json\", 'r', encoding='utf-8') as f:\n",
    "    chunks_list = json.load(f)\n",
    "\n",
    "# Convert the flat list structure back to document_chunks dictionary\n",
    "document_chunks = {}\n",
    "for chunk in chunks_list:\n",
    "    doc_name = chunk['document_name']\n",
    "    if doc_name not in document_chunks:\n",
    "        document_chunks[doc_name] = []\n",
    "    document_chunks[doc_name].append(chunk['chunk_content'])\n",
    "\n",
    "print(f\"Loaded chunks for {len(document_chunks)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To verify all chunks are loaded correctly\n",
    "# len(document_chunks['GDPR-with-image-refs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_document_chunks(chunks_data: List[dict]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Format chunks from JSON data into strings organized by document.\n",
    "    \n",
    "    Args:\n",
    "        chunks_data: List of dictionaries containing chunk information from document_chunks.json\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping document names to their formatted content string\n",
    "    \"\"\"\n",
    "    formatted_docs = {}\n",
    "    \n",
    "    # Group chunks by document\n",
    "    for chunk in chunks_data:\n",
    "        doc_name = chunk['document_name']\n",
    "        \n",
    "        if doc_name not in formatted_docs:\n",
    "            formatted_docs[doc_name] = f\"{doc_name}:\\n\\n\"\n",
    "            \n",
    "        formatted_docs[doc_name] += \"----x----\\n\"\n",
    "        formatted_docs[doc_name] += f\"chunk_id: {chunk['chunk_id']}\\n\"\n",
    "        formatted_docs[doc_name] += f\"chunk_content: {chunk['chunk_content']}\\n\\n\"\n",
    "    \n",
    "    return formatted_docs\n",
    "\n",
    "# Load chunks from JSON\n",
    "with open(\"document_chunks.json\", 'r', encoding='utf-8') as f:\n",
    "    chunks_data = json.load(f)\n",
    "\n",
    "# Generate formatted documents\n",
    "formatted_docs = format_document_chunks(chunks_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"question\": \"What is the purpose of the AI Act?\", \"answer\": \"The purpose of the AI Act is to improve the functioning of the internal market by laying down a uniform legal framework for the development, placing on the market, putting into service, and use of artificial intelligence systems in the Union.\", \"difficulty\": \"medium\", \"chunk_ids\": [\"AI_ACT-with-image-refs_chunk_3\"]}, {\"question\": \"When did the European Parliament and Council adopt the AI Act?\", \"answer\": \"13 June 2024\", \"difficulty\": \"easy\", \"chunk_ids\": [\"AI_ACT-with-image-refs_chunk_1\", \"AI_ACT-with-image-refs_chunk_130\"]}, {\"question\": \"What does the AI Act lay down?\", \"answer\": \"The AI Act lays down harmonized rules for AI systems, prohibitions of certain AI practices, requirements for high-risk AI systems, transparency rules, rules for general-purpose AI models, rules on market monitoring and governance, and measures to support innovation.\", \"difficulty\": \"medium\", \"chunk_ids\": [\"AI_ACT-with-image-refs_chunk_12\"]}, {\"question\": \"What is an \\'AI system\\'?\", \"answer\": \"A machine-based system designed to operate with varying levels of autonomy, may exhibit adaptiveness after deployment, and for explicit or implicit objectives, infers how to generate outputs influencing physical or virtual environments.\", \"difficulty\": \"hard\", \"chunk_ids\": [\"AI_ACT-with-image-refs_chunk_14\"]}, {\"question\": \"What are some prohibited AI practices?\", \"answer\": \"Some prohibited practices include manipulative or exploitative AI systems causing harm, social scoring leading to detrimental treatment, real-time remote biometric identification in public for law enforcement (with exceptions), and creating facial recognition databases via untargeted scraping.\", \"difficulty\": \"hard\", \"chunk_ids\": [\"AI_ACT-with-image-refs_chunk_17\"]}, {\"question\": \"What are some of the criteria for high-risk AI systems?\", \"answer\": \"High-risk AI systems are those intended to be used as safety components of products requiring third-party conformity assessments, and systems listed in Annex III that pose a significant risk of harm to health, safety, or fundamental rights.\", \"difficulty\": \"hard\", \"chunk_ids\": [\"AI_ACT-with-image-refs_chunk_20\"]}, {\"question\": \"What are some obligations of providers of high-risk AI systems?\", \"answer\": \"Providers must ensure compliance with requirements, affix CE marking, establish quality management and post-market monitoring systems, maintain technical documentation, and cooperate with authorities.\", \"difficulty\": \"hard\", \"chunk_ids\": [\"AI_ACT-with-image-refs_chunk_30\"]}, {\"question\": \"What is the role of the AI Office?\", \"answer\": \"The AI Office develops Union expertise and capabilities in AI and contributes to implementing, monitoring, and supervising Union law on AI.\", \"difficulty\": \"medium\", \"chunk_ids\": [\"AI_ACT-with-image-refs_chunk_79\"]}, {\"question\": \"What are the rights of affected persons regarding AI decisions?\", \"answer\": \"Affected persons have the right to obtain explanations for decisions based on high-risk AI systems that produce legal effects or significantly affect them.\", \"difficulty\": \"medium\", \"chunk_ids\": [\"AI_ACT-with-image-refs_chunk_102\"]}, {\"question\": \"When does the AI Act apply from?\", \"answer\": \"The AI Act applies from 2 August 2026, with some provisions, such as prohibitions and general provisions, applying from 2 February 2025.\", \"difficulty\": \"medium\", \"chunk_ids\": [\"AI_ACT-with-image-refs_chunk_130\"]}]'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate eval set for one doc to see results\n",
    "# generate_questions(formatted_docs['AI_ACT-with-image-refs'],10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating questions for AI_ACT-with-image-refs...\n",
      "Generating questions for Cybersecurity_California_Privacy-with-image-refs...\n",
      "Generating questions for GDPR-with-image-refs...\n"
     ]
    }
   ],
   "source": [
    "# Generate eval sets for each document\n",
    "eval_sets = {}\n",
    "for doc_id, formatted_content in formatted_docs.items():\n",
    "    print(f\"Generating questions for {doc_id}...\")\n",
    "    eval_sets[doc_id] = generate_questions(formatted_content,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 176 questions to evaluation_sets.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Parse the eval sets and add document information\n",
    "parsed_eval_sets = []\n",
    "\n",
    "for doc_id, eval_set in eval_sets.items():\n",
    "    # Convert string response to Python list of dictionaries\n",
    "    questions = json.loads(eval_set)\n",
    "    \n",
    "    # Add document information to each question\n",
    "    for question in questions:\n",
    "        question['document'] = doc_id\n",
    "        parsed_eval_sets.append(question)\n",
    "\n",
    "# Save to JSON file\n",
    "output_path = \"evaluation_sets.json\"\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(parsed_eval_sets, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved {len(parsed_eval_sets)} questions to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the eval sets when needed\n",
    "with open(\"evaluation_sets.json\", 'r', encoding='utf-8') as f:\n",
    "    eval_sets = json.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_case_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
