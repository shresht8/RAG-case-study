{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG System\n",
    "Now that the data pre-processing, indexing and evaluation for retrieval is complete the next step is to put it all together and create the RAG system which works end to end. This notebook will include the following:\n",
    "1. Read chunks from the directory of the current run (experiment).\n",
    "2. Create index with the chunks and the chunk ids\n",
    "3. Link the retriever and LLM together to create an end to end pipeline where the user asks questions and receives an answer from the LLM which includes the answer as well as the sources for the answer\n",
    "4. Input and output validation and guardrails to prevent LLM from hallucinating, leaking PII etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shres\\anaconda3\\envs\\rag_case_study\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field, field_validator, ValidationInfo\n",
    "from typing import Optional, Dict, Any, List, Annotated\n",
    "from dataclasses import dataclass\n",
    "import instructor\n",
    "from instructor import openai_moderation\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "client = instructor.from_openai(OpenAI(api_key=OPENAI_API_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a retriever class\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "from pylate import indexes, models, retrieve\n",
    "\n",
    "class Retriever:\n",
    "    def __init__(self, experiment_number: str):\n",
    "        \"\"\"Initialize the Retriever with experiment number.\n",
    "        \n",
    "        Args:\n",
    "            experiment_number (str): The experiment number (e.g., '001')\n",
    "        \"\"\"\n",
    "        self.experiment_dir = Path(f\"Experiments/{experiment_number}\")\n",
    "        self.model = models.ColBERT(\n",
    "            model_name_or_path=\"shresht8/modernBERT_text_similarity_finetune\"\n",
    "        )\n",
    "        self.index = indexes.Voyager(\n",
    "            index_folder=\"pylate-index\",\n",
    "            index_name=\"index\",\n",
    "            override=True\n",
    "        )\n",
    "        self.retriever = None\n",
    "        self.chunks_data = None\n",
    "        \n",
    "    def read_chunks(self) -> List[Dict]:\n",
    "        \"\"\"Read document chunks from the experiment directory.\"\"\"\n",
    "        chunks_path = self.experiment_dir / \"document_chunks.json\"\n",
    "        with open(chunks_path, 'r', encoding='utf-8') as f:\n",
    "            self.chunks_data = json.load(f)\n",
    "        return self.chunks_data\n",
    "    \n",
    "    def create_index(self):\n",
    "        \"\"\"Create index from chunks and initialize retriever.\"\"\"\n",
    "        if self.chunks_data is None:\n",
    "            self.read_chunks()\n",
    "            \n",
    "        # Prepare lists for indexing\n",
    "        all_chunks = []\n",
    "        chunk_ids = []\n",
    "        \n",
    "        # Extract chunks and their IDs\n",
    "        for chunk in self.chunks_data:\n",
    "            all_chunks.append(chunk['chunk_content'])\n",
    "            chunk_ids.append(chunk['chunk_id'])\n",
    "            \n",
    "        # Encode all chunks\n",
    "        documents_embeddings = self.model.encode(\n",
    "            all_chunks,\n",
    "            batch_size=32,\n",
    "            is_query=False,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        \n",
    "        # Add documents to index\n",
    "        self.index.add_documents(\n",
    "            documents_ids=chunk_ids,\n",
    "            documents_embeddings=documents_embeddings\n",
    "        )\n",
    "        \n",
    "        # Initialize retriever\n",
    "        self.retriever = retrieve.ColBERT(index=self.index)\n",
    "        \n",
    "    def get_relevant_chunks(self, query: str, k: int = 3) -> List[Dict]:\n",
    "        \"\"\"Retrieve relevant chunks for a given query.\n",
    "        \n",
    "        Args:\n",
    "            query (str): The search query\n",
    "            k (int): Number of chunks to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            List[Dict]: List of relevant chunks with their metadata\n",
    "        \"\"\"\n",
    "        if self.retriever is None:\n",
    "            raise ValueError(\"Index not created. Call create_index() first.\")\n",
    "            \n",
    "        # Encode the query\n",
    "        query_embeddings = self.model.encode(\n",
    "            [query],\n",
    "            batch_size=32,\n",
    "            is_query=True,\n",
    "            show_progress_bar=False\n",
    "        )\n",
    "        \n",
    "        # Get top k retrievals\n",
    "        scores = self.retriever.retrieve(\n",
    "            queries_embeddings=query_embeddings,\n",
    "            k=k\n",
    "        )\n",
    "        \n",
    "        # Get retrieved chunk IDs\n",
    "        retrieved_chunks = scores[0]  # First (and only) query results\n",
    "        retrieved_chunk_ids = [chunk['id'] for chunk in retrieved_chunks]\n",
    "        \n",
    "        # Map chunk IDs to full chunk data\n",
    "        chunk_map = {chunk['chunk_id']: chunk for chunk in self.chunks_data}\n",
    "        relevant_chunks = [chunk_map[chunk_id] for chunk_id in retrieved_chunk_ids]\n",
    "        \n",
    "        return relevant_chunks\n",
    "    \n",
    "    def format_chunks_to_context(self, chunks: List[Dict]) -> str:\n",
    "        \"\"\"Format retrieved chunks into a single context string.\n",
    "        \n",
    "        Args:\n",
    "            chunks (List[Dict]): List of chunk dictionaries\n",
    "            \n",
    "        Returns:\n",
    "            str: Formatted context string with source information\n",
    "        \"\"\"\n",
    "        formatted_chunks = []\n",
    "        for chunk in chunks:\n",
    "            chunk_text = (\n",
    "                f\"Source: {chunk['document_name']}\\n\"\n",
    "                f\"Content: {chunk['chunk_content']}\\n\"\n",
    "            )\n",
    "            formatted_chunks.append(chunk_text)\n",
    "            \n",
    "        return \"\\n\".join(formatted_chunks)\n",
    "    \n",
    "    def create_prompt(self, query: str, system_prompt: str, k: int = 3) -> Tuple[List[Dict], Dict[str, str]]:\n",
    "        \"\"\"Create a formatted prompt for the OpenAI API with retrieved context and a context dictionary.\n",
    "        \n",
    "        Args:\n",
    "            query (str): User's question.\n",
    "            system_prompt (str): System prompt for the LLM.\n",
    "            k (int): Number of chunks to retrieve.\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[List[Dict], Dict[str, str]]:\n",
    "                - A list of formatted messages for the OpenAI API.\n",
    "                - A dictionary mapping chunk ids to chunk content.\n",
    "        \"\"\"\n",
    "        # Get relevant chunks\n",
    "        relevant_chunks = self.get_relevant_chunks(query, k=k)\n",
    "        \n",
    "        # Format chunks into context text for messages\n",
    "        context_text = self.format_chunks_to_context(relevant_chunks)\n",
    "        \n",
    "        # Create a dictionary with chunk ids as keys and chunk content as values\n",
    "        context_dict = {chunk['chunk_id']: chunk['chunk_content'] for chunk in relevant_chunks}\n",
    "        \n",
    "        # Create messages array for OpenAI API\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Context:\\n{context_text}\\n\\nQuestion: {query}\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        return messages, context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyLate model loaded successfully.\n",
      "Encoding documents (bs=32): 100%|██████████| 10/10 [02:32<00:00, 15.24s/it]\n",
      "Adding documents to the index (bs=2000): 100%|██████████| 1/1 [00:08<00:00,  8.83s/it]\n"
     ]
    }
   ],
   "source": [
    "# Creating the index\n",
    "retriever = Retriever(experiment_number=\"001\")\n",
    "retriever.create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerWithCitation(BaseModel):\n",
    "    \"\"\"Validates and structures the final response. Answers are provided with citation to ensure that the response to the\n",
    "    user query is grounded in context provided by the user, preventing harmful responses and maximizing accuracy.\"\"\"\n",
    "    is_relevant: bool = Field(\n",
    "        description='Whether the query asked by the user is relevant to the provided context. If not relevant, return False.'\n",
    "    )\n",
    "    answer: Annotated[\n",
    "        str, \n",
    "        Field(\n",
    "            description='Final answer to user. Must be a response that is relevant to the user query if relevant information is available. Otherwise, the assistant cannot help user.'\n",
    "        ),\n",
    "        openai_moderation(client=client)\n",
    "    ] = Field(...)\n",
    "    \n",
    "    citation: Optional[Dict[str, str]] = Field(\n",
    "        None,\n",
    "        description=\"Citation extracted from the provided context. A dictionary mapping chunk ids to their corresponding chunk content.\"\n",
    "        \"The chunk content can be part of the content of the relevant chunk or can be the entire content of the relevant chunk.\"\n",
    "        \"You must output all the relevant chunks. If the query is not relevant, this must be None.\"\n",
    "    )\n",
    "\n",
    "    @field_validator('is_relevant', 'answer', 'citation')\n",
    "    def validate_response(cls, v, info: ValidationInfo):\n",
    "        if info.field_name == 'answer':\n",
    "            is_relevant = info.data.get('is_relevant')\n",
    "            if not is_relevant and v != \"I cannot help with that\":\n",
    "                raise ValueError(\"Answer must be 'I cannot help with that' if the query is not relevant.\")\n",
    "        if info.field_name == 'citation':\n",
    "            is_relevant = info.data.get('is_relevant')\n",
    "            if not is_relevant and v is not None:\n",
    "                raise ValueError(\"Citation must be None if the query is not relevant.\")\n",
    "            if is_relevant and v is None:\n",
    "                raise ValueError(\"Citation must be provided as a dictionary if the query is relevant.\")\n",
    "        return v\n",
    "\n",
    "    @field_validator('citation')\n",
    "    def validate_citation_contains_expected_ids(cls, v, info: ValidationInfo):\n",
    "        \"\"\"\n",
    "        Checks that the output citation dictionary contains the expected chunk ids.\n",
    "        The expected chunk ids should be passed through info.context under the key \"relevant_chunk_ids\".\n",
    "        \"\"\"\n",
    "        expected_chunk_ids = info.context.get(\"relevant_chunk_ids\", []) if info.context else []\n",
    "        if v is not None:\n",
    "            missing_ids = [chunk_id for chunk_id in expected_chunk_ids if chunk_id not in v]\n",
    "            if missing_ids:\n",
    "                raise ValueError(f\"The citation dictionary is missing the following expected chunk ids: {missing_ids}\")\n",
    "        return v\n",
    "\n",
    "# Define system prompt\n",
    "# system_prompt = \"You are a helpful assistant. Answer the question based on the provided context only. If you cannot find the answer in the context, say so.\"\n",
    "\n",
    "# # Create formatted prompt\n",
    "# query = \"What are the requirements for AI systems?\"\n",
    "# messages = retriever.create_prompt(\n",
    "#     query=query,\n",
    "#     system_prompt=system_prompt,\n",
    "#     k=10\n",
    "# )\n",
    "\n",
    "# # Use with OpenAI API\n",
    "# response = client.chat.completions.create(\n",
    "#     response_model=AnswerWithCitation,\n",
    "#     model=\"o1-2024-12-17\",\n",
    "#     messages=messages,\n",
    "#     max_retries=3\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMResponse:\n",
    "    def __init__(\n",
    "            self, \n",
    "            openai_api_key: str,\n",
    "            model: str = 'o3-mini', \n",
    "            max_retries: int = 3, \n",
    "            system_prompt_str: str = \"You are a helpful assistant. Answer the question based on the provided context only. If you cannot find the answer in the context, say so.\"):\n",
    "        \n",
    "        self.OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "        self.client = instructor.from_openai(OpenAI(api_key=self.OPENAI_API_KEY))\n",
    "        self.model = model\n",
    "        self.max_retries = max_retries\n",
    "        self.system_prompt_str = system_prompt_str\n",
    "\n",
    "    def generate_response(self, messages: list[dict], context: dict):\n",
    "        \"\"\"\n",
    "        Generate a response using the chat completion API, and pass additional context to the response model.\n",
    "\n",
    "        Args:\n",
    "            messages (list[dict]): List of message dictionaries for the API.\n",
    "            context (dict): Context dictionary containing relevant chunk information (e.g., {'relevant_chunk_ids': [...]})\n",
    "            \n",
    "        Returns:\n",
    "            AnswerWithCitation: The validated response model that includes the answer and citation.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                response_model=AnswerWithCitation,\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "                max_retries=self.max_retries,\n",
    "                context=context\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating response: {e}\")\n",
    "            return None\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.98s/it]\n"
     ]
    }
   ],
   "source": [
    "# 1. Get a query input from the user\n",
    "from prompts import system_prompt_reply_bot\n",
    "query = 'What is the AI Acts objective?'\n",
    "\n",
    "# 2. Retrieve the relevant documents and generate the prompt & context\n",
    "messages, context_dict = retriever.create_prompt(\n",
    "    query=query,\n",
    "    system_prompt=system_prompt_reply_bot,\n",
    "    k=10  # Adjust the number of chunks to retrieve if needed\n",
    ")\n",
    "\n",
    "# Build the context for the LLMResponse; it expects the key \"relevant_chunk_ids\" to validate the citation dictionary.\n",
    "context = {\"relevant_chunk_ids\": list(context_dict.keys())}\n",
    "\n",
    "# 3. Create an instance of LLMResponse and generate the final LLM response.\n",
    "llm_response_handler = LLMResponse(openai_api_key=OPENAI_API_KEY)\n",
    "response = llm_response_handler.generate_response(messages=messages, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "The objective of the AI Act is to establish a harmonized legal framework across the European Union that both improves the functioning of the internal market and promotes the adoption of human‐centric and trustworthy artificial intelligence (AI). In doing so, it aims to ensure a high level of protection for health, safety, and fundamental rights—including democracy, the rule of law, and environmental protection—while also fostering innovation and supporting free cross‑border circulation of AI-based goods and services.\n",
      "\n",
      "Citations:\n",
      "AI_ACT-with-image-refs_chunk_73: The purpose of this Regulation is to improve the functioning of the internal market and promote the uptake of human-centric and trustworthy artificial intelligence (AI), while ensuring a high level of protection of health, safety, fundamental rights enshrined in the Charter, including democracy, the rule of law and environmental protection, against the harmful effects of AI systems in the Union and supporting innovation.\n",
      "AI_ACT-with-image-refs_chunk_11: This Regulation lays down harmonised rules for the placing on the market, the putting into service, and the use of AI systems in the Union, thereby enhancing legal certainty and supporting innovation.\n",
      "AI_ACT-with-image-refs_chunk_17: The objective is also to establish clear requirements for high‐risk AI systems and general‑purpose AI models, ensuring that they do not undermine fundamental rights or public interests.\n",
      "AI_ACT-with-image-refs_chunk_3: By creating these unified rules, the Regulation helps avoid market fragmentation and contributes to a level playing field across the Union.\n",
      "AI_ACT-with-image-refs_chunk_14: The Regulation aims to protect public interests—health, safety and fundamental rights—while boosting innovation and the uptake of AI across various sectors.\n",
      "AI_ACT-with-image-refs_chunk_21: It ensures that AI systems are developed and used in line with Union values, supporting both economic growth and the protection of citizens.\n",
      "AI_ACT-with-image-refs_chunk_128: The framework set by the Regulation provides for the safe development, deployment, and monitoring of AI systems, thereby fostering trust and accountability in digital technologies.\n",
      "AI_ACT-with-image-refs_chunk_12: The overall goal is to serve as a foundation for trustworthy AI that not only safeguards fundamental rights but also encourages innovation and free movement within the digital single market.\n",
      "AI_ACT-with-image-refs_chunk_71: It specifically addresses and mitigates the risks associated with high‐risk AI systems to ensure that the benefits of AI are realized without compromising public welfare.\n",
      "AI_ACT-with-image-refs_chunk_84: In summary, the AI Act is intended to balance innovation with robust safeguards, ensuring that AI systems contribute positively to society while protecting citizens’ rights.\n"
     ]
    }
   ],
   "source": [
    "# 4. Print the final answer and its citations\n",
    "if response:\n",
    "    print(\"Answer:\")\n",
    "    print(response.answer)\n",
    "    print(\"\\nCitations:\")\n",
    "    for chunk_id, content in response.citation.items():\n",
    "        print(f\"{chunk_id}: {content}\")\n",
    "else:\n",
    "    print(\"No valid response was generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Import your classes (adjust the import paths as needed)\n",
    "# from rag_system_final import Retriever, LLMResponse\n",
    "\n",
    "def generate_eval_responses(retriever, experiment_number: str, evaluation_file: str, output_file: str):\n",
    "    \"\"\"\n",
    "    Generate LLM responses for an evaluation set and write them to a new JSON file.\n",
    "    \n",
    "    The evaluation file should be a JSON list of the form:\n",
    "    [\n",
    "      {\n",
    "        \"question\": \"What is the AI Act's objective?\",\n",
    "        \"answer\": \"Expected answer so far...\",\n",
    "        \"difficulty\": \"easy\",\n",
    "        \"chunk_ids\": [ list of chunk ids ],\n",
    "        \"document\": \"document_name\"\n",
    "      },\n",
    "      ...\n",
    "    ]\n",
    "    \n",
    "    The output file will add/update fields:\n",
    "      - llm_response: final answer from the LLM response (as a string)\n",
    "      - is_relevant: boolean value from the LLM response\n",
    "      - citation: dict mapping chunk ids to their content (str -> str)\n",
    "    \n",
    "    Args:\n",
    "        experiment_number (str): experiment identifier (e.g. \"001\")\n",
    "        evaluation_file (str): path to the evaluation JSON file\n",
    "        output_file (str): path to output the new JSON file with LLM responses\n",
    "    \"\"\"\n",
    "    # Load evaluation set\n",
    "    with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
    "        eval_set = json.load(f)\n",
    "    \n",
    "    # Instantiate the retriever (ensure that the index is created/load as needed)\n",
    "    # retriever = Retriever(experiment_number=experiment_number)\n",
    "    # Optional: if you need to create or load your index, do it here\n",
    "    # retriever.create_index()\n",
    "\n",
    "    # Define the system prompt (can also be a property of LLMResponse(system_prompt_str))\n",
    "    system_prompt = system_prompt_reply_bot\n",
    "    \n",
    "    llm_response_handler = LLMResponse(openai_api_key=OPENAI_API_KEY)\n",
    "    \n",
    "    # Process each evaluation query from the evaluation set\n",
    "    for record in eval_set:\n",
    "        question = record.get(\"question\")\n",
    "        print(f\"Processing question: {question}\")\n",
    "        \n",
    "        # Retrieve the relevant document chunks and create prompt messages\n",
    "        messages, context_dict = retriever.create_prompt(\n",
    "            query=question,\n",
    "            system_prompt=system_prompt,\n",
    "            k=10  # Adjust k (number of chunks) as needed\n",
    "        )\n",
    "        \n",
    "        # Build the context dictionary for reference validation\n",
    "        context = {\"relevant_chunk_ids\": list(context_dict.keys())}\n",
    "        \n",
    "        # Generate LLM response using our LLM response handler, passing the context\n",
    "        response_model = llm_response_handler.generate_response(messages=messages, context=context)\n",
    "        \n",
    "        if response_model:\n",
    "            # Map the response fields to the evaluation record's extra fields\n",
    "            record['llm_response'] = response_model.answer\n",
    "            record['is_relevant'] = response_model.is_relevant\n",
    "            record['citation'] = response_model.citation\n",
    "        else:\n",
    "            # If there was an error generating a response\n",
    "            record['llm_response'] = None\n",
    "            record['is_relevant'] = None\n",
    "            record['citation'] = None\n",
    "    \n",
    "    # Save the updated evaluation set to a new JSON file\n",
    "    with open(output_file, 'w', encoding='utf-8') as out_f:\n",
    "        json.dump(eval_set, out_f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"LLM responses have been written to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What is the AI Act's objective?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: When will AI Act be applicable?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What does \"AI System\" mean?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What does \"putting into service\" mean regarding an AI system?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: Who is considered a \"provider\"?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What is \"informed consent\" in testing?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What is a \"deep fake\"?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What's the definition of \"widespread infringement\"?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What does \"critical infrastructure\" mean?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: Who is responsible for ensuring AI literacy?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: CCPA effective date?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: Which entities must comply with CCPA?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: Who is considered a 'Consumer' under CCPA?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:03<00:00,  3.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What constitutes 'Personal Information' under CCPA?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What is 'selling' Personal Information under CCPA?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What does GDPR stand for?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:03<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: When was GDPR adopted?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What is main objective of GDPR?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What is a data subject?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What does 'processing' mean under GDPR?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:03<00:00,  3.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What is pseudonymisation?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What constitutes a \"filing system\"?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:03<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: Who is a 'controller' under GDPR?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:03<00:00,  3.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: Define \"processor\" in GDPR context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What does data concerning health include?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:03<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What are \"biometric data\" under GDPR?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: How is \"main establishment\" defined for a controller?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: How is data breach defined?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents (bs=50): 100%|██████████| 1/1 [00:03<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM responses have been written to Experiments\\001\\llm_responses_eval_set.json\n"
     ]
    }
   ],
   "source": [
    "experiment_number = \"001\"\n",
    "evaluation_file = os.path.join(\"Experiments\", experiment_number, \"evaluation_sets.json\")\n",
    "output_file = os.path.join(\"Experiments\", experiment_number, \"llm_responses_eval_set.json\")\n",
    "# Creating the index. Uncomment if index has not already been created\n",
    "# retriever = Retriever(experiment_number=\"001\")\n",
    "# retriever.create_index()\n",
    "generate_eval_responses(retriever, experiment_number, evaluation_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_case_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
